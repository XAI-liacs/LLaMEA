{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLaMEA Minimal Example\n",
    "\n",
    "This notebook shows a simple usage of LLaMEA to automatically generate and refine a Python-based optimization algorithm for a toy evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import os\n",
    "import numpy as np\n",
    "from llamea import LLaMEA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Define an evaluation function for LLaMEA\n",
    "\n",
    "- The function must accept a \"solution\" argument, which contains code, a name, etc.\n",
    "- You parse solution.solution (the raw code), dynamically load it, and run it on your problem(s).\n",
    "- You then set_scores() to record how well it did.\n",
    "\n",
    "We'll define a simple example with a 1D quadratic function: f(x) = (x - 2)^2\n",
    "We'll ask the solution code to search for the minimum x in [-5, 5].\n",
    "We'll then return a score based on how close x is to 2. The closer, the higher the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import textwrap\n",
    "import math\n",
    "\n",
    "# We implement an exception to stop algorithms that try a too large budget (to prevent infinite loops).\n",
    "class OverBudgetException(Exception):\n",
    "    \"\"\"The algorithm tried to do more evaluations than allowed.\"\"\"\n",
    "    pass\n",
    "\n",
    "def evaluate_simple(solution, explogger=None):\n",
    "    code_str = solution.solution  # The Python code the LLM generated\n",
    "    alg_name = solution.name\n",
    "\n",
    "    # We define our 1D search space: x in [-5, 5], budget=100\n",
    "    # We'll create a small function that the generated code should optimize.\n",
    "    def f(x):\n",
    "        # We only allow so many function calls\n",
    "        if f.call_count >= 100:\n",
    "            raise OverBudgetException(\"Budget exceeded.\")\n",
    "        f.call_count += 1\n",
    "        return (x - 2.0)**2\n",
    "    \n",
    "    f.call_count = 0\n",
    "    \n",
    "    # Dynamically run the generated code\n",
    "    # The code is expected to define a class named alg_name, with __init__(budget, dim) and __call__(f).\n",
    "    # We'll create a safe execution context to run it.\n",
    "    safe_globals = {\n",
    "        \"OverBudgetException\": OverBudgetException,\n",
    "        \"math\": math,\n",
    "        \"np\": np,\n",
    "    }\n",
    "    local_env = {}\n",
    "    try:\n",
    "        exec(code_str, safe_globals, local_env)\n",
    "    except Exception as e:\n",
    "        # If there's an error in code, set the score to 0\n",
    "        solution.set_scores(0, feedback=f\"Runtime/Syntax error: {e}\")\n",
    "        return solution\n",
    "    \n",
    "    # Instantiate the class with budget=100, dim=1\n",
    "    try:\n",
    "        AlgorithmClass = local_env[alg_name]\n",
    "        algo = AlgorithmClass(budget=100, dim=1)\n",
    "    except Exception as e:\n",
    "        solution.set_scores(0, feedback=f\"Instantiation error: {e}\")\n",
    "        return solution\n",
    "\n",
    "    # Now run the algorithm\n",
    "    best_f = math.inf\n",
    "    try:\n",
    "        best_f, best_x = algo(f)\n",
    "    except OverBudgetException:\n",
    "        # If over budget, we penalize heavily\n",
    "        best_f = 9999\n",
    "\n",
    "    # We'll convert it to a \"score\" where smaller f is better => we do `score = 1/(1 + best_f)`\n",
    "    # so that 0 => 1/1 => 1, big f => near 0\n",
    "    # Note: LLaMEA is optimizing by default! (bigger is better)\n",
    "    score = 1.0 / (1.0 + best_f)\n",
    "    \n",
    "    # Provide feedback\n",
    "    feedback_str = f\"Algorithm {alg_name} got score={score:.4f} (bigger is better).\"\n",
    "    \n",
    "    # Save the score to the solution object\n",
    "    solution.set_scores(score, feedback_str)\n",
    "    return solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Create and run the LLaMEA search\n",
    "\n",
    "We define a small prompt. The LLM will see how we want it to write code (like a class, with __call__).\n",
    "Then we let LLaMEA iterate a few times, generating and refining solutions.\n",
    "\n",
    "If you haven't already, set your OpenAI or other API key in your environment variables, e.g.,\n",
    "`export OPENAI_API_KEY=\"...\"` or `export GEMINI_API_KEY=\"....\"`\n",
    "\n",
    "You can also use Gemini in most countries for free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:48:48 INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-03 13:48:48 WARNING Message contained no code block\n",
      "2025-03-03 13:48:48 INFO Started evolutionary loop, best so far: -inf\n",
      "2025-03-03 13:49:00 INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-03 13:49:00 INFO Generation 2, best so far: 0.0001\n",
      "2025-03-03 13:49:12 INFO HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-03 13:49:12 INFO Generation 3, best so far: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp-03-03_134845-LLaMEA-gpt-4o-my-llamea-example/log.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neocortex/.cache/pypoetry/virtualenvs/llamea-84rNYHzd-py3.10/lib/python3.10/site-packages/networkx/algorithms/assortativity/correlation.py:302: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return float((xy * (M - ab)).sum() / np.sqrt(vara * varb))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best found solution: Optimize, Score=0.0001\n",
      "Generated code:\n",
      "import numpy as np\n",
      "\n",
      "class Optimize:\n",
      "    def __init__(self, budget, dim):\n",
      "        self.budget = budget\n",
      "        self.dim = dim\n",
      "        self.bounds = (-5, 5)\n",
      "        self.num_particles = 30\n",
      "        self.inertia = 0.5\n",
      "        self.cognitive = 1.5\n",
      "        self.social = 1.5\n",
      "\n",
      "    def __call__(self, func):\n",
      "        # Initialize particles\n",
      "        particles = np.random.uniform(self.bounds[0], self.bounds[1], (self.num_particles, self.dim))\n",
      "        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n",
      "        personal_best_positions = particles.copy()\n",
      "        personal_best_scores = np.full(self.num_particles, float('inf'))\n",
      "        \n",
      "        # Global best\n",
      "        global_best_score = float('inf')\n",
      "        global_best_position = np.zeros(self.dim)\n",
      "        \n",
      "        # Optimization loop\n",
      "        for _ in range(self.budget):\n",
      "            # Evaluate current scores\n",
      "            scores = np.apply_along_axis(func, 1, particles)\n",
      "            for i, score in enumerate(scores):\n",
      "                if score < personal_best_scores[i]:\n",
      "                    personal_best_scores[i] = score\n",
      "                    personal_best_positions[i] = particles[i]\n",
      "                if score < global_best_score:\n",
      "                    global_best_score = score\n",
      "                    global_best_position = particles[i]\n",
      "                    \n",
      "            # Update velocities and positions\n",
      "            r1, r2 = np.random.rand(2)\n",
      "            velocities = (self.inertia * velocities +\n",
      "                          self.cognitive * r1 * (personal_best_positions - particles) + \n",
      "                          self.social * r2 * (global_best_position - particles))\n",
      "            particles = particles + velocities\n",
      "            \n",
      "            # Enforce bounds\n",
      "            particles = np.clip(particles, *self.bounds)\n",
      "        \n",
      "        return global_best_score, global_best_position\n",
      "Additional feedback: Algorithm Optimize got score=0.0001 (bigger is better).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neocortex/.cache/pypoetry/virtualenvs/llamea-84rNYHzd-py3.10/lib/python3.10/site-packages/networkx/algorithms/assortativity/correlation.py:302: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return float((xy * (M - ab)).sum() / np.sqrt(vara * varb))\n",
      "/home/neocortex/.cache/pypoetry/virtualenvs/llamea-84rNYHzd-py3.10/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:479: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "/home/neocortex/.cache/pypoetry/virtualenvs/llamea-84rNYHzd-py3.10/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n"
     ]
    }
   ],
   "source": [
    "role_prompt = \"You are an AI that generates Python optimization code.\"\n",
    "\n",
    "task_prompt = textwrap.dedent(\"\"\"\\\n",
    "Create a Python class named Optimize, with __init__(self, budget, dim), \n",
    "and a __call__(self, func) method that tries to find x in [-5, 5] that minimizes func(x).\n",
    "The function should return the tuple best_f, best_x (value best found and the location).\n",
    "Implement an efficient algorithm for this task. \n",
    "\"\"\")\n",
    "\n",
    "# We'll use a small number of iterations for demonstration\n",
    "es = LLaMEA(\n",
    "    f=evaluate_simple,\n",
    "    n_parents=1, \n",
    "    n_offspring=1,\n",
    "    role_prompt=role_prompt,\n",
    "    task_prompt=task_prompt,\n",
    "    experiment_name=\"my-llamea-example\",\n",
    "    elitism=True,\n",
    "    model=\"gpt-4o\",  # or e.g. 'gpt-4-turbo'\n",
    "    api_key=\"*******\",           # Set to your actual key or use environment variable\n",
    "    budget=3                # Try 3 iterations for a quick demo\n",
    ")\n",
    "\n",
    "best_solution = es.run()\n",
    "print(f\"Best found solution: {best_solution.name}, Score={best_solution.fitness:.4f}\")\n",
    "print(f\"Generated code:\\n{best_solution.solution}\")\n",
    "print(f\"Additional feedback: {best_solution.feedback}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamea-kernel",
   "language": "python",
   "name": "llamea-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
