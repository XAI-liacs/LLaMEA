{"id": "f0ade619-373b-4ce5-b57b-0df5556863af", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n                \n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "The algorithm combines evolutionary strategies with a dynamic neighborhood search and adaptive mutation rates to optimize black box functions efficiently within a limited budget. ", "configspace": "", "generation": 0, "fitness": 0.7836192321423315, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.784 with standard deviation 0.019. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7636897638872712, 0.8095061384255449, 0.7776617941141787], "final_y": [0.1668096957898395, 0.15251371306501538, 0.16058116366622233]}, "mutation_prompt": null}
{"id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "A novel \"Adaptive Swarm-Based Harmony Search\" algorithm, combining swarm intelligence and harmony memory with an adaptive mechanism to efficiently explore and exploit the search space.", "configspace": "", "generation": 0, "fitness": 0.8655223689731014, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.012. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8692009423284914, 0.8775919289835774, 0.8497742356072355], "final_y": [0.12267238654076784, 0.1229470183642607, 0.1326007409151001]}, "mutation_prompt": null}
{"id": "f5450004-ecda-4702-8d86-1e272e5f7f19", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            # Dynamic pitch adjustment\n            pitch_adjustment_rate = 0.1 + 0.2 * (1 - eval_count / self.budget)\n            if np.random.rand() < pitch_adjustment_rate: \n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        # Memory size adaptation\n        if np.std(fitness_memory) > 0.1 and len(memory) < 20:\n            memory = np.vstack([memory, np.random.uniform(memory.min(axis=0), memory.max(axis=0), (5, self.dim))])\n        variation = np.std(memory, axis=0)\n        for harmony in memory:\n            harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "A refined \"Adaptive Swarm-Based Harmony Search\" enhances exploration by introducing dynamic pitch adjustment and memory size adaptation.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'eval_count' is not defined\").", "error": "NameError(\"name 'eval_count' is not defined\")", "parent_id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "metadata": {}, "mutation_prompt": null}
{"id": "3dbf7763-557a-44cc-911f-d8656fe989eb", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory, eval_count)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.15:  # Pitch adjustment (increased probability)\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory, eval_count):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation\n        if eval_count < self.budget // 2:  # Dynamically adjust memory size\n            memory = np.vstack((memory, np.random.uniform(lb, ub, (2, self.dim))))", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhance exploration by adjusting pitch alteration probability and adaptively controlling memory size.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'lb' is not defined\").", "error": "NameError(\"name 'lb' is not defined\")", "parent_id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "metadata": {}, "mutation_prompt": null}
{"id": "30d0108e-e627-4dcc-be78-12408ededfa5", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.15:  # Pitch adjustment (increased probability)\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced the pitch adjustment mechanism by increasing its probability to intensify exploration, aiming to improve convergence speed and solution quality.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'eval_count' is not defined\").", "error": "NameError(\"name 'eval_count' is not defined\")", "parent_id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "metadata": {}, "mutation_prompt": null}
{"id": "da89c76d-4d52-4aae-ac49-ba7f6623d501", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n                \n            # Adjust memory size based on budget utilization\n            if eval_count % (self.budget // 5) == 0:\n                memory_size = min(memory_size + 1, self.budget // 10)\n                harmony_memory = harmony_memory[:memory_size]\n                fitness_memory = fitness_memory[:memory_size]\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced Adaptive Swarm-Based Harmony Search with Dynamic Memory Size Adjustment to Improve Exploration-Exploitation Balance.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'eval_count' is not defined\").", "error": "NameError(\"name 'eval_count' is not defined\")", "parent_id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "metadata": {}, "mutation_prompt": null}
{"id": "cfc21c95-ab1c-4b32-86a4-19fb42198fca", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = max(10, self.budget // 100)  # Dynamically adjust memory size\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduced a dynamic memory size mechanism that adjusts according to the evaluation budget to enhance exploration and exploitation balance in Adaptive Swarm Harmony Search.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'eval_count' is not defined\").", "error": "NameError(\"name 'eval_count' is not defined\")", "parent_id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "metadata": {}, "mutation_prompt": null}
{"id": "b90b580c-226b-491e-8cf5-c35a325186b5", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.15:  # Pitch adjustment\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Improved Adaptive Swarm-Based Harmony Search with enhanced pitch adjustment for better exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'eval_count' is not defined\").", "error": "NameError(\"name 'eval_count' is not defined\")", "parent_id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "metadata": {}, "mutation_prompt": null}
{"id": "126f5e16-70ce-434b-9fab-1f63d4ec5750", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.5 * np.std(population, axis=0).mean()\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "The algorithm refines its exploration strategy by dynamically adjusting the mutation scale based on the diversity of the population to improve exploration efficiency within the limited budget.", "configspace": "", "generation": 1, "fitness": 0.8187358148702071, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.819 with standard deviation 0.005. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "f0ade619-373b-4ce5-b57b-0df5556863af", "metadata": {"aucs": [0.8147609667303543, 0.8250763909941619, 0.8163700868861048], "final_y": [0.14658846012434457, 0.14636288490039484, 0.15098562694937456]}, "mutation_prompt": null}
{"id": "c9a23473-ef8a-484a-b00a-18a0be574173", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            diversity = np.std(population, axis=0).mean()  # Calculate population diversity\n            mutate_scale = 0.1 * (1 + diversity)  # Adjust mutation scale based on diversity\n\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n                \n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "The algorithm enhances convergence by introducing a diversity-controlled mutation rate that adapts based on the population's diversity.", "configspace": "", "generation": 1, "fitness": 0.8008560277066566, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.065. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "f0ade619-373b-4ce5-b57b-0df5556863af", "metadata": {"aucs": [0.7120212422436318, 0.8267304128501365, 0.8638164280262016], "final_y": [0.189780293854248, 0.14475334637236914, 0.13278130086705953]}, "mutation_prompt": null}
{"id": "1d1d45f9-90f3-47bf-8640-822035e5761c", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Adaptive neighborhood size\n            neighborhood_size = max(3, int(population_size * (1 - evaluations / self.budget)))\n\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n                \n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Introduce adaptive neighborhood size to balance exploration and exploitation during optimization.", "configspace": "", "generation": 1, "fitness": 0.7833720459882669, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.042. And the mean value of best solutions found was 0.162 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "f0ade619-373b-4ce5-b57b-0df5556863af", "metadata": {"aucs": [0.7274834342147442, 0.8298682421991092, 0.7927644615509475], "final_y": [0.1835461990087517, 0.14545462402704734, 0.15601858069677932]}, "mutation_prompt": null}
{"id": "bc27461b-7747-49a5-beb4-a647dc7efa06", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents using tournament selection\n            tournament_size = 3\n            tournament_indices = np.random.choice(range(population_size), size=(neighborhood_size, tournament_size))\n            parents_idx = [indices[np.argmin(fitness[indices])] for indices in tournament_indices]\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n                \n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Improved neighborhood selection by using tournament selection to enhance exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.781517589735781, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.062. And the mean value of best solutions found was 0.162 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "f0ade619-373b-4ce5-b57b-0df5556863af", "metadata": {"aucs": [0.7030443057629967, 0.7873131537347625, 0.8541953097095835], "final_y": [0.1927312689605183, 0.15816864512404538, 0.13407733403385558]}, "mutation_prompt": null}
{"id": "2e174419-aca1-489f-8ec4-31d5989875ee", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub):\n        harmony = np.empty(self.dim)\n        scale_factor = 0.1 * (1 - eval_count / self.budget)  # Dynamic pitch adjustment scale\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * scale_factor\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced pitch adjustment by introducing a dynamic scale factor to improve exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'eval_count' is not defined\").", "error": "NameError(\"name 'eval_count' is not defined\")", "parent_id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "metadata": {}, "mutation_prompt": null}
{"id": "e49ea7e6-3e97-4930-934f-8ef099ac3c68", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n        \n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.15:  # Pitch adjustment (changed value)\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "A refined \"Adaptive Swarm-Based Harmony Search\" algorithm that adjusts pitch adjustment probability for improved exploration and exploitation.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'eval_count' is not defined\").", "error": "NameError(\"name 'eval_count' is not defined\")", "parent_id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "metadata": {}, "mutation_prompt": null}
{"id": "9f2a2bc0-16a4-4a17-bb80-fdf4e206ec1b", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.6:  # Reduced Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.2:  # Increased Pitch adjustment frequency\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhance exploitation by decreasing memory consideration probability and increasing pitch adjustment frequency.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'eval_count' is not defined\").", "error": "NameError(\"name 'eval_count' is not defined\")", "parent_id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "metadata": {}, "mutation_prompt": null}
{"id": "e5e40c01-70fd-44c2-9344-c3acc205c18f", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i] * 0.9)  # Use non-uniform distribution\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced Adaptive Swarm-Based Harmony Search with improved harmony generation strategy using a non-uniform distribution for better exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'eval_count' is not defined\").", "error": "NameError(\"name 'eval_count' is not defined\")", "parent_id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "metadata": {}, "mutation_prompt": null}
{"id": "a8cfa488-00c4-436c-afbe-db3f4729886f", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity and fitness variance\n                mutate_scale = 0.1 + 0.5 * np.std(population, axis=0).mean() + 0.1 * np.std(fitness)\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "A novel metaheuristic algorithm that refines exploration by dynamically adjusting mutation scale using both population diversity and fitness variance for better convergence.", "configspace": "", "generation": 2, "fitness": 0.8217714955127664, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.032. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "126f5e16-70ce-434b-9fab-1f63d4ec5750", "metadata": {"aucs": [0.7978988663133058, 0.7997261493188118, 0.8676894709061816], "final_y": [0.15410025894031298, 0.15271260296694777, 0.12807220080068504]}, "mutation_prompt": null}
{"id": "6265b02b-40ec-4996-8c5b-6076605d7d3d", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity and success rate\n                success_rate = np.sum(fitness < np.mean(fitness)) / population_size\n                mutate_scale = 0.1 + 0.5 * np.std(population, axis=0).mean() * success_rate\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Enhancing solution retention by updating the mutation scale based on both success rate and population diversity.", "configspace": "", "generation": 2, "fitness": 0.8278707459792773, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.050. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "126f5e16-70ce-434b-9fab-1f63d4ec5750", "metadata": {"aucs": [0.7569309080847216, 0.8666818681119278, 0.8599994617411824], "final_y": [0.17024478015007216, 0.12953200171793466, 0.13009890057025497]}, "mutation_prompt": null}
{"id": "482fffcf-2813-42e9-820e-5211cdb9cb6f", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on fitness variance\n                mutate_scale = 0.1 + 0.5 * np.std(fitness)\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "The algorithm enhances exploration by adjusting the mutation scale based on the variance of fitness scores, improving adaptation to diverse landscapes.", "configspace": "", "generation": 2, "fitness": 0.7773005402175587, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.777 with standard deviation 0.064. And the mean value of best solutions found was 0.163 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "126f5e16-70ce-434b-9fab-1f63d4ec5750", "metadata": {"aucs": [0.6989836241934317, 0.8565641433477538, 0.7763538531114909], "final_y": [0.19506490509063146, 0.1348845634305994, 0.15876500704533492]}, "mutation_prompt": null}
{"id": "ddb571b1-7b7c-4edb-a02d-425093a251a7", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                diversity = np.mean(np.linalg.norm(population - population.mean(axis=0), axis=1))\n                mutate_scale = 0.1 + 0.5 * np.std(population, axis=0).mean() + 0.1 * diversity\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "\"Diversity-Enhanced Adaptive Mutation Optimizer\" enhances exploration by incorporating a diversity metric into the mutation mechanism, improving adaptability to complex landscapes.", "configspace": "", "generation": 2, "fitness": 0.8313406089674044, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.831 with standard deviation 0.024. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "126f5e16-70ce-434b-9fab-1f63d4ec5750", "metadata": {"aucs": [0.8635264019927099, 0.8071316737094018, 0.8233637512001014], "final_y": [0.11899074315029767, 0.15046655633945583, 0.14369936733822852]}, "mutation_prompt": null}
{"id": "7c2f8f6c-0c6e-4962-a04a-e1196d3760e3", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity and convergence speed\n                mutate_scale = 0.1 + 0.5 * np.std(population, axis=0).mean() * (1 - (evaluations / self.budget))\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Enhance mutation scale adjustment by incorporating an adaptive factor tied to convergence speed.", "configspace": "", "generation": 2, "fitness": 0.8567343493502074, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.017. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "126f5e16-70ce-434b-9fab-1f63d4ec5750", "metadata": {"aucs": [0.8412674078562861, 0.8803128606834518, 0.8486227795108845], "final_y": [0.1392776273509878, 0.1232658080369351, 0.1341944390563402]}, "mutation_prompt": null}
{"id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.4 * np.std(population, axis=0).mean()  # Reduced scale adjustment\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Enhanced mutation strategy using adaptive crossover to intensify the search around the best individuals while maintaining diversity.", "configspace": "", "generation": 2, "fitness": 0.8715808506215997, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.039. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "126f5e16-70ce-434b-9fab-1f63d4ec5750", "metadata": {"aucs": [0.8880981423753982, 0.9084567026421715, 0.8181877068472297], "final_y": [0.12557930813508789, 0.11736123853547642, 0.14793706889998492]}, "mutation_prompt": null}
{"id": "1b3caf47-08a6-4c58-8fe3-a99070280c06", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.uniform(-1, 1, self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.normal(0, mutate_scale, self.dim)\n\n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Enhanced mutation adjustment based on both diversity and distance from best\n                mutate_scale = 0.1 + 0.3 * np.std(population, axis=0).mean() + 0.1 * np.linalg.norm(child - best_parent)\n                \n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Improved diversity maintenance and adaptive mutation in the population to enhance convergence.", "configspace": "", "generation": 3, "fitness": 0.8421707270424172, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.012. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.8337069858398894, 0.858981004463021, 0.8338241908243413], "final_y": [0.1386407654095626, 0.13486115111834407, 0.14194830729080143]}, "mutation_prompt": null}
{"id": "3bfd7210-b273-42c5-8d94-b4a0a72d59dc", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = min(20, max(5, self.budget // 50))\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, eval_count)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, eval_count):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.15:  # Adjusted Pitch adjustment probability\n                adjustment_scale = (ub[i] - lb[i]) * (0.5 + 0.5 * (eval_count / self.budget))\n                adjustment = adjustment_scale * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Improved Adaptive Swarm-Based Harmony Search with dynamic memory size and enhanced pitch adjustment for better exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8595603247106639, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.007. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "metadata": {"aucs": [0.8513739368666386, 0.8579747673578471, 0.8693322699075062], "final_y": [0.12649828094581084, 0.13072924735913682, 0.11978169492082924]}, "mutation_prompt": null}
{"id": "4cb7d64e-e9da-473c-b610-786b92aa8b45", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.25 * np.std(population, axis=0).mean()  # Refined scale adjustment\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Refined mutation scale adjustment for enhanced convergence accuracy.", "configspace": "", "generation": 3, "fitness": 0.8186643781535775, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.819 with standard deviation 0.017. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.8072579060379181, 0.8420718401460242, 0.8066633882767904], "final_y": [0.14903979014390145, 0.13952978400279048, 0.14839852148214494]}, "mutation_prompt": null}
{"id": "f5c2fd66-8947-46c9-8702-a1dc81dd09be", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n                memory_size = max(5, int(memory_size * 0.9))  # Dynamically adjust memory size\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduced a dynamic memory size adjustment based on the convergence speed to improve search efficiency.", "configspace": "", "generation": 3, "fitness": 0.8637774428376916, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.024. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "metadata": {"aucs": [0.8588517656751, 0.8957432850449828, 0.8367372777929918], "final_y": [0.12570411720533758, 0.12063465052647626, 0.13600715047851952]}, "mutation_prompt": null}
{"id": "744632f8-36ef-432e-bb6f-5400614ae380", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.15:  # Pitch adjustment (increased probability)\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * 0.7  # Reduced adjustment scale\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Refined Adaptive Swarm-Based Harmony Search with enhanced pitch adjustment mechanism for improved convergence.", "configspace": "", "generation": 3, "fitness": 0.862915761052637, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.009. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "metadata": {"aucs": [0.8737435546329211, 0.8637430782530571, 0.8512606502719328], "final_y": [0.12043139205322329, 0.12664670380273302, 0.12592439538674427]}, "mutation_prompt": null}
{"id": "316cf1d5-831f-4cf4-890e-dce3dfe25c42", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Dynamic neighborhood selection\n            elite_idx = np.argsort(fitness)[:3]  # Select top 3 elites\n            elite_population = population[elite_idx]\n            \n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size - 3, replace=False)\n            parents = np.vstack((elite_population, population[parents_idx]))\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.4 * np.std(population, axis=0).mean()  # Reduced scale adjustment\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Incorporating a dynamic neighborhood strategy with elite selection to enhance exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.7891259416048078, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.017. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.8123013742973046, 0.7844106641281325, 0.7706657863889859], "final_y": [0.1502245602060691, 0.15880377703858417, 0.16101550056896385]}, "mutation_prompt": null}
{"id": "55251704-53e6-4aa0-980f-f6af8d5b8bdd", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.2:  # Pitch adjustment (changed probability from 0.1 to 0.2)\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced diversity by increasing pitch adjustment probability, improving exploration and convergence speed.", "configspace": "", "generation": 3, "fitness": 0.8546393555106553, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.003. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "metadata": {"aucs": [0.8565353470648926, 0.8506516113357072, 0.8567311081313662], "final_y": [0.12740920766260355, 0.12350491035827127, 0.13108698182125444]}, "mutation_prompt": null}
{"id": "522c65d2-2e78-4103-9255-39905b1b06b9", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.normal(0, mutate_scale, self.dim) * (best_parent - other)\n                else:\n                    child = best_parent + np.random.normal(0, mutate_scale, self.dim)\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.5 * np.std(population, axis=0).mean()  # Increased scale adjustment\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Enhanced adaptive mutation scaling with dynamic neighborhood adjustment to improve convergence rate and solution quality.", "configspace": "", "generation": 3, "fitness": 0.8461312417313054, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.047. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.7954887554685605, 0.8338222909977376, 0.9090826787276182], "final_y": [0.15280829885026137, 0.14304587665806556, 0.11864943141299389]}, "mutation_prompt": null}
{"id": "ef879959-df5f-40a3-bff4-31f71305e101", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, eval_count)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.dynamic_adjustment(harmony_memory, fitness_memory, eval_count)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, eval_count):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7 - eval_count/self.budget*0.2:  # Modified consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.15:  # Modified pitch adjustment\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n        \n        return harmony\n\n    def dynamic_adjustment(self, memory, fitness_memory, eval_count):\n        diversity = np.std(memory, axis=0)\n        speed = np.std(fitness_memory)\n        if speed > 0.05:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1 + eval_count/self.budget*0.05, size=self.dim) * diversity", "name": "AdaptiveSwarmHarmonySearch", "description": "Improved exploration-exploitation balance by integrating dynamic mutation based on convergence speed and diversity assessment.", "configspace": "", "generation": 3, "fitness": 0.8508545270917619, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.008. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "metadata": {"aucs": [0.8454398799727414, 0.845398261382055, 0.8617254399204894], "final_y": [0.13610151200537823, 0.12907313105905882, 0.12944949985955045]}, "mutation_prompt": null}
{"id": "5ed118cc-0b86-4230-bca3-97776a504467", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other) * 0.5 \n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.4 * np.std(population, axis=0).mean()  # Reduced scale adjustment\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Refined crossover strategy by incorporating a weighted contribution from the best individual in the population.", "configspace": "", "generation": 3, "fitness": 0.810798656893685, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.029. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.7885385142426181, 0.8522276806384773, 0.79162977579996], "final_y": [0.15819311134475533, 0.13668169769920246, 0.15106545304574537]}, "mutation_prompt": null}
{"id": "f87b09dd-08ba-4011-8bb7-9677e67fc679", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment = (ub[i] - lb[i]) * np.random.uniform(-0.3, 0.3)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced swarm-based harmony search through improved pitch adjustment for refined exploration.", "configspace": "", "generation": 4, "fitness": 0.8701334796335244, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.018. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "metadata": {"aucs": [0.8952626710350279, 0.8590417413825993, 0.8560960264829462], "final_y": [0.11925862658613695, 0.12983779778614102, 0.1278197384527654]}, "mutation_prompt": null}
{"id": "cf1203bd-a544-4b39-b794-913bac14c970", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.4 * np.std(population, axis=0).mean()  # Reduced scale adjustment\n                crossover_rate = 0.5 + 0.5 * np.std(population, axis=0).mean()  # New line added for dynamic crossover adjustment\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Enhanced adaptive mutation strategy by dynamically adjusting crossover rate based on population diversity.", "configspace": "", "generation": 4, "fitness": 0.8298039357444544, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.098. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.036.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.6921863381265311, 0.8803681772536557, 0.9168572918531768], "final_y": [0.19475109754689335, 0.1271383179014859, 0.1132434697773641]}, "mutation_prompt": null}
{"id": "246c8da0-6a94-4262-bc0d-ad09160bf3ef", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony)  # Modified line\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony):  # Modified line\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            harmony[i] += 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Improved harmony generation by introducing directional bias towards best solutions for enhanced convergence.", "configspace": "", "generation": 4, "fitness": 0.8778176160697483, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.016. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "metadata": {"aucs": [0.9002333722006544, 0.8699530253131735, 0.8632664506954167], "final_y": [0.11380652004858027, 0.12273734177031381, 0.130137480962353]}, "mutation_prompt": null}
{"id": "2b139399-cc97-4c74-9a63-3ce415dede01", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n\n            # Adjust crossover rate dynamically based on population diversity\n            crossover_rate = 0.5 + 0.2 * np.std(population, axis=0).mean()\n\n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.4 * np.std(population, axis=0).mean()  # Reduced scale adjustment\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Enhanced mutation strategy using adaptive crossover to intensify the search around the best individuals while maintaining diversity, with a dynamic crossover rate based on population diversity.", "configspace": "", "generation": 4, "fitness": 0.8239842699509644, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.096. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.035.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.6905341849040401, 0.8668921065936341, 0.9145265183552189], "final_y": [0.19538927914089554, 0.1314734426067088, 0.11455482089840308]}, "mutation_prompt": null}
{"id": "ca57cf15-c9bf-4be5-a2fe-6eb6f8e499c3", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity and convergence\n                mutate_scale = 0.1 + 0.4 * np.std(population, axis=0).mean() * (1.0 - np.min(fitness)/np.mean(fitness))\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Improved adaptive mutation strategy by incorporating population convergence information to enhance search efficiency.", "configspace": "", "generation": 4, "fitness": 0.825933190517095, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.081. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.7153505575574182, 0.8564165591475719, 0.906032454846295], "final_y": [0.18748875895895878, 0.1332697003968889, 0.11857638680053495]}, "mutation_prompt": null}
{"id": "8da81c0b-e4ff-4203-8db0-470cae6861e2", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation\n\n        # Dynamic memory size adjustment\n        if np.random.rand() < 0.3:\n            memory_size = max(5, len(memory) + (1 if np.random.rand() < 0.5 else -1))\n            memory = np.resize(memory, (memory_size, self.dim))\n            fitness_memory = fitness_memory[:memory_size]", "name": "AdaptiveSwarmHarmonySearch", "description": "Refined Adaptive Swarm-Based Harmony Search with dynamic memory size adjustment for improved exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.8677870120170829, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.004. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f1c04b05-2721-4143-aa79-4e3c91c55767", "metadata": {"aucs": [0.8645352756934814, 0.8727561661245937, 0.8660695942331735], "final_y": [0.1266001533110378, 0.12507333408247323, 0.12058611761376681]}, "mutation_prompt": null}
{"id": "fa441241-c944-4a71-8f36-b1d0b8395765", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on offspring fitness\n                if child_fitness < fitness.mean():\n                    mutate_scale *= 1.05\n                else:\n                    mutate_scale *= 0.95\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Incorporating adaptive mutation scaling based on offspring fitness to effectively balance exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.8387557541230569, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.036. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.8323407252364441, 0.7984293342713915, 0.885497202861335], "final_y": [0.13576250690948455, 0.14605336565433003, 0.12101128259247851]}, "mutation_prompt": null}
{"id": "a0ce9259-c68a-499e-af7c-f164d596a994", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n\n            # Crossover and Mutation\n            for i in range(population_size):\n                adaptive_crossover_rate = crossover_rate * (1 - fitness[best_parent_idx] / np.max(fitness))  # Adjust crossover rate\n                if np.random.rand() < adaptive_crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.4 * np.std(population, axis=0).mean()  # Reduced scale adjustment\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Incorporating an adaptive crossover rate to further enhance exploitation around high-performing solutions while keeping diversity.", "configspace": "", "generation": 4, "fitness": 0.8491601584846195, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.036. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.8018778595848294, 0.8572775710279679, 0.8883250448410612], "final_y": [0.15050228639723062, 0.13083215648040458, 0.11794179311522279]}, "mutation_prompt": null}
{"id": "c73dfded-821c-466a-8429-d6690c606058", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        memory = np.copy(population[np.argmin(fitness)])  # Store best individual\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n\n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = memory if np.random.rand() < 0.3 else parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.3 * np.std(population, axis=0).mean()  # Further reduced scale adjustment\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n                if child_fitness < np.min(fitness):  # Update memory with best so far\n                    memory = np.copy(child)\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Integrate dynamic crossover adaptation and memory with enhanced selection pressure for focused exploration.", "configspace": "", "generation": 4, "fitness": 0.8333796421220642, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.081. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.7238042626184072, 0.8607644147821565, 0.915570248965629], "final_y": [0.1765302206299263, 0.13188613345389977, 0.11632014857800377]}, "mutation_prompt": null}
{"id": "57f4919a-6263-457d-b159-3091d0b564df", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.uniform(-0.5, 0.5, self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.4 * np.std(population, axis=0).mean()  # Reduced scale adjustment\n                crossover_rate = 0.5 + 0.3 * np.std(population, axis=0).mean()  # Dynamic crossover rate adjustment\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Enhanced mutation and dynamic crossover rate adjustment to improve exploration around promising individuals.", "configspace": "", "generation": 4, "fitness": 0.8260325677635145, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.094. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.6961855004385398, 0.8651641994222742, 0.9167480034297294], "final_y": [0.19189283973532956, 0.132912239069212, 0.11374054006573353]}, "mutation_prompt": null}
{"id": "be5a0454-7072-4965-ac57-1715fa7a764d", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                improvement_rate = (best_fitness - np.min(fitness_memory)) / best_fitness  # New line\n                harmony[i] = np.clip(harmony[i] + adjustment * (1 + improvement_rate), lb[i], ub[i)\n\n            harmony[i] += 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced pitch adjustment by incorporating dynamic scaling based on fitness improvement rate for refined exploration.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: SyntaxError(\"closing parenthesis ')' does not match opening parenthesis '['\", ('<string>', 49, 99, '                harmony[i] = np.clip(harmony[i] + adjustment * (1 + improvement_rate), lb[i], ub[i)', 49, 99)).", "error": "SyntaxError(\"closing parenthesis ')' does not match opening parenthesis '['\", ('<string>', 49, 99, '                harmony[i] = np.clip(harmony[i] + adjustment * (1 + improvement_rate), lb[i], ub[i)', 49, 99))", "parent_id": "246c8da0-6a94-4262-bc0d-ad09160bf3ef", "metadata": {}, "mutation_prompt": null}
{"id": "2156c213-d913-473f-8433-4686dacca358", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Adaptive neighborhood size based on diversity\n            neighborhood_size = max(2, int(5 * np.std(population, axis=0).mean()))  # Changed line\n            \n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.4 * np.std(population, axis=0).mean()  # Reduced scale adjustment\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Introduce adaptive neighborhood strategy to enhance exploration by dynamically adjusting neighborhood size based on population diversity.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {}, "mutation_prompt": null}
{"id": "3fdd74ba-3a7a-4f39-994e-016ac47fbfb8", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Introduce adaptive mutation scaling\n                mutate_scale = 0.2 + 0.3 * np.std(population, axis=0).mean()\n\n                # Cluster-based mutation for diversity\n                cluster_center = np.mean(population, axis=0)\n                child += np.random.randn(self.dim) * 0.05 * (cluster_center - child)\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Introduce diversity by adaptive cluster-based mutation and enhanced fitness-based selection to refine convergence.", "configspace": "", "generation": 5, "fitness": 0.8226535648302753, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.016. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.801394689163661, 0.8265741985443817, 0.8399918067827833], "final_y": [0.15278615381480298, 0.1450552853953957, 0.13769676255790408]}, "mutation_prompt": null}
{"id": "895fadea-7c90-4752-be9f-70e13b0c906e", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            harmony[i] += 0.1 * (best_harmony[i] - harmony[i])  # Increased precision\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced directional adjustment towards the best harmony with increased precision for improved convergence.", "configspace": "", "generation": 5, "fitness": 0.8625244224681993, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.004. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "246c8da0-6a94-4262-bc0d-ad09160bf3ef", "metadata": {"aucs": [0.8584034197332866, 0.860479592751201, 0.8686902549201101], "final_y": [0.1247003081015815, 0.1312596904271227, 0.12915085188118058]}, "mutation_prompt": null}
{"id": "93201079-617e-43d4-ab07-cb7e13765d2f", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate_initial = 0.6\n        crossover_rate_final = 0.9\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Dynamic crossover rate\n            crossover_rate = crossover_rate_initial + (crossover_rate_final - crossover_rate_initial) * (evaluations / self.budget)\n\n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.4 * np.std(population, axis=0).mean()  # Reduced scale adjustment\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Introduced selective elitism and adaptive crossover rates to enhance exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.815764955350648, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.051. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.8459063206238819, 0.8574303315891909, 0.743958213838871], "final_y": [0.1397611257202993, 0.13556249731826964, 0.16960278991493916]}, "mutation_prompt": null}
{"id": "13729115-c86e-49f3-ac6a-bdf4b4726c6c", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                crossover_rate = 0.5 + 0.5 * np.std(fitness)  # Adaptive crossover rate based on fitness variance\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.4 * np.std(population, axis=0).mean()  # Reduced scale adjustment\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Introduced adaptive crossover rates based on fitness variance to balance exploration and exploitation dynamically.", "configspace": "", "generation": 5, "fitness": 0.8061207546973886, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.068. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.7115806957122097, 0.8380907053969673, 0.8686908629829893], "final_y": [0.19227088355983624, 0.14123192246677785, 0.12955275375529152]}, "mutation_prompt": null}
{"id": "12813d30-02bb-465d-bbdf-dba2bae5664a", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                # Dynamic crossover rate based on population diversity\n                crossover_rate = 0.5 + 0.2 * np.std(population, axis=0).mean()\n                \n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.4 * np.std(population, axis=0).mean()  # Reduced scale adjustment\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Introduce a dynamic crossover rate that adapts based on the current diversity of the population to enhance exploration and convergence. ", "configspace": "", "generation": 5, "fitness": 0.787167098910916, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.787 with standard deviation 0.022. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.8047394093647181, 0.8008396039686312, 0.7559222833993986], "final_y": [0.1500869162077304, 0.15513407501126553, 0.17051890375594525]}, "mutation_prompt": null}
{"id": "313ff6ac-a843-47ac-bd68-3d3e8dbf614f", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents using probability-based selection\n            selection_prob = fitness / fitness.sum()\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False, p=selection_prob)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.4 * np.std(population, axis=0).mean()  # Reduced scale adjustment\n\n                # Replace worst individual if the child is better, ensure elitism\n                worst_idx = np.argmax(fitness)\n                elite_idx = np.argmin(fitness)\n                if child_fitness < fitness[worst_idx] and not np.array_equal(population[elite_idx], child):\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Enhanced selection strategy by introducing elitism and probability-based parent selection to maintain high-quality solutions and diversity.", "configspace": "", "generation": 5, "fitness": 0.8048117268897877, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.059. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.7838200180004231, 0.884634903718809, 0.745980258950131], "final_y": [0.1607189334932314, 0.1251254444509602, 0.1766192604945972]}, "mutation_prompt": null}
{"id": "ca100711-a77c-44cd-925d-f13d493c9c42", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = max(10, self.budget // (10 * self.dim))  # Dynamic memory size\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony):\n        harmony = np.empty(self.dim)\n        elite_idx = np.argsort(memory[:, 0])[:3]  # Top 3 elite harmonies\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.choice(elite_idx), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += 0.1 * (best_harmony[i] - harmony[i])  # Increased directional adjustment\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduce dynamic harmony memory size and improved directional adjustment towards elite harmonies for better convergence.", "configspace": "", "generation": 5, "fitness": 0.8685179169586253, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.011. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "246c8da0-6a94-4262-bc0d-ad09160bf3ef", "metadata": {"aucs": [0.8612751692863165, 0.8598613661578005, 0.8844172154317591], "final_y": [0.12720472033998798, 0.1325488399853455, 0.12399963454544716]}, "mutation_prompt": null}
{"id": "a1c707bb-8fda-4bf9-a289-a6b3f04a720a", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.4 * np.std(population, axis=0).mean()  # Reduced scale adjustment\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                # Update the best solution found\n                if child_fitness < best_fitness:\n                    best_solution = child\n                    best_fitness = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_solution", "name": "NovelMetaheuristicOptimizer", "description": "Introduced elitism by retaining the best solution found so far, ensuring it is never overwritten by less optimal solutions.", "configspace": "", "generation": 5, "fitness": 0.8443846593306422, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.038. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.79082030083659, 0.8698575050809939, 0.8724761720743426], "final_y": [0.15777584814234236, 0.1308590753429133, 0.12823411917976446]}, "mutation_prompt": null}
{"id": "6897d16d-b264-4489-bd85-3c27f36fcffd", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, best_fitness)  # Modified line\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, best_fitness):  # Modified line\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            pitch_adjust_prob = 0.1 * (1 - (best_fitness / (np.min(fitness_memory) + 1e-9)))  # Modified line\n            if np.random.rand() < pitch_adjust_prob:  # Modified line\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            harmony[i] += 0.05 * (best_harmony[i] - harmony[i]) * (best_fitness / (np.min(fitness_memory) + 1e-9))  # Modified line\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhance convergence by dynamically adjusting directional bias and pitch adjustment probability based on solution quality.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'fitness_memory' is not defined\").", "error": "NameError(\"name 'fitness_memory' is not defined\")", "parent_id": "246c8da0-6a94-4262-bc0d-ad09160bf3ef", "metadata": {}, "mutation_prompt": null}
{"id": "135a04f5-314c-4603-b816-7488383d95f9", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n        \n        # Track the best solution found so far\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx].copy()\n        best_fitness = fitness[best_idx]\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.4 * np.std(population, axis=0).mean()\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                # Update best solution if child is better\n                if child_fitness < best_fitness:\n                    best_solution = child.copy()\n                    best_fitness = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_solution", "name": "NovelMetaheuristicOptimizer", "description": "Introducing elitism by retaining the best solution found so far to enhance convergence reliability.", "configspace": "", "generation": 6, "fitness": 0.8017343559061606, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.052. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.8693373993734556, 0.7923869361652567, 0.7434787321797696], "final_y": [0.13012604149801266, 0.1551461052204881, 0.1686233402796914]}, "mutation_prompt": null}
{"id": "a140f172-7401-4d4a-b34d-3287fe9ca04a", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n        pitch_adjustment_rate = 0.1  # Initial pitch adjustment rate\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, pitch_adjustment_rate)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n                pitch_adjustment_rate *= 0.9  # Decrease rate if improvement\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, pitch_adjustment_rate):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < pitch_adjustment_rate:  # Dynamic pitch adjustment\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            harmony[i] += 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Introducing dynamic pitch adjustment factor based on fitness improvement history to enhance exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.8826106950127764, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.883 with standard deviation 0.015. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "246c8da0-6a94-4262-bc0d-ad09160bf3ef", "metadata": {"aucs": [0.8626538702476398, 0.8973905111387604, 0.8877877036519292], "final_y": [0.12018573994703263, 0.12118234731470656, 0.119223753026657]}, "mutation_prompt": null}
{"id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget  # New line\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor)  # Modified line\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor):  # Modified line\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])  # Modified line\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced convergence by incorporating a dynamic learning factor, adapting the influence of the best solution based on iteration progression.", "configspace": "", "generation": 6, "fitness": 0.8829739441299392, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.883 with standard deviation 0.009. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "246c8da0-6a94-4262-bc0d-ad09160bf3ef", "metadata": {"aucs": [0.8729441909691897, 0.8956037484364054, 0.8803738929842224], "final_y": [0.12469779364026046, 0.11777045661467767, 0.12272361647577057]}, "mutation_prompt": null}
{"id": "7cb6ce79-59b0-4f02-b76f-cf3013324a01", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment_scale = np.std(memory[:, i]) / (ub[i] - lb[i])  # Adaptive scaling factor\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * adjustment_scale\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            harmony[i] += 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced pitch adjustment by incorporating adaptive scaling factors based on fitness variability for improved convergence.", "configspace": "", "generation": 6, "fitness": 0.8925584510752307, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.017. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "246c8da0-6a94-4262-bc0d-ad09160bf3ef", "metadata": {"aucs": [0.8708232856011329, 0.8943867318662482, 0.9124653357583109], "final_y": [0.12268007151287375, 0.12087026176631255, 0.11509110189800464]}, "mutation_prompt": null}
{"id": "67496aab-af8f-4424-ac5d-88ecd13f46ae", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                dynamic_crossover_rate = 0.9 - 0.5 * (fitness[i] - fitness.min()) / (fitness.max() - fitness.min())\n                if np.random.rand() < dynamic_crossover_rate:  # 1 line changed\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    step_size = np.random.standard_cauchy(self.dim) * mutate_scale  # 1 line changed\n                    child = best_parent + step_size  # 1 line changed\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.4 * np.std(population, axis=0).mean()\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Integrate an exploration-exploitation balance by introducing Lévy flight for mutation and incorporate a dynamic adaptive crossover rate.", "configspace": "", "generation": 6, "fitness": 0.8161046652382417, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.066. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.9068102702283118, 0.790272006017552, 0.7512317194688611], "final_y": [0.11182756498062352, 0.15635085106879942, 0.1650150282958699]}, "mutation_prompt": null}
{"id": "ee7e247f-30b3-45c3-9507-b4b44d019451", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, best_fitness)  # Modified line\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, best_fitness):  # Modified line\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            learning_rate = 0.05 if best_fitness == 0 else 0.05 * (1 - np.exp(-best_fitness))  # Adjusted line\n            harmony[i] += learning_rate * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced directional bias towards the best solution by adjusting the learning rate dynamically based on fitness improvement.", "configspace": "", "generation": 6, "fitness": 0.8770415527058387, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.005. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "246c8da0-6a94-4262-bc0d-ad09160bf3ef", "metadata": {"aucs": [0.8722899499216199, 0.8751580415751102, 0.8836766666207859], "final_y": [0.1308184211847615, 0.12184099366288526, 0.11847190260952589]}, "mutation_prompt": null}
{"id": "a81c2723-27da-49f9-96ab-80734bb17a43", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                crossover_rate = 0.5 + 0.2 * np.std(population, axis=0).mean()  # Dynamic crossover rate\n                neighborhood_size = 5 + int(np.std(fitness) * 5)  # Adaptive neighborhood size\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.4 * np.std(population, axis=0).mean()  # Reduced scale adjustment\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Introduced adaptive neighborhood size and dynamic crossover rate based on population diversity to enhance exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.785357807544493, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.025. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.7526794884872381, 0.7910646650900397, 0.8123292690562014], "final_y": [0.17332154506662634, 0.15377266872503437, 0.14563256641403866]}, "mutation_prompt": null}
{"id": "901f3695-6f9b-4a83-a7d8-25d45997f17c", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Dynamic population size adaptation\n        initial_population_size = 10\n        max_population_size = 20\n        min_population_size = 5\n        population_size = initial_population_size\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Introduce adaptive exploration-exploitation balance\n            mutate_scale = 0.1 + 0.5 * np.std(fitness) / (np.mean(fitness) + 1e-9)\n\n            for i in range(population_size):\n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Update population size dynamically\n                if evaluations % 10 == 0:\n                    if np.std(fitness) < 0.01:\n                        population_size = max(min_population_size, population_size - 1)\n                    else:\n                        population_size = min(max_population_size, population_size + 1)\n\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Introduced dynamic population resizing and adaptive exploration-exploitation balance for enhanced solution discovery.", "configspace": "", "generation": 6, "fitness": 0.8066492533185542, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.073. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.703271138449252, 0.8577941327763816, 0.8588824887300286], "final_y": [0.19372251980594757, 0.13329086488573094, 0.12824378164272388]}, "mutation_prompt": null}
{"id": "9d8fc9c3-b0c6-4791-8515-66cfb23f3295", "solution": "import numpy as np\n\nclass NovelMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10\n        mutate_scale = 0.1\n        crossover_rate = 0.7\n        neighborhood_size = 5\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            # Select parents\n            parents_idx = np.random.choice(range(population_size), size=neighborhood_size, replace=False)\n            parents = population[parents_idx]\n            best_parent_idx = np.argmin(fitness[parents_idx])\n            best_parent = parents[best_parent_idx]\n            \n            # Crossover and Mutation\n            for i in range(population_size):\n                current_best_fitness = np.min(fitness)\n                if current_best_fitness < fitness[best_parent_idx]:\n                    crossover_rate = 0.5 + (0.2 * (current_best_fitness - fitness[best_parent_idx]) / current_best_fitness)\n                \n                if np.random.rand() < crossover_rate:\n                    other = parents[np.random.randint(0, neighborhood_size)]\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale * (best_parent - other)\n                else:\n                    child = best_parent + np.random.randn(self.dim) * mutate_scale\n                \n                child = np.clip(child, lb, ub)\n\n                # Evaluate child\n                child_fitness = func(child)\n                evaluations += 1\n\n                # Adjust mutation scale dynamically based on population diversity\n                mutate_scale = 0.1 + 0.4 * np.std(population, axis=0).mean()  # Reduced scale adjustment\n\n                # Replace worst individual if the child is better\n                worst_idx = np.argmax(fitness)\n                if child_fitness < fitness[worst_idx]:\n                    population[worst_idx] = child\n                    fitness[worst_idx] = child_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "NovelMetaheuristicOptimizer", "description": "Introduce a dynamic crossover rate that adapts based on the best fitness improvement to maintain diversity and explore more efficiently.", "configspace": "", "generation": 6, "fitness": 0.7802180012547021, "feedback": "The algorithm NovelMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.780 with standard deviation 0.022. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "2f148854-7a88-4c6f-bfa4-8a69322b3f0c", "metadata": {"aucs": [0.8020300255739401, 0.7880310624113871, 0.7505929157787791], "final_y": [0.15158321953165643, 0.15614004061568942, 0.16566622504720097]}, "mutation_prompt": null}
{"id": "41350dcb-2a96-4ff2-b0b3-df0be39c0f8a", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                # Modified line for enhanced pitch adjustment\n                temperature = 1 - (eval_count / self.budget)           # Temperature-based scaling factor\n                adjustment_scale = np.std(memory[:, i]) / (ub[i] - lb[i]) * temperature\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * adjustment_scale\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            harmony[i] += 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduced an enhanced pitch adjustment mechanism that utilizes a temperature-based scaling factor for improved exploration-exploitation balance.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'eval_count' is not defined\").", "error": "NameError(\"name 'eval_count' is not defined\")", "parent_id": "7cb6ce79-59b0-4f02-b76f-cf3013324a01", "metadata": {}, "mutation_prompt": null}
{"id": "1df9eb2d-e86e-4823-abbb-b98ea3e17a22", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony):\n        harmony = np.empty(self.dim)\n        dynamic_prob = 0.5 + 0.5 * (eval_count / self.budget)  # Dynamic random selection probability\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < dynamic_prob:  # Updated pitch adjustment probability\n                adjustment_scale = np.std(memory[:, i]) / (ub[i] - lb[i])\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * adjustment_scale\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += 0.1 * (best_harmony[i] - harmony[i])  # Increased adjustment weight\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Further enhanced convergence by integrating a dynamic random selection probability and adjusting the weight towards the best harmony.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'eval_count' is not defined\").", "error": "NameError(\"name 'eval_count' is not defined\")", "parent_id": "7cb6ce79-59b0-4f02-b76f-cf3013324a01", "metadata": {}, "mutation_prompt": null}
{"id": "59aa5dc5-62fb-4953-afb6-ed93c966f99f", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment_scale = np.std(memory[:, i]) / (ub[i] - lb[i])  # Adaptive scaling factor\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * adjustment_scale\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony with dynamic adjustment\n            harmony[i] += (0.05 + 0.01 * (best_fitness - np.min(fitness_memory))) * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduced a dynamic adjustment multiplier for the directional adjustment towards the best harmony based on fitness improvement.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_fitness' is not defined\").", "error": "NameError(\"name 'best_fitness' is not defined\")", "parent_id": "7cb6ce79-59b0-4f02-b76f-cf3013324a01", "metadata": {}, "mutation_prompt": null}
{"id": "eb23ce09-264f-4089-af19-5aeab45f34a9", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = min(10, int(5 + self.budget / 1000))  # Adjusted line\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduced a dynamic memory size adjustment to continually balance exploration and exploitation.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_fitness' is not defined\").", "error": "NameError(\"name 'best_fitness' is not defined\")", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {}, "mutation_prompt": null}
{"id": "de3c5b05-9b26-451f-b89a-509cbfe3b539", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.6:  # Changed line\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.15:  # Changed line\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * 1.2  # Changed line\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.07 * (best_harmony[i] - harmony[i])  # Changed line\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.08:  # Changed line\n            for harmony in memory:\n                reinforcement = 0.05 * (fitness_memory - np.min(fitness_memory))  # Changed line\n                harmony += (np.random.normal(0, 0.1, size=self.dim) + reinforcement) * variation  # Changed line", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced exploration through stochastic harmony generation and adaptive reinforcement of promising solutions.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_fitness' is not defined\").", "error": "NameError(\"name 'best_fitness' is not defined\")", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {}, "mutation_prompt": null}
{"id": "bea59583-54bc-4067-848f-ba10f46284f9", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        temperature = 1.0  # New line\n        cooling_rate = 0.95  # New line\n\n        while eval_count < self.budget:\n            temperature *= cooling_rate  # New line\n            learning_factor = 1.0 - eval_count / self.budget\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor, temperature)  # Modified line\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor, temperature):  # Modified line\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # Introduce stochastic search component\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])\n            stochastic_adjustment = temperature * (np.random.rand() - 0.5)  # New line\n            harmony[i] = np.clip(harmony[i] + stochastic_adjustment, lb[i], ub[i])  # New line\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.05, size=self.dim) * variation  # Modified line", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced exploration by introducing a temperature-based stochastic search and refining adaptive adjustments for better convergence.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_fitness' is not defined\").", "error": "NameError(\"name 'best_fitness' is not defined\")", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {}, "mutation_prompt": null}
{"id": "3f5a7277-9401-4ffe-a4f5-71a76681bb48", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation\n            if np.std(fitness_memory) > 0.2:  # New line\n                memory = np.concatenate((memory, memory + np.random.normal(0, 0.1, size=memory.shape)), axis=0)", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduced a dynamic memory size adjustment based on fitness variability to enhance exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_fitness' is not defined\").", "error": "NameError(\"name 'best_fitness' is not defined\")", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {}, "mutation_prompt": null}
{"id": "b17c0d9e-8973-497e-a7a2-a771d4aa074b", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = np.exp(-eval_count / (self.budget / 10))  # Modified line\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Adaptive learning factor update based on exponential decay for more robust convergence.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_fitness' is not defined\").", "error": "NameError(\"name 'best_fitness' is not defined\")", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {}, "mutation_prompt": null}
{"id": "5656997f-30aa-4af0-8594-381142f4a59e", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment_scale = np.std(memory[:, i]) / (ub[i] - lb[i])  # Adaptive scaling factor\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * adjustment_scale\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            harmony[i] += 0.07 * (best_harmony[i] - harmony[i])  # Adjusted the influence factor\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Fine-tuning the influence of the best harmony in directional adjustment to refine convergence.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_fitness' is not defined\").", "error": "NameError(\"name 'best_fitness' is not defined\")", "parent_id": "7cb6ce79-59b0-4f02-b76f-cf3013324a01", "metadata": {}, "mutation_prompt": null}
{"id": "06828667-fc3f-4793-80e7-be4027add42a", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, eval_count)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, eval_count):\n        harmony = np.empty(self.dim)\n        harmony_memory_consideration_rate = 0.5 + 0.2 * np.sin(np.pi * eval_count / self.budget)  # Dynamic rate\n        for i in range(self.dim):\n            if np.random.rand() < harmony_memory_consideration_rate:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment_scale = np.std(memory[:, i]) / (ub[i] - lb[i])  # Adaptive scaling factor\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * adjustment_scale\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            harmony[i] += 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Introducing a dynamic harmony memory consideration rate to enhance exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_fitness' is not defined\").", "error": "NameError(\"name 'best_fitness' is not defined\")", "parent_id": "7cb6ce79-59b0-4f02-b76f-cf3013324a01", "metadata": {}, "mutation_prompt": null}
{"id": "99e9ebc0-ac5c-49a7-8189-5fb00b0d8412", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1 + (eval_count / self.budget) * 0.2:  # Adaptive pitch adjustment frequency\n                adjustment_scale = np.std(memory[:, i]) / (ub[i] - lb[i])  # Adaptive scaling factor\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * adjustment_scale\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            harmony[i] += 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduced adaptive pitch adjustment frequency to balance exploration and exploitation dynamically.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'eval_count' is not defined\").", "error": "NameError(\"name 'eval_count' is not defined\")", "parent_id": "7cb6ce79-59b0-4f02-b76f-cf3013324a01", "metadata": {}, "mutation_prompt": null}
{"id": "6f74eaf4-df13-4c56-a2b8-639b784f69c8", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.9:  # Increased probability for memory selection\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduced a probabilistic memory selection factor to improve exploration and escape local optima.", "configspace": "", "generation": 8, "fitness": 0.8581333410354453, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.037. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {"aucs": [0.9094222738883551, 0.8409146245403205, 0.8240631246776601], "final_y": [0.11618031130399875, 0.1415993560297799, 0.14281997042877992]}, "mutation_prompt": null}
{"id": "ca440614-c848-42a8-9f46-b5604eecebb0", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget\n            memory_prob = np.random.rand()\n            new_harmony = (self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor) \n                           if memory_prob < 0.5 else \n                           self.stochastic_harmony(harmony_memory, lb, ub, best_harmony))  # Modified line\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n    \n    def stochastic_harmony(self, memory, lb, ub, best_harmony):  # New function\n        new_harmony = np.copy(best_harmony)\n        random_index = np.random.randint(0, self.dim)\n        new_harmony[random_index] = np.random.uniform(lb[random_index], ub[random_index])\n        return new_harmony  # Modified line\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced exploration via stochastic harmony memory consideration alongside adaptive learning for robust convergence.", "configspace": "", "generation": 8, "fitness": 0.8450943879962275, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.008. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {"aucs": [0.8553793832354618, 0.845302714510786, 0.8346010662424346], "final_y": [0.12275789994649344, 0.13534658353554907, 0.1357332158938156]}, "mutation_prompt": null}
{"id": "5e790e50-bb26-41fe-bd44-6ebe6bf33203", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget\n            memory_consideration_rate = min(0.7, 0.3 + 0.4 * np.std(fitness_memory))  # Modified line\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor, memory_consideration_rate)  # Modified line\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor, memory_consideration_rate):  # Modified line\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < memory_consideration_rate:  # Modified line\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced exploration by dynamically adjusting harmony memory consideration probability based on fitness diversity.", "configspace": "", "generation": 8, "fitness": 0.8296362778874163, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.005. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {"aucs": [0.8236182198215819, 0.8303011593931875, 0.8349894544474794], "final_y": [0.12173745655525814, 0.1355219256537019, 0.13887218666621115]}, "mutation_prompt": null}
{"id": "465acb48-6cf1-407b-9ce8-4ed8eb0a968e", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment_scale = np.std(memory[:, i]) / (ub[i] - lb[i])  # Adaptive scaling factor\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * adjustment_scale\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            harmony[i] += 0.06 * (best_harmony[i] - harmony[i])  # Enhanced adjustment\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduced a minor enhancement in directional adjustment towards the best harmony to improve convergence precision.", "configspace": "", "generation": 8, "fitness": 0.8519532957337604, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.026. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "7cb6ce79-59b0-4f02-b76f-cf3013324a01", "metadata": {"aucs": [0.8873449333715345, 0.8279248226724638, 0.8405901311572828], "final_y": [0.1191648340986956, 0.13906089896153828, 0.13746414458758183]}, "mutation_prompt": null}
{"id": "176fa2d9-cb17-41ef-827b-9ec7da3e25ea", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget  # New line\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor)  # Modified line\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            harmony_memory[np.argmax(fitness_memory)] = best_harmony  # Elitism mechanism line\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor):  # Modified line\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])  # Modified line\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduce an elitism mechanism by preserving the best solution in each iteration to enhance convergence stability.", "configspace": "", "generation": 8, "fitness": 0.8383241523661705, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.018. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {"aucs": [0.863157667325488, 0.8285483180605546, 0.8232664717124689], "final_y": [0.12939040875321528, 0.13695373988521653, 0.1386494562358973]}, "mutation_prompt": null}
{"id": "a4cc44fa-a61d-49b2-8ba2-5739af783e9d", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n                # Elitism strategy\n                harmony_memory[worst_idx] = best_harmony\n                fitness_memory[worst_idx] = best_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment_scale = np.std(memory[:, i]) / (ub[i] - lb[i])  # Adaptive scaling factor\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * adjustment_scale\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            harmony[i] += 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduced an elitism strategy to replace the worst harmony with the best upon improvement, ensuring retention of superior solutions.", "configspace": "", "generation": 8, "fitness": 0.8459420486509245, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.028. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "7cb6ce79-59b0-4f02-b76f-cf3013324a01", "metadata": {"aucs": [0.8850087884155827, 0.8242209214189319, 0.8285964361182588], "final_y": [0.1180777537589559, 0.14439261309280338, 0.14144141296233836]}, "mutation_prompt": null}
{"id": "2cca34d9-bf0a-46b7-9d23-bdb2f7aaeb0f", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory, lb, ub)  # Modified line\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory, lb, ub):  # Modified line\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                local_search_factor = 0.1 * (ub - lb) * np.random.rand(self.dim)  # New line\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation + local_search_factor  # Modified line", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced convergence by utilizing a local search strategy and diversity maintenance to balance exploration and exploitation.", "configspace": "", "generation": 8, "fitness": 0.8301147259734365, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.008. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {"aucs": [0.8315636731593012, 0.8393517630986738, 0.8194287416623345], "final_y": [0.1302332679244249, 0.13296182042090066, 0.14371879820461586]}, "mutation_prompt": null}
{"id": "6cb64863-ad95-429a-8bfb-89cd258803d5", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget  # New line\n            mutation_factor = np.std(harmony_memory, axis=0)  # New line\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor, mutation_factor)  # Modified line\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor, mutation_factor):  # Modified line\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = mutation_factor[i] * (np.random.rand() - 0.5)  # Modified line\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])  # Modified line\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced exploration and exploitation balance via variability-based mutation factor adjustment.", "configspace": "", "generation": 8, "fitness": 0.8359218532870587, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.836 with standard deviation 0.022. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {"aucs": [0.8663479182490594, 0.8273056827110947, 0.8141119589010217], "final_y": [0.12786589886204835, 0.14287506794342297, 0.13577648747451243]}, "mutation_prompt": null}
{"id": "2df5d98d-3147-42bb-afb5-6721e7f495e6", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - (eval_count / self.budget) ** 2  # Modified line\n            adapt_factor = np.exp(-eval_count / self.budget)  # New line\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor, adapt_factor)  # Modified line\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor, adapt_factor):  # Modified line\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7 * adapt_factor:  # Modified line\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.15:  # Modified line\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduce adaptive mutation and dynamic exploration-exploitation balance by adjusting memory influence and harmony generation, improving solution diversity and convergence speed.", "configspace": "", "generation": 8, "fitness": 0.8287191009896128, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.016. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {"aucs": [0.8371663148556706, 0.8424216570206754, 0.8065693310924923], "final_y": [0.1299050773911229, 0.13262461148550697, 0.15075534162900428]}, "mutation_prompt": null}
{"id": "87a65dd4-1b1d-4ad7-8c54-aed833396aca", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n                if np.std(fitness_memory) < 0.05:  # Strategic memory regeneration\n                    harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment_scale = np.std(memory[:, i]) / (ub[i] - lb[i])  # Adaptive scaling factor\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * adjustment_scale\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            harmony[i] += 0.05 * (best_harmony[i] - harmony[i]) * (1 - eval_count / self.budget)\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduced strategic memory regeneration and adaptive learning rates to further enhance convergence and exploration balance.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'eval_count' is not defined\").", "error": "NameError(\"name 'eval_count' is not defined\")", "parent_id": "7cb6ce79-59b0-4f02-b76f-cf3013324a01", "metadata": {}, "mutation_prompt": null}
{"id": "c77fc84e-1408-488a-bf40-b4e35e7ff25f", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            # Probabilistic Pitch Adjustment\n            if np.random.rand() < 0.2:  # Increased likelihood of adjustment\n                adjustment_scale = (np.std(memory[:, i]) / (ub[i] - lb[i])) * (1 - (best_fitness / np.mean(fitness_memory)))\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * adjustment_scale\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            harmony[i] += 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduce a probabilistic pitch adjustment that dynamically scales based on fitness improvement to boost convergence rates.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_fitness' is not defined\").", "error": "NameError(\"name 'best_fitness' is not defined\")", "parent_id": "7cb6ce79-59b0-4f02-b76f-cf3013324a01", "metadata": {}, "mutation_prompt": null}
{"id": "e9d0535c-1c6c-436e-8d23-10acac1049be", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])\n        \n        # New code for variance-based mutation\n        if np.random.rand() < 0.2:\n            var_adj = np.std(memory, axis=0) * np.random.normal(0, 0.1, self.dim)\n            harmony = np.clip(harmony + var_adj, lb, ub)\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Fusing variance-based adaptive mutation with dynamic learning for improved exploration and convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_fitness' is not defined\").", "error": "NameError(\"name 'best_fitness' is not defined\")", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {}, "mutation_prompt": null}
{"id": "1adc161a-fb37-46e0-a3f0-96a910019f31", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n            # Probabilistic memory reshuffle\n            if np.random.rand() < 0.1:\n                self.memory_reshuffle(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                selection_probs = self.calculate_selection_probs(memory)\n                selected_idx = np.random.choice(len(memory), p=selection_probs)\n                harmony[i] = memory[selected_idx, i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment_scale = np.std(memory[:, i]) / (ub[i] - lb[i])\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * adjustment_scale\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation\n\n    def memory_reshuffle(self, memory, fitness_memory):\n        idx = np.argsort(fitness_memory)\n        top_half = memory[idx[:len(idx)//2]]\n        np.random.shuffle(top_half)\n        memory[:len(top_half)] = top_half\n\n    def calculate_selection_probs(self, memory):\n        distances = np.linalg.norm(memory - np.mean(memory, axis=0), axis=1)\n        probabilities = distances / np.sum(distances)\n        return probabilities", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced convergence by integrating a probabilistic selection strategy and strategic memory reshuffling to diversify search.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_fitness' is not defined\").", "error": "NameError(\"name 'best_fitness' is not defined\")", "parent_id": "7cb6ce79-59b0-4f02-b76f-cf3013324a01", "metadata": {}, "mutation_prompt": null}
{"id": "98693dec-291d-4bfb-a01b-3cb9476ad305", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                memory_size = max(10, int(memory_size * 0.9))  # Modified line\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation\n", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduced a dynamic memory size mechanism to enhance adaptability to varying complexity in different phases of the search process.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_fitness' is not defined\").", "error": "NameError(\"name 'best_fitness' is not defined\")", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {}, "mutation_prompt": null}
{"id": "14cb5316-4e28-4470-9bf7-c88fae8cc6c1", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n            # Inject random harmonies for diversity - New line\n            if eval_count % (self.budget // 5) == 0:  # New line\n                self.inject_random_harmonies(harmony_memory, lb, ub)  # New line\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation\n\n    def inject_random_harmonies(self, memory, lb, ub):  # New line\n        for i in range(len(memory) // 2):  # New line\n            memory[i] = np.random.uniform(lb, ub, self.dim)  # New line", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduced diversity reinforcement by periodically injecting new random harmonies and enhanced adaptive adjustment for improved exploration and convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_fitness' is not defined\").", "error": "NameError(\"name 'best_fitness' is not defined\")", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {}, "mutation_prompt": null}
{"id": "8f501780-3249-4d16-8453-8bde9910783d", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony):\n        harmony = np.empty(self.dim)\n        elite_idx = np.argsort(memory[:, 0])[:3]  # Select elites based on first dimension\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  \n                if np.random.rand() < 0.2:\n                    harmony[i] = memory[np.random.choice(elite_idx), i]  # Elite consideration\n                else:\n                    harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.15:  # Adjusted pitch adjustment rate\n                adjustment_scale = np.std(memory[:, i]) / (ub[i] - lb[i])  \n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * adjustment_scale\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced convergence by introducing elite harmony selection and improved random pitch adjustment to refine search precision and diversity.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_fitness' is not defined\").", "error": "NameError(\"name 'best_fitness' is not defined\")", "parent_id": "7cb6ce79-59b0-4f02-b76f-cf3013324a01", "metadata": {}, "mutation_prompt": null}
{"id": "c669f7b6-6fa9-4f5d-b775-308e84101be6", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.15:  # Modified line\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])\n        \n        if np.random.rand() < 0.2:  # Modified line\n            mutation_factor = np.random.uniform(-0.1, 0.1, size=self.dim)  # Modified line\n            harmony += mutation_factor  # Modified line\n            harmony = np.clip(harmony, lb, ub)  # Modified line\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Improved exploration by introducing a stochastic mutation factor and adaptive memory update to enhance diversity and convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_fitness' is not defined\").", "error": "NameError(\"name 'best_fitness' is not defined\")", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {}, "mutation_prompt": null}
{"id": "4bd61926-12ac-4759-9eb1-54635c7e9dd8", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, eval_count)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, eval_count):\n        harmony = np.empty(self.dim)\n        memory_consideration_rate = 0.5 + 0.2 * np.sin(eval_count / self.budget * np.pi)  # Dynamic adjustment\n        for i in range(self.dim):\n            if np.random.rand() < memory_consideration_rate:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment_scale = np.std(memory[:, i]) / (ub[i] - lb[i])  # Adaptive scaling factor\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * adjustment_scale\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            harmony[i] += 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Improved exploration by adjusting the balance between random selection and memory consideration dynamically over iterations.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_fitness' is not defined\").", "error": "NameError(\"name 'best_fitness' is not defined\")", "parent_id": "7cb6ce79-59b0-4f02-b76f-cf3013324a01", "metadata": {}, "mutation_prompt": null}
{"id": "bbec5e33-4e45-4d65-a930-702a6782da97", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 12  # Changed line\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget\n            mutation_probability = 0.15  # Changed line\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor, mutation_probability)  # Modified line\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor, mutation_probability):  # Modified line\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.75:  # Changed line\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < mutation_probability:  # Changed line\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.05, size=self.dim) * variation  # Changed line", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduced adaptive mutation control and diversified memory initialization to enhance exploration and convergence balancing.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_fitness' is not defined\").", "error": "NameError(\"name 'best_fitness' is not defined\")", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {}, "mutation_prompt": null}
{"id": "142ef27d-0a04-478b-b7c2-18a8db3426e6", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor):\n        harmony = np.empty(self.dim)\n        pitch_adjustment_rate = 0.1 + 0.9 * (eval_count / self.budget)  # Modified line\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < pitch_adjustment_rate:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduced a dynamic pitch adjustment rate based on iteration progression to enhance convergence rate and solution quality.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'eval_count' is not defined\").", "error": "NameError(\"name 'eval_count' is not defined\")", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {}, "mutation_prompt": null}
{"id": "2e646bd8-fa82-4517-b443-bc9b44be0964", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget\n            # Updated line: Adaptive pitch adjustment probability based on fitness improvement rate\n            adaptive_probability = 0.7 + (1.0 - np.std(fitness_memory) / best_fitness) * 0.1  \n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor, adaptive_probability)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor, adaptive_probability):  \n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < adaptive_probability:  # Modified line\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Improved convergence by adjusting the harmony generation process with adaptive probability based on fitness improvement rate.", "configspace": "", "generation": 10, "fitness": 0.8819726602980845, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.008. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {"aucs": [0.8934209502105438, 0.8767116418072913, 0.8757853888764188], "final_y": [0.11994026983436135, 0.12010379703222385, 0.12126428530947786]}, "mutation_prompt": null}
{"id": "7ecd3b2a-c99b-4bd1-b48a-e8acde228574", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget  # New line\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor)  # Modified line\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor):  # Modified line\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * 0.7  # Modified line\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])  # Modified line\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced exploration by diversifying memory updates with strategic factor adjustments, while maintaining dynamic learning. ", "configspace": "", "generation": 10, "fitness": 0.8820199171530748, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.012. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {"aucs": [0.8681672712511359, 0.8967559926311808, 0.8811364875769075], "final_y": [0.12772075689189455, 0.11981753332431888, 0.12527738565204538]}, "mutation_prompt": null}
{"id": "56f6396e-c758-49d1-8b03-b4aa7a77b40b", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment_scale = np.std(memory[:, i]) / (ub[i] - lb[i])  # Adaptive scaling factor\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * adjustment_scale\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            harmony[i] += 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation\n\n        # Elite harmony retention: Preserve a copy of the best harmony\n        elite_harmony = memory[np.argmin(fitness_memory)].copy()", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduced elite harmony retention to preserve top solutions and enhance convergence stability.", "configspace": "", "generation": 10, "fitness": 0.8771263386125905, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.003. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "7cb6ce79-59b0-4f02-b76f-cf3013324a01", "metadata": {"aucs": [0.8812456002619083, 0.8772708099693354, 0.8728626056065275], "final_y": [0.12148050897399398, 0.12337138196660424, 0.11723779772222853]}, "mutation_prompt": null}
{"id": "277cb051-adc7-4fa5-8886-ccfeea2cdd25", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor):\n        harmony = np.empty(self.dim)\n        memory_consideration_prob = 0.2 + 0.5 * np.random.rand()  # Modified line\n        for i in range(self.dim):\n            if np.random.rand() < memory_consideration_prob:  # Modified line\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Utilize stochastic selection for memory consideration probability and increase exploration by dynamic adjustment of pitch.", "configspace": "", "generation": 10, "fitness": 0.8785391209494291, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.027. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {"aucs": [0.8404583145122604, 0.9032702179760402, 0.8918888303599868], "final_y": [0.13254580650844383, 0.11563681119549984, 0.12465491539459905]}, "mutation_prompt": null}
{"id": "96e3f4f1-31b4-408a-91e7-3616f83ee80d", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10 + (self.budget // 1000)  # Adjust memory size dynamically\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment_scale = np.std(memory[:, i]) / (ub[i] - lb[i])  # Adaptive scaling factor\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * adjustment_scale\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            harmony[i] += 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduced dynamic harmony memory size adjustment to enhance adaptability and convergence.", "configspace": "", "generation": 10, "fitness": 0.8800533482266322, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.010. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "7cb6ce79-59b0-4f02-b76f-cf3013324a01", "metadata": {"aucs": [0.8674739159834762, 0.8929795908362753, 0.879706537860145], "final_y": [0.11798065207419206, 0.1160263736878846, 0.11846912937944087]}, "mutation_prompt": null}
{"id": "499ac0df-d837-4fdb-99bb-aa617ec6401e", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - (best_fitness / np.mean(fitness_memory))  # Changed line\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5)\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Introduced fitness-dependent learning factor to balance exploration and exploitation dynamically.", "configspace": "", "generation": 10, "fitness": 0.8748668153215035, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.011. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {"aucs": [0.8592924162291781, 0.885038133865021, 0.8802698958703112], "final_y": [0.12825744751245738, 0.1209265761151157, 0.1209346809029671]}, "mutation_prompt": null}
{"id": "9c4b7635-56c2-473c-a61e-a252d77a9ae3", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, eval_count)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, eval_count):\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            pitch_adjustment_prob = 0.1 + 0.4 * (eval_count / self.budget)  # Dynamically adjust pitch adjustment probability\n            if np.random.rand() < pitch_adjustment_prob:  # Pitch adjustment\n                adjustment_scale = np.std(memory[:, i]) / (ub[i] - lb[i])  # Adaptive scaling factor\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * adjustment_scale\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            harmony[i] += 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced exploration by dynamically adjusting pitch adjustment probability based on evaluation count.", "configspace": "", "generation": 10, "fitness": 0.8819992444787622, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.006. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "7cb6ce79-59b0-4f02-b76f-cf3013324a01", "metadata": {"aucs": [0.8900768043790621, 0.881372045845138, 0.8745488832120866], "final_y": [0.11839570755553408, 0.11714883619421779, 0.12154503902020053]}, "mutation_prompt": null}
{"id": "89a869f3-df18-432a-bec5-92af2d0dc0d2", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            learning_factor = 1.0 - eval_count / self.budget  # New line\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, learning_factor)  # Modified line\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, learning_factor):  # Modified line\n        harmony = np.empty(self.dim)\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * learning_factor  # Modified line\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            harmony[i] += learning_factor * 0.05 * (best_harmony[i] - harmony[i])  # Modified line\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced exploration by adapting the pitch adjustment rate dynamically based on the number of evaluations.", "configspace": "", "generation": 10, "fitness": 0.8835012484723136, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.007. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "4a9ea90e-27b9-4640-9f03-097e50e12d6e", "metadata": {"aucs": [0.878384543934127, 0.8930162729250057, 0.879102928557808], "final_y": [0.11689771195377618, 0.11995534965551402, 0.12224603208585938]}, "mutation_prompt": null}
{"id": "e4687f9a-e72e-414a-a4fc-49cbbe479c1e", "solution": "import numpy as np\n\nclass AdaptiveSwarmHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb = func.bounds.lb\n        ub = func.bounds.ub\n        memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (memory_size, self.dim))\n        fitness_memory = np.array([func(harmony) for harmony in harmony_memory])\n        best_harmony = harmony_memory[np.argmin(fitness_memory)]\n        best_fitness = np.min(fitness_memory)\n        eval_count = memory_size\n\n        while eval_count < self.budget:\n            new_harmony = self.generate_harmony(harmony_memory, lb, ub, best_harmony, eval_count)\n            new_fitness = func(new_harmony)\n            eval_count += 1\n\n            worst_idx = np.argmax(fitness_memory)\n            if new_fitness < fitness_memory[worst_idx]:\n                harmony_memory[worst_idx] = new_harmony\n                fitness_memory[worst_idx] = new_fitness\n\n            if new_fitness < best_fitness:\n                best_harmony = new_harmony\n                best_fitness = new_fitness\n\n            # Adaptive adjustment\n            if eval_count % (self.budget // 10) == 0:\n                self.adaptive_adjustment(harmony_memory, fitness_memory)\n\n        return best_harmony\n\n    def generate_harmony(self, memory, lb, ub, best_harmony, eval_count):\n        harmony = np.empty(self.dim)\n        adjustment_factor = 1 - (eval_count / self.budget)  # Dynamic adjustment factor\n        for i in range(self.dim):\n            if np.random.rand() < 0.7:  # Harmony memory consideration\n                harmony[i] = memory[np.random.randint(len(memory)), i]\n            else:  # Random selection\n                harmony[i] = np.random.uniform(lb[i], ub[i])\n\n            if np.random.rand() < 0.1:  # Pitch adjustment\n                adjustment_scale = np.std(memory[:, i]) / (ub[i] - lb[i])  # Adaptive scaling factor\n                adjustment = (ub[i] - lb[i]) * (np.random.rand() - 0.5) * adjustment_scale * adjustment_factor\n                harmony[i] = np.clip(harmony[i] + adjustment, lb[i], ub[i])\n\n            # New directional adjustment towards best harmony\n            harmony[i] += 0.05 * (best_harmony[i] - harmony[i])\n        \n        return harmony\n\n    def adaptive_adjustment(self, memory, fitness_memory):\n        variation = np.std(memory, axis=0)\n        if np.std(fitness_memory) > 0.1:\n            for harmony in memory:\n                harmony += np.random.normal(0, 0.1, size=self.dim) * variation", "name": "AdaptiveSwarmHarmonySearch", "description": "Enhanced adaptive pitch adjustment with a dynamic adjustment factor based on iteration progression.", "configspace": "", "generation": 10, "fitness": 0.8752583596002453, "feedback": "The algorithm AdaptiveSwarmHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.003. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "7cb6ce79-59b0-4f02-b76f-cf3013324a01", "metadata": {"aucs": [0.8736375661075272, 0.879161658674467, 0.8729758540187418], "final_y": [0.1231302793042971, 0.11883077997863423, 0.12144931408629167]}, "mutation_prompt": null}
