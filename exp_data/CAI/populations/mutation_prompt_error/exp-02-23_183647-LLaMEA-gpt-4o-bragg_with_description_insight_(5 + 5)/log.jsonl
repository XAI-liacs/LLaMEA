{"id": "423b5a4e-535a-48c4-8fa0-18501482a41c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HGLEO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 2 * dim)\n        self.current_budget = 0\n\n    def _initialize_population(self, bounds):\n        # Symmetric initialization with periodic suggestion\n        lb, ub = bounds.lb, bounds.ub\n        population = np.random.rand(self.pop_size, self.dim) * (ub - lb) + lb\n        return np.vstack((population, np.flip(population, axis=1)))\n\n    def _evaluate_population(self, population, func):\n        evaluations = np.apply_along_axis(func, 1, population)\n        self.current_budget += len(population)\n        return evaluations\n\n    def _differential_evolution_step(self, population, scores, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = []\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            a, b, c = population[idxs]\n            mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < 0.9\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            new_population.append(trial)\n        new_population = np.array(new_population)\n        new_scores = self._evaluate_population(new_population, func)\n        improved = new_scores < scores\n        population[improved] = new_population[improved]\n        scores[improved] = new_scores[improved]\n        return population, scores\n\n    def _local_optimization(self, best_solution, func, bounds):\n        def wrapped_func(x):\n            self.current_budget += 1\n            return func(x)\n        \n        result = minimize(wrapped_func, best_solution, bounds=[(l, u) for l, u in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else best_solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self._initialize_population(bounds)\n        scores = self._evaluate_population(population, func)\n\n        while self.current_budget < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, bounds)\n            best_idx = np.argmin(scores)\n            best_solution = population[best_idx]\n            \n            if self.current_budget + self.dim <= self.budget:\n                best_solution = self._local_optimization(best_solution, func, bounds)\n                best_score = func(best_solution)\n                self.current_budget += 1\n                if best_score < scores[best_idx]:\n                    scores[best_idx] = best_score\n                    population[best_idx] = best_solution\n\n        best_idx = np.argmin(scores)\n        return population[best_idx]", "name": "HGLEO", "description": "Hybrid Global-Local Evolutionary Optimization (HGLEO) combines global exploration via Differential Evolution with local refinement using BFGS, encouraging periodicity by introducing periodic constraints and symmetric initialization for robust optimization of multilayered photonic structures.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 55, in __call__\n  File \"<string>\", line 35, in _differential_evolution_step\nNameError: name 'func' is not defined\n.", "error": "NameError(\"name 'func' is not defined\")Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 55, in __call__\n  File \"<string>\", line 35, in _differential_evolution_step\nNameError: name 'func' is not defined\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "fd5ff609-5996-4203-8c8a-b5ce3927a34a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass PeriodicDEBFGS:\n    def __init__(self, budget, dim, pop_size=30, f=0.5, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.population = None\n        self.best_solution = None\n        self.best_score = float('-inf')\n        self.bounds = None\n\n    def __call__(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        self.population = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.pop_size, self.dim))\n        self.population = self.apply_periodicity(self.population)\n\n        for _ in range(self.budget // self.pop_size):\n            new_population = []\n            for idx in range(self.pop_size):\n                candidates = list(range(0, idx)) + list(range(idx + 1, self.pop_size))\n                a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), *self.bounds)\n                mutant = self.apply_periodicity(mutant.reshape(1, -1)).flatten()\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, self.population[idx])\n                trial_score = func(trial)\n                \n                if trial_score > self.best_score:\n                    self.best_score = trial_score\n                    self.best_solution = trial\n\n                if trial_score > func(self.population[idx]):\n                    new_population.append(trial)\n                else:\n                    new_population.append(self.population[idx])\n\n            self.population = np.array(new_population)\n            self.apply_local_search(func)\n\n        return self.best_solution\n\n    def apply_local_search(self, func):\n        for individual in self.population:\n            result = minimize(lambda x: -func(x), individual, bounds=list(zip(*self.bounds)), method='L-BFGS-B')\n            score = -result.fun\n            \n            if score > self.best_score:\n                self.best_score = score\n                self.best_solution = result.x\n\n    def apply_periodicity(self, solutions):\n        quarter_dim = self.dim // 2\n        for solution in solutions:\n            solution[:quarter_dim] = solution[quarter_dim:2 * quarter_dim]\n            solution[2 * quarter_dim:] = solution[:quarter_dim]\n        return solutions", "name": "PeriodicDEBFGS", "description": "The algorithm combines global exploration through Differential Evolution with local refinement using BFGS and imposes periodicity constraints to enhance performance in multilayered photonic structures optimization.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 19, in __call__\n  File \"<string>\", line 58, in apply_periodicity\nValueError: could not broadcast input array from shape (5,) into shape (0,)\n.", "error": "ValueError('could not broadcast input array from shape (5,) into shape (0,)')Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 19, in __call__\n  File \"<string>\", line 58, in apply_periodicity\nValueError: could not broadcast input array from shape (5,) into shape (0,)\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "05743ea8-b683-43c2-85c0-d14cb99273be", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPeriodicOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        \n    def _initialize_population(self, bounds, population_size):\n        lb, ub = bounds\n        population = np.random.rand(population_size, self.dim) * (ub - lb) + lb\n        return population\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution(self, func, bounds, population_size=20, F=0.8, CR=0.9):\n        population = self._initialize_population(bounds, population_size)\n        fitness = self._evaluate_population(population, func)\n        \n        for _ in range(self.budget // population_size):\n            for i in range(population_size):\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), bounds[0], bounds[1])\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n                trial_fitness = func(trial)\n                \n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n            \n            # Enforce periodicity by averaging every two adjacent layers\n            half_dim = self.dim // 2\n            for ind in population:\n                ind[:half_dim] = (ind[:half_dim] + ind[half_dim:]) / 2\n        \n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]\n    \n    def _local_optimization(self, x0, func, bounds):\n        result = minimize(func, x0, method='L-BFGS-B', bounds=bounds)\n        return result.x, result.fun\n    \n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        global_best, global_best_fitness = self._differential_evolution(func, bounds)\n        \n        # Local optimization to fine-tune the final solution\n        local_best, local_best_fitness = self._local_optimization(global_best, func, bounds)\n        \n        return local_best if local_best_fitness < global_best_fitness else global_best", "name": "HybridPeriodicOptimization", "description": "A hybrid optimization algorithm that combines Differential Evolution's global exploration with a periodicity-enforcing strategy and local optimization for fine-tuning, ensuring modular design and leveraging constructive interference principles.", "configspace": "", "generation": 0, "fitness": 0.9237254643411719, "feedback": "The algorithm HybridPeriodicOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.004. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": null, "metadata": {"aucs": [0.9245156389857778, 0.9189716575065883, 0.9276890965311494], "final_y": [0.17151701754274096, 0.1715117077573215, 0.17117803690084388]}, "mutation_prompt": null}
{"id": "c584efb2-52df-46ad-a4cc-a27b2be744ee", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50  # Number of candidate solutions\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.9\n        self.population = None\n        self.func_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds\n        center = (lb + ub) / 2\n        range_half = (ub - lb) / 2\n        # Symmetric initialization: around the mid-point of the search space\n        self.population = center + np.random.uniform(-range_half, range_half, (self.population_size, self.dim))\n\n    def mutate(self, target_idx):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, 0, 1)  # Assuming normalized [0, 1] bounds for mutation\n\n    def crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.crossover_probability\n        if not np.any(crossover):\n            crossover[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover, mutant, target)\n        return trial\n\n    def local_optimization(self, candidate, func):\n        # Encourage periodicity by optimizing a cost that penalizes deviation from periodic patterns\n        def periodic_cost(x):\n            period = self.dim // 2  # Example: Half the dimension as a period\n            deviation = np.sum((x[:period] - x[period:]) ** 2)\n            return func(x) + deviation\n\n        result = minimize(periodic_cost, candidate, bounds=func.bounds)\n        return result.x\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        best_solution = None\n        best_score = float('inf')\n\n        while self.func_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.func_evaluations >= self.budget:\n                    break\n                \n                target = self.population[i]\n                mutant = self.mutate(i)\n                trial = self.crossover(target, mutant)\n\n                trial = self.local_optimization(trial, func)\n\n                trial_score = func(trial)\n                self.func_evaluations += 1\n\n                if trial_score < best_score:\n                    best_score = trial_score\n                    best_solution = trial\n\n                # Selection\n                if trial_score < func(target):\n                    self.population[i] = trial\n\n        return best_solution", "name": "SymmetricPeriodicDE", "description": "A hybrid approach combining Differential Evolution with symmetry-aware initialization and periodicity-inducing local search to solve multilayered photonic structure optimization problems.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 45, in __call__\n  File \"<string>\", line 15, in initialize_population\nTypeError: cannot unpack non-iterable ioh.iohcpp.RealBounds object\n.", "error": "TypeError('cannot unpack non-iterable ioh.iohcpp.RealBounds object')Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 45, in __call__\n  File \"<string>\", line 15, in initialize_population\nTypeError: cannot unpack non-iterable ioh.iohcpp.RealBounds object\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "61e0aa5f-225c-4cf6-9ab6-493375e8cf6a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass BraggMirrorOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.8\n        self.crossover_probability = 0.7\n        self.periodicity_weight = 0.2\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        periodicity_error = np.sum((solution - np.roll(solution, 2))**2)\n        return periodicity_error\n    \n    def differential_evolution_step(self, population, lb, ub, func):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_weight * self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for _ in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "BraggMirrorOptimizer", "description": "A hybrid metaheuristic algorithm combining Differential Evolution with a periodicity bias and local optimization using BFGS to efficiently explore and exploit the search space for optimizing multilayered photonic structures.", "configspace": "", "generation": 0, "fitness": 0.9414461004566297, "feedback": "The algorithm BraggMirrorOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": null, "metadata": {"aucs": [0.9532824880203105, 0.9481220126341869, 0.9229338007153918], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "eb8cdfb6-1eb9-4b1b-a1f8-9b58cd8dee01", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50  # Number of candidate solutions\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.9\n        self.population = None\n        self.func_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        range_half = (ub - lb) / 2\n        # Symmetric initialization: around the mid-point of the search space\n        self.population = center + np.random.uniform(-range_half, range_half, (self.population_size, self.dim))\n\n    def mutate(self, target_idx):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, 0, 1)  # Assuming normalized [0, 1] bounds for mutation\n\n    def crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.crossover_probability\n        if not np.any(crossover):\n            crossover[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover, mutant, target)\n        return trial\n\n    def local_optimization(self, candidate, func):\n        # Encourage periodicity by optimizing a cost that penalizes deviation from periodic patterns\n        def periodic_cost(x):\n            period = self.dim // 2  # Example: Half the dimension as a period\n            deviation = np.sum((x[:period] - x[period:]) ** 2)\n            return func(x) + deviation\n\n        result = minimize(periodic_cost, candidate, bounds=func.bounds)\n        return result.x\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        best_solution = None\n        best_score = float('inf')\n\n        while self.func_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.func_evaluations >= self.budget:\n                    break\n                \n                target = self.population[i]\n                mutant = self.mutate(i)\n                trial = self.crossover(target, mutant)\n\n                trial = self.local_optimization(trial, func)\n\n                trial_score = func(trial)\n                self.func_evaluations += 1\n\n                if trial_score < best_score:\n                    best_score = trial_score\n                    best_solution = trial\n\n                # Selection\n                if trial_score < func(target):\n                    self.population[i] = trial\n\n        return best_solution", "name": "SymmetricPeriodicDE", "description": "The refined hybrid algorithm integrates symmetry-aware initialization and periodicity-inducing optimization with a correction to handle bounds unpacking for robust black-box optimization.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('zip() argument after * must be an iterable, not ioh.iohcpp.RealBounds').", "error": "TypeError('zip() argument after * must be an iterable, not ioh.iohcpp.RealBounds')", "parent_id": "c584efb2-52df-46ad-a4cc-a27b2be744ee", "metadata": {}, "mutation_prompt": null}
{"id": "d8ebfe62-5a76-4b2c-a973-a85ce65490c7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Adaptive Periodic Differential Evolution (APDE) dynamically adjusts control parameters and encourages periodicity using sinusoidal modulation for effective optimization of multilayered photonic structures.", "configspace": "", "generation": 1, "fitness": 0.9414461004566297, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "61e0aa5f-225c-4cf6-9ab6-493375e8cf6a", "metadata": {"aucs": [0.9532824880203105, 0.9481220126341869, 0.9229338007153918], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "203d7841-5c15-4789-9e27-47dc98f25851", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50  # Number of candidate solutions\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.9\n        self.population = None\n        self.func_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        center = (lb + ub) / 2\n        range_half = (ub - lb) / 2\n        # Symmetric initialization: around the mid-point of the search space\n        self.population = center + np.random.uniform(-range_half, range_half, (self.population_size, self.dim))\n\n    def mutate(self, target_idx):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, 0, 1)  # Assuming normalized [0, 1] bounds for mutation\n\n    def crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.crossover_probability\n        if not np.any(crossover):\n            crossover[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover, mutant, target)\n        return trial\n\n    def local_optimization(self, candidate, func):\n        # Encourage periodicity by optimizing a cost that penalizes deviation from periodic patterns\n        def periodic_cost(x):\n            period = self.dim // 2  # Example: Half the dimension as a period\n            deviation = np.sum((x[:period] - x[period:]) ** 2)\n            return func(x) + deviation\n\n        result = minimize(periodic_cost, candidate, bounds=func.bounds)\n        return result.x\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        best_solution = None\n        best_score = float('inf')\n\n        while self.func_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.func_evaluations >= self.budget:\n                    break\n                \n                target = self.population[i]\n                mutant = self.mutate(i)\n                trial = self.crossover(target, mutant)\n\n                trial = self.local_optimization(trial, func)\n\n                trial_score = func(trial)\n                self.func_evaluations += 1\n\n                if trial_score < best_score:\n                    best_score = trial_score\n                    best_solution = trial\n\n                # Selection\n                if trial_score < func(target):\n                    self.population[i] = trial\n\n        return best_solution", "name": "SymmetricPeriodicDE", "description": "A hybrid approach combining Differential Evolution with symmetry-aware initialization and periodicity-inducing local search to solve multilayered photonic structure optimization problems, fixed bounds unpacking bug by directly accessing attributes.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('zip() argument after * must be an iterable, not ioh.iohcpp.RealBounds').", "error": "TypeError('zip() argument after * must be an iterable, not ioh.iohcpp.RealBounds')", "parent_id": "c584efb2-52df-46ad-a4cc-a27b2be744ee", "metadata": {}, "mutation_prompt": null}
{"id": "fa022b5f-911e-4e6d-a10d-acbf226f0f48", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50  # Number of candidate solutions\n        self.mutation_factor = 0.8\n        self.crossover_probability = 0.9\n        self.population = None\n        self.func_evaluations = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub  # Correctly unpacking bounds\n        center = (lb + ub) / 2\n        range_half = (ub - lb) / 2\n        # Symmetric initialization: around the mid-point of the search space\n        self.population = center + np.random.uniform(-range_half, range_half, (self.population_size, self.dim))\n\n    def mutate(self, target_idx):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, 0, 1)  # Assuming normalized [0, 1] bounds for mutation\n\n    def crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.crossover_probability\n        if not np.any(crossover):\n            crossover[np.random.randint(0, self.dim)] = True\n        trial = np.where(crossover, mutant, target)\n        return trial\n\n    def local_optimization(self, candidate, func):\n        # Encourage periodicity by optimizing a cost that penalizes deviation from periodic patterns\n        def periodic_cost(x):\n            period = self.dim // 2  # Example: Half the dimension as a period\n            deviation = np.sum((x[:period] - x[period:]) ** 2)\n            return func(x) + deviation\n\n        result = minimize(periodic_cost, candidate, bounds=func.bounds)\n        return result.x\n\n    def __call__(self, func):\n        self.initialize_population(func.bounds)\n        best_solution = None\n        best_score = float('inf')\n\n        while self.func_evaluations < self.budget:\n            for i in range(self.population_size):\n                if self.func_evaluations >= self.budget:\n                    break\n                \n                target = self.population[i]\n                mutant = self.mutate(i)\n                trial = self.crossover(target, mutant)\n\n                trial = self.local_optimization(trial, func)\n\n                trial_score = func(trial)\n                self.func_evaluations += 1\n\n                if trial_score < best_score:\n                    best_score = trial_score\n                    best_solution = trial\n\n                # Selection\n                if trial_score < func(target):\n                    self.population[i] = trial\n\n        return best_solution", "name": "SymmetricPeriodicDE", "description": "A hybrid approach combining Differential Evolution with symmetry-aware initialization and periodicity-inducing local search to solve multilayered photonic structure optimization problems, using correct bounds initialization.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('zip() argument after * must be an iterable, not ioh.iohcpp.RealBounds').", "error": "TypeError('zip() argument after * must be an iterable, not ioh.iohcpp.RealBounds')", "parent_id": "c584efb2-52df-46ad-a4cc-a27b2be744ee", "metadata": {}, "mutation_prompt": null}
{"id": "7687f2bf-648f-42bc-aef9-f262da6fd516", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.8\n        self.crossover_probability = 0.7\n        self.periodicity_weight = 0.2\n        self.pso_weight = 0.5\n        self.velocity_clamp = 0.1\n        \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def initialize_velocity(self):\n        return np.random.uniform(-self.velocity_clamp, self.velocity_clamp, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        periodicity_error = np.sum((solution - np.roll(solution, 2))**2)\n        return periodicity_error\n\n    def differential_evolution_step(self, population, lb, ub, func):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_weight * self.periodicity_cost(trial)\n\n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def pso_step(self, population, velocity, personal_best, global_best, lb, ub):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        velocity = self.velocity_clamp * (velocity \n                                          + self.pso_weight * r1 * (personal_best - population) \n                                          + self.pso_weight * r2 * (global_best - population))\n        population = np.clip(population + velocity, lb, ub)\n        return population, velocity\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        velocity = self.initialize_velocity()\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        best_solution = None\n        best_score = float('inf')\n        \n        for _ in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func)\n            population, velocity = self.pso_step(population, velocity, personal_best, global_best, lb, ub)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                \n                if score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = score\n                \n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n                    global_best = best_solution\n        \n        return best_solution", "name": "DynamicSymbioticEvolution", "description": "Dynamic Symbiotic Evolution (DSE) leverages a symbiotic relationship between Differential Evolution and Particle Swarm Optimization, with periodicity enforcement and adaptive mutation strategies, to optimize multilayered photonic structures.  ", "configspace": "", "generation": 1, "fitness": 0.9331340028698029, "feedback": "The algorithm DynamicSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.933 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "61e0aa5f-225c-4cf6-9ab6-493375e8cf6a", "metadata": {"aucs": [0.9454401526524027, 0.9390479218947304, 0.9149139340622754], "final_y": [0.16485626884803328, 0.16485696278277207, 0.16485659285048015]}, "mutation_prompt": null}
{"id": "df2f0f66-4d4a-4248-92b9-9e4694d8b43f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HGLEO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 2 * dim)\n        self.current_budget = 0\n\n    def _initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        population = np.random.rand(self.pop_size, self.dim) * (ub - lb) + lb\n        return np.vstack((population, np.flip(population, axis=1)))\n\n    def _evaluate_population(self, population, func):\n        evaluations = np.apply_along_axis(func, 1, population)\n        self.current_budget += len(population)\n        return evaluations\n\n    def _differential_evolution_step(self, population, scores, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = []\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            a, b, c = population[idxs]\n            mutant = np.clip(a + np.random.rand() * (b - c), lb, ub)  # Adjusted mutation strategy\n            cross_points = np.random.rand(self.dim) < 0.9\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, 0.5 * (population[i] + mutant))  # Blended crossover\n            new_population.append(trial)\n        new_population = np.array(new_population)\n        new_scores = self._evaluate_population(new_population, func)\n        improved = new_scores < scores\n        population[improved] = new_population[improved]\n        scores[improved] = new_scores[improved]\n        return population, scores\n\n    def _local_optimization(self, best_solution, func, bounds):\n        def wrapped_func(x):\n            self.current_budget += 1\n            return func(x)\n        \n        result = minimize(wrapped_func, best_solution, bounds=[(l, u) for l, u in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else best_solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self._initialize_population(bounds)\n        scores = self._evaluate_population(population, func)\n\n        while self.current_budget < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, bounds)\n            best_idx = np.argmin(scores)\n            best_solution = population[best_idx]\n            \n            if self.current_budget + self.dim <= self.budget:\n                best_solution = self._local_optimization(best_solution, func, bounds)\n                best_score = func(best_solution)\n                self.current_budget += 1\n                if best_score < scores[best_idx]:\n                    scores[best_idx] = best_score\n                    population[best_idx] = best_solution\n\n        best_idx = np.argmin(scores)\n        return population[best_idx]", "name": "HGLEO", "description": "Enhanced Hybrid Global-Local Evolutionary Optimization (HGLEO) by integrating a validation mechanism for mutation efficiency and using a blended crossover to improve optimization robustness.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "423b5a4e-535a-48c4-8fa0-18501482a41c", "metadata": {}, "mutation_prompt": null}
{"id": "e1dd0904-9df8-44d6-b33d-a6aca1088536", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Adaptive Periodic Differential Evolution utilizes a sine-modulated scale factor and local optimization to enhance convergence, now with a dynamic crossover probability increasing exploration as generations progress.", "configspace": "", "generation": 2, "fitness": 0.9414461004566297, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d8ebfe62-5a76-4b2c-a973-a85ce65490c7", "metadata": {"aucs": [0.9532824880203105, 0.9481220126341869, 0.9229338007153918], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "17a6e97d-33a6-483d-b392-78c1c6b28069", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HGLEO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10, 2 * dim)\n        self.current_budget = 0\n\n    def _initialize_population(self, bounds):\n        # Symmetric initialization with periodic suggestion\n        lb, ub = bounds.lb, bounds.ub\n        population = np.random.rand(self.pop_size, self.dim) * (ub - lb) + lb\n        return np.vstack((population, np.flip(population, axis=1)))\n\n    def _evaluate_population(self, population, func):\n        evaluations = np.apply_along_axis(func, 1, population)\n        self.current_budget += len(population)\n        return evaluations\n\n    def _differential_evolution_step(self, population, scores, bounds, func):  # Corrected function signature\n        lb, ub = bounds.lb, bounds.ub\n        new_population = []\n        for i in range(self.pop_size):\n            idxs = np.random.choice(self.pop_size, 3, replace=False)\n            a, b, c = population[idxs]\n            mutant = np.clip(a + 0.8 * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < 0.9\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            new_population.append(trial)\n        new_population = np.array(new_population)\n        new_scores = self._evaluate_population(new_population, func)\n        improved = new_scores < scores\n        population[improved] = new_population[improved]\n        scores[improved] = new_scores[improved]\n        return population, scores\n\n    def _local_optimization(self, best_solution, func, bounds):\n        def wrapped_func(x):\n            self.current_budget += 1\n            return func(x)\n        \n        result = minimize(wrapped_func, best_solution, bounds=[(l, u) for l, u in zip(bounds.lb, bounds.ub)], method='L-BFGS-B')\n        return result.x if result.success else best_solution\n\n    def __call__(self, func):\n        bounds = func.bounds\n        population = self._initialize_population(bounds)\n        scores = self._evaluate_population(population, func)\n\n        while self.current_budget < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, bounds, func)  # Pass func\n            best_idx = np.argmin(scores)\n            best_solution = population[best_idx]\n            \n            if self.current_budget + self.dim <= self.budget:\n                best_solution = self._local_optimization(best_solution, func, bounds)\n                best_score = func(best_solution)\n                self.current_budget += 1\n                if best_score < scores[best_idx]:\n                    scores[best_idx] = best_score\n                    population[best_idx] = best_solution\n\n        best_idx = np.argmin(scores)\n        return population[best_idx]", "name": "HGLEO", "description": "Refine the error handling in Differential Evolution step by ensuring the function `func` is correctly passed.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (20,) (40,) ').", "error": "ValueError('operands could not be broadcast together with shapes (20,) (40,) ')", "parent_id": "423b5a4e-535a-48c4-8fa0-18501482a41c", "metadata": {}, "mutation_prompt": null}
{"id": "e54e3235-5479-49dd-bff8-134cf447c088", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.8\n        self.crossover_probability = 0.7\n        self.periodicity_weight = 0.2\n        self.pso_weight = 0.5\n        self.velocity_clamp = 0.1\n        \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def initialize_velocity(self):\n        return np.random.uniform(-self.velocity_clamp, self.velocity_clamp, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        periodicity_error = np.sum((solution - np.roll(solution, 2))**2)\n        return periodicity_error\n\n    def differential_evolution_step(self, population, lb, ub, func):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_weight * self.periodicity_cost(trial)\n\n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def pso_step(self, population, velocity, personal_best, global_best, lb, ub):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.pso_weight = np.random.uniform(0.4, 0.9)  # Dynamically adjust PSO weight\n        velocity = self.velocity_clamp * (velocity \n                                          + self.pso_weight * r1 * (personal_best - population) \n                                          + self.pso_weight * r2 * (global_best - population))\n        population = np.clip(population + velocity, lb, ub)\n        return population, velocity\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        velocity = self.initialize_velocity()\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        best_solution = None\n        best_score = float('inf')\n        \n        for _ in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func)\n            population, velocity = self.pso_step(population, velocity, personal_best, global_best, lb, ub)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                \n                if score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = score\n                \n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n                    global_best = best_solution\n        \n        return best_solution", "name": "DynamicSymbioticEvolution", "description": "Enhanced Dynamic Symbiotic Evolution (EDSE) increases exploration by adjusting the PSO weight dynamically, improving the optimization of multilayered photonic structures.", "configspace": "", "generation": 2, "fitness": 0.9334022040212759, "feedback": "The algorithm DynamicSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.933 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7687f2bf-648f-42bc-aef9-f262da6fd516", "metadata": {"aucs": [0.9468000755705598, 0.9390036755184269, 0.9144028609748412], "final_y": [0.16485644875450045, 0.1648562218868962, 0.1648564433962867]}, "mutation_prompt": null}
{"id": "d78547b0-1cd4-49d8-9aaa-bae8d45ce372", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.8\n        self.crossover_probability = 0.7\n        self.periodicity_weight = 0.2\n        self.pso_weight = 0.5\n        self.velocity_clamp = 0.1\n        \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def initialize_velocity(self):\n        return np.random.uniform(-self.velocity_clamp, self.velocity_clamp, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        periodicity_error = np.sum((solution - np.roll(solution, 2))**2)\n        return periodicity_error\n\n    def differential_evolution_step(self, population, lb, ub, func):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            self.periodicity_weight = 0.2 + 0.8 * (i / self.population_size)  # Adaptive adjustment\n            trial_with_periodicity = trial + self.periodicity_weight * self.periodicity_cost(trial)\n\n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def pso_step(self, population, velocity, personal_best, global_best, lb, ub):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        velocity = self.velocity_clamp * (velocity \n                                          + self.pso_weight * r1 * (personal_best - population) \n                                          + self.pso_weight * r2 * (global_best - population))\n        population = np.clip(population + velocity, lb, ub)\n        return population, velocity\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        velocity = self.initialize_velocity()\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        best_solution = None\n        best_score = float('inf')\n        \n        for _ in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func)\n            population, velocity = self.pso_step(population, velocity, personal_best, global_best, lb, ub)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                \n                if score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = score\n                \n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n                    global_best = best_solution\n        \n        return best_solution", "name": "DynamicSymbioticEvolution", "description": "Enhanced Dynamic Symbiotic Evolution (EDSE) integrates adaptive periodicity weight adjustment for improved exploration and exploitation balance, optimizing multilayered photonic structures.", "configspace": "", "generation": 2, "fitness": 0.9331340028698029, "feedback": "The algorithm DynamicSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.933 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7687f2bf-648f-42bc-aef9-f262da6fd516", "metadata": {"aucs": [0.9454401526524027, 0.9390479218947304, 0.9149139340622754], "final_y": [0.16485626884803328, 0.16485696278277207, 0.16485659285048015]}, "mutation_prompt": null}
{"id": "f74ee1e7-16ac-4daf-8838-aa4820371e77", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(10 * dim * (1 + 0.1 * np.sin(np.pi * np.arange(budget // (10 * dim)))))\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Adaptive Periodic DE with improved solution diversity by dynamically varying population size.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('only length-1 arrays can be converted to Python scalars').", "error": "TypeError('only length-1 arrays can be converted to Python scalars')", "parent_id": "e1dd0904-9df8-44d6-b33d-a6aca1088536", "metadata": {}, "mutation_prompt": null}
{"id": "2e22f291-f65c-4a7a-b967-cf11ce2619af", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(4 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            self.crossover_probability = 0.5 + 0.4 * np.sin(np.pi * gen / (self.budget // self.population_size))\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Improved Adaptive Periodic DE by dynamically adjusting crossover probability and enhancing periodicity cost function for better exploration and convergence.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('only length-1 arrays can be converted to Python scalars').", "error": "TypeError('only length-1 arrays can be converted to Python scalars')", "parent_id": "d8ebfe62-5a76-4b2c-a973-a85ce65490c7", "metadata": {}, "mutation_prompt": null}
{"id": "3dbac0e9-ae0a-4638-a104-a063a9ca2a05", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution, gen):  # Add gen as a parameter\n        dynamic_periodicity_weight = self.periodicity_weight * (1 + gen / (self.budget // self.population_size))  # Dynamic adjustment\n        return np.sum((solution - np.roll(solution, 1))**2) - dynamic_periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)  # Pass gen to periodicity_cost\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced Adaptive Periodic Differential Evolution (EAPDE) introduces a dynamic periodicity weight to improve exploration and convergence speed in optimizing multilayered photonic structures.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('only length-1 arrays can be converted to Python scalars').", "error": "TypeError('only length-1 arrays can be converted to Python scalars')", "parent_id": "e1dd0904-9df8-44d6-b33d-a6aca1088536", "metadata": {}, "mutation_prompt": null}
{"id": "057e3c27-9512-433f-8344-8e65cf98ea0b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.8\n        self.crossover_probability = 0.7\n        self.periodicity_weight = 0.2\n        self.pso_weight = 0.5\n        self.velocity_clamp = 0.1\n        \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def initialize_velocity(self):\n        return np.random.uniform(-self.velocity_clamp, self.velocity_clamp, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        periodicity_error = np.sum((solution - np.roll(solution, 2))**2)\n        return periodicity_error\n\n    def differential_evolution_step(self, population, lb, ub, func):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_weight * self.periodicity_cost(trial)\n\n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def pso_step(self, population, velocity, personal_best, global_best, lb, ub):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        velocity = self.velocity_clamp * (velocity \n                                          + self.pso_weight * r1 * (personal_best - population) \n                                          + self.pso_weight * r2 * (global_best - population))\n        population = np.clip(population + velocity, lb, ub)\n        return population, velocity\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        velocity = self.initialize_velocity()\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        best_solution = None\n        best_score = float('inf')\n        \n        for _ in range(self.budget // self.population_size):\n            self.periodicity_weight = 0.2 + 0.3 * (_ / (self.budget // self.population_size))  # Adaptive adjustment\n            population = self.differential_evolution_step(population, lb, ub, func)\n            population, velocity = self.pso_step(population, velocity, personal_best, global_best, lb, ub)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                \n                if score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = score\n                \n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n                    global_best = best_solution\n        \n        return best_solution", "name": "DynamicSymbioticEvolution", "description": "Enhanced Dynamic Symbiotic Evolution with adaptive periodicity weight adjustment for improved Bragg mirror optimization.", "configspace": "", "generation": 3, "fitness": 0.9330076006420587, "feedback": "The algorithm DynamicSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.933 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7687f2bf-648f-42bc-aef9-f262da6fd516", "metadata": {"aucs": [0.9454401526524027, 0.9390479218947304, 0.9145347273790432], "final_y": [0.16485626884803328, 0.16485696278277207, 0.16485651693851877]}, "mutation_prompt": null}
{"id": "afed3f32-0ebd-4b43-8085-90136dc2702f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.8\n        self.crossover_probability = 0.7\n        self.periodicity_weight = 0.3  # Adjusted periodicity weight\n        self.pso_weight = 0.5\n        self.velocity_clamp = 0.1\n        \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def initialize_velocity(self):\n        return np.random.uniform(-self.velocity_clamp, self.velocity_clamp, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        periodicity_error = np.sum((solution - np.roll(solution, 2))**2)\n        return periodicity_error\n\n    def differential_evolution_step(self, population, lb, ub, func):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_weight * self.periodicity_cost(trial)\n\n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def pso_step(self, population, velocity, personal_best, global_best, lb, ub):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        velocity = self.velocity_clamp * (velocity \n                                          + (self.pso_weight + np.random.rand()/10) * r1 * (personal_best - population) \n                                          + (self.pso_weight + np.random.rand()/10) * r2 * (global_best - population))  # Adjusted PSO weight\n        population = np.clip(population + velocity, lb, ub)\n        return population, velocity\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        velocity = self.initialize_velocity()\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        best_solution = None\n        best_score = float('inf')\n        \n        for _ in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func)\n            population, velocity = self.pso_step(population, velocity, personal_best, global_best, lb, ub)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                \n                if score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = score\n                \n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n                    global_best = best_solution\n        \n        return best_solution", "name": "DynamicSymbioticEvolution", "description": "Enhanced Dynamic Symbiotic Evolution (EDSE) with improved periodicity enforcement and dynamically adjusted PSO weight for better exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.9331146243416626, "feedback": "The algorithm DynamicSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.933 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7687f2bf-648f-42bc-aef9-f262da6fd516", "metadata": {"aucs": [0.9452734843140453, 0.9395356613318995, 0.9145347273790432], "final_y": [0.16485724856971284, 0.1648567254439074, 0.16485651693851877]}, "mutation_prompt": null}
{"id": "2ae80906-3268-4bf0-ab7a-83b8154e4802", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass BraggMirrorOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Changed from 10 * dim to 12 * dim\n        self.scale_factor = 0.8\n        self.crossover_probability = 0.7\n        self.periodicity_weight = 0.2\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        periodicity_error = np.sum((solution - np.roll(solution, 2))**2)\n        return periodicity_error\n    \n    def differential_evolution_step(self, population, lb, ub, func):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.scale_factor * (c - b), lb, ub)  # Changed from (b - c) to (c - b)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_weight * self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for _ in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "BraggMirrorOptimizer", "description": "Refined BraggMirrorOptimizer increasing population size for enhanced diversity and exploring alternative mutation strategy to potentially improve convergence.  ", "configspace": "", "generation": 4, "fitness": 0.9374172671163122, "feedback": "The algorithm BraggMirrorOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.937 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "61e0aa5f-225c-4cf6-9ab6-493375e8cf6a", "metadata": {"aucs": [0.9492688712814552, 0.9440386550800896, 0.9189442749873923], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "10546e50-ec75-4a7b-9ab6-f9f193679dc5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = 0.4 + 0.6 * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            trial_fitness = func(mutant)\n            cross_prob = self.crossover_probability * (1 - trial_fitness / func(population[i]))\n            cross_points = np.random.rand(self.dim) < cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Adaptive Periodic Differential Evolution now includes a fitness-based crossover probability and a dynamic scale factor adjustment to enhance exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.9344132274066128, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.934 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e1dd0904-9df8-44d6-b33d-a6aca1088536", "metadata": {"aucs": [0.9321838688702595, 0.9481220126341869, 0.9229338007153918], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "9404fd50-5e5d-4cbb-8b50-d8189b508f7d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(np.sin(solution))\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Improved Adaptive Periodic Differential Evolution with enhanced periodicity cost calculation to boost optimization in multilayered photonic structures.", "configspace": "", "generation": 4, "fitness": 0.9414461004566297, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e1dd0904-9df8-44d6-b33d-a6aca1088536", "metadata": {"aucs": [0.9532824880203105, 0.9481220126341869, 0.9229338007153918], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "6e313fad-311c-4c1a-9652-2d75df123c08", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.8\n        self.crossover_probability = 0.7\n        self.periodicity_weight = 0.2\n        self.pso_weight = 0.5\n        self.velocity_clamp = 0.1\n        \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def initialize_velocity(self):\n        return np.random.uniform(-self.velocity_clamp, self.velocity_clamp, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        periodicity_error = np.sum((solution - np.roll(solution, 2))**2)\n        return periodicity_error\n\n    def differential_evolution_step(self, population, lb, ub, func):\n        new_population = np.empty_like(population)\n        current_best_score = np.min([func(ind) for ind in population])  # Added line\n        self.scale_factor = 0.5 + 0.5 * (current_best_score / self.budget)  # Adjusted line\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_weight * self.periodicity_cost(trial)\n\n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def pso_step(self, population, velocity, personal_best, global_best, lb, ub):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        velocity = self.velocity_clamp * (velocity \n                                          + self.pso_weight * r1 * (personal_best - population) \n                                          + self.pso_weight * r2 * (global_best - population))\n        population = np.clip(population + velocity, lb, ub)\n        return population, velocity\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        velocity = self.initialize_velocity()\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        best_solution = None\n        best_score = float('inf')\n        \n        for _ in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func)\n            population, velocity = self.pso_step(population, velocity, personal_best, global_best, lb, ub)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                \n                if score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = score\n                \n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n                    global_best = best_solution\n        \n        return best_solution", "name": "DynamicSymbioticEvolution", "description": "Enhanced Dynamic Symbiotic Evolution (EDSE) refines the interplay between DE and PSO by dynamically adjusting the scale factor and PSO weight based on convergence progress to optimize multilayered photonic structures, while maintaining periodicity.", "configspace": "", "generation": 4, "fitness": 0.931654160552467, "feedback": "The algorithm DynamicSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.932 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7687f2bf-648f-42bc-aef9-f262da6fd516", "metadata": {"aucs": [0.9354061070278157, 0.9423180100217049, 0.9172383646078808], "final_y": [0.16485626884803328, 0.16496348085137558, 0.16550908101092843]}, "mutation_prompt": null}
{"id": "478aab22-83cf-4d3b-bb7a-bddb6942de9b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DynamicSymbioticEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.8\n        self.crossover_probability = 0.7\n        self.periodicity_weight = 0.2\n        self.pso_weight = 0.5\n        self.velocity_clamp = 0.1\n        \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def initialize_velocity(self):\n        return np.random.uniform(-self.velocity_clamp, self.velocity_clamp, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        periodicity_error = np.sum((solution - np.roll(solution, 2))**2)\n        return periodicity_error\n\n    def differential_evolution_step(self, population, lb, ub, func):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            # Adaptively adjust periodicity weight based on iteration progress\n            adaptive_periodicity_weight = self.periodicity_weight * (0.5 + 0.5 * np.random.rand())\n            trial_with_periodicity = trial + adaptive_periodicity_weight * self.periodicity_cost(trial)\n\n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def pso_step(self, population, velocity, personal_best, global_best, lb, ub):\n        r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n        self.pso_weight = np.random.uniform(0.4, 0.9)  # Dynamically adjust PSO weight\n        velocity = self.velocity_clamp * (velocity \n                                          + self.pso_weight * r1 * (personal_best - population) \n                                          + self.pso_weight * r2 * (global_best - population))\n        population = np.clip(population + velocity, lb, ub)\n        return population, velocity\n    \n    def local_optimization(self, x0, func, lb, ub):\n        # Adjusted local optimizer integration for efficiency\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)], options={'maxiter': 10})\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        velocity = self.initialize_velocity()\n        personal_best = population.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        best_solution = None\n        best_score = float('inf')\n        \n        for _ in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func)\n            population, velocity = self.pso_step(population, velocity, personal_best, global_best, lb, ub)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                \n                if score < personal_best_scores[i]:\n                    personal_best[i] = population[i]\n                    personal_best_scores[i] = score\n                \n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n                    global_best = best_solution\n        \n        return best_solution", "name": "DynamicSymbioticEvolution", "description": "Enhanced Dynamic Symbiotic Evolution with adaptive periodicity weight and improved local optimization integration to optimize multilayered photonic structures.", "configspace": "", "generation": 4, "fitness": 0.9359264558770709, "feedback": "The algorithm DynamicSymbioticEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.936 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e54e3235-5479-49dd-bff8-134cf447c088", "metadata": {"aucs": [0.9482229930016267, 0.9423180100217049, 0.9172383646078808], "final_y": [0.164989953685585, 0.16496348085137558, 0.16550908101092843]}, "mutation_prompt": null}
{"id": "6151b31f-1430-481c-9b1d-f1c94594b197", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.8  # Adjusted to enhance exploration\n        self.periodicity_weight = 0.5  # Increased to strengthen periodicity bias\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Improved Adaptive Periodic Differential Evolution with adjusted periodicity weight and dynamic crossover probability.", "configspace": "", "generation": 5, "fitness": 0.9444937432476804, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d8ebfe62-5a76-4b2c-a973-a85ce65490c7", "metadata": {"aucs": [0.9532824880203105, 0.9481220126341869, 0.9320767290885443], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "4eaa7ee9-55e9-4030-b741-d73085533c02", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.35  # Changed from 0.3 to 0.35\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced Adaptive Periodic Differential Evolution with refined periodicity cost calculation by adjusting the periodicity weight to further boost optimization in multilayered photonic structures.", "configspace": "", "generation": 5, "fitness": 0.9478965412094285, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.948 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e1dd0904-9df8-44d6-b33d-a6aca1088536", "metadata": {"aucs": [0.9532824880203105, 0.9583304065194305, 0.9320767290885443], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "0479f63c-a0de-4b77-b7ef-e940d6ab787c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced AdaptivePeriodicDE by refining periodicity cost calculation and introducing adaptive population size based on convergence rate.", "configspace": "", "generation": 5, "fitness": 0.9513755090769033, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d8ebfe62-5a76-4b2c-a973-a85ce65490c7", "metadata": {"aucs": [0.9637193916227346, 0.9583304065194305, 0.9320767290885443], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "1163e707-e369-4cf4-bec4-68f28829355b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(np.sin(solution))\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size)) * (1 + 0.1 * np.sin(gen))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial) * (1 + 0.1 * np.cos(gen))\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhance AdaptivePeriodicDE by adjusting the scale factor and periodicity weight dynamically for better convergence.", "configspace": "", "generation": 5, "fitness": 0.9478965412094285, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.948 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9404fd50-5e5d-4cbb-8b50-d8189b508f7d", "metadata": {"aucs": [0.9532824880203105, 0.9583304065194305, 0.9320767290885443], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "d2fd39fd-0e55-4b8c-a3b7-d5d763506687", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass BraggMirrorOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Changed from 10 * dim to 12 * dim\n        self.scale_factor = 0.8\n        self.crossover_probability = 0.7\n        self.periodicity_weight = 0.2\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        periodicity_error = np.sum((solution - np.roll(solution, 2))**2)\n        return periodicity_error\n    \n    def differential_evolution_step(self, population, lb, ub, func):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip((a + c) / 2 + self.scale_factor * (c - b), lb, ub)  # Changed from a + self.scale_factor * (c - b)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_weight * self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for _ in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "BraggMirrorOptimizer", "description": "Enhanced mutation strategy using a weighted average of vectors to improve diversity and exploration in the algorithm.", "configspace": "", "generation": 5, "fitness": 0.9374172671163122, "feedback": "The algorithm BraggMirrorOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.937 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2ae80906-3268-4bf0-ab7a-83b8154e4802", "metadata": {"aucs": [0.9492688712814552, 0.9440386550800896, 0.9189442749873923], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "b19ed32b-b1db-48c5-ada9-9e786f91143f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.8  # Adjusted to enhance exploration\n        self.periodicity_weight = 0.5  # Increased to strengthen periodicity bias\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * np.exp(-gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial) * (1 + 0.1 * (gen / self.budget))  # Adaptive periodicity weight\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced periodicity bias and dynamic crossover probability by introducing adaptive periodicity weight and incorporating a temperature-based cooling schedule in the crossover probability.", "configspace": "", "generation": 6, "fitness": 0.9414461004566297, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "6151b31f-1430-481c-9b1d-f1c94594b197", "metadata": {"aucs": [0.9532824880203105, 0.9481220126341869, 0.9229338007153918], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "f0733594-b989-4166-be3d-401c8565e8d9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.38  # Changed from 0.35 to 0.38\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Refined AdaptivePeriodicDE by adjusting the periodicity_weight to further boost optimization in multilayered photonic structures.", "configspace": "", "generation": 6, "fitness": 0.9393943071142927, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.939 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4eaa7ee9-55e9-4030-b741-d73085533c02", "metadata": {"aucs": [0.9532824880203105, 0.9419666326071758, 0.9229338007153918], "final_y": [0.16485632498843794, 0.16485932362977007, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "7b0b98f7-c1bc-4e94-ad73-3662819428ef", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced AdaptivePeriodicDE by modifying the crossover probability to adaptively decrease over generations for improved solution convergence.", "configspace": "", "generation": 6, "fitness": 0.9449250683241045, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.945 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0479f63c-a0de-4b77-b7ef-e940d6ab787c", "metadata": {"aucs": [0.9637193916227346, 0.9481220126341869, 0.9229338007153918], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "c77d3f28-d9a2-45ad-b6e8-bf0fedcc4f9f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.35  # Changed from 0.3 to 0.35\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution, gen):  # Modified function signature\n        periodicity_weight_dynamic = self.periodicity_weight * (1 - gen / (self.budget // self.population_size))  # Dynamically adjust periodicity weight\n        return np.sum((solution - np.roll(solution, 1))**2) - periodicity_weight_dynamic * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)  # Pass `gen` to the changed function\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Introduced a dynamic periodicity weight adjustment based on generation count to improve convergence in the Adaptive Periodic Differential Evolution algorithm.", "configspace": "", "generation": 6, "fitness": 0.9414461004566297, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4eaa7ee9-55e9-4030-b741-d73085533c02", "metadata": {"aucs": [0.9532824880203105, 0.9481220126341869, 0.9229338007153918], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "6922257e-f682-43b4-b983-c76073bbaa2f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(np.sin(solution))\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size)) * (1 + 0.1 * np.sin(gen))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            self.crossover_probability = 0.9 - 0.5 * (gen / (self.budget // self.population_size))  # Adjust crossover probability\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial) * (1 + 0.1 * np.cos(gen))\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.05:  # Reinitialize some individuals to enhance exploration\n                    population[i] = np.random.uniform(lb, ub, self.dim)\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhance AdaptivePeriodicDE by dynamically adapting crossover probability and introducing random reinitialization to improve global search.", "configspace": "", "generation": 6, "fitness": 0.9384772615337904, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.938 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "1163e707-e369-4cf4-bec4-68f28829355b", "metadata": {"aucs": [0.9443759712517926, 0.9481220126341869, 0.9229338007153918], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "07d20d72-9522-4565-8e68-0577e1bbe8de", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n\n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size + 1))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size + 1)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n\n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n\n        return new_population\n\n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n\n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n\n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Refined AdaptivePeriodicDE by enhancing periodicity management and adapting scale factor and crossover probability for improved convergence.", "configspace": "", "generation": 7, "fitness": 0.9514375060876445, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7b0b98f7-c1bc-4e94-ad73-3662819428ef", "metadata": {"aucs": [0.9637193916227346, 0.958414455650413, 0.9321786709897859], "final_y": [0.16485632498843794, 0.16485665264553784, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "3366cf81-f122-46f6-a91c-6fe386e6d386", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.8  # Adjusted to enhance exploration\n        self.periodicity_weight = 0.5  # Increased to strengthen periodicity bias\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))  # Dynamically adjust crossover probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Refine AdaptivePeriodicDE by dynamically adjusting the crossover probability over generations to enhance convergence.", "configspace": "", "generation": 7, "fitness": 0.9479585382201697, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.948 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "6151b31f-1430-481c-9b1d-f1c94594b197", "metadata": {"aucs": [0.9532824880203105, 0.958414455650413, 0.9321786709897859], "final_y": [0.16485632498843794, 0.16485665264553784, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "5a4093c7-f1b5-485f-a545-7a8cf04f35a1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution, gen):\n        dynamic_weight = self.periodicity_weight * (1 + gen / (self.budget // self.population_size))\n        return np.sum((solution - np.roll(solution, 1))**2) - dynamic_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Improved solution exploration by dynamically adjusting the periodicity weight based on generation number for enhanced convergence.", "configspace": "", "generation": 7, "fitness": 0.9514375060876445, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7b0b98f7-c1bc-4e94-ad73-3662819428ef", "metadata": {"aucs": [0.9637193916227346, 0.958414455650413, 0.9321786709897859], "final_y": [0.16485632498843794, 0.16485665264553784, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "fe4a86b1-97e2-4702-a912-973ae82da842", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.cos(np.arange(self.dim) * np.pi / self.dim))  # Tweaked initialization\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen / (self.budget // self.population_size))  # Dynamic scheduling\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Improved AdaptivePeriodicDE by adjusting the periodicity weight scheduling dynamically and tweaking the initialization strategy for more efficient search.", "configspace": "", "generation": 7, "fitness": 0.9514385444494917, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7b0b98f7-c1bc-4e94-ad73-3662819428ef", "metadata": {"aucs": [0.9637225067082762, 0.958414455650413, 0.9321786709897859], "final_y": [0.16485650919719053, 0.16485665264553784, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "a4518741-8f87-40b6-8644-ba219e650234", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.8  # Adjusted to enhance exploration\n        self.periodicity_weight = 0.5  # Increased to strengthen periodicity bias\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution, gen):\n        weight_adaptive = self.periodicity_weight * (1 + (gen / (self.budget // self.population_size)))\n        return np.sum((solution - np.roll(solution, 1))**2) - weight_adaptive * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size)) * (1 + gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Introduced adaptive scale factor and periodicity weight based on generation count for improved convergence.", "configspace": "", "generation": 7, "fitness": 0.9479585382201697, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.948 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "6151b31f-1430-481c-9b1d-f1c94594b197", "metadata": {"aucs": [0.9532824880203105, 0.958414455650413, 0.9321786709897859], "final_y": [0.16485632498843794, 0.16485665264553784, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "815d614e-8eba-4d61-bb4f-af03d83a7055", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        # Enhanced periodicity cost calculation for better convergence\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.sum(np.cos(2 * np.pi * np.arange(self.dim) / self.dim) * solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced periodicity cost function to improve the emphasis on periodicity, aiming for better convergence.", "configspace": "", "generation": 8, "fitness": 0.9483278662858523, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.948 with standard deviation 0.018. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0479f63c-a0de-4b77-b7ef-e940d6ab787c", "metadata": {"aucs": [0.9637193916227346, 0.9583304065194305, 0.9229338007153918], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "1dd6fd25-4248-446f-9e32-e71fb8bae830", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution, gen):\n        dynamic_weight = self.periodicity_weight * (1 + gen / (self.budget // self.population_size))\n        return np.sum((solution - np.roll(solution, 1))**2) - dynamic_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.cos(np.pi * gen / (self.budget // self.population_size))  # Changed line\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Refined periodicity adjustment by modifying the scale factor calculation for enhanced exploration and convergence.", "configspace": "", "generation": 8, "fitness": 0.9449250683241045, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.945 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5a4093c7-f1b5-485f-a545-7a8cf04f35a1", "metadata": {"aucs": [0.9637193916227346, 0.9481220126341869, 0.9229338007153918], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "ae96b2a7-6c0f-4726-81b0-80fad708c86d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))  # Adjusted crossover\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhance AdaptivePeriodicDE by dynamically adjusting the crossover probability based on generation number for improved convergence.", "configspace": "", "generation": 8, "fitness": 0.9449250683241045, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.945 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0479f63c-a0de-4b77-b7ef-e940d6ab787c", "metadata": {"aucs": [0.9637193916227346, 0.9481220126341869, 0.9229338007153918], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "ccdf3f24-2cbe-4649-8402-d4c0381e137d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.cos(np.arange(self.dim) * np.pi / self.dim))  # Tweaked initialization\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen / (self.budget // self.population_size)) * (0.5 + 0.5 * np.cos(2 * np.pi * gen / self.budget))  # Adjusted weight with cosine modulation\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced AdaptivePeriodicDE by modifying the periodicity weight function to include a cosine wave modulation for finer control over periodicity influence.", "configspace": "", "generation": 8, "fitness": 0.9449261066859517, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.945 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fe4a86b1-97e2-4702-a912-973ae82da842", "metadata": {"aucs": [0.9637225067082762, 0.9481220126341869, 0.9229338007153918], "final_y": [0.16485650919719053, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "57395ce7-268b-4cd0-a089-bb3426230b52", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.8  # Adjusted to enhance exploration\n        self.periodicity_weight = 0.5  # Increased to strengthen periodicity bias\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution, gen):\n        return np.sum((solution - np.roll(solution, 1))**2) - (self.periodicity_weight * (1 - gen / (self.budget // self.population_size))) * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))  # Dynamically adjust crossover probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Refine AdaptivePeriodicDE by incorporating adaptive periodicity weight adjustment for improved convergence and solution quality.", "configspace": "", "generation": 8, "fitness": 0.9414461004566297, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3366cf81-f122-46f6-a91c-6fe386e6d386", "metadata": {"aucs": [0.9532824880203105, 0.9481220126341869, 0.9229338007153918], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "5dae79c9-2ce0-4865-94b7-3169643b124e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.8 + 0.2 * np.sin(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial) * 0.5  # Adaptive periodicity correction\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced local exploitation by adjusting scale factor for DE and added adaptive periodicity correction in trial solution creation.", "configspace": "", "generation": 9, "fitness": 0.9513755090769033, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0479f63c-a0de-4b77-b7ef-e940d6ab787c", "metadata": {"aucs": [0.9637193916227346, 0.9583304065194305, 0.9320767290885443], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "c7f8e1bd-d78e-468a-a773-c16bd036d518", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.5 + 0.5 * np.sin(np.pi * gen / (self.budget // self.population_size)))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Slightly adjusted the scale factor calculation to enhance the balance between exploration and exploitation during the optimization process.", "configspace": "", "generation": 9, "fitness": 0.9513755090769033, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0479f63c-a0de-4b77-b7ef-e940d6ab787c", "metadata": {"aucs": [0.9637193916227346, 0.9583304065194305, 0.9320767290885443], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "88e9b504-137a-4104-ae43-54701f09362a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            self.periodicity_weight = 0.3 + 0.7 * (gen / (self.budget // self.population_size))  # Update periodicity weight\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced AdaptivePeriodicDE by refining the periodicity weight update strategy for improved solution periodicity.", "configspace": "", "generation": 9, "fitness": 0.9513755090769033, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0479f63c-a0de-4b77-b7ef-e940d6ab787c", "metadata": {"aucs": [0.9637193916227346, 0.9583304065194305, 0.9320767290885443], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "28fec926-6263-41ad-b6f4-ae6bf57b80ea", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        # Enhanced periodicity cost calculation for better convergence\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.sum(np.cos(2 * np.pi * np.arange(self.dim) / self.dim) * solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            self.periodicity_weight = 0.3 + 0.7 * (gen / (self.budget // self.population_size))  # Adjusted line\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Refined periodicity management by enhancing the periodicity weight scheduling to better adapt to the optimization landscape.", "configspace": "", "generation": 9, "fitness": 0.9513755090769033, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "815d614e-8eba-4d61-bb4f-af03d83a7055", "metadata": {"aucs": [0.9637193916227346, 0.9583304065194305, 0.9320767290885443], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "b4607714-27f6-42f3-96a8-c36c315bc22c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        # Enhanced periodicity cost calculation for better convergence\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.sum(np.cos(2 * np.pi * np.arange(self.dim) / self.dim) * solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * np.cos(gen / self.budget * np.pi)) # dynamic adjustment\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + 0.5 * self.periodicity_cost(trial)  # partial periodicity influence\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced exploration by dynamically adjusting crossover probability and incorporating partial periodicity-based mutation for improved convergence.", "configspace": "", "generation": 9, "fitness": 0.9513755090769033, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "815d614e-8eba-4d61-bb4f-af03d83a7055", "metadata": {"aucs": [0.9637193916227346, 0.9583304065194305, 0.9320767290885443], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "b578e5c6-0643-4336-b000-e62e50345798", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.cos(np.arange(self.dim) * np.pi / self.dim))\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen / (self.budget // self.population_size))\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        diversity = np.mean(np.std(population, axis=0))  # Calculate population diversity\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (1 + diversity) * np.sin(np.pi * gen / (self.budget // self.population_size))  # Adapt scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Refined AdaptivePeriodicDE by dynamically adapting scale factor based on population diversity to enhance convergence.", "configspace": "", "generation": 10, "fitness": 0.9514045638157445, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fe4a86b1-97e2-4702-a912-973ae82da842", "metadata": {"aucs": [0.9637225067082762, 0.958414455650413, 0.9320767290885443], "final_y": [0.16485650919719053, 0.16485665264553784, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "3a3f0681-6c39-4be3-be28-3f61c1051b95", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveWavefrontDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.index_adjustment_weight = 0.1\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def refractive_index_adjustment(self, solution, gen):\n        # Adjust refractive indices to favor constructive interference dynamically\n        phase_shift = (np.cos(2 * np.pi * np.arange(self.dim) / self.dim) +\n                       np.sin(np.pi * gen / (self.budget // self.population_size)))\n        return solution + self.index_adjustment_weight * phase_shift\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.cos(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_adjustment = self.refractive_index_adjustment(trial, gen)\n            \n            if func(trial_with_adjustment) < func(population[i]):\n                new_population[i] = trial_with_adjustment\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptiveWavefrontDE", "description": "Introduced an Adaptive Wavefront Propagation DE with dynamic refractive index adjustments to enhance constructive interference in multilayer optimization.", "configspace": "", "generation": 10, "fitness": 0.9575311822479803, "feedback": "The algorithm AdaptiveWavefrontDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.028. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0479f63c-a0de-4b77-b7ef-e940d6ab787c", "metadata": {"aucs": [0.97347238838769, 0.9815530240004172, 0.917568134355834], "final_y": [0.164857165475093, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "d682aae9-e27e-45c6-beba-ec61e9940321", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.8 + 0.2 * np.sin(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + (self.periodicity_cost(trial) * 0.5 * gen / (self.budget // self.population_size))  # Dynamic periodicity correction\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced exploitation by fine-tuning the periodicity weight dynamically based on generation progress for better convergence.", "configspace": "", "generation": 10, "fitness": 0.9549061784880335, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.955 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5dae79c9-2ce0-4865-94b7-3169643b124e", "metadata": {"aucs": [0.9743113998561256, 0.9583304065194305, 0.9320767290885443], "final_y": [0.16485712454319468, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "e764d604-dbd6-4471-ad3f-e8378cb7dda4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = lambda gen: 0.9 * (1 - gen / (self.budget // self.population_size))\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability(gen)\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Improved convergence by dynamically adjusting the crossover probability based on the generation number.", "configspace": "", "generation": 10, "fitness": 0.9513755090769033, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0479f63c-a0de-4b77-b7ef-e940d6ab787c", "metadata": {"aucs": [0.9637193916227346, 0.9583304065194305, 0.9320767290885443], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "ac94369d-92f3-402b-8022-132c1d714f9b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution, gen):\n        dynamic_weight = self.periodicity_weight * (1 + gen / (self.budget // self.population_size))\n        return np.sum((solution - np.roll(solution, 1))**2) - dynamic_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            # Dynamic crossover probability adjustment\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / self.budget))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Improved the exploration strategy by adjusting crossover probability dynamically based on generation number for better convergence.", "configspace": "", "generation": 10, "fitness": 0.9513755090769033, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5a4093c7-f1b5-485f-a545-7a8cf04f35a1", "metadata": {"aucs": [0.9637193916227346, 0.9583304065194305, 0.9320767290885443], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "d53c5514-1692-4673-9262-a311fead27ef", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.8 + 0.2 * np.sin(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * np.sin(np.pi * gen / self.budget))  # Oscillating crossover probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + (self.periodicity_cost(trial) * 0.5 * gen / (self.budget // self.population_size))  # Dynamic periodicity correction\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced AdaptivePeriodicDE by incorporating an oscillating crossover probability for improved solution diversity and convergence.", "configspace": "", "generation": 11, "fitness": 0.9511933158554973, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d682aae9-e27e-45c6-beba-ec61e9940321", "metadata": {"aucs": [0.9630708700572752, 0.9583304065194305, 0.9321786709897859], "final_y": [0.16485632498843794, 0.16485620555962366, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "4b8864fa-e6f3-4a31-92dd-a89d6202ac62", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.8 + 0.2 * np.sin(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            # Adjust crossover probability dynamically based on generation\n            crossover_probability = self.crossover_probability * (0.8 + 0.2 * np.cos(np.pi * gen / (self.budget // self.population_size)))\n            cross_points = np.random.rand(self.dim) < crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + (self.periodicity_cost(trial) * 0.5 * gen / (self.budget // self.population_size))  # Dynamic periodicity correction\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Improved AdaptivePeriodicDE by dynamically adjusting the crossover probability for enhanced solution exploration and convergence.", "configspace": "", "generation": 11, "fitness": 0.9549681754987748, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.955 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d682aae9-e27e-45c6-beba-ec61e9940321", "metadata": {"aucs": [0.9743113998561256, 0.958414455650413, 0.9321786709897859], "final_y": [0.16485712454319468, 0.16485665264553784, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "67b4edf1-4b5d-4a26-9765-e83c6cd158b6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution, gen):\n        dynamic_weight = self.periodicity_weight * (1 + gen / (self.budget // self.population_size))\n        return np.sum((solution - np.roll(solution, 1))**2) - dynamic_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * np.cos(np.pi * gen / (self.budget // self.population_size)))  # Changed line\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Improved exploration by dynamically adjusting crossover probability based on generation number for better convergence.", "configspace": "", "generation": 11, "fitness": 0.9514375060876445, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5a4093c7-f1b5-485f-a545-7a8cf04f35a1", "metadata": {"aucs": [0.9637193916227346, 0.958414455650413, 0.9321786709897859], "final_y": [0.16485632498843794, 0.16485665264553784, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "0231f663-0319-4d32-98fa-5e79146f379d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveWavefrontDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.index_adjustment_weight = 0.1\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def refractive_index_adjustment(self, solution, gen):\n        phase_shift = (np.cos(2 * np.pi * np.arange(self.dim) / self.dim) +\n                       np.sin(np.pi * gen / (self.budget // self.population_size)))\n        return solution + self.index_adjustment_weight * phase_shift\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        self.crossover_probability = 0.9 - 0.5 * (gen / (self.budget // self.population_size))  # Line changed\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.cos(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_adjustment = self.refractive_index_adjustment(trial, gen)\n            \n            if func(trial_with_adjustment) < func(population[i]):\n                new_population[i] = trial_with_adjustment\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptiveWavefrontDE", "description": "Enhanced AdaptiveWavefrontDE by introducing dynamic crossover probability adjustment for better exploration-exploitation trade-off.", "configspace": "", "generation": 11, "fitness": 0.9575311822479803, "feedback": "The algorithm AdaptiveWavefrontDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.028. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3a3f0681-6c39-4be3-be28-3f61c1051b95", "metadata": {"aucs": [0.97347238838769, 0.9815530240004172, 0.917568134355834], "final_y": [0.164857165475093, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "5e7e4b76-2d99-41e2-aa86-a3d444296291", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.cos(np.arange(self.dim) * np.pi / self.dim))  # Tweaked initialization\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen / (self.budget // self.population_size))  # Dynamic scheduling\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        dynamic_crossover_probability = self.crossover_probability * np.cos(np.pi * gen / (self.budget // self.population_size))\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (dynamic_crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Tweaked the crossover probability dynamically for improved exploration.", "configspace": "", "generation": 11, "fitness": 0.9514385444494917, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fe4a86b1-97e2-4702-a912-973ae82da842", "metadata": {"aucs": [0.9637225067082762, 0.958414455650413, 0.9321786709897859], "final_y": [0.16485650919719053, 0.16485665264553784, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "ee0815dc-631b-41d3-aa79-50578290f30e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution, best_solution):\n        weight_adjustment = np.linalg.norm(solution - best_solution) / self.dim\n        return np.sum((solution - np.roll(solution, 1))**2) - (self.periodicity_weight + weight_adjustment) * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen, best_solution):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.8 + 0.2 * np.sin(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + (self.periodicity_cost(trial, best_solution) * 0.5 * gen / (self.budget // self.population_size))  # Dynamic periodicity correction\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen, best_solution)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced AdaptivePeriodicDE by dynamically adjusting the periodicity weight based on the current best solution to achieve better convergence.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"unsupported operand type(s) for -: 'float' and 'NoneType'\").", "error": "TypeError(\"unsupported operand type(s) for -: 'float' and 'NoneType'\")", "parent_id": "d682aae9-e27e-45c6-beba-ec61e9940321", "metadata": {}, "mutation_prompt": null}
{"id": "c1c014cf-4660-4553-9fbe-af3171f3cc58", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveWavefrontDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.index_adjustment_weight = 0.1\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def refractive_index_adjustment(self, solution, gen):\n        # Adjust refractive indices to favor constructive interference dynamically\n        phase_shift = (np.cos(2 * np.pi * np.arange(self.dim) / self.dim) +\n                       np.sin(np.pi * gen / (self.budget // self.population_size)))\n        return solution + self.index_adjustment_weight * phase_shift\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.cos(np.pi * gen / (self.budget // self.population_size)) * np.random.uniform(0.5, 1.5)\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_adjustment = self.refractive_index_adjustment(trial, gen)\n            \n            if func(trial_with_adjustment) < func(population[i]):\n                new_population[i] = trial_with_adjustment\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptiveWavefrontDE", "description": "Enhanced AdaptiveWavefrontDE by dynamically adjusting the scale factor for better adaptability in varied problem landscapes.", "configspace": "", "generation": 12, "fitness": 0.9516584685934156, "feedback": "The algorithm AdaptiveWavefrontDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.952 with standard deviation 0.028. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3a3f0681-6c39-4be3-be28-3f61c1051b95", "metadata": {"aucs": [0.9627250517219396, 0.9787965320667799, 0.9134538219915272], "final_y": [0.16485751310148167, 0.16485729180328945, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "db81c91a-cdb7-4b76-90d1-8900b2501cba", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.8 + 0.2 * np.sin(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + (self.periodicity_cost(trial) * (0.5 * gen / (self.budget // self.population_size)) ** 1.1)  # Dynamic periodicity correction\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced periodicity by modifying the periodicity weight adjustment function for better convergence.", "configspace": "", "generation": 12, "fitness": 0.9641739019074196, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.019. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d682aae9-e27e-45c6-beba-ec61e9940321", "metadata": {"aucs": [0.9743113998561256, 0.9806807429908415, 0.937529562875292], "final_y": [0.16485712454319468, 0.16502689925503777, 0.1710502678042528]}, "mutation_prompt": null}
{"id": "db839fef-4dbd-47f6-9448-e9d422efa303", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.cos(np.arange(self.dim) * np.pi / self.dim))  # Tweaked initialization\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen / (self.budget // self.population_size))  # Dynamic scheduling\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', tol=1e-5, bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Tweaked the local optimization step to use a tighter convergence criterion for better fine-tuning near promising regions.", "configspace": "", "generation": 12, "fitness": 0.962310890756279, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.018. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "fe4a86b1-97e2-4702-a912-973ae82da842", "metadata": {"aucs": [0.9687223664027032, 0.9806807429908415, 0.937529562875292], "final_y": [0.16485650919719053, 0.16502689925503777, 0.1710502678042528]}, "mutation_prompt": null}
{"id": "18667393-06b0-405d-867e-520a5526509e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.8 + 0.2 * np.sin(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            crossover_probability = self.crossover_probability * (0.8 + 0.2 * np.cos(np.pi * gen / (self.budget // self.population_size)))\n            cross_points = np.random.rand(self.dim) < crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            # Tweaked periodicity correction\n            trial_with_periodicity = trial + (self.periodicity_cost(trial) * 0.1 * gen / (self.budget // self.population_size))\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)], options={'maxiter': 10})\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced AdaptivePeriodicDE by refining the local optimization integration and tweaking periodicity correction for better convergence.", "configspace": "", "generation": 12, "fitness": 0.9590535438070523, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.018. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "4b8864fa-e6f3-4a31-92dd-a89d6202ac62", "metadata": {"aucs": [0.9589503255550236, 0.9806807429908415, 0.937529562875292], "final_y": [0.16503724703014633, 0.16502689925503777, 0.1710502678042528]}, "mutation_prompt": null}
{"id": "724fa40c-d4c4-4f1c-b52f-6723cb256c1c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.8 + 0.2 * np.sin(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + (self.periodicity_cost(trial) * (0.5 * gen / (self.budget // self.population_size)) ** 1.2)  # Enhanced dynamic periodicity correction\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Improved periodicity correction by enhancing dynamic periodicity weight adaptation for better convergence.", "configspace": "", "generation": 13, "fitness": 0.9626587500874133, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.022. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "db81c91a-cdb7-4b76-90d1-8900b2501cba", "metadata": {"aucs": [0.9743113998561256, 0.9815224615485509, 0.9321423888575633], "final_y": [0.16485712454319468, 0.16485589532401457, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "7f849765-ad60-4918-893f-898fc956246b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveWavefrontDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.index_adjustment_weight = 0.1\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def refractive_index_adjustment(self, solution, gen):\n        dynamic_weight = self.index_adjustment_weight * (1 - gen / (self.budget // self.population_size))\n        phase_shift = (np.cos(2 * np.pi * np.arange(self.dim) / self.dim) +\n                       np.sin(np.pi * gen / (self.budget // self.population_size)))\n        return solution + dynamic_weight * phase_shift\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        self.crossover_probability = 0.9 - 0.5 * (gen / (self.budget // self.population_size))\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.cos(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_adjustment = self.refractive_index_adjustment(trial, gen)\n            \n            if func(trial_with_adjustment) < func(population[i]):\n                new_population[i] = trial_with_adjustment\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptiveWavefrontDE", "description": "Improved AdaptiveWavefrontDE by refining the refractive index adjustment with dynamic weight scaling for better solution adaptability.", "configspace": "", "generation": 13, "fitness": 0.9575311822479803, "feedback": "The algorithm AdaptiveWavefrontDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.028. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0231f663-0319-4d32-98fa-5e79146f379d", "metadata": {"aucs": [0.97347238838769, 0.9815530240004172, 0.917568134355834], "final_y": [0.164857165475093, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "2e0cc4fe-0add-4306-8d04-99fd67563306", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.8 + 0.2 * np.sin(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            crossover_probability = self.crossover_probability * (0.8 + 0.2 * np.cos(np.pi * gen / (self.budget // self.population_size)))\n            cross_points = np.random.rand(self.dim) < crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            # Tweaked periodicity correction\n            dynamic_periodicity_weight = self.periodicity_weight * (1.0 - float(gen) / (self.budget // self.population_size))\n            trial_with_periodicity = trial + (self.periodicity_cost(trial) * dynamic_periodicity_weight * 0.1 * gen / (self.budget // self.population_size))\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)], options={'maxiter': 10})\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced AdaptivePeriodicDE by introducing a dynamic periodicity weight adjustment to better exploit periodic patterns in solutions.", "configspace": "", "generation": 13, "fitness": 0.9590535438070523, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.018. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "18667393-06b0-405d-867e-520a5526509e", "metadata": {"aucs": [0.9589503255550236, 0.9806807429908415, 0.937529562875292], "final_y": [0.16503724703014633, 0.16502689925503777, 0.1710502678042528]}, "mutation_prompt": null}
{"id": "c78560b1-a848-4b22-a23d-d397f2f6732a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveWavefrontDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.index_adjustment_weight = 0.1\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def refractive_index_adjustment(self, solution, gen):\n        # Adjust refractive indices to favor constructive interference dynamically\n        phase_shift = (np.cos(2 * np.pi * np.arange(self.dim) / self.dim) +\n                       np.sin(np.pi * gen / (self.budget // self.population_size)))\n        return solution + self.index_adjustment_weight * phase_shift\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (1 - 0.5 * np.cos(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor oscillation\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_adjustment = self.refractive_index_adjustment(trial, gen)\n            \n            if func(trial_with_adjustment) < func(population[i]):\n                new_population[i] = trial_with_adjustment\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptiveWavefrontDE", "description": "Improved Adaptive Wavefront Propagation DE by adjusting scale factor oscillation to enhance exploration-exploitation balance. ", "configspace": "", "generation": 13, "fitness": 0.9606882823658522, "feedback": "The algorithm AdaptiveWavefrontDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.023. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3a3f0681-6c39-4be3-be28-3f61c1051b95", "metadata": {"aucs": [0.9749209047913175, 0.9782445400184959, 0.9288994022877431], "final_y": [0.16485700686728777, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "b4909d8e-7d52-4c2d-b593-7b9332d32bcc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveWavefrontDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.index_adjustment_weight = 0.1\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def refractive_index_adjustment(self, solution, gen):\n        # Adjust refractive indices to favor constructive interference dynamically\n        phase_shift = (np.cos(2 * np.pi * np.arange(self.dim) / self.dim) +\n                       np.sin(np.pi * gen / (self.budget // self.population_size)))\n        return solution + self.index_adjustment_weight * phase_shift\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        dynamic_crossover_probability = 0.7 + 0.3 * np.cos(np.pi * gen / (self.budget // self.population_size))\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.cos(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < dynamic_crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_adjustment = self.refractive_index_adjustment(trial, gen)\n            \n            if func(trial_with_adjustment) < func(population[i]):\n                new_population[i] = trial_with_adjustment\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptiveWavefrontDE", "description": "Improved exploration-exploitation balance by introducing dynamic scaling of the crossover probability.", "configspace": "", "generation": 13, "fitness": 0.9535029265623157, "feedback": "The algorithm AdaptiveWavefrontDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.020. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3a3f0681-6c39-4be3-be28-3f61c1051b95", "metadata": {"aucs": [0.953268819326011, 0.9783405580731931, 0.9288994022877431], "final_y": [0.16485785008543985, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "d4485492-55e3-46c3-b6dd-25f8fe500197", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveWavefrontDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.85  # Adjusted crossover probability\n        self.index_adjustment_weight = 0.1\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def refractive_index_adjustment(self, solution, gen):\n        # Adjust refractive indices to favor constructive interference dynamically\n        phase_shift = (np.cos(2 * np.pi * np.arange(self.dim) / self.dim) +\n                       np.sin(2 * np.pi * gen / (self.budget // self.population_size)))  # Adjusted phase shift\n        return solution + self.index_adjustment_weight * phase_shift\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (1 - 0.5 * np.cos(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor oscillation\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_adjustment = self.refractive_index_adjustment(trial, gen)\n            \n            if func(trial_with_adjustment) < func(population[i]):\n                new_population[i] = trial_with_adjustment\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptiveWavefrontDE", "description": "Refinement of Adaptive Wavefront DE by adjusting crossover probability and phase shift for enhanced search efficiency.", "configspace": "", "generation": 14, "fitness": 0.9573373692605879, "feedback": "The algorithm AdaptiveWavefrontDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.957 with standard deviation 0.018. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c78560b1-a848-4b22-a23d-d397f2f6732a", "metadata": {"aucs": [0.965390923107332, 0.9742520049982486, 0.9323691796761835], "final_y": [0.16485727097718128, 0.16485616531112002, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "8cdc8330-dd05-47ec-bd0f-d2de12f4b4ae", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.9 + 0.1 * np.cos(2 * np.pi * gen / self.budget))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            periodicity_adjustment = self.periodicity_cost(trial) * (0.6 * gen / (self.budget // self.population_size)) ** 0.9  # Dynamic periodicity correction\n            trial_with_periodicity = trial + periodicity_adjustment\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced convergence by adjusting scale factor dynamics and periodicity correction strategy.", "configspace": "", "generation": 14, "fitness": 0.9638547845418705, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.019. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "db81c91a-cdb7-4b76-90d1-8900b2501cba", "metadata": {"aucs": [0.9734690289022392, 0.9805657618480804, 0.937529562875292], "final_y": [0.16485777913495614, 0.16506967937327244, 0.1710502678042528]}, "mutation_prompt": null}
{"id": "ef22fdd9-2878-4bd7-8c92-d096d2830a29", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveWavefrontDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.index_adjustment_weight = 0.1\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def refractive_index_adjustment(self, solution, gen):\n        # Adjust refractive indices to favor constructive interference dynamically\n        phase_shift = (np.cos(2 * np.pi * np.arange(self.dim) / self.dim) +\n                       np.sin(2 * np.pi * gen / (self.budget // self.population_size)))  # Enhanced adjustment\n        return solution + self.index_adjustment_weight * phase_shift\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (1 - 0.5 * np.cos(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor oscillation\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_adjustment = self.refractive_index_adjustment(trial, gen)\n            \n            if func(trial_with_adjustment) < func(population[i]):\n                new_population[i] = trial_with_adjustment\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptiveWavefrontDE", "description": "Enhanced the refractive index adjustment to better exploit periodicity and constructive interference.", "configspace": "", "generation": 14, "fitness": 0.9607905323638967, "feedback": "The algorithm AdaptiveWavefrontDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.019. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c78560b1-a848-4b22-a23d-d397f2f6732a", "metadata": {"aucs": [0.9749209047913175, 0.9741994361887046, 0.9332512561116679], "final_y": [0.16485700686728777, 0.16485620555962366, 0.1648573074351377]}, "mutation_prompt": null}
{"id": "7e0ba41f-3101-4204-a62b-9447e9b0353e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.8  # Reduced crossover probability for better diversity\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.1 * (np.sin(np.arange(self.dim) * np.pi / self.dim))  # Enhanced initialization\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen**2 / (self.budget // self.population_size)**2)  # Quadratic scheduling\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.5 + 0.5 * np.sin(np.pi * gen / (self.budget // self.population_size)))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', tol=1e-6, bounds=[(lb[i], ub[i]) for i in range(self.dim)])  # Enhanced tolerance\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced periodicity and refined crossover probability for improved exploration and convergence.", "configspace": "", "generation": 14, "fitness": 0.9606571980732603, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.018. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "db839fef-4dbd-47f6-9448-e9d422efa303", "metadata": {"aucs": [0.9637612883536478, 0.9806807429908415, 0.937529562875292], "final_y": [0.16485609379495592, 0.16502689925503777, 0.1710502678042528]}, "mutation_prompt": null}
{"id": "af731de7-524d-4826-9d0b-bfd69a26a2af", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.8 + 0.2 * np.sin(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            crossover_probability = self.crossover_probability * (0.8 + 0.2 * np.cos(np.pi * gen / (self.budget // self.population_size)))\n            cross_points = np.random.rand(self.dim) < crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            # Tweaked periodicity correction\n            trial_with_periodicity = trial + (self.periodicity_cost(trial) * 0.1 * gen / np.sqrt(self.budget // self.population_size))  # Modified adjustment\n\n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)], options={'maxiter': 10})\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced periodicity integration by modifying the periodicity weight adjustment for improved convergence.", "configspace": "", "generation": 14, "fitness": 0.9590535438070523, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.018. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "18667393-06b0-405d-867e-520a5526509e", "metadata": {"aucs": [0.9589503255550236, 0.9806807429908415, 0.937529562875292], "final_y": [0.16503724703014633, 0.16502689925503777, 0.1710502678042528]}, "mutation_prompt": null}
{"id": "acadc852-38b7-4acb-b821-79c972b65fc3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.sin(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)  # Adjusted periodicity cost\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.8 + 0.2 * np.sin(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + (self.periodicity_cost(trial) * (0.5 * gen / (self.budget // self.population_size)) ** 1.1)  # Dynamic periodicity correction\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Fine-tuned the periodicity cost function to enhance convergence near optimal regions.", "configspace": "", "generation": 15, "fitness": 0.9626587500874133, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.022. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "db81c91a-cdb7-4b76-90d1-8900b2501cba", "metadata": {"aucs": [0.9743113998561256, 0.9815224615485509, 0.9321423888575633], "final_y": [0.16485712454319468, 0.16485589532401457, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "05c3dde8-fb0c-41c5-bc2d-7435ec0f5901", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.cos(np.arange(self.dim) * np.pi / self.dim))  # Tweaked initialization\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen / (self.budget // self.population_size))  # Dynamic scheduling\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * np.sin(np.pi * gen / (self.budget // self.population_size))) # Dynamic scaling\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', tol=1e-5, bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced the crossover strategy to utilize a dynamic probability scaling based on the generation number for better exploration.", "configspace": "", "generation": 15, "fitness": 0.9694875060914964, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "db839fef-4dbd-47f6-9448-e9d422efa303", "metadata": {"aucs": [0.9687223664027032, 0.9815224615485509, 0.9582176903232351], "final_y": [0.16485650919719053, 0.16485589532401457, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "a523a7cf-57a9-44f8-8c95-014774fbfb13", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveWavefrontDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.index_adjustment_weight = 0.1\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def refractive_index_adjustment(self, solution, gen):\n        # Adjust refractive indices to favor constructive interference dynamically\n        phase_shift = (np.cos(4 * np.pi * np.arange(self.dim) / self.dim) +  # Adjusted phase shift for better periodicity\n                       np.sin(2 * np.pi * gen / (self.budget // self.population_size)))  # Enhanced adjustment\n        return solution + self.index_adjustment_weight * phase_shift\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (1 - 0.5 * np.cos(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor oscillation\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_adjustment = self.refractive_index_adjustment(trial, gen)\n            \n            if func(trial_with_adjustment) < func(population[i]):\n                new_population[i] = trial_with_adjustment\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptiveWavefrontDE", "description": "Improved exploitation of periodicity by adjusting the cosine phase shift in the refractive index adjustment.", "configspace": "", "generation": 15, "fitness": 0.9587776931062092, "feedback": "The algorithm AdaptiveWavefrontDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.022. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ef22fdd9-2878-4bd7-8c92-d096d2830a29", "metadata": {"aucs": [0.9744441535139173, 0.9742272137017363, 0.927661712102974], "final_y": [0.16485666047289593, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "a751dd55-efe7-45fb-addc-88a229912955", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.8 + 0.2 * np.sin(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            self.crossover_probability = 0.9 - 0.3 * (gen / (self.budget // self.population_size))  # Adaptive crossover probability\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + (self.periodicity_cost(trial) * (0.5 * gen / (self.budget // self.population_size)) ** 1.2)  # Enhanced dynamic periodicity correction\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Improved convergence by adapting crossover probability based on generation progress.", "configspace": "", "generation": 15, "fitness": 0.9713505172426373, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.971 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "724fa40c-d4c4-4f1c-b52f-6723cb256c1c", "metadata": {"aucs": [0.9743113998561256, 0.9815224615485509, 0.9582176903232351], "final_y": [0.16485712454319468, 0.16485589532401457, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "66b95d2e-2c2a-4dec-b6a5-1dae8a628ef6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.cos(np.arange(self.dim) * np.pi / self.dim))  # Tweaked initialization\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen / (self.budget // self.population_size))  # Dynamic scheduling\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (1 + 0.5 * np.cos(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor dynamics\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', tol=1e-5, bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Improved differential evolution by refining scale factor dynamics for better adaptability during the optimization process.", "configspace": "", "generation": 15, "fitness": 0.9688914099385669, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "db839fef-4dbd-47f6-9448-e9d422efa303", "metadata": {"aucs": [0.9687223664027032, 0.9797341730897626, 0.9582176903232351], "final_y": [0.16485650919719053, 0.164856474788171, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "33d8cab1-b8ca-451b-8542-a84adf586f6d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.8 + 0.2 * np.sin(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / self.budget))  # Dynamic crossover probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + (self.periodicity_cost(trial) * (0.5 * gen / (self.budget // self.population_size)) ** 1.1)  # Dynamic periodicity correction\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Introduced dynamic crossover probability adjustment based on generation count to enhance diversity.", "configspace": "", "generation": 16, "fitness": 0.9623806607384698, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "db81c91a-cdb7-4b76-90d1-8900b2501cba", "metadata": {"aucs": [0.9743113998561256, 0.9746331868810281, 0.9381973954782561], "final_y": [0.16485712454319468, 0.1648577102085329, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "97d65060-e215-4037-887d-1e852467ca83", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.8 + 0.2 * np.sin(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            self.crossover_probability = 0.9 * (1 - gen / (self.budget // self.population_size))  # Adaptive crossover probability\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + (self.periodicity_cost(trial) * (0.5 * gen / (self.budget // self.population_size)) ** 1.1)  # Dynamic periodicity correction\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Introduced an adaptive crossover probability to enhance exploration capabilities over generations.", "configspace": "", "generation": 16, "fitness": 0.959421156282443, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.015. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "db81c91a-cdb7-4b76-90d1-8900b2501cba", "metadata": {"aucs": [0.9743113998561256, 0.9644242820638048, 0.9395277869273986], "final_y": [0.16485712454319468, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "00057e53-99d3-47f7-8a70-8e7df41b9c7f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.8 + 0.2 * np.sin(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            self.crossover_probability = 0.9 - 0.3 * (gen / (self.budget // self.population_size))  # Adaptive crossover probability\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + (self.periodicity_cost(trial) * (0.5 * gen / (self.budget // self.population_size)) ** 1.3)  # Enhanced dynamic periodicity correction\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Improved adaptive periodicity by adjusting the periodicity weight function to enhance global exploration.", "configspace": "", "generation": 16, "fitness": 0.9589776924660622, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.015. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a751dd55-efe7-45fb-addc-88a229912955", "metadata": {"aucs": [0.9743113998561256, 0.9644242820638048, 0.9381973954782561], "final_y": [0.16485712454319468, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "688bc6dc-a67d-4b54-b13f-e5c0fb4b4068", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.initial_periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.cos(np.arange(self.dim) * np.pi / self.dim))\n    \n    def adaptive_periodicity_cost(self, solution, gen):\n        adaptive_weight = self.initial_periodicity_weight * (1 + 0.5 * np.sin(np.pi * gen / (self.budget // self.population_size)))\n        return np.sum((solution - np.roll(solution, 1))**2) - adaptive_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (1 + 0.5 * np.cos(np.pi * gen / (self.budget // self.population_size)))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.adaptive_periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def multi_step_local_optimization(self, x0, func, lb, ub):\n        result = x0\n        for _ in range(3):  # Perform multiple local searches to refine solutions\n            res = minimize(func, result, method='L-BFGS-B', tol=1e-5, bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n            if res.success and func(res.x) < func(result):\n                result = res.x\n        return result\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.multi_step_local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Introduced adaptive periodicity weight and multi-step local search for enhanced convergence dynamics.", "configspace": "", "generation": 16, "fitness": 0.9561524269543771, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.956 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "66b95d2e-2c2a-4dec-b6a5-1dae8a628ef6", "metadata": {"aucs": [0.9658356033210705, 0.9644242820638048, 0.9381973954782561], "final_y": [0.16485650919719053, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "7a44459f-2081-4e13-b0bd-81ae3c2fb4b7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.9 + 0.1 * np.cos(2 * np.pi * gen / self.budget))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c) + 0.01 * np.random.randn(self.dim), lb, ub)  # Added noise term\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            periodicity_adjustment = self.periodicity_cost(trial) * (0.6 * gen / (self.budget // self.population_size)) ** 0.9  # Dynamic periodicity correction\n            trial_with_periodicity = trial + periodicity_adjustment\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced convergence by refining mutation strategy to promote diversity near optima.", "configspace": "", "generation": 16, "fitness": 0.9618908098473579, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.018. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8cdc8330-dd05-47ec-bd0f-d2de12f4b4ae", "metadata": {"aucs": [0.9830507520000124, 0.9644242820638048, 0.9381973954782561], "final_y": [0.16485785008543985, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "d0cf4b68-49b8-400b-81fe-b2a71fda21fc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.cos(np.arange(self.dim) * np.pi / self.dim))  # Tweaked initialization\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen / (self.budget // self.population_size))  # Dynamic scheduling\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * np.cos(np.pi * gen / (self.budget // self.population_size))) # Dynamic scaling\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', tol=1e-5, bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced differential evolution with an adaptive scale factor and crossover probability for improved exploration.", "configspace": "", "generation": 17, "fitness": 0.9688914099385669, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "05c3dde8-fb0c-41c5-bc2d-7435ec0f5901", "metadata": {"aucs": [0.9687223664027032, 0.9797341730897626, 0.9582176903232351], "final_y": [0.16485650919719053, 0.164856474788171, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "d8ccd2a3-f1f3-459a-a90d-21efc4e2b200", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.cos(np.arange(self.dim) * np.pi / self.dim))  # Tweaked initialization\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen / (self.budget // self.population_size))  # Dynamic scheduling\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (1 + np.sin(np.pi * gen / (self.budget // self.population_size)))  # Modified scale factor dynamics\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * np.sin(np.pi * gen / (self.budget // self.population_size))) # Dynamic scaling\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', tol=1e-5, bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Refined scale factor dynamics to enhance adaptability and convergence speed.", "configspace": "", "generation": 17, "fitness": 0.9688914099385669, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "05c3dde8-fb0c-41c5-bc2d-7435ec0f5901", "metadata": {"aucs": [0.9687223664027032, 0.9797341730897626, 0.9582176903232351], "final_y": [0.16485650919719053, 0.164856474788171, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "d32a2a21-0eb6-4553-afa9-d120bc7241b5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.cos(np.arange(self.dim) * np.pi / self.dim))\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen / (self.budget // self.population_size))\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        tau1, tau2 = 0.1, 0.1  # learning rates for mutation and crossover rates\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.scale_factor += tau1 * (np.random.rand() - 0.5)  # Self-adaptive mutation rate\n            self.crossover_probability += tau2 * (np.random.rand() - 0.5)  # Self-adaptive crossover rate\n            mutant = np.clip(a + self.scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', tol=1e-5, bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Improved convergence by introducing self-adaptive mutation and crossover rates and enhanced periodicity handling.", "configspace": "", "generation": 17, "fitness": 0.9688914099385669, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "05c3dde8-fb0c-41c5-bc2d-7435ec0f5901", "metadata": {"aucs": [0.9687223664027032, 0.9797341730897626, 0.9582176903232351], "final_y": [0.16485650919719053, 0.164856474788171, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "8e0da8cf-9535-4561-b8d2-c09da9240674", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.8 + 0.2 * np.sin(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            self.crossover_probability = 0.9 - 0.3 * (gen / (self.budget // self.population_size))  # Adaptive crossover probability\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            dynamic_periodicity_weight = self.periodicity_weight * (1 - gen / self.budget)  # Dynamic periodicity weight adjustment\n            trial_with_periodicity = trial + (self.periodicity_cost(trial) * dynamic_periodicity_weight)  # Enhanced dynamic periodicity correction\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        best_idx = np.argmin([func(ind) for ind in new_population])  # Elite preservation\n        if func(new_population[best_idx]) < func(population[best_idx]):\n            new_population[best_idx] = population[best_idx]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced exploration and exploitation by dynamically adjusting the periodicity weight and integrating elite preservation.", "configspace": "", "generation": 17, "fitness": 0.9651996586992428, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a751dd55-efe7-45fb-addc-88a229912955", "metadata": {"aucs": [0.9576471126847306, 0.9797341730897626, 0.9582176903232351], "final_y": [0.16485632498843794, 0.164856474788171, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "cc78cf5c-adcc-412b-a7d2-80ff8398ecd3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.cos(np.arange(self.dim) * np.pi / self.dim))  # Tweaked initialization\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen / (self.budget // self.population_size))  # Dynamic scheduling\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (1 + 0.5 * np.random.rand() * np.cos(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor dynamics\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', tol=1e-5, bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced solution diversity with adaptive scale factor randomness for better exploration.", "configspace": "", "generation": 17, "fitness": 0.9688914099385669, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "66b95d2e-2c2a-4dec-b6a5-1dae8a628ef6", "metadata": {"aucs": [0.9687223664027032, 0.9797341730897626, 0.9582176903232351], "final_y": [0.16485650919719053, 0.164856474788171, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "45bd0e60-0538-4280-b897-d16940ccea1c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.1 * (np.cos(np.arange(self.dim) * np.pi / self.dim))  # More periodic emphasis\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen / (self.budget // self.population_size))  # Dynamic scheduling\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (1 + 0.5 * np.cos(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor dynamics\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', tol=1e-5, bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced reflection by modifying initialization to more prominently emphasize periodicity in early generations.", "configspace": "", "generation": 18, "fitness": 0.968298875524337, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "66b95d2e-2c2a-4dec-b6a5-1dae8a628ef6", "metadata": {"aucs": [0.9673250233337511, 0.9794165104695403, 0.9581550927697196], "final_y": [0.1648565471665452, 0.1648565869504398, 0.16486436700977836]}, "mutation_prompt": null}
{"id": "96581623-eb44-41d7-a388-409bf97cdee5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.cos(np.arange(self.dim) * np.pi / self.dim))\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * np.exp(-gen / (self.budget // self.population_size))  # Enhanced dynamic scheduling\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * np.cos(np.pi * gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            # Diversity retention by random perturbation\n            perturbation = 0.01 * np.random.randn(self.dim) * (gen / self.budget)\n            trial_with_perturbation = np.clip(trial_with_periodicity + perturbation, lb, ub)\n            \n            if func(trial_with_perturbation) < func(population[i]):\n                new_population[i] = trial_with_perturbation\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', tol=1e-5, bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Further enhancement by introducing adaptive periodicity modulation and diversity retention strategies.", "configspace": "", "generation": 18, "fitness": 0.9688914099385669, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d0cf4b68-49b8-400b-81fe-b2a71fda21fc", "metadata": {"aucs": [0.9687223664027032, 0.9797341730897626, 0.9582176903232351], "final_y": [0.16485650919719053, 0.164856474788171, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "1ff639ec-dbef-4fb6-bdb1-187986e6d581", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.sin(np.arange(self.dim) * np.pi / self.dim))  # Tweaked initialization\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen / (self.budget // self.population_size))  # Dynamic scheduling\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (1 + np.sin(np.pi * gen / (self.budget // self.population_size)))  # Modified scale factor dynamics\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * np.sin(np.pi * gen / (self.budget // self.population_size))) # Dynamic scaling\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', tol=1e-5, bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced continuity of periodicity by refining initialization with sinusoidal modulation.", "configspace": "", "generation": 18, "fitness": 0.9686743735379105, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d8ccd2a3-f1f3-459a-a90d-21efc4e2b200", "metadata": {"aucs": [0.9685246255107585, 0.9794074295036923, 0.9580910655992809], "final_y": [0.16485652780641946, 0.1648561409393412, 0.16486109412215344]}, "mutation_prompt": null}
{"id": "50c5de32-45bf-458f-83e5-91d4f279d2a4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.sin(np.arange(self.dim) * np.pi / self.dim))  # More balanced initialization\n        \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen / (self.budget // self.population_size)) ** 2  # Stronger influence on periodicity over generations\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (1 + 0.5 * np.cos(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor dynamics\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', tol=1e-5, bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced differential evolution by improving periodicity influence and initialization robustness for better exploration.", "configspace": "", "generation": 18, "fitness": 0.9688254963079187, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "66b95d2e-2c2a-4dec-b6a5-1dae8a628ef6", "metadata": {"aucs": [0.9685246255107585, 0.9797341730897626, 0.9582176903232351], "final_y": [0.16485652780641946, 0.164856474788171, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "bb4836a1-daee-412c-936d-5d29a1031a55", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.cos(np.arange(self.dim) * np.pi / self.dim))  # Tweaked initialization\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen / self.budget)  # Adjusted dynamic scheduling\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (1 + np.sin(np.pi * gen / (self.budget // self.population_size)))  # Modified scale factor dynamics\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * np.sin(np.pi * gen / (self.budget // self.population_size))) # Dynamic scaling\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', tol=1e-5, bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Introduced a time-varying periodicity weight to improve the balance between exploration and exploitation.", "configspace": "", "generation": 18, "fitness": 0.9688914099385669, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d8ccd2a3-f1f3-459a-a90d-21efc4e2b200", "metadata": {"aucs": [0.9687223664027032, 0.9797341730897626, 0.9582176903232351], "final_y": [0.16485650919719053, 0.164856474788171, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "6215d137-e789-4341-aa7c-7b0aef8ce741", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.8 + 0.2 * np.sin(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            self.crossover_probability = 0.9 - 0.3 * (gen / (self.budget // self.population_size))  # Adaptive crossover probability\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + (self.periodicity_cost(trial) * (0.6 * gen / (self.budget // self.population_size)) ** 1.2)  # Enhanced dynamic periodicity correction\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced the periodicity correction factor for better adaptation over generations.", "configspace": "", "generation": 19, "fitness": 0.9707544210897078, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.971 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a751dd55-efe7-45fb-addc-88a229912955", "metadata": {"aucs": [0.9743113998561256, 0.9797341730897626, 0.9582176903232351], "final_y": [0.16485712454319468, 0.164856474788171, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "a1d682f1-63c0-4bde-b58c-261852038d77", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.cos(np.arange(self.dim) * np.pi / self.dim))  # Tweaked initialization\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen / (self.budget // self.population_size))  # Dynamic scheduling\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * np.sin(np.pi * gen / (self.budget // self.population_size))\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * np.sin(np.pi * gen / (self.budget // self.population_size))) # Dynamic scaling\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', tol=1e-5, bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Introduced dynamic crossover probability using sine function for improved exploration.", "configspace": "", "generation": 19, "fitness": 0.9663137413279408, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d0cf4b68-49b8-400b-81fe-b2a71fda21fc", "metadata": {"aucs": [0.9687223664027032, 0.972001167257884, 0.9582176903232351], "final_y": [0.16485650919719053, 0.1648604858817868, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "6dcf74df-d1e8-4b0b-86e2-156ba832fca2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.cos(np.arange(self.dim) * np.pi / self.dim))  # Tweaked initialization\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen / (self.budget // self.population_size)) * (0.5 + 0.5 * np.cos(np.pi * gen / (self.budget // self.population_size)))  # Dynamic adjustment\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (1 + 0.5 * np.cos(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor dynamics\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability * (1 - gen / (self.budget // self.population_size)))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', tol=1e-5, bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Introduced dynamic adjustment of the periodicity weight to enhance adaptability over generations.", "configspace": "", "generation": 19, "fitness": 0.9688914099385669, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "66b95d2e-2c2a-4dec-b6a5-1dae8a628ef6", "metadata": {"aucs": [0.9687223664027032, 0.9797341730897626, 0.9582176903232351], "final_y": [0.16485650919719053, 0.164856474788171, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "bfca0339-8361-470d-876d-07b72b406489", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(12 * dim // 2, dim)  # Slightly increased adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def periodicity_cost(self, solution):\n        return np.sum((solution - np.roll(solution, 1))**2) - self.periodicity_weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (0.8 + 0.2 * np.sin(np.pi * gen / (self.budget // self.population_size)))  # Adjusted scale factor\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            self.crossover_probability = 0.9 - 0.3 * (gen / (self.budget // self.population_size))  # Adaptive crossover probability\n            cross_points = np.random.rand(self.dim) < self.crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + (self.periodicity_cost(trial) * (0.6 * gen / (self.budget // self.population_size)) ** 1.1)  # Adjusted periodicity correction factor\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Enhanced periodicity correction and adaptive population size for improved exploration and convergence.", "configspace": "", "generation": 19, "fitness": 0.9670861772353566, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a751dd55-efe7-45fb-addc-88a229912955", "metadata": {"aucs": [0.9633066682930719, 0.9797341730897626, 0.9582176903232351], "final_y": [0.16485632498843794, 0.164856474788171, 0.16486136986862765]}, "mutation_prompt": null}
{"id": "905f09a8-e392-4d3a-bebe-38847e2288bf", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptivePeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10 * dim // 2, dim)  # Adaptive population size\n        self.scale_factor = 0.5\n        self.crossover_probability = 0.9\n        self.periodicity_weight = 0.3\n    \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim)) + 0.05 * (np.cos(np.arange(self.dim) * np.pi / self.dim))  # Tweaked initialization\n    \n    def periodicity_cost(self, solution, gen):\n        weight = self.periodicity_weight * (1 - gen / (self.budget // self.population_size))  # Dynamic scheduling\n        return np.sum((solution - np.roll(solution, 1))**2) - weight * np.cos(2 * np.pi * np.arange(self.dim) / self.dim).dot(solution)\n    \n    def differential_evolution_step(self, population, lb, ub, func, gen):\n        new_population = np.empty_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            scale_factor = self.scale_factor * (1 + np.sin(np.pi * gen / (self.budget // self.population_size)))  # Modified scale factor dynamics\n            mutant = np.clip(a + scale_factor * (b - c), lb, ub)\n            cross_points = np.random.rand(self.dim) < (self.crossover_probability + 0.05 * np.sin(2 * np.pi * gen / (self.budget // self.population_size))) # Sinusoidal adjustment\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_with_periodicity = trial + self.periodicity_cost(trial, gen)\n            \n            if func(trial_with_periodicity) < func(population[i]):\n                new_population[i] = trial_with_periodicity\n            else:\n                new_population[i] = population[i]\n        \n        return new_population\n    \n    def local_optimization(self, x0, func, lb, ub):\n        res = minimize(func, x0, method='L-BFGS-B', tol=1e-5, bounds=[(lb[i], ub[i]) for i in range(self.dim)])\n        return res.x if res.success else x0\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        best_solution = None\n        best_score = float('inf')\n        \n        for gen in range(self.budget // self.population_size):\n            population = self.differential_evolution_step(population, lb, ub, func, gen)\n            for i in range(self.population_size):\n                population[i] = self.local_optimization(population[i], func, lb, ub)\n                score = func(population[i])\n                if score < best_score:\n                    best_score = score\n                    best_solution = population[i]\n        \n        return best_solution", "name": "AdaptivePeriodicDE", "description": "Introduced sinusoidal adjustment to crossover probability for improved exploration-exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.9688914099385669, "feedback": "The algorithm AdaptivePeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d8ccd2a3-f1f3-459a-a90d-21efc4e2b200", "metadata": {"aucs": [0.9687223664027032, 0.9797341730897626, 0.9582176903232351], "final_y": [0.16485650919719053, 0.164856474788171, 0.16486136986862765]}, "mutation_prompt": null}
