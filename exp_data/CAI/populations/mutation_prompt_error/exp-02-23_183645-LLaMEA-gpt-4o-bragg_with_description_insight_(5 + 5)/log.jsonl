{"id": "393ff4a4-ec2d-4163-be73-3138410a9949", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Typical rule of thumb for DE\n        self.f = 0.8  # DE mutation factor\n        self.cr = 0.7  # DE crossover probability\n    \n    def __call__(self, func):\n        np.random.seed(42)\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        best_solution = None\n        best_score = float('inf')\n        func_calls = 0\n\n        while func_calls < self.budget:\n            new_population = []\n            for i in range(self.population_size):\n                if func_calls >= self.budget:\n                    break\n                # Differential Evolution Mutation\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), lb, ub)\n\n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.cr\n                trial = np.where(crossover_mask, mutant, population[i])\n\n                # Evaluate\n                trial_score = func(trial)\n                func_calls += 1\n\n                # Select\n                if trial_score < func(population[i]):\n                    new_population.append(trial)\n                    if trial_score < best_score:\n                        best_solution, best_score = trial, trial_score\n                else:\n                    new_population.append(population[i])\n            \n            population = np.array(new_population)\n\n            # Periodicity encouragement\n            for i in range(self.population_size):\n                if func_calls >= self.budget:\n                    break\n                trial = self._encourage_periodicity(population[i])\n                trial_score = func(trial)\n                func_calls += 1\n                if trial_score < best_score:\n                    best_solution, best_score = trial, trial_score\n\n            # Local Optimization with BFGS\n            if func_calls + self.dim <= self.budget:\n                result = minimize(func, best_solution, method='L-BFGS-B', bounds=[(lb, ub)]*self.dim)\n                func_calls += result.nfev\n                if result.fun < best_score:\n                    best_solution, best_score = result.x, result.fun\n\n        return best_solution, best_score\n\n    def _encourage_periodicity(self, solution):\n        # Encourage periodicity by averaging segments of the solution\n        mid = self.dim // 2\n        periodic_solution = np.concatenate([solution[:mid], solution[:mid]])\n        return np.clip(periodic_solution, solution.min(), solution.max())", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic algorithm combining Differential Evolution for global exploration with a local optimization refinement step using BFGS, tailored to encourage periodicity and modularity in multilayered photonic structure optimization.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 61, in __call__\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 670, in minimize\n    bounds = standardize_bounds(bounds, x0, 'new')\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 1058, in standardize_bounds\n    lb, ub = old_bound_to_new(bounds)\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_constraints.py\", line 437, in old_bound_to_new\n    lb = np.array([float(_arr_to_scalar(x)) if x is not None else -np.inf\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_constraints.py\", line 437, in <listcomp>\n    lb = np.array([float(_arr_to_scalar(x)) if x is not None else -np.inf\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_constraints.py\", line 14, in _arr_to_scalar\n    return x.item() if isinstance(x, np.ndarray) else x\nValueError: can only convert an array of size 1 to a Python scalar\n.", "error": "ValueError('can only convert an array of size 1 to a Python scalar')Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 61, in __call__\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 670, in minimize\n    bounds = standardize_bounds(bounds, x0, 'new')\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 1058, in standardize_bounds\n    lb, ub = old_bound_to_new(bounds)\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_constraints.py\", line 437, in old_bound_to_new\n    lb = np.array([float(_arr_to_scalar(x)) if x is not None else -np.inf\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_constraints.py\", line 437, in <listcomp>\n    lb = np.array([float(_arr_to_scalar(x)) if x is not None else -np.inf\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_constraints.py\", line 14, in _arr_to_scalar\n    return x.item() if isinstance(x, np.ndarray) else x\nValueError: can only convert an array of size 1 to a Python scalar\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "072efe26-4b05-4f33-bbaa-d43dcb7100e2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDELocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Population size, a standard choice is 10 times the dimension\n        self.crossover_rate = 0.7\n        self.differential_weight = 0.8\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        # Initialize population with symmetric and random values\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in pop])\n        evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while evaluations < self.budget:\n            new_pop = np.copy(pop)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.differential_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Evaluate trial point\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Check if the trial is better and update\n                if trial_fitness < fitness[i]:\n                    new_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best = trial\n                        best_fitness = trial_fitness\n\n            pop = new_pop\n\n            # Local search for a fraction of the population\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size // 5):  # Randomly pick 20% of the population\n                    if evaluations >= self.budget:\n                        break\n                    local_search_result = minimize(func, pop[i], bounds=list(zip(lb, ub)), method='L-BFGS-B')\n                    evaluations += local_search_result.nfev\n                    if local_search_result.fun < fitness[i]:\n                        pop[i] = local_search_result.x\n                        fitness[i] = local_search_result.fun\n                        if local_search_result.fun < best_fitness:\n                            best = local_search_result.x\n                            best_fitness = local_search_result.fun                      \n\n        return best", "name": "HybridDELocalSearch", "description": "A novel hybrid metaheuristic that combines Differential Evolution for global exploration with gradient-based local search to enhance solution refinement, tailored to leverage periodicity and symmetrical properties in multilayer photonic structure optimization.", "configspace": "", "generation": 0, "fitness": 0.9299788450525212, "feedback": "The algorithm HybridDELocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.019. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": null, "metadata": {"aucs": [0.955941433866354, 0.9211799188470983, 0.9128151824441113], "final_y": [0.16485751310148167, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "fbbe0188-f6eb-41db-af28-2424d1cd9b3d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDEPeriodicOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.7\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def evolve_population(self, population, func):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n            x1, x2, x3 = population[indices]\n            mutant_vector = x1 + self.mutation_factor * (x2 - x3)\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            \n            cross_points = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n                \n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            if func(trial_vector) < func(population[i]):\n                new_population[i] = trial_vector\n\n        return new_population\n\n    def periodic_local_search(self, individual, func):\n        def periodicity_objective(x):\n            regularity_penalty = np.sum((x[:-1] - x[1:])**2)\n            return func(x) + 0.1 * regularity_penalty\n\n        result = minimize(periodicity_objective, individual, bounds=[(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        population = self.initialize_population(func.bounds.lb, func.bounds.ub)\n        evaluations = 0\n        best_solution = None\n        best_value = float('inf')\n\n        while evaluations < self.budget:\n            population = self.evolve_population(population, func)\n            evaluations += self.population_size\n\n            for individual in population:\n                optimized_individual = self.periodic_local_search(individual, func)\n                individual_value = func(optimized_individual)\n                evaluations += 1\n\n                if individual_value < best_value:\n                    best_value = individual_value\n                    best_solution = optimized_individual\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_solution", "name": "HybridDEPeriodicOptimization", "description": "A hybrid global-local metaheuristic combining Differential Evolution with periodicity-promoting local search to optimize multilayer photonic structures.", "configspace": "", "generation": 0, "fitness": 0.8868514319520707, "feedback": "The algorithm HybridDEPeriodicOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.079. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7760963570052928, 0.9516734868864559, 0.9327844519644634], "final_y": [0.17320964713874876, 0.17328269096240967, 0.17317182707450307]}, "mutation_prompt": null}
{"id": "88f481b7-03dd-4c0b-ab66-3cb2c4f9a21d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass BraggMirrorOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = 2  # Period to enforce (could be tuned or made adaptive)\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub):\n        for i in range(self.population_size):\n            # Select three random indices different from i\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            # Mutation\n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Crossover\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            # Periodicity promotion\n            trial = self._apply_periodicity_promotion(trial)\n            \n            # Selection\n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)  # Minimize negative reflectivity for maximization\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub)\n            evaluations += self.population_size\n            \n            # Local optimization step\n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "BraggMirrorOptimizer", "description": "A hybrid metaheuristic that combines Differential Evolution with adaptive periodicity promotion and local optimization to efficiently explore and exploit multimodal landscapes in multilayer Bragg mirror design.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 66, in __call__\n  File \"<string>\", line 44, in _differential_evolution_step\nNameError: name 'func' is not defined\n.", "error": "NameError(\"name 'func' is not defined\")Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 66, in __call__\n  File \"<string>\", line 44, in _differential_evolution_step\nNameError: name 'func' is not defined\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "320ccf50-8926-46c0-a762-ef9c834b2c29", "solution": "import numpy as np\n\nclass BraggMirrorOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.best_solution = None\n        self.best_fitness = float('inf')\n        self.evaluations = 0\n\n    def _initialize_population(self, bounds):\n        pop = np.random.rand(self.population_size, self.dim)\n        pop = bounds.lb + pop * (bounds.ub - bounds.lb)\n        return pop\n\n    def _evaluate_population(self, pop, func):\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.evaluations += len(fitness)\n        return fitness\n\n    def _select_best(self, pop, fitness):\n        idx = np.argmin(fitness)\n        return pop[idx], fitness[idx]\n\n    def _mutate(self, pop, idx):\n        a, b, c = np.random.choice([i for i in range(self.population_size) if i != idx], 3, replace=False)\n        mutant = pop[a] + self.F * (pop[b] - pop[c])\n        return mutant\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _local_search_periodicity(self, solution, func):\n        # Encourage periodic solutions by averaging solutions to enforce a periodic pattern\n        periodic_solution = solution.copy()\n        period = self.dim // 2\n        for i in range(period):\n            avg_value = (solution[i] + solution[i + period]) / 2\n            periodic_solution[i] = avg_value\n            periodic_solution[i + period] = avg_value\n        periodic_solution = np.clip(periodic_solution, func.bounds.lb, func.bounds.ub)\n        fitness = func(periodic_solution)\n        self.evaluations += 1\n        return periodic_solution, fitness\n\n    def __call__(self, func):\n        bounds = func.bounds\n        pop = self._initialize_population(bounds)\n        fitness = self._evaluate_population(pop, func)\n\n        self.best_solution, self.best_fitness = self._select_best(pop, fitness)\n\n        while self.evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self._mutate(pop, i)\n                trial = self._crossover(pop[i], mutant)\n                trial_fitness = func(trial)\n                self.evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                    if trial_fitness < self.best_fitness:\n                        self.best_solution, self.best_fitness = trial, trial_fitness\n\n                if self.evaluations >= self.budget:\n                    break\n\n            # Local search with periodicity enhancement\n            local_best, local_best_fitness = self._local_search_periodicity(self.best_solution, func)\n            if local_best_fitness < self.best_fitness:\n                self.best_solution, self.best_fitness = local_best, local_best_fitness\n\n        return self.best_solution", "name": "BraggMirrorOptimizer", "description": "The algorithm combines Differential Evolution with periodicity-enhancing local search to optimize multilayer structures by exploiting constructive interference.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 66, in __call__\n  File \"<string>\", line 44, in _differential_evolution_step\nNameError: name 'func' is not defined\n.", "error": "NameError(\"name 'func' is not defined\")Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 66, in __call__\n  File \"<string>\", line 44, in _differential_evolution_step\nNameError: name 'func' is not defined\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "53da3328-3e81-426b-8a26-b02d02e9df1b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDELocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.crossover_rate = 0.7\n        self.differential_weight = 0.8\n        self.base_local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in pop])\n        evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while evaluations < self.budget:\n            new_pop = np.copy(pop)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.differential_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best = trial\n                        best_fitness = trial_fitness\n\n            pop = new_pop\n\n            # Dynamically adjust local search probability and apply local search\n            local_search_probability = self.base_local_search_probability * (1 - evaluations / self.budget)\n            if np.random.rand() < local_search_probability:\n                for i in range(self.population_size // 5):\n                    if evaluations >= self.budget:\n                        break\n                    local_search_result = minimize(func, pop[i], bounds=list(zip(lb, ub)), method='L-BFGS-B')\n                    evaluations += local_search_result.nfev\n                    if local_search_result.fun < fitness[i]:\n                        pop[i] = local_search_result.x\n                        fitness[i] = local_search_result.fun\n                        if local_search_result.fun < best_fitness:\n                            best = local_search_result.x\n                            best_fitness = local_search_result.fun                      \n\n        return best", "name": "EnhancedHybridDELocalSearch", "description": "An enhanced hybrid metaheuristic integrating Differential Evolution with adaptive local search that exploits symmetry and periodicity while dynamically adjusting local search intensity based on convergence progress.", "configspace": "", "generation": 1, "fitness": 0.9295406883453304, "feedback": "The algorithm EnhancedHybridDELocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.019. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "072efe26-4b05-4f33-bbaa-d43dcb7100e2", "metadata": {"aucs": [0.955941433866354, 0.9211799188470983, 0.9115007123225392], "final_y": [0.16485751310148167, 0.16485620555962366, 0.16485744449341777]}, "mutation_prompt": null}
{"id": "0bf6997c-6268-4289-ad3c-41faf31e7c34", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDELocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.crossover_rate = 0.7\n        self.differential_weight = 0.8\n        self.local_search_probability = 0.3  # Increased probability for more local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in pop])\n        evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while evaluations < self.budget:\n            new_pop = np.copy(pop)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.differential_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                \n                # Adaptive crossover rate\n                if fitness[i] < best_fitness:\n                    more_exploit = 0.2\n                else:\n                    more_exploit = 0.8\n                cross_points = np.random.rand(self.dim) < more_exploit\n\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best = trial\n                        best_fitness = trial_fitness\n\n            pop = new_pop\n\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size // 5):\n                    if evaluations >= self.budget:\n                        break\n                    local_search_result = minimize(func, pop[i], bounds=list(zip(lb, ub)), method='L-BFGS-B')\n                    evaluations += local_search_result.nfev\n                    if local_search_result.fun < fitness[i]:\n                        pop[i] = local_search_result.x\n                        fitness[i] = local_search_result.fun\n                        if local_search_result.fun < best_fitness:\n                            best = local_search_result.x\n                            best_fitness = local_search_result.fun\n\n        return best", "name": "HybridDELocalSearch", "description": "The algorithm enhances Differential Evolution with adaptive crossover and mutation strategies and a refined local search step, improving convergence in photonic structure optimization.", "configspace": "", "generation": 1, "fitness": 0.9277519899741286, "feedback": "The algorithm HybridDELocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "072efe26-4b05-4f33-bbaa-d43dcb7100e2", "metadata": {"aucs": [0.93025025792869, 0.9467547321192826, 0.9062509798744132], "final_y": [0.16485632498843794, 0.16485620555962366, 0.1648561668070896]}, "mutation_prompt": null}
{"id": "68f1dacd-64f9-4e03-a1e8-a89317289bf1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = 2  # Period to enforce (could be tuned or adaptive)\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Novel Periodicity-Driven Symmetric Differential Evolution Algorithm infuses symmetric initialization and adaptive periodicity constraints to efficiently navigate the multimodal landscape of multilayer photonic structure optimization.", "configspace": "", "generation": 1, "fitness": 0.9590105674062865, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.024. And the mean value of best solutions found was 0.174 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "88f481b7-03dd-4c0b-ab66-3cb2c4f9a21d", "metadata": {"aucs": [0.9734045974884585, 0.9246220241512366, 0.9790050805791645], "final_y": [0.17113944805324255, 0.18726567702426, 0.16494024298629073]}, "mutation_prompt": null}
{"id": "e3d63c06-669e-42db-af28-725fb79b52f6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass BraggMirrorOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = 2  # Period to enforce (could be tuned or made adaptive)\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            # Select three random indices different from i\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            # Mutation\n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Crossover\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            # Periodicity promotion\n            trial = self._apply_periodicity_promotion(trial)\n            \n            # Selection\n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)  # Minimize negative reflectivity for maximization\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            # Local optimization step\n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "BraggMirrorOptimizer", "description": "A hybrid metaheuristic combining Differential Evolution with adaptive periodicity promotion and local optimization to efficiently explore and exploit multimodal landscapes in multilayer Bragg mirror design, with a minor fix for variable scoping.", "configspace": "", "generation": 1, "fitness": 0.9613284831352319, "feedback": "The algorithm BraggMirrorOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.021. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "88f481b7-03dd-4c0b-ab66-3cb2c4f9a21d", "metadata": {"aucs": [0.9801137198464622, 0.9314400328298839, 0.9724316967293497], "final_y": [0.16980868071795596, 0.1767949339372571, 0.1650370738614665]}, "mutation_prompt": null}
{"id": "5ac34d83-ab7f-47ec-89c4-df1612a1d693", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDEPeriodicOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.85  # Changed from 0.8 to 0.85\n        self.crossover_rate = 0.7\n\n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n\n    def evolve_population(self, population, func):\n        new_population = np.copy(population)\n        for i in range(self.population_size):\n            indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n            x1, x2, x3 = population[indices]\n            mutant_vector = x1 + self.mutation_factor * (x2 - x3)\n            mutant_vector = np.clip(mutant_vector, func.bounds.lb, func.bounds.ub)\n            \n            cross_points = np.random.rand(self.dim) < self.crossover_rate\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n                \n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            if func(trial_vector) < func(population[i]):\n                new_population[i] = trial_vector\n\n        return new_population\n\n    def periodic_local_search(self, individual, func):\n        def periodicity_objective(x):\n            regularity_penalty = np.sum((x[:-1] - x[1:])**2)\n            return func(x) + 0.1 * regularity_penalty\n\n        result = minimize(periodicity_objective, individual, bounds=[(func.bounds.lb[i], func.bounds.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        population = self.initialize_population(func.bounds.lb, func.bounds.ub)\n        evaluations = 0\n        best_solution = None\n        best_value = float('inf')\n\n        while evaluations < self.budget:\n            population = self.evolve_population(population, func)\n            evaluations += self.population_size\n\n            for individual in population:\n                optimized_individual = self.periodic_local_search(individual, func)\n                individual_value = func(optimized_individual)\n                evaluations += 1\n\n                if individual_value < best_value:\n                    best_value = individual_value\n                    best_solution = optimized_individual\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_solution", "name": "HybridDEPeriodicOptimization", "description": "A refined hybrid metaheuristic that integrates Differential Evolution with a periodicity-promoting local search, featuring a slightly adjusted mutation factor to enhance global exploration capabilities.", "configspace": "", "generation": 1, "fitness": 0.8152493034405045, "feedback": "The algorithm HybridDEPeriodicOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.084. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fbbe0188-f6eb-41db-af28-2424d1cd9b3d", "metadata": {"aucs": [0.7348440496217319, 0.9303670341672806, 0.7805368265325011], "final_y": [0.17320964713874876, 0.17319470122330016, 0.17328702713517585]}, "mutation_prompt": null}
{"id": "f16a59d1-a6a2-467d-8b15-31d43989a585", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDELocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Population size, a standard choice is 10 times the dimension\n        self.crossover_rate = 0.7\n        self.differential_weight = 0.8\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        # Initialize population with symmetric and random values\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in pop])\n        evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while evaluations < self.budget:\n            new_pop = np.copy(pop)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_diff_weight = self.differential_weight * (1 - evaluations / self.budget)\n                mutant = np.clip(a + adaptive_diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Evaluate trial point\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Check if the trial is better and update\n                if trial_fitness < fitness[i]:\n                    new_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best = trial\n                        best_fitness = trial_fitness\n\n            pop = new_pop\n\n            # Local search for a fraction of the population\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size // 5):  # Randomly pick 20% of the population\n                    if evaluations >= self.budget:\n                        break\n                    local_search_result = minimize(func, pop[i], bounds=list(zip(lb, ub)), method='L-BFGS-B')\n                    evaluations += local_search_result.nfev\n                    if local_search_result.fun < fitness[i]:\n                        pop[i] = local_search_result.x\n                        fitness[i] = local_search_result.fun\n                        if local_search_result.fun < best_fitness:\n                            best = local_search_result.x\n                            best_fitness = local_search_result.fun                      \n\n        return best", "name": "HybridDELocalSearch", "description": "Refined Hybrid DE with Adaptive Differential Weight and Enhanced Periodicity Consideration for Multilayer Photonic Structure Optimization.", "configspace": "", "generation": 2, "fitness": 0.9311045337147877, "feedback": "The algorithm HybridDELocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.018. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "072efe26-4b05-4f33-bbaa-d43dcb7100e2", "metadata": {"aucs": [0.9564184390322422, 0.9227050743762106, 0.9141900877359104], "final_y": [0.16485751310148167, 0.1648579151925491, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "5c9d9649-c795-424d-a940-8ac65f11ee2d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridDELocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.crossover_rate = 0.7\n        self.differential_weight = 0.8\n        self.base_local_search_probability = 0.2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in pop])\n        evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while evaluations < self.budget:\n            new_pop = np.copy(pop)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                # Adaptive differential weight\n                self.differential_weight = 0.5 + 0.3 * (1 - evaluations / self.budget)\n                mutant = np.clip(a + self.differential_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best = trial\n                        best_fitness = trial_fitness\n\n            pop = new_pop\n\n            # Dynamically adjust local search probability and apply local search\n            local_search_probability = self.base_local_search_probability * (1 - evaluations / self.budget)\n            if np.random.rand() < local_search_probability:\n                for i in range(self.population_size // 5):\n                    if evaluations >= self.budget:\n                        break\n                    # Adaptive periodicity-driven initialization for local search\n                    perturbed_pop = np.sin(np.pi * pop[i]) * (ub - lb) / 4 + pop[i]\n                    local_search_result = minimize(func, perturbed_pop, bounds=list(zip(lb, ub)), method='L-BFGS-B')\n                    evaluations += local_search_result.nfev\n                    if local_search_result.fun < fitness[i]:\n                        pop[i] = local_search_result.x\n                        fitness[i] = local_search_result.fun\n                        if local_search_result.fun < best_fitness:\n                            best = local_search_result.x\n                            best_fitness = local_search_result.fun                      \n\n        return best", "name": "EnhancedHybridDELocalSearch", "description": "Refined Enhanced Hybrid Metaheuristic embraces adaptive periodicity-driven local search and dynamic mutation scaling to enhance performance in multimodal optimization of multilayer photonic structures.", "configspace": "", "generation": 2, "fitness": 0.8866845549252028, "feedback": "The algorithm EnhancedHybridDELocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.035. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "53da3328-3e81-426b-8a26-b02d02e9df1b", "metadata": {"aucs": [0.936658599077413, 0.8585600842838474, 0.8648349814143479], "final_y": [0.1648569337901834, 0.18187982321058194, 0.16485832079057328]}, "mutation_prompt": null}
{"id": "0ceb86e6-7dc3-4f83-bd64-5cfcbbc9c7c7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDELocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Population size, a standard choice is 10 times the dimension\n        self.crossover_rate = 0.7\n        self.differential_weight = 0.8\n        self.local_search_probability = 0.25  # Adjusted local search probability\n\n    def __call__(self, func):\n        # Initialize population with symmetric and random values\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in pop])\n        evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while evaluations < self.budget:\n            new_pop = np.copy(pop)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.differential_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Evaluate trial point\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Check if the trial is better and update\n                if trial_fitness < fitness[i]:\n                    new_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best = trial\n                        best_fitness = trial_fitness\n\n            pop = new_pop\n\n            # Local search for a fraction of the population\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size // 5):  # Randomly pick 20% of the population\n                    if evaluations >= self.budget:\n                        break\n                    local_search_result = minimize(func, pop[i], bounds=list(zip(lb, ub)), method='L-BFGS-B')\n                    evaluations += local_search_result.nfev\n                    if local_search_result.fun < fitness[i]:\n                        pop[i] = local_search_result.x\n                        fitness[i] = local_search_result.fun\n                        if local_search_result.fun < best_fitness:\n                            best = local_search_result.x\n                            best_fitness = local_search_result.fun                      \n\n        return best", "name": "HybridDELocalSearch", "description": "A novel hybrid metaheuristic that enhances Differential Evolution for global exploration combined with gradient-based local search to improve solution refinement, specifically leveraging periodicity and symmetrical properties in multilayer photonic structure optimization, now with slight local search probability adjustment for better refinement.", "configspace": "", "generation": 2, "fitness": 0.9299788450525212, "feedback": "The algorithm HybridDELocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.019. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "072efe26-4b05-4f33-bbaa-d43dcb7100e2", "metadata": {"aucs": [0.955941433866354, 0.9211799188470983, 0.9128151824441113], "final_y": [0.16485751310148167, 0.16485620555962366, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "cefd54dc-9ca2-4c9e-9f69-18c22f1ed54a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDELocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Population size, a standard choice is 10 times the dimension\n        self.crossover_rate = 0.7\n        self.differential_weight = 0.8\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        # Initialize population with symmetric and random values\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in pop])\n        evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while evaluations < self.budget:\n            new_pop = np.copy(pop)\n            # Calculate diversity and adjust crossover rate\n            diversity = np.std(pop, axis=0).mean()\n            self.crossover_rate = 0.5 + 0.2 * diversity / (ub - lb).mean()  # Change line 1\n            \n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.differential_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Evaluate trial point\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Check if the trial is better and update\n                if trial_fitness < fitness[i]:\n                    new_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best = trial\n                        best_fitness = trial_fitness\n\n            pop = new_pop\n\n            # Local search for a fraction of the population\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size // 5):  # Randomly pick 20% of the population\n                    if evaluations >= self.budget:\n                        break\n                    local_search_result = minimize(func, pop[i], bounds=list(zip(lb, ub)), method='L-BFGS-B')\n                    evaluations += local_search_result.nfev\n                    if local_search_result.fun < fitness[i]:\n                        pop[i] = local_search_result.x\n                        fitness[i] = local_search_result.fun\n                        if local_search_result.fun < best_fitness:\n                            best = local_search_result.x\n                            best_fitness = local_search_result.fun                      \n\n        return best", "name": "HybridDELocalSearch", "description": "Improved HybridDELocalSearch using adaptive crossover rate based on population diversity to enhance convergence in multimodal landscapes.", "configspace": "", "generation": 2, "fitness": 0.9301883542977677, "feedback": "The algorithm HybridDELocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "072efe26-4b05-4f33-bbaa-d43dcb7100e2", "metadata": {"aucs": [0.9525470214492968, 0.9252018648941664, 0.9128161765498397], "final_y": [0.16485785008543985, 0.16485620555962366, 0.16485703642646454]}, "mutation_prompt": null}
{"id": "375aa6a0-93b8-464c-816e-7a972fce4b67", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDELocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim  # Population size, a standard choice is 10 times the dimension\n        self.crossover_rate = 0.7\n        self.differential_weight = 0.8\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        # Initialize population with symmetric and random values\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in pop])\n        evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while evaluations < self.budget:\n            new_pop = np.copy(pop)\n            diversity = np.mean(np.std(pop, axis=0))  # Calculate population diversity\n            self.crossover_rate = 0.5 + 0.3 * (1 - diversity / (ub - lb).mean())  # Dynamically adjust crossover rate\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.differential_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Evaluate trial point\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Check if the trial is better and update\n                if trial_fitness < fitness[i]:\n                    new_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best = trial\n                        best_fitness = trial_fitness\n\n            pop = new_pop\n\n            # Local search for a fraction of the population\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size // 5):  # Randomly pick 20% of the population\n                    if evaluations >= self.budget:\n                        break\n                    local_search_result = minimize(func, pop[i], bounds=list(zip(lb, ub)), method='L-BFGS-B')\n                    evaluations += local_search_result.nfev\n                    if local_search_result.fun < fitness[i]:\n                        pop[i] = local_search_result.x\n                        fitness[i] = local_search_result.fun\n                        if local_search_result.fun < best_fitness:\n                            best = local_search_result.x\n                            best_fitness = local_search_result.fun                      \n\n        return best", "name": "HybridDELocalSearch", "description": "Enhanced HybridDELocalSearch with a dynamic adjustment of the crossover rate based on population diversity to improve exploration and exploitation balance in photonic structure optimization.", "configspace": "", "generation": 2, "fitness": 0.9299791722032044, "feedback": "The algorithm HybridDELocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.019. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "072efe26-4b05-4f33-bbaa-d43dcb7100e2", "metadata": {"aucs": [0.955941433866354, 0.9211799061934192, 0.9128161765498397], "final_y": [0.16485751310148167, 0.16485620555962366, 0.16485703642646454]}, "mutation_prompt": null}
{"id": "668f1624-6267-42d8-aebc-82e83fefbd7d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDELocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.crossover_rate = 0.7\n        self.differential_weight = 0.8\n        self.local_search_probability = 0.3  # Increased probability for local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in pop])\n        evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        periodicity_factor = 0.1  # Introduce periodicity factor\n        target_frequency = np.ones(self.dim) / 2  # Target periodicity\n\n        while evaluations < self.budget:\n            new_pop = np.copy(pop)\n            diversity = np.mean(np.std(pop, axis=0))\n            self.crossover_rate = 0.5 + 0.3 * (1 - diversity / (ub - lb).mean())\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.differential_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                    \n                # Encourage periodic solutions\n                mutant_frequency = np.sin(2 * np.pi * target_frequency * mutant)\n                mutant = mutant + periodicity_factor * (mutant_frequency - mutant)\n                \n                trial = np.where(cross_points, mutant, pop[i])\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best = trial\n                        best_fitness = trial_fitness\n\n            pop = new_pop\n            \n            # Enhanced local search\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size // 4):  # Increase local search population\n                    if evaluations >= self.budget:\n                        break\n                    local_search_result = minimize(func, pop[i], bounds=list(zip(lb, ub)), method='L-BFGS-B')\n                    evaluations += local_search_result.nfev\n                    if local_search_result.fun < fitness[i]:\n                        pop[i] = local_search_result.x\n                        fitness[i] = local_search_result.fun\n                        if local_search_result.fun < best_fitness:\n                            best = local_search_result.x\n                            best_fitness = local_search_result.fun\n\n        return best", "name": "HybridDELocalSearch", "description": "Enhanced Hybrid Metaheuristic with Adaptive Differential Evolution and Local Search using diversity-driven parameter tuning and periodicity-enforcing strategies.", "configspace": "", "generation": 3, "fitness": 0.9300806891124213, "feedback": "The algorithm HybridDELocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "375aa6a0-93b8-464c-816e-7a972fce4b67", "metadata": {"aucs": [0.9474388915361172, 0.9257734310773508, 0.9170297447237958], "final_y": [0.16485785008543985, 0.16485593654923902, 0.16485630246256722]}, "mutation_prompt": null}
{"id": "2979c9d2-bbe9-41ea-a3c9-b4ba97b28941", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = 2  # Period to enforce (could be tuned or adaptive)\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        diversity = np.mean(np.std(population, axis=0))  # Calculate population diversity\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adapt crossover probability based on diversity\n            adaptive_cross_prob = min(1.0, max(0.3, diversity))\n            cross_points = np.random.rand(self.dim) < adaptive_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhance crossover probability adaptively based on population diversity to improve convergence in multimodal landscapes.", "configspace": "", "generation": 3, "fitness": 0.9764404531069294, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.976 with standard deviation 0.009. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "68f1dacd-64f9-4e03-a1e8-a89317289bf1", "metadata": {"aucs": [0.9897149831558625, 0.9703474499508997, 0.9692589262140259], "final_y": [0.16584385862260587, 0.16507890652675883, 0.17332285893356392]}, "mutation_prompt": null}
{"id": "94428ba0-95e2-4e03-9909-b634290690af", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced SymmetricPeriodicDE by improving the periodicity promotion with adaptive period selection for better exploration of the search space.", "configspace": "", "generation": 3, "fitness": 0.9693531953943447, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.004. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "68f1dacd-64f9-4e03-a1e8-a89317289bf1", "metadata": {"aucs": [0.9740372651425654, 0.9646327768333076, 0.9693895442071612], "final_y": [0.16872981248062713, 0.17418676877778017, 0.17332382059554985]}, "mutation_prompt": null}
{"id": "0b1df635-a618-4ba3-8f41-c9767f11b893", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass BraggMirrorOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate, diversity):\n        period = 2 + int(diversity > 0.1)  # Adaptive period based on diversity\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            # Select three random indices different from i\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            # Mutation\n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Crossover\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            # Periodicity promotion\n            diversity = np.std(population, axis=0).mean()\n            trial = self._apply_periodicity_promotion(trial, diversity)\n            \n            # Selection\n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)  # Minimize negative reflectivity for maximization\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            # Local optimization step\n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "BraggMirrorOptimizer", "description": "Enhanced BraggMirrorOptimizer with adaptive periodicity enforcement based on the population diversity to improve convergence in multilayer photonic structure optimization.", "configspace": "", "generation": 3, "fitness": 0.9025765123933421, "feedback": "The algorithm BraggMirrorOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.011. And the mean value of best solutions found was 0.181 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "e3d63c06-669e-42db-af28-725fb79b52f6", "metadata": {"aucs": [0.8963945252856476, 0.9177276154476135, 0.8936073964467652], "final_y": [0.18067215053639019, 0.1780755789066396, 0.18408187393990483]}, "mutation_prompt": null}
{"id": "8408a28d-a848-4d2d-b83b-64f0f0fac303", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDELocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 5 * dim)  # Adjusted population size for better scalability\n        self.crossover_rate = 0.7\n        self.differential_weight = 0.8\n        self.local_search_probability = 0.2\n\n    def __call__(self, func):\n        # Initialize population with symmetric and random values\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in pop])\n        evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while evaluations < self.budget:\n            new_pop = np.copy(pop)\n            diversity = np.mean(np.std(pop, axis=0))  # Calculate population diversity\n            self.crossover_rate = 0.5 + 0.3 * (1 - diversity / (ub - lb).mean())  # Dynamically adjust crossover rate\n\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                # Mutation and crossover\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.differential_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Evaluate trial point\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Check if the trial is better and update\n                if trial_fitness < fitness[i]:\n                    new_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best = trial\n                        best_fitness = trial_fitness\n\n            pop = new_pop\n\n            # Local search for a fraction of the population\n            if np.random.rand() < self.local_search_probability:\n                for i in range(self.population_size // 5):  # Randomly pick 20% of the population\n                    if evaluations >= self.budget:\n                        break\n                    local_search_result = minimize(func, pop[i], bounds=list(zip(lb, ub)), method='L-BFGS-B')\n                    evaluations += local_search_result.nfev\n                    if local_search_result.fun < fitness[i]:\n                        pop[i] = local_search_result.x\n                        fitness[i] = local_search_result.fun\n                        if local_search_result.fun < best_fitness:\n                            best = local_search_result.x\n                            best_fitness = local_search_result.fun                      \n\n        return best", "name": "HybridDELocalSearch", "description": "Improved exploration-exploitation balance by adjusting population size based on dimensionality, enhancing local and global search efficiency.", "configspace": "", "generation": 3, "fitness": 0.9273668180033491, "feedback": "The algorithm HybridDELocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.927 with standard deviation 0.013. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "375aa6a0-93b8-464c-816e-7a972fce4b67", "metadata": {"aucs": [0.9420015736647399, 0.9101193989288399, 0.9299794814164674], "final_y": [0.16485716748314472, 0.18188071772564318, 0.16485848066033448]}, "mutation_prompt": null}
{"id": "262e78de-662b-4cef-8550-d19c42446a7c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.2  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Improved the local optimization probability from 0.1 to 0.2 to enhance exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.9533353274443614, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.019. And the mean value of best solutions found was 0.174 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "94428ba0-95e2-4e03-9909-b634290690af", "metadata": {"aucs": [0.9577623995142839, 0.9739514095123709, 0.9282921733064298], "final_y": [0.16837822056007434, 0.16680993925776955, 0.18609342247646132]}, "mutation_prompt": null}
{"id": "d759fdad-a8a6-4ec9-9b56-fb317138561d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate, evaluations):\n        period = 2 + (self.budget - evaluations) // (self.budget / 4)  # Adaptive period based on evaluations\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial, func.evaluations)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Improved periodicity promotion by adapting the period based on the current evaluations, facilitating better exploration early in the search.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'ioh.iohcpp.problem.RealSingleObjectiveWrappedProbl' object has no attribute 'evaluations'\").", "error": "AttributeError(\"'ioh.iohcpp.problem.RealSingleObjectiveWrappedProbl' object has no attribute 'evaluations'\")", "parent_id": "68f1dacd-64f9-4e03-a1e8-a89317289bf1", "metadata": {}, "mutation_prompt": null}
{"id": "7c7678a5-419d-4448-a38c-6eac255e81a2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDELocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.crossover_rate = 0.7\n        self.differential_weight = 0.8\n        self.local_search_probability = 0.3  # Adjusted probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        fitness = np.array([func(ind) for ind in pop])\n        evaluations = self.population_size\n\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while evaluations < self.budget:\n            new_pop = np.copy(pop)\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                adaptive_diff_weight = self.differential_weight * (1 - evaluations / self.budget)\n                mutant = np.clip(a + adaptive_diff_weight * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial = self.enforce_periodicity(trial, lb, ub)  # Enforcing periodicity\n\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    new_pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best = trial\n                        best_fitness = trial_fitness\n\n            pop = new_pop\n\n            if np.random.rand() < self.local_search_probability:\n                idxs = np.random.choice(self.population_size, self.population_size // 5, replace=False)\n                for i in idxs:\n                    if evaluations >= self.budget:\n                        break\n                    local_search_result = minimize(func, pop[i], bounds=list(zip(lb, ub)), method='L-BFGS-B')\n                    evaluations += local_search_result.nfev\n                    if local_search_result.fun < fitness[i]:\n                        pop[i] = local_search_result.x\n                        fitness[i] = local_search_result.fun\n                        if local_search_result.fun < best_fitness:\n                            best = local_search_result.x\n                            best_fitness = local_search_result.fun\n\n        return best\n\n    def enforce_periodicity(self, solution, lb, ub):\n        # Encourage periodicity by averaging pairs of layers\n        half = self.dim // 2\n        for i in range(half):\n            avg_value = (solution[i] + solution[self.dim - 1 - i]) / 2\n            solution[i] = np.clip(avg_value, lb[i], ub[i])\n            solution[self.dim - 1 - i] = np.clip(avg_value, lb[self.dim - 1 - i], ub[self.dim - 1 - i])\n        return solution", "name": "HybridDELocalSearch", "description": "Enhanced Hybrid DE with Adaptive Periodicity Constraints and Dimension-Wise Local Search Strategy for Improved Multilayer Photonic Structure Optimization.", "configspace": "", "generation": 4, "fitness": 0.9664194746315831, "feedback": "The algorithm HybridDELocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f16a59d1-a6a2-467d-8b15-31d43989a585", "metadata": {"aucs": [0.9654858817074706, 0.966509233017464, 0.9672633091698148], "final_y": [0.16485622571554448, 0.1648559006508925, 0.1648561217680925]}, "mutation_prompt": null}
{"id": "f2b5529b-0e14-4472-a613-34b9d81c0aef", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cross_prob = 0.7  \n        self.diff_weight = 0.8\n        self.local_optimization_prob = 0.1\n\n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _adaptive_differential_weight(self, scores):\n        max_score = np.max(scores)\n        min_score = np.min(scores)\n        return 0.5 + 0.5 * (max_score - scores) / (max_score - min_score + 1e-9)\n\n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            adaptive_diff_weight = self._adaptive_differential_weight(scores[i])\n            mutant = np.clip(population[a] + adaptive_diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 15})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced SymmetricPeriodicDE by integrating adaptive differential weights and boosting local optimization for better convergence in multimodal landscapes.", "configspace": "", "generation": 4, "fitness": 0.9589640788125449, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.009. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "94428ba0-95e2-4e03-9909-b634290690af", "metadata": {"aucs": [0.9466371274258982, 0.9641475828737474, 0.9661075261379891], "final_y": [0.17745840858417772, 0.17435699253371895, 0.16612602913119778]}, "mutation_prompt": null}
{"id": "6e25478b-36a5-4a55-b607-ddb58b3fa7af", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, min(5, self.dim))  # Dynamic period selection for periodicity promotion\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        diversity = np.mean(np.std(population, axis=0))  # Calculate population diversity\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adapt crossover probability based on diversity\n            adaptive_cross_prob = min(1.0, max(0.3, diversity))\n            cross_points = np.random.rand(self.dim) < adaptive_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced dynamic periodicity promotion to enhance exploration in the optimization process.", "configspace": "", "generation": 4, "fitness": 0.9791182797721726, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.979 with standard deviation 0.003. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "2979c9d2-bbe9-41ea-a3c9-b4ba97b28941", "metadata": {"aucs": [0.9751122879886764, 0.9821348291933107, 0.9801077221345302], "final_y": [0.16777917318335678, 0.16827966369077674, 0.1695521826131271]}, "mutation_prompt": null}
{"id": "5f734830-a728-439e-95a3-2a92de394d81", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < (self.cross_prob * (1 - evaluations/self.budget))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Refined SymmetricPeriodicDE by adjusting crossover probability based on iteration count to balance exploration and exploitation.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_id": "94428ba0-95e2-4e03-9909-b634290690af", "metadata": {}, "mutation_prompt": null}
{"id": "1993d286-c109-4bab-9593-c4859c327a20", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        diversity = np.std(population, axis=0).mean()\n        self.cross_prob = 0.5 + 0.5 * (1 - diversity)  # Adaptive crossover probability\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced adaptive crossover probability based on the diversity of the population to enhance convergence speed.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_id": "94428ba0-95e2-4e03-9909-b634290690af", "metadata": {}, "mutation_prompt": null}
{"id": "c433c401-5bb5-46a1-8522-2c12e8454922", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced SymmetricPeriodicDE with dynamic population resizing and targeted periodicity adjustment for improved exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.9719160173071796, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.972 with standard deviation 0.012. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "94428ba0-95e2-4e03-9909-b634290690af", "metadata": {"aucs": [0.9839326136060957, 0.9756109571507319, 0.956204481164711], "final_y": [0.16586444030673186, 0.1683618178155133, 0.17331926714210188]}, "mutation_prompt": null}
{"id": "0015eda9-dd54-41d7-9489-0aec431b5b02", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cross_prob = 0.7\n        self.diff_weight = 0.8\n        self.local_optimization_prob = 0.15  # Increased probability for local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, min(5, self.dim))\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        diversity = np.mean(np.std(population, axis=0))\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            # Adaptive differential weight based on diversity\n            self.diff_weight = 0.5 + 0.3 * (diversity / np.max(np.std(population, axis=0)))\n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            adaptive_cross_prob = min(1.0, max(0.3, diversity))\n            cross_points = np.random.rand(self.dim) < adaptive_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced adaptive mutation strategy and enhanced local search frequency to improve convergence and exploration.", "configspace": "", "generation": 5, "fitness": 0.9522668206418534, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.952 with standard deviation 0.012. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6e25478b-36a5-4a55-b607-ddb58b3fa7af", "metadata": {"aucs": [0.9557920895048505, 0.9646936160600907, 0.9363147563606189], "final_y": [0.16704758511151918, 0.17340877955826528, 0.17396932640794482]}, "mutation_prompt": null}
{"id": "4e591f4e-abf9-487c-a106-28589011ec43", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Base probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, min(5, self.dim))  # Dynamic period selection for periodicity promotion\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        diversity = np.mean(np.std(population, axis=0))  # Calculate population diversity\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            adaptive_cross_prob = min(1.0, max(0.3, diversity))\n            cross_points = np.random.rand(self.dim) < adaptive_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            # Adapt local optimization probability based on diversity\n            current_diversity = np.mean(np.std(population, axis=0))\n            self.local_optimization_prob = min(0.3, max(0.1, current_diversity / 2))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced adaptive local optimization probability based on population diversity to enhance convergence in the optimization process.", "configspace": "", "generation": 5, "fitness": 0.9503042147884116, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.950 with standard deviation 0.027. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6e25478b-36a5-4a55-b607-ddb58b3fa7af", "metadata": {"aucs": [0.9673484306291387, 0.9122765045006, 0.9712877092354963], "final_y": [0.16495827257855666, 0.1733733524820914, 0.16752747979668992]}, "mutation_prompt": null}
{"id": "9d86bee1-7681-45b2-ac46-9d760215db75", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            diversity = np.std(scores) / np.mean(scores)\n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduce adaptive local optimization probability based on the diversity of the population to improve convergence.", "configspace": "", "generation": 6, "fitness": 0.977122712454206, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.977 with standard deviation 0.010. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "94428ba0-95e2-4e03-9909-b634290690af", "metadata": {"aucs": [0.9655484631248719, 0.976293997945212, 0.9895256762925342], "final_y": [0.16524878170643698, 0.16683460074918988, 0.16507484584641985]}, "mutation_prompt": null}
{"id": "62eec6a9-c87e-46ff-aa2a-caa1a5610dc6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            self.cross_prob = 0.5 + 0.5 * (np.sin(i / self.population_size * np.pi))  # Adjust crossover prob\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced periodicity-based crossover probability adjustment to better balance exploration and exploitation.", "configspace": "", "generation": 6, "fitness": 0.9620649139273986, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.001. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "94428ba0-95e2-4e03-9909-b634290690af", "metadata": {"aucs": [0.9617015781000715, 0.963161926578992, 0.9613312371031321], "final_y": [0.1733870480465517, 0.17337466553497383, 0.17232830872632565]}, "mutation_prompt": null}
{"id": "6a34fea9-09d9-4e7e-a4dc-6cb3623e8dd4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.cross_prob = 0.7\n        self.diff_weight = 0.8\n        self.local_optimization_prob = 0.1\n        self.population_growth_factor = 1.1\n        self.diversity_threshold = 0.1\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n\n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 3, 5])  # Adjusted periods to better target periodic structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _calculate_population_diversity(self, population):\n        return np.mean(np.std(population, axis=0))\n\n    def _adaptive_crossover(self, diversity):\n        if diversity < self.diversity_threshold:\n            return min(1.0, self.cross_prob + 0.2)  # Increase crossover probability if diversity is low\n        return self.cross_prob\n\n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        diversity = self._calculate_population_diversity(population)\n        crossover_probability = self._adaptive_crossover(diversity)\n        \n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < crossover_probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced SymmetricPeriodicDE with adaptive crossover based on diversity and refined periodicity promotion to improve exploration in complex landscapes.", "configspace": "", "generation": 6, "fitness": 0.9642600645450375, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.006. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c433c401-5bb5-46a1-8522-2c12e8454922", "metadata": {"aucs": [0.9628102514044234, 0.9572199586441383, 0.9727499835865508], "final_y": [0.17332371520582257, 0.17091370901944725, 0.1673540043906918]}, "mutation_prompt": null}
{"id": "31196b50-3368-4d2f-83fc-57b33a6a9186", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n\n            # Adaptive differential weight adjustment\n            diversity = np.std(population, axis=0).mean()\n            self.diff_weight = 0.5 + 0.5 * (diversity / (ub - lb).mean())\n\n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced adaptive differential weight adjustment based on population convergence to improve exploration-exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.9727068260912396, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.007. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c433c401-5bb5-46a1-8522-2c12e8454922", "metadata": {"aucs": [0.98127430773338, 0.9648613748493546, 0.9719847956909842], "final_y": [0.16694575002771195, 0.17332117013940895, 0.16547863527461137]}, "mutation_prompt": null}
{"id": "2129255a-50ff-4ed0-99da-66c959662a16", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * score_variance\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhance candidate selection by promoting diversity using adjusted crossover probability based on score variance.", "configspace": "", "generation": 6, "fitness": 0.9742795245148667, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.009. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c433c401-5bb5-46a1-8522-2c12e8454922", "metadata": {"aucs": [0.9661436577037666, 0.9873053716336723, 0.9693895442071612], "final_y": [0.1671734075258834, 0.16636186973668565, 0.17332382059554985]}, "mutation_prompt": null}
{"id": "395ee75b-a58a-43bb-b9c5-16e0e51cf115", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, min(5, self.dim))  # Dynamic period selection for periodicity promotion\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period] * (1 + np.random.uniform(-0.05, 0.05))  # Introduce small random noise\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        diversity = np.mean(np.std(population, axis=0))  # Calculate population diversity\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            adaptive_cross_prob = min(1.0, max(0.3, diversity))\n            cross_points = np.random.rand(self.dim) < adaptive_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Adjusted periodicity promotion by introducing a small random noise to enhance exploration around periodic solutions.", "configspace": "", "generation": 7, "fitness": 0.764230929596609, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.764 with standard deviation 0.273. And the mean value of best solutions found was 0.282 (0. is the best) with standard deviation 0.155.", "error": "", "parent_id": "6e25478b-36a5-4a55-b607-ddb58b3fa7af", "metadata": {"aucs": [0.9418689008722987, 0.37793339533629355, 0.972890492581235], "final_y": [0.17754627291514613, 0.5015331544530953, 0.16833031065559512]}, "mutation_prompt": null}
{"id": "e20df5b4-65f0-4b46-a198-5ac4027cd6c0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HierarchicalCooperativeDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.subpop_count = 3\n        self.subpop_size = 8\n        self.cross_prob = 0.7\n        self.diff_weight = 0.8\n        self.local_optimization_prob = 0.1\n\n    def _initialize_subpopulations(self, lb, ub):\n        subpopulations = []\n        for _ in range(self.subpop_count):\n            mid_point = (lb + ub) / 2\n            half_range = (ub - lb) / 2\n            subpop = mid_point + np.random.uniform(-half_range, half_range, (self.subpop_size, self.dim))\n            subpopulations.append(subpop)\n        return subpopulations\n\n    def _evaluate_subpopulations(self, subpopulations, func):\n        return [np.array([func(ind) for ind in subpop]) for subpop in subpopulations]\n\n    def _differential_evolution_step(self, subpop, scores, lb, ub, func):\n        for i in range(self.subpop_size):\n            indices = [idx for idx in range(self.subpop_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutant = np.clip(subpop[a] + self.diff_weight * (subpop[b] - subpop[c]), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, subpop[i])\n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                subpop[i] = trial\n                scores[i] = trial_score\n        return subpop, scores\n\n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)], method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        subpopulations = self._initialize_subpopulations(lb, ub)\n        scores = self._evaluate_subpopulations(subpopulations, func)\n\n        evaluations = self.subpop_count * self.subpop_size\n        while evaluations < self.budget:\n            for subpop_idx in range(self.subpop_count):\n                subpopulations[subpop_idx], scores[subpop_idx] = self._differential_evolution_step(subpopulations[subpop_idx], scores[subpop_idx], lb, ub, func)\n                evaluations += self.subpop_size\n\n                if np.random.rand() < self.local_optimization_prob:\n                    idx = np.random.randint(0, self.subpop_size)\n                    candidate = subpopulations[subpop_idx][idx]\n                    optimized = self._local_optimization(candidate, func, lb, ub)\n                    optimized_score = func(optimized)\n                    evaluations += 1\n                    if optimized_score > scores[subpop_idx][idx]:\n                        subpopulations[subpop_idx][idx] = optimized\n                        scores[subpop_idx][idx] = optimized_score\n\n            if evaluations < self.budget:\n                # Cooperation among subpopulations\n                best_individuals = [subpop[np.argmax(score)] for subpop, score in zip(subpopulations, scores)]\n                global_best = best_individuals[np.argmax([func(ind) for ind in best_individuals])]\n                for subpop_idx in range(self.subpop_count):\n                    if np.random.rand() < 0.5:\n                        random_idx = np.random.randint(0, self.subpop_size)\n                        subpopulations[subpop_idx][random_idx] = global_best\n                        scores[subpop_idx][random_idx] = func(global_best)\n                        evaluations += 1\n\n        best_subpop = np.argmax([np.max(score) for score in scores])\n        best_idx = np.argmax(scores[best_subpop])\n        return subpopulations[best_subpop][best_idx]", "name": "HierarchicalCooperativeDE", "description": "Introduced hierarchical cooperation among subpopulations to enhance exploration and exploitation balance in complex landscapes.", "configspace": "", "generation": 7, "fitness": 0.4648535444365767, "feedback": "The algorithm HierarchicalCooperativeDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.465 with standard deviation 0.026. And the mean value of best solutions found was 0.427 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "6e25478b-36a5-4a55-b607-ddb58b3fa7af", "metadata": {"aucs": [0.42939936140729396, 0.4722540333014288, 0.4929072386010075], "final_y": [0.45872162936418337, 0.42193860415613316, 0.3993649455967895]}, "mutation_prompt": null}
{"id": "322d1d66-f9ee-4eeb-b0d3-8e6f6c9097f0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate, diversity):\n        period = max(2, int(self.dim * diversity))  # Adapt period based on diversity\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        diversity = np.mean(np.std(population, axis=0))  # Calculate population diversity\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adapt crossover probability based on diversity\n            adaptive_cross_prob = min(1.0, max(0.3, diversity))\n            cross_points = np.random.rand(self.dim) < adaptive_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial, diversity)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced adaptive periodicity promotion based on population diversity to enhance constructive interference and improve solution quality.", "configspace": "", "generation": 7, "fitness": 0.8056984619789088, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.253. And the mean value of best solutions found was 0.256 (0. is the best) with standard deviation 0.125.", "error": "", "parent_id": "2979c9d2-bbe9-41ea-a3c9-b4ba97b28941", "metadata": {"aucs": [0.44832105517715193, 0.9887554745409007, 0.9800188562186735], "final_y": [0.4336518088056278, 0.16733252480992467, 0.16800872623677487]}, "mutation_prompt": null}
{"id": "f29257c9-d622-411a-8d8e-d9854e99f5fb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        avg_score = np.mean(scores)  # Calculate average score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / avg_score)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced adaptive crossover probability scaling to enhance exploration by dynamically adjusting self.cross_prob based on score variance and average population score.", "configspace": "", "generation": 7, "fitness": 0.9765952038183373, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.977 with standard deviation 0.004. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "2129255a-50ff-4ed0-99da-66c959662a16", "metadata": {"aucs": [0.9763345766515867, 0.9820967482361667, 0.9713542865672583], "final_y": [0.1653605752819748, 0.16598006264151544, 0.16960862817563926]}, "mutation_prompt": null}
{"id": "dd2d0cc4-ef41-4d38-832e-ff67da5c1773", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            # Changed line: Adjust differential weight dynamically\n            self.diff_weight = np.random.uniform(0.5, 1.0)  \n\n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            diversity = np.std(scores) / np.mean(scores)\n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduce dynamic adjustment of differential weight to enhance balance between exploration and exploitation.", "configspace": "", "generation": 7, "fitness": 0.9707171045506328, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.971 with standard deviation 0.015. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "9d86bee1-7681-45b2-ac46-9d760215db75", "metadata": {"aucs": [0.9910098230871381, 0.9538010332045281, 0.9673404573602319], "final_y": [0.16628627169256815, 0.16521319137618862, 0.16489067192039952]}, "mutation_prompt": null}
{"id": "e244f20e-6df7-43c8-aaeb-a72e215afaaf", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * score_variance\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 3:  # Accelerate resizing based on budget utilization\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced dynamic population resizing acceleration based on budget utilization to enhance convergence speed.", "configspace": "", "generation": 8, "fitness": 0.9624792318016304, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.021. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "2129255a-50ff-4ed0-99da-66c959662a16", "metadata": {"aucs": [0.9819461242367693, 0.972088535946336, 0.9334030352217859], "final_y": [0.16491230380207167, 0.16554968631635159, 0.17922574214575726]}, "mutation_prompt": null}
{"id": "5ca6f361-9d3f-44d8-98ef-8057a70a4477", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, min(5, self.dim))  # Dynamic period selection for periodicity promotion\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        diversity = np.mean(np.std(population, axis=0))  # Calculate population diversity\n        # Adaptive differential weight based on diversity\n        self.diff_weight = min(1.0, max(0.5, 0.8 + (diversity - 0.1)))\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adapt crossover probability based on diversity\n            adaptive_cross_prob = min(1.0, max(0.3, diversity))\n            cross_points = np.random.rand(self.dim) < adaptive_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced adaptive differential weight to enhance exploration by dynamically adjusting self.diff_weight based on population diversity.", "configspace": "", "generation": 8, "fitness": 0.9621290143085403, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.015. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6e25478b-36a5-4a55-b607-ddb58b3fa7af", "metadata": {"aucs": [0.9437278811313854, 0.9799018306529167, 0.9627573311413186], "final_y": [0.17333629747413548, 0.16543007614871363, 0.17333673310456021]}, "mutation_prompt": null}
{"id": "e8dfc945-1ff4-42cf-9b03-f50987def40d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * score_variance\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        improvement_rate = 0\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            # Adjust local optimization probability based on improvement rate\n            improvement_rate = np.mean(scores) - improvement_rate\n            self.local_optimization_prob = min(0.2, max(0.05, 0.1 + 0.05 * improvement_rate))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhance local optimization by dynamically adjusting the probability based on the score improvement rate.", "configspace": "", "generation": 8, "fitness": 0.9726417420559926, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.011. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "2129255a-50ff-4ed0-99da-66c959662a16", "metadata": {"aucs": [0.9845913703441588, 0.9580888032874227, 0.9752450525363965], "final_y": [0.16738625602806811, 0.17532658285424974, 0.1680823573630159]}, "mutation_prompt": null}
{"id": "fb0eeb94-13ac-4b45-9ff4-02966597112c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        avg_score = np.mean(scores)  # Calculate average score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / avg_score)\n            \n            # Adjust differential weight based on population diversity\n            population_diversity = np.std(population)\n            self.diff_weight = 0.5 + 0.5 * (population_diversity / np.mean([ub - lb]))\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced adaptive differential weight scaling based on population diversity to enhance exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.9865374843972536, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.987 with standard deviation 0.001. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "f29257c9-d622-411a-8d8e-d9854e99f5fb", "metadata": {"aucs": [0.9866304220449164, 0.9873135311043568, 0.9856685000424878], "final_y": [0.16737704765137218, 0.16563228089100623, 0.16498012582139543]}, "mutation_prompt": null}
{"id": "d0278ea9-dc43-4d1f-81f5-f0c35d355aab", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))  # Adjust differential weight adaptively based on diversity\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduce a mechanism to adaptively adjust the differential weight based on the current diversity of the population to enhance exploration and convergence.", "configspace": "", "generation": 8, "fitness": 0.9853796140635871, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.985 with standard deviation 0.008. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "9d86bee1-7681-45b2-ac46-9d760215db75", "metadata": {"aucs": [0.991607866494323, 0.99013870634111, 0.9743922693553282], "final_y": [0.16505850408158396, 0.16491129624705747, 0.16800613096178652]}, "mutation_prompt": null}
{"id": "960d05ca-2600-486c-9651-9a70460b2e96", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(0, self.dim, period):  # Synchronizing periodic structure\n            candidate[i:i+period] = candidate[i]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            diversity = np.std(scores) / np.mean(scores)\n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhance periodicity promotion by synchronizing candidate modifications with dimensional periodic structures.", "configspace": "", "generation": 9, "fitness": 0.5733624363310105, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.573 with standard deviation 0.034. And the mean value of best solutions found was 0.319 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "9d86bee1-7681-45b2-ac46-9d760215db75", "metadata": {"aucs": [0.5255487035103472, 0.5922330165137952, 0.6023055889688892], "final_y": [0.30370331539839357, 0.3350220756462279, 0.31815917299824636]}, "mutation_prompt": null}
{"id": "6b048fef-f55b-42d1-9e62-76247b10f776", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 22  # Increased population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))  # Adjust differential weight adaptively based on diversity\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhance convergence by increasing population size for broader exploration in high-dimensional spaces.", "configspace": "", "generation": 9, "fitness": 0.9384091155170798, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.938 with standard deviation 0.048. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "d0278ea9-dc43-4d1f-81f5-f0c35d355aab", "metadata": {"aucs": [0.9866952590251635, 0.8738206100651262, 0.9547114774609493], "final_y": [0.16613493105297472, 0.2029245496295854, 0.16623274742328076]}, "mutation_prompt": null}
{"id": "fb3336f0-6c79-43e0-a536-47a468941b19", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))  # Adjust differential weight adaptively based on diversity\n            self.cross_prob = max(0.3, min(0.9, 0.5 + 0.5 * (np.std(scores) / np.mean(scores) - diversity)))\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced adaptive crossover probability scaling to enhance exploration by dynamically adjusting self.cross_prob based on score variance and average population score to improve convergence (Score: 0.986).", "configspace": "", "generation": 9, "fitness": 0.9559261889627316, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.956 with standard deviation 0.008. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "d0278ea9-dc43-4d1f-81f5-f0c35d355aab", "metadata": {"aucs": [0.9515806830010811, 0.9485826677230415, 0.9676152161640722], "final_y": [0.17248817644588743, 0.16826014584151583, 0.17332382059554985]}, "mutation_prompt": null}
{"id": "f0f9b832-9ce7-42d4-9175-33024600b280", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            population_variance = np.var(population)\n            self.diff_weight = max(0.5, min(1.0, diversity * population_variance))  # Adjust differential weight adaptively\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity * population_variance))  # Adjust local opt probability\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Refine differential weight and local optimization probability by utilizing both diversity and population variance for enhanced exploration and convergence.", "configspace": "", "generation": 9, "fitness": 0.9668674284044556, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d0278ea9-dc43-4d1f-81f5-f0c35d355aab", "metadata": {"aucs": [0.9704829344639977, 0.9612167178957464, 0.9689026328536228], "final_y": [0.16527609034170865, 0.16491639098817024, 0.16566420080633482]}, "mutation_prompt": null}
{"id": "388323f0-0646-466a-a9f8-d12d3019d6fe", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom sklearn.cluster import KMeans\n\nclass DynamicClusterDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cross_prob = 0.7\n        self.diff_weight = 0.8\n        self.local_optimization_prob = 0.1\n        self.cluster_merge_threshold = 1e-3\n\n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n\n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n\n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n\n        return population, scores\n\n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n\n    def _dynamic_clustering(self, population):\n        kmeans = KMeans(n_clusters=min(5, len(population)))\n        kmeans.fit(population)\n        return kmeans.cluster_centers_\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n\n            cluster_centers = self._dynamic_clustering(population)\n            if len(cluster_centers) > 1:\n                distances = np.linalg.norm(cluster_centers[None, :] - cluster_centers[:, None], axis=2)\n                min_distance = np.min(distances + np.eye(len(cluster_centers)) * np.inf)\n                if min_distance < self.cluster_merge_threshold:\n                    population = cluster_centers\n                    scores = self._evaluate_population(population, func)\n                    evaluations += len(cluster_centers)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "DynamicClusterDE", "description": "Introduced dynamic population clustering with adaptive cluster merging to enhance exploration and exploit periodicity.", "configspace": "", "generation": 9, "fitness": 0.4992436108652401, "feedback": "The algorithm DynamicClusterDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.499 with standard deviation 0.047. And the mean value of best solutions found was 0.377 (0. is the best) with standard deviation 0.054.", "error": "", "parent_id": "6e25478b-36a5-4a55-b607-ddb58b3fa7af", "metadata": {"aucs": [0.502478722331472, 0.4396068242124991, 0.5556452860517493], "final_y": [0.32004051182581383, 0.44928985224401685, 0.3621235738778843]}, "mutation_prompt": null}
{"id": "0d4ad7ca-48d4-41df-8cf5-96229e516a5b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cross_prob = 0.7\n        self.diff_weight = 0.8\n        self.local_optimization_prob = 0.1\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)\n        if np.random.rand() < 0.5:  # Probabilistic periodicity promotion\n            for i in range(self.dim):\n                candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))\n            self.cross_prob = max(0.5, min(0.9, 1 - diversity))  # Adaptive crossover probability\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced exploration with adaptive crossover probability and probabilistic periodicity promotion.", "configspace": "", "generation": 10, "fitness": 0.9702917833186605, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.002. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d0278ea9-dc43-4d1f-81f5-f0c35d355aab", "metadata": {"aucs": [0.9720121372031463, 0.9674469228519995, 0.9714162899008356], "final_y": [0.16736882232393357, 0.1733235038598827, 0.16864634206574358]}, "mutation_prompt": null}
{"id": "ceb7df86-7f07-4873-88f4-5aa450affd67", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate, diversity):\n        period = np.random.randint(1, min(5, self.dim))  # Dynamic period selection for periodicity promotion\n        adaptive_periodicity_factor = np.clip(diversity, 0.5, 1.5) \n        for i in range(self.dim):\n            candidate[i] = candidate[i % int(period * adaptive_periodicity_factor)]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        diversity = np.mean(np.std(population, axis=0))  # Calculate population diversity\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adapt crossover probability based on diversity\n            adaptive_cross_prob = min(1.0, max(0.3, diversity))\n            cross_points = np.random.rand(self.dim) < adaptive_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial, diversity)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced adaptive periodicity promotion by dynamically adjusting the promotion based on the diversity of the population to enhance exploration and convergence.", "configspace": "", "generation": 10, "fitness": 0.9529311813432507, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.006. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "6e25478b-36a5-4a55-b607-ddb58b3fa7af", "metadata": {"aucs": [0.945806378836228, 0.9593254191311588, 0.9536617460623654], "final_y": [0.1734295621364378, 0.1733517251516462, 0.1733188138000754]}, "mutation_prompt": null}
{"id": "29f533a6-1bf2-460e-8b7d-ad1f1b8bb770", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        avg_score = np.mean(scores)  # Calculate average score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / avg_score)\n            \n            # Adjust differential weight based on population diversity\n            population_diversity = np.std(population)\n            self.diff_weight = 0.5 + 0.5 * (population_diversity / np.mean([ub - lb])) * (np.max(scores) - np.min(scores))\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced adaptive differential weight scaling based on population diversity to enhance exploration and exploitation balance, with emphasis on exploiting high-quality regions.", "configspace": "", "generation": 10, "fitness": 0.954448516174205, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.027. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "fb0eeb94-13ac-4b45-9ff4-02966597112c", "metadata": {"aucs": [0.9767513676493484, 0.9172046366661054, 0.9693895442071612], "final_y": [0.16493260711208857, 0.16733315987865638, 0.17332382059554985]}, "mutation_prompt": null}
{"id": "16356eee-f362-4467-9008-361a0bd23351", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))  # Adjust differential weight adaptively based on diversity\n            self.population_size = max(10, int(20 * diversity))  # Dynamic population size based on diversity\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhance exploration by introducing a dynamic population size adjustment based on diversity.", "configspace": "", "generation": 10, "fitness": 0.9764005417942806, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.976 with standard deviation 0.012. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d0278ea9-dc43-4d1f-81f5-f0c35d355aab", "metadata": {"aucs": [0.9627710443986633, 0.9741582809269925, 0.9922723000571859], "final_y": [0.1706159140648279, 0.16503065144707918, 0.16534695362470997]}, "mutation_prompt": null}
{"id": "464b0781-d71e-4bb7-a04a-71d9d75d5fcf", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        avg_score = np.mean(scores)  # Calculate average score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / avg_score)\n            \n            # Adjust differential weight based on population diversity\n            population_diversity = np.std(population)\n            self.diff_weight = 0.5 + 0.5 * (population_diversity / np.mean([ub - lb]))\n\n            # Adjust local optimization probability based on score variance\n            self.local_optimization_prob = 0.1 + 0.1 * (score_variance / avg_score)\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhance exploration by introducing a dynamic local optimization probability scaling based on score variance.  ", "configspace": "", "generation": 10, "fitness": 0.972798740964806, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.014. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "fb0eeb94-13ac-4b45-9ff4-02966597112c", "metadata": {"aucs": [0.990531705963977, 0.9557913663754065, 0.9720731505550348], "final_y": [0.16491640541770813, 0.16946245274382243, 0.16814755648682944]}, "mutation_prompt": null}
{"id": "02484be5-1330-46d8-9015-aa4febff0455", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, self.dim // 2)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))  # Adjust differential weight adaptively based on diversity\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced periodicity promotion by allowing adaptive random selection of periodicity for broader exploration.", "configspace": "", "generation": 11, "fitness": 0.9394348362648014, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.939 with standard deviation 0.045. And the mean value of best solutions found was 0.180 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "d0278ea9-dc43-4d1f-81f5-f0c35d355aab", "metadata": {"aucs": [0.9740908531791577, 0.8752588971544032, 0.9689547584608434], "final_y": [0.1651707752742646, 0.2029245496295854, 0.17311455606980786]}, "mutation_prompt": null}
{"id": "71be535e-8b63-424f-8d93-0a5e67fa6280", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, min(5, self.dim))  # Dynamic period selection for periodicity promotion\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        diversity = np.mean(np.std(population, axis=0))  # Calculate population diversity\n        self.diff_weight = 0.5 + 0.4 * (1 - diversity) # Adjust differential weight based on diversity\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adapt crossover probability based on diversity\n            adaptive_cross_prob = min(1.0, max(0.3, diversity))\n            cross_points = np.random.rand(self.dim) < adaptive_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced adaptive differential weight adjustment based on population diversity to enhance exploration and convergence.", "configspace": "", "generation": 11, "fitness": 0.8968211061968359, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.043. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "6e25478b-36a5-4a55-b607-ddb58b3fa7af", "metadata": {"aucs": [0.884791860233208, 0.8517708754274298, 0.9539005829298698], "final_y": [0.1822579986615812, 0.2029245496295854, 0.17381390039819422]}, "mutation_prompt": null}
{"id": "6db16c40-8532-4100-a3ac-25110b528293", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        avg_score = np.mean(scores)  # Calculate average score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / avg_score)\n            \n            # Adjust differential weight based on score variance\n            self.diff_weight = 0.5 + 0.5 * (score_variance / np.mean(scores))\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced exploration by introducing dynamic differential weight scaling based on the score variance.", "configspace": "", "generation": 11, "fitness": 0.9824420754297596, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.982 with standard deviation 0.009. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fb0eeb94-13ac-4b45-9ff4-02966597112c", "metadata": {"aucs": [0.988560428175737, 0.969883999239493, 0.9888817988740488], "final_y": [0.16625750156166308, 0.16526842284694354, 0.16567479890997283]}, "mutation_prompt": null}
{"id": "cededa91-b9be-4c33-8811-e4ac1ce4ab50", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        avg_score = np.mean(scores)  # Calculate average score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / avg_score)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            # Dynamically adjust local optimization probability\n            self.local_optimization_prob = 0.1 + 0.05 * np.std(scores)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced dynamic local optimization probability scaling based on the standard deviation of scores to improve convergence in promising regions.", "configspace": "", "generation": 11, "fitness": 0.9751364304088028, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.010. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "f29257c9-d622-411a-8d8e-d9854e99f5fb", "metadata": {"aucs": [0.9627002413168958, 0.9761106780739657, 0.9865983718355471], "final_y": [0.17021979742778126, 0.16501593301199802, 0.16585126420830776]}, "mutation_prompt": null}
{"id": "6eb5194b-3cd1-4424-aad6-40795ef9d6a1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on population diversity\n            population_diversity = np.std(population)\n            self.cross_prob = 0.5 + 0.5 * (population_diversity / np.mean([ub - lb]))\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced adaptive crossover probability scaling based on population diversity to enhance convergence.", "configspace": "", "generation": 11, "fitness": 0.9503359907619471, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.950 with standard deviation 0.016. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "fb0eeb94-13ac-4b45-9ff4-02966597112c", "metadata": {"aucs": [0.9293404969935591, 0.9694783121994344, 0.9521891630928476], "final_y": [0.18251341014142808, 0.16545214326315782, 0.17144634155251348]}, "mutation_prompt": null}
{"id": "18e60936-1f47-404c-a579-a0cbc55d79b5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, max(4, int(1 / np.std(candidate))))  # Adaptive period selection based on diversity\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            diversity = np.std(scores) / np.mean(scores)\n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhance the periodicity promotion by incorporating adaptive period selection based on population diversity to improve exploration.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: OverflowError('cannot convert float infinity to integer').", "error": "OverflowError('cannot convert float infinity to integer')", "parent_id": "9d86bee1-7681-45b2-ac46-9d760215db75", "metadata": {}, "mutation_prompt": null}
{"id": "6f9004b9-28e8-4ef4-962a-cdb53a614350", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(2, min(6, self.dim))  # Adjusted period selection range for periodicity promotion\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        diversity = np.mean(np.std(population, axis=0))  # Calculate population diversity\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adapt crossover probability based on diversity\n            adaptive_cross_prob = min(1.0, max(0.3, diversity))\n            cross_points = np.random.rand(self.dim) < adaptive_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Adjust the dynamic periodicity promotion by refining the period selection range to improve exploration and convergence.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: OverflowError('cannot convert float infinity to integer').", "error": "OverflowError('cannot convert float infinity to integer')", "parent_id": "6e25478b-36a5-4a55-b607-ddb58b3fa7af", "metadata": {}, "mutation_prompt": null}
{"id": "c6753aea-5c11-4387-95f3-10af9cbbaa62", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.2, diversity))  # Adjust differential weight adaptively based on diversity\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced diversity adaptation by refining differential weight adjustment to better balance exploration and convergence.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: OverflowError('cannot convert float infinity to integer').", "error": "OverflowError('cannot convert float infinity to integer')", "parent_id": "d0278ea9-dc43-4d1f-81f5-f0c35d355aab", "metadata": {}, "mutation_prompt": null}
{"id": "9929bb5e-6ea4-42e0-acdf-905e26a89cde", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, min(5, self.dim))  # Dynamic period selection for periodicity promotion\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        diversity = np.mean(np.std(population, axis=0))  # Calculate population diversity\n        adaptive_diff_weight = self.diff_weight * (1 + diversity)  # Adaptive differential weight based on diversity\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + adaptive_diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adapt crossover probability based on diversity\n            adaptive_cross_prob = min(1.0, max(0.3, diversity))\n            cross_points = np.random.rand(self.dim) < adaptive_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Improved exploration by introducing diversity-dependent adaptive differential weight scaling.", "configspace": "", "generation": 12, "fitness": 0.8413873608739185, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.166. And the mean value of best solutions found was 0.218 (0. is the best) with standard deviation 0.063.", "error": "", "parent_id": "6e25478b-36a5-4a55-b607-ddb58b3fa7af", "metadata": {"aucs": [0.60860651614846, 0.9334860357475151, 0.9820695307257808], "final_y": [0.3067345023118072, 0.1795039375178885, 0.1666062825948198]}, "mutation_prompt": null}
{"id": "6bd3d590-6a43-4287-b123-5fa345b3222b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        initial_avg_score = np.mean(scores) if self.budget == self.budget else initial_avg_score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / initial_avg_score)\n            \n            # Adjust differential weight based on score variance\n            self.diff_weight = 0.5 + 0.5 * ((score_variance / np.mean(scores)) * (initial_avg_score / np.mean(scores)))\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        initial_avg_score = np.mean(scores)\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced differential weight adaptation by incorporating the ratio of the current to initial scores to balance exploration and exploitation.", "configspace": "", "generation": 12, "fitness": 0.9821489123867945, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.982 with standard deviation 0.008. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "6db16c40-8532-4100-a3ac-25110b528293", "metadata": {"aucs": [0.9850450601588813, 0.9713329400281112, 0.9900687369733907], "final_y": [0.16523225124208407, 0.16952463054963274, 0.1656508622729429]}, "mutation_prompt": null}
{"id": "459d919a-6221-432f-bd80-74d6c8fddcca", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.15  # Increased probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(2, min(5, self.dim//2))  # Adaptive period selection for enhanced periodicity promotion\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        diversity = np.mean(np.std(population, axis=0))  # Calculate population diversity\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adapt crossover probability based on diversity\n            adaptive_cross_prob = min(1.0, max(0.3, diversity))\n            cross_points = np.random.rand(self.dim) < adaptive_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced periodicity promotion with adaptive period length and synchronized local search to improve convergence.", "configspace": "", "generation": 13, "fitness": 0.9418195042821885, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.942 with standard deviation 0.010. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "6e25478b-36a5-4a55-b607-ddb58b3fa7af", "metadata": {"aucs": [0.9273818233769939, 0.9493191253203526, 0.9487575641492189], "final_y": [0.18193985301220794, 0.17757534991138602, 0.17879553655388825]}, "mutation_prompt": null}
{"id": "54f54a94-7cee-4d65-b4c8-f85163a4a75b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cross_prob = 0.7\n        self.initial_diff_weight = 0.8\n        self.local_optimization_prob = 0.1\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))\n            self.cross_prob = max(0.6, min(0.9, 1 - diversity))  # Adaptive crossover probability\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced exploitation-exploration balance by incorporating adaptive crossover probability and diversity-weighted local optimization.", "configspace": "", "generation": 13, "fitness": 0.9812535583717716, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.981 with standard deviation 0.004. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "d0278ea9-dc43-4d1f-81f5-f0c35d355aab", "metadata": {"aucs": [0.975984975623091, 0.9836242812798754, 0.9841514182123485], "final_y": [0.170201581227843, 0.16650590883834393, 0.1654589509258726]}, "mutation_prompt": null}
{"id": "3576cc9c-b031-4b7d-95d9-8e9339d97858", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        initial_avg_score = np.mean(scores) if self.budget == self.budget else initial_avg_score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / initial_avg_score)\n            \n            # Adjust differential weight based on score variance and a penalty term for deviation from periodicity\n            penalty = np.sum(np.abs(np.diff(mutant, n=2))) / self.dim\n            self.diff_weight = 0.5 + 0.5 * ((score_variance / np.mean(scores)) * (initial_avg_score / np.mean(scores))) - 0.1 * penalty\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        initial_avg_score = np.mean(scores)\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced differential weight adaptation by incorporating a penalty term based on deviation from known optimal periodic solutions to balance exploration and exploitation.", "configspace": "", "generation": 13, "fitness": 0.9426564176457278, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.943 with standard deviation 0.030. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "6bd3d590-6a43-4287-b123-5fa345b3222b", "metadata": {"aucs": [0.9595549552732632, 0.9009493719966422, 0.9674649256672783], "final_y": [0.16866167747344307, 0.1733265000713835, 0.17332382059554985]}, "mutation_prompt": null}
{"id": "f53b1ad5-415a-4ab5-a9d4-5ae6bb005107", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        avg_score = np.mean(scores)  # Calculate average score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / avg_score)\n            \n            # Adjust differential weight based on score variance\n            self.diff_weight = 0.5 + 0.5 * (score_variance / np.mean(scores))\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            # Adjust local optimization probability based on best score\n            self.local_optimization_prob = 0.1 + 0.2 * (1 - np.max(scores))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Dynamically adjust the local optimization probability based on the current best score to enhance local search when nearing optima.", "configspace": "", "generation": 13, "fitness": 0.9684609320792772, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.017. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "6db16c40-8532-4100-a3ac-25110b528293", "metadata": {"aucs": [0.9695245118980964, 0.9469247900258644, 0.9889334943138708], "final_y": [0.16821850783346404, 0.18017059536599644, 0.16522144065995403]}, "mutation_prompt": null}
{"id": "8ffc9ba4-e002-44d4-9f29-759f6c726fb9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate, iter_count):\n        period = np.random.choice([1, 2, 4]) + iter_count % 3  # Dynamic period selection based on iteration count\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        avg_score = np.mean(scores)  # Calculate average score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / avg_score)\n            \n            # Adjust differential weight based on score variance\n            self.diff_weight = 0.5 + 0.5 * (score_variance / np.mean(scores))\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial, len(population))\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced periodicity promotion through the use of dynamic period selection based on the iteration count.", "configspace": "", "generation": 13, "fitness": 0.945508128547278, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.946 with standard deviation 0.047. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "6db16c40-8532-4100-a3ac-25110b528293", "metadata": {"aucs": [0.8784394276405627, 0.9819563366446217, 0.9761286213566496], "final_y": [0.18268294640353122, 0.1678290131580208, 0.16865980631535515]}, "mutation_prompt": null}
{"id": "3d426577-6133-40d3-99e3-c4c0ff24771d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cross_prob = 0.7\n        self.diff_weight = 0.8\n        self.local_optimization_prob = 0.1\n        self.elite_fraction = 0.1  # Fraction of elite individuals to preserve\n\n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n\n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n\n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n\n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n\n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n\n    def _preserve_elite(self, population, scores):\n        elite_count = max(1, int(self.elite_fraction * self.population_size))\n        elite_indices = np.argsort(scores)[-elite_count:]\n        return population[elite_indices], scores[elite_indices]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        recent_improvement = 0\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n                    recent_improvement += 1\n            \n            if recent_improvement > 0:\n                self.local_optimization_prob = min(0.5, self.local_optimization_prob + 0.05)\n            else:\n                self.local_optimization_prob = max(0.05, self.local_optimization_prob - 0.05)\n            \n            recent_improvement = 0\n\n            elite_population, elite_scores = self._preserve_elite(population, scores)\n            population = np.vstack((population, elite_population))\n            scores = np.concatenate((scores, elite_scores))\n\n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhance local exploitation by dynamically adjusting the local optimization probability based on improvement in recent iterations and introducing elite preservation.", "configspace": "", "generation": 14, "fitness": 0.962458448009552, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.022. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "d0278ea9-dc43-4d1f-81f5-f0c35d355aab", "metadata": {"aucs": [0.9549318307965107, 0.93953300041728, 0.9929105128148655], "final_y": [0.17333159047795388, 0.18159849919996707, 0.16485655963543666]}, "mutation_prompt": null}
{"id": "b24e060e-144c-40ea-aae4-91cc6cb205a6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 3])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        avg_score = np.mean(scores)  # Calculate average score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / avg_score)\n            \n            # Adjust differential weight based on population diversity\n            population_diversity = np.std(population)\n            self.diff_weight = 0.5 + 0.5 * (population_diversity / np.mean([ub - lb]))\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhance the periodicity promotion mechanism by dynamically adjusting the period choice based on the population's convergence state to improve solution quality.", "configspace": "", "generation": 14, "fitness": 0.954519921817698, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.955 with standard deviation 0.012. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "fb0eeb94-13ac-4b45-9ff4-02966597112c", "metadata": {"aucs": [0.9703611609034293, 0.942973420998537, 0.9502251835511275], "final_y": [0.16671584774413462, 0.1736709057755914, 0.17373248521991613]}, "mutation_prompt": null}
{"id": "ce0ce9a2-aa63-4135-a136-961d80ade5ae", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cross_prob = 0.7\n        self.initial_diff_weight = 0.8\n        self.local_optimization_prob = 0.1\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, self._apply_periodicity_promotion(candidate), bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))\n            self.cross_prob = max(0.6, min(0.9, 1 - diversity))  # Adaptive crossover probability\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced periodic alignment in the local optimization step for enhanced solution periodicity and convergence.", "configspace": "", "generation": 14, "fitness": 0.9648688513982018, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.013. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "54f54a94-7cee-4d65-b4c8-f85163a4a75b", "metadata": {"aucs": [0.980600307763244, 0.9489925243371646, 0.9650137220941967], "final_y": [0.1657138284799078, 0.17332832229639272, 0.17332382059554985]}, "mutation_prompt": null}
{"id": "c07d46bf-423a-43f2-8ca7-3d1e55df0f3b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 20})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))  # Adjust differential weight adaptively based on diversity\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced local optimization by increasing L-BFGS-B iterations for better fine-tuning near promising regions.", "configspace": "", "generation": 14, "fitness": 0.9673340918798106, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.011. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "d0278ea9-dc43-4d1f-81f5-f0c35d355aab", "metadata": {"aucs": [0.9812464063142801, 0.9671581327420327, 0.953597736583119], "final_y": [0.1649672281033545, 0.173373809778402, 0.1733187376915517]}, "mutation_prompt": null}
{"id": "0136d663-842f-4bdd-aeee-d7c2d1d3acd1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 3, 5])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        avg_score = np.mean(scores)  # Calculate average score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / avg_score)\n            \n            # Adjust differential weight based on population diversity\n            population_diversity = np.std(population)\n            self.diff_weight = 0.5 + 0.5 * (population_diversity / np.mean([ub - lb]))\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced the periodic structure by adjusting the choice of periods for better alignment with known optimal solutions.", "configspace": "", "generation": 14, "fitness": 0.9622866882677639, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.002. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fb0eeb94-13ac-4b45-9ff4-02966597112c", "metadata": {"aucs": [0.9651602032617125, 0.9595279689392936, 0.9621718926022855], "final_y": [0.1733292401347909, 0.1733602377808604, 0.17338476842285522]}, "mutation_prompt": null}
{"id": "52e54164-b284-4d99-a356-0247b7a71644", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))  # Adjust differential weight adaptively based on diversity\n            self.cross_prob = max(0.3, min(0.9, diversity))  # Adjust crossover probability based on diversity\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Improved exploration by adjusting the crossover probability based on population diversity.", "configspace": "", "generation": 15, "fitness": 0.9809033544023759, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.981 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d0278ea9-dc43-4d1f-81f5-f0c35d355aab", "metadata": {"aucs": [0.9866432684680966, 0.9723774673426449, 0.9836893273963863], "final_y": [0.16486767937113977, 0.16512382179731233, 0.1649369393426724]}, "mutation_prompt": null}
{"id": "43d0f441-091a-45ca-af00-76ccf8c6a3c2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        # Introduced periodicity awareness\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim // 2)).repeat(2, axis=1)\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        initial_avg_score = np.mean(scores) if self.budget == self.budget else initial_avg_score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / initial_avg_score)\n            \n            # Adjust differential weight based on score variance\n            self.diff_weight = 0.5 + 0.5 * ((score_variance / np.mean(scores)) * (initial_avg_score / np.mean(scores)))\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        initial_avg_score = np.mean(scores)\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced periodicity awareness in initialization to further enhance constructive interference from the start.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (20, 5) and arg 1 with shape (10,).').", "error": "ValueError('shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (20, 5) and arg 1 with shape (10,).')", "parent_id": "6bd3d590-6a43-4287-b123-5fa345b3222b", "metadata": {}, "mutation_prompt": null}
{"id": "1d3a8125-15f3-4122-b261-a0b8f3a2e099", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Base probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        initial_avg_score = np.mean(scores) if self.budget == self.budget else initial_avg_score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / initial_avg_score)\n            \n            # Adjust differential weight based on score variance\n            self.diff_weight = 0.5 + 0.5 * ((score_variance / np.mean(scores)) * (initial_avg_score / np.mean(scores)))\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        initial_avg_score = np.mean(scores)\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            best_idx = np.argmax(scores)\n            if np.random.rand() < self.local_optimization_prob * (1 - np.linalg.norm(population[best_idx] - population[idx]) / np.linalg.norm(ub - lb)):\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced adaptive local optimization probability based on distance to the best candidate to enhance convergence efficiency.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'idx' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'idx' referenced before assignment\")", "parent_id": "6bd3d590-6a43-4287-b123-5fa345b3222b", "metadata": {}, "mutation_prompt": null}
{"id": "017d3e3a-26bf-4132-9ca3-773af2949e66", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = 2  # Using a fixed period of 2 for Bragg mirror optimization\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        avg_score = np.mean(scores)  # Calculate average score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / avg_score)\n            \n            # Adjust differential weight based on score feedback and population diversity\n            score_feedback = (scores[i] - avg_score) / avg_score\n            self.diff_weight = 0.5 + 0.4 * (score_feedback + np.std(population) / np.mean([ub - lb]))\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced periodicity promotion by using problem-specific periods and improved differential weight adaptation with score-based feedback.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'idx' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'idx' referenced before assignment\")", "parent_id": "fb0eeb94-13ac-4b45-9ff4-02966597112c", "metadata": {}, "mutation_prompt": null}
{"id": "1979ff34-fba8-491a-b962-cc8ba7bb3495", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, int(4 * self.diff_weight) + 1)  # Dynamic period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))  # Adjust differential weight adaptively based on diversity\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced periodicity promotion by dynamically adjusting period based on diversity to improve convergence.", "configspace": "", "generation": 15, "fitness": 0.985600074887245, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.986 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d0278ea9-dc43-4d1f-81f5-f0c35d355aab", "metadata": {"aucs": [0.9794998250608109, 0.9888844913351726, 0.9884159082657513], "final_y": [0.16486756453564055, 0.16545166830124447, 0.1648863224142657]}, "mutation_prompt": null}
{"id": "f42f8316-c0a5-49e2-8cdc-695977d98456", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        avg_score = np.mean(scores)  # Calculate average score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on evaluation progress\n            progress_ratio = (self.budget - len(population) * len(scores)) / self.budget\n            self.cross_prob = 0.5 + 0.5 * progress_ratio\n\n            population_diversity = np.std(population)\n            self.diff_weight = 0.5 + 0.5 * (population_diversity / np.mean([ub - lb]))\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Improved exploration by dynamically adjusting the crossover probability based on evaluation progress to enhance population diversity.", "configspace": "", "generation": 16, "fitness": 0.976335503032305, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.976 with standard deviation 0.010. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "fb0eeb94-13ac-4b45-9ff4-02966597112c", "metadata": {"aucs": [0.9682536206179237, 0.9710384198519011, 0.9897144686270904], "final_y": [0.16963636122552428, 0.1659381966730079, 0.1648626628285006]}, "mutation_prompt": null}
{"id": "1e746d44-2712-4375-a9df-4443241afc80", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))  # Adjust differential weight adaptively based on diversity\n            self.cross_prob = max(0.5, min(1.0, diversity))  # Dynamically adjust crossover probability based on diversity\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced dynamic adjustment of crossover probability based on population diversity to balance exploration and exploitation.", "configspace": "", "generation": 16, "fitness": 0.9859604172648174, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.986 with standard deviation 0.003. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "d0278ea9-dc43-4d1f-81f5-f0c35d355aab", "metadata": {"aucs": [0.9840906817322738, 0.9901308833369682, 0.9836596867252104], "final_y": [0.165044725080422, 0.16555681223638696, 0.16816090591791555]}, "mutation_prompt": null}
{"id": "52f479bb-deec-4b15-94bb-0b0ceaeb598c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))  # Adjust differential weight adaptively based on diversity\n            self.cross_prob = max(0.5, min(0.9, diversity))  # Adjust crossover probability adaptively based on diversity\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced adaptive crossover probability scaling based on population diversity to improve convergence and exploration balance.", "configspace": "", "generation": 16, "fitness": 0.9822429281969146, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.982 with standard deviation 0.004. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "d0278ea9-dc43-4d1f-81f5-f0c35d355aab", "metadata": {"aucs": [0.9782723608970175, 0.9873371220608818, 0.9811193016328448], "final_y": [0.16766148933538616, 0.16545698782496243, 0.1657102986129262]}, "mutation_prompt": null}
{"id": "2eed767a-873d-4b4d-80a2-e2849fcbb9a4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.cross_prob = 0.7\n        self.diff_weight = 0.8\n        self.local_optimization_prob = 0.1\n        self.population_growth_factor = 1.1\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 3, 4])  # Modified periods to enhance periodicity adaptation\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        avg_score = np.mean(scores)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n\n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.3 * (score_variance / avg_score)  # Adjusted scaling factor for crossover probability\n            \n            self.diff_weight = 0.5 + 0.3 * (score_variance / np.mean(scores))  # Adjusted scaling factor for differential weight\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n        \n        diversity_factor = np.std(candidate) / (ub - lb).mean()  # Introduce diversity-based scaling\n        max_iter = int(10 * (1 + diversity_factor))  # Scale max iterations by diversity\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': max_iter})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced exploration by incorporating adaptive periodicity selection and diversity-based scaling of local optimization efforts.", "configspace": "", "generation": 16, "fitness": 0.8934571978207583, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.105. And the mean value of best solutions found was 0.199 (0. is the best) with standard deviation 0.043.", "error": "", "parent_id": "6db16c40-8532-4100-a3ac-25110b528293", "metadata": {"aucs": [0.9695680312531093, 0.7443656811952194, 0.9664378810139461], "final_y": [0.1724602403659512, 0.26027540340696087, 0.1653314147793199]}, "mutation_prompt": null}
{"id": "5c90982e-92d1-4b44-9dbd-d468369872d8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        initial_avg_score = np.mean(scores) if self.budget == self.budget else initial_avg_score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            periodic_diversity = np.sum(np.abs(np.diff(population, axis=0)))\n            self.cross_prob = 0.5 + 0.5 * (score_variance / initial_avg_score) * (periodic_diversity / np.mean(scores))\n            \n            # Adjust differential weight based on score variance\n            self.diff_weight = 0.5 + 0.5 * ((score_variance / np.mean(scores)) * (initial_avg_score / np.mean(scores)))\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        initial_avg_score = np.mean(scores)\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Integrate periodic diversity measure to dynamically adjust crossover probability, enhancing exploration-exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.9480118805000398, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.948 with standard deviation 0.039. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "6bd3d590-6a43-4287-b123-5fa345b3222b", "metadata": {"aucs": [0.8962625127654114, 0.9894087483764982, 0.9583643803582101], "final_y": [0.19601799201056458, 0.16491918535756622, 0.17349212420727078]}, "mutation_prompt": null}
{"id": "4492586d-c59f-49c8-bab0-686bfa199f57", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4, 5])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        avg_score = np.mean(scores)  # Calculate average score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / avg_score)\n            \n            # Adjust differential weight based on score variance\n            self.diff_weight = 0.5 + 0.5 * (score_variance / np.mean(scores))\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Improved solution accuracy by refining the periodicity promotion mechanism to enhance constructive interference effects.", "configspace": "", "generation": 17, "fitness": 0.9615408635921653, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.015. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "6db16c40-8532-4100-a3ac-25110b528293", "metadata": {"aucs": [0.9720993418237641, 0.9724432818217613, 0.9400799671309705], "final_y": [0.16580156704842997, 0.16943118040413163, 0.1818491315013394]}, "mutation_prompt": null}
{"id": "f35ffa00-6fdb-45cb-8b82-222d9f6d4200", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.15  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate, diversity):\n        period = np.random.choice(range(1, min(5, self.dim // 2 + 1)))  # More adaptive period selection\n        if diversity > 0.5:\n            period = 1  # Favor simpler structures if diversity is high\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        avg_score = np.mean(scores)  # Calculate average score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / avg_score)\n            \n            # Adjust differential weight based on population diversity\n            population_diversity = np.std(population)\n            self.diff_weight = 0.5 + 0.5 * (population_diversity / np.mean([ub - lb]))\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial, population_diversity)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob * (1 - np.std(scores)):\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced periodicity promotion using adaptive period selection based on diversity, and refined local optimization application frequency.", "configspace": "", "generation": 17, "fitness": 0.8740883217174922, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.131. And the mean value of best solutions found was 0.180 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "fb0eeb94-13ac-4b45-9ff4-02966597112c", "metadata": {"aucs": [0.9640005793879056, 0.6888748415574095, 0.9693895442071612], "final_y": [0.17331872698682438, 0.19218328467866674, 0.17332382059554985]}, "mutation_prompt": null}
{"id": "afee6bf9-d1df-4b4f-b064-0ee162a40bb0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))  # Adjust differential weight adaptively based on diversity\n            self.cross_prob = max(0.5, min(0.9, 1.0 - diversity))  # Adjust crossover probability adaptively\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced adaptive crossover probability scaling based on population diversity to enhance exploration and convergence.", "configspace": "", "generation": 17, "fitness": 0.8734272380333471, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.125. And the mean value of best solutions found was 0.209 (0. is the best) with standard deviation 0.053.", "error": "", "parent_id": "d0278ea9-dc43-4d1f-81f5-f0c35d355aab", "metadata": {"aucs": [0.9735350609865945, 0.6971779817422781, 0.9495686713711686], "final_y": [0.17006697312430263, 0.2832773896292745, 0.17332382059554985]}, "mutation_prompt": null}
{"id": "c386cca4-caa9-4bac-b440-631f34721223", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        avg_score = np.mean(scores)  # Calculate average score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and population diversity\n            score_variance = np.var(scores)\n            population_diversity = np.std(population)\n            self.cross_prob = 0.5 + 0.5 * ((score_variance / avg_score) + (population_diversity / np.mean([ub - lb])))\n\n            # Adjust differential weight based on population diversity\n            self.diff_weight = 0.5 + 0.5 * (population_diversity / np.mean([ub - lb]))\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Refined crossover probability adjustment by incorporating both score variance and population diversity, further enhancing exploration and exploitation dynamics.", "configspace": "", "generation": 17, "fitness": 0.8932045863777031, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.069. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "fb0eeb94-13ac-4b45-9ff4-02966597112c", "metadata": {"aucs": [0.9819173788477722, 0.8131862868362163, 0.8845100934491207], "final_y": [0.16572806697995035, 0.17746087336382455, 0.16950562298797656]}, "mutation_prompt": null}
{"id": "003bec8a-b9e5-4f70-93b2-2984a5cb6a35", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        avg_score = np.mean(scores)  # Calculate average score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            # Adaptive mutation based on diversity\n            diversity_factor = np.std(population)\n            mutant = np.clip(population[a] + self.diff_weight * diversity_factor * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / avg_score)\n            \n            # Adjust differential weight based on population diversity\n            population_diversity = np.std(population)\n            self.diff_weight = 0.5 + 0.5 * (population_diversity / np.mean([ub - lb]))\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Incorporated adaptive mutation based on diversity to enhance exploration in sparse regions of the search space.", "configspace": "", "generation": 17, "fitness": 0.9539189636284494, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.003. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "fb0eeb94-13ac-4b45-9ff4-02966597112c", "metadata": {"aucs": [0.9553901298591397, 0.9502546880338186, 0.9561120729923902], "final_y": [0.16689805217082276, 0.17341080095883732, 0.17332114931350706]}, "mutation_prompt": null}
{"id": "3a4f9cf8-8bd9-4e82-bee4-96510358246d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cross_prob = 0.7\n        self.diff_weight = 0.8\n        self.local_optimization_prob = 0.1\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_adaptive_periodicity_promotion(self, candidate, diversity):\n        period = np.random.randint(1, int(6 * diversity) + 1)  \n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            mutation_factor = 0.5 + 0.5 * (1 - scores[i] / np.max(scores))\n            mutant = np.clip(population[a] + mutation_factor * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_adaptive_periodicity_promotion(trial, np.std(scores))\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced exploration by incorporating adaptive periodic crossover and fitness-dependent mutation strategy to improve convergence in complex landscapes.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('low >= high').", "error": "ValueError('low >= high')", "parent_id": "1979ff34-fba8-491a-b962-cc8ba7bb3495", "metadata": {}, "mutation_prompt": null}
{"id": "8687043e-99c9-4935-8658-28839d3e6a27", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass NeighborhoodDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.global_cross_prob = 0.7\n        self.local_cross_prob = 0.4\n        self.diff_weight = 0.8\n        self.local_optimization_prob = 0.1\n        self.neighborhood_size = 5  # Number of neighbors considered\n\n    def _initialize_population(self, lb, ub):\n        return lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n\n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n\n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.global_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n\n        return population, scores\n\n    def _localized_exploration(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            neighborhood_indices = np.argsort(scores)[:self.neighborhood_size]\n            a, b, c = np.random.choice(neighborhood_indices, 3, replace=False)\n\n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n\n            cross_points = np.random.rand(self.dim) < self.local_cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n\n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n\n        return population, scores\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n\n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n\n            if np.random.rand() < self.local_optimization_prob:\n                population, scores = self._localized_exploration(population, scores, lb, ub, func)\n                evaluations += self.population_size\n\n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "NeighborhoodDifferentialEvolution", "description": "Introduced adaptive localized exploration by incorporating neighborhood-based differential evolution to enhance convergence precision and maintain diversity.", "configspace": "", "generation": 18, "fitness": 0.5260496973210707, "feedback": "The algorithm NeighborhoodDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.526 with standard deviation 0.026. And the mean value of best solutions found was 0.340 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "1e746d44-2712-4375-a9df-4443241afc80", "metadata": {"aucs": [0.5460649160048242, 0.5421451714788827, 0.4899390044795049], "final_y": [0.3623106788864413, 0.29714872675277126, 0.3609342043546412]}, "mutation_prompt": null}
{"id": "4dc7af2b-d274-41cb-8b86-3e10b6badf5b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.cross_prob = 0.7\n        self.diff_weight = 0.8\n        self.local_optimization_prob = 0.1\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))\n            self.cross_prob = max(0.5, min(1.0, diversity))\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            convergence_rate = np.mean(np.abs(np.diff(scores))) / np.std(scores)\n            self.local_optimization_prob = max(0.05, min(0.3, 1.0 - convergence_rate))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced local optimization by dynamically adjusting its frequency based on population convergence pace.", "configspace": "", "generation": 18, "fitness": 0.981880170633645, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.982 with standard deviation 0.010. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "1e746d44-2712-4375-a9df-4443241afc80", "metadata": {"aucs": [0.9940247050805514, 0.9827001833197135, 0.9689156235006701], "final_y": [0.16510407129912597, 0.16691097168060587, 0.1733983925098449]}, "mutation_prompt": null}
{"id": "5323fba0-f80c-4775-bc8c-7ca488d26a10", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, int(4 * self.diff_weight) + 1)  # Dynamic period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))  # Adjust differential weight adaptively based on diversity\n            self.cross_prob = max(0.6, min(0.9, diversity))  # New: Adjust crossover probability based on diversity\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Introduced adaptive crossover probability based on diversity to improve exploration and exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.9777217760422494, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.978 with standard deviation 0.009. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "1979ff34-fba8-491a-b962-cc8ba7bb3495", "metadata": {"aucs": [0.9845595176466845, 0.983450972381373, 0.9651548380986907], "final_y": [0.16508328120928983, 0.16492391651070892, 0.173318614659417]}, "mutation_prompt": null}
{"id": "1cab2325-5663-439e-8805-86f784cd8a48", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, int(4 * self.diff_weight) + 1)  # Dynamic period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        success_count = 0\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n                success_count += 1\n        \n        success_rate = success_count / self.population_size\n        self.diff_weight = max(0.5, min(1.0, success_rate + np.std(scores) / np.mean(scores)))\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, np.std(scores) / np.mean(scores)))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Refine differential weight adaptation to improve exploration-exploitation balance by including a factor based on trial success rate.", "configspace": "", "generation": 18, "fitness": 0.9850954048504504, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.985 with standard deviation 0.002. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "1979ff34-fba8-491a-b962-cc8ba7bb3495", "metadata": {"aucs": [0.9822669483643337, 0.9876977200509871, 0.9853215461360306], "final_y": [0.16536412040232995, 0.16615229018990973, 0.16630057277309707]}, "mutation_prompt": null}
{"id": "93772340-ea88-46ee-9215-4a5b9b238087", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, int(4 * self.diff_weight * np.random.rand()) + 1)  # Dynamic period selection with scale factor\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))  # Adjust differential weight adaptively based on diversity\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced periodicity promotion by adjusting period based on both diversity and a dynamic scale factor to improve convergence.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('low >= high').", "error": "ValueError('low >= high')", "parent_id": "1979ff34-fba8-491a-b962-cc8ba7bb3495", "metadata": {}, "mutation_prompt": null}
{"id": "faa2860d-1543-40bd-b971-d82d9c750fd4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.diff_weight = max(0.5, min(1.0, diversity))  # Adjust differential weight adaptively based on diversity\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n            \n            if evaluations % (self.budget // 10) == 0:  # Reset diversity metric periodically\n                diversity = np.std(scores) / np.mean(scores)\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Adjust local optimization probability based on diversity and periodically reset diversity metric for improved convergence.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('low >= high').", "error": "ValueError('low >= high')", "parent_id": "d0278ea9-dc43-4d1f-81f5-f0c35d355aab", "metadata": {}, "mutation_prompt": null}
{"id": "eca0538e-d3c2-4912-a967-b3b2adf1e21d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, int(4 * self.diff_weight) + 1)  # Dynamic period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        while evaluations < self.budget:\n            diversity = np.std(scores) / np.mean(scores)\n            self.cross_prob = max(0.6, min(0.9, diversity))  # Adjust crossover probability adaptively based on diversity\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, diversity))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced exploration by adjusting crossover probability dynamically based on diversity.", "configspace": "", "generation": 19, "fitness": 0.9770630502244888, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.977 with standard deviation 0.016. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "1979ff34-fba8-491a-b962-cc8ba7bb3495", "metadata": {"aucs": [0.9862292525437314, 0.954907390045987, 0.9900525080837478], "final_y": [0.16630317433242037, 0.17223512057820956, 0.16600227357073338]}, "mutation_prompt": null}
{"id": "73463173-fd63-4b62-a942-26cf2478fbe2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveTrendDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Set a reasonable population size\n        self.cross_prob = 0.7  # Initial crossover probability\n        self.diff_weight = 0.8  # Initial differential weight\n        self.local_optimization_prob = 0.1  # Initial probability to apply local optimization\n        self.trend_memory = 5  # Number of iterations to consider for trend analysis\n    \n    def _initialize_population(self, lb, ub):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (self.population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.randint(1, 4)  # Adaptive period selection\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self._initialize_population(lb, ub)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = self.population_size\n        best_scores = [np.max(scores)]\n        \n        while evaluations < self.budget:\n            if len(best_scores) >= self.trend_memory:\n                trend = np.polyfit(range(self.trend_memory), best_scores[-self.trend_memory:], 1)[0]\n                if trend > 0:\n                    self.diff_weight = max(0.5, self.diff_weight - 0.1)\n                    self.cross_prob = min(1.0, self.cross_prob + 0.1)\n                else:\n                    self.diff_weight = min(1.0, self.diff_weight + 0.1)\n                    self.cross_prob = max(0.5, self.cross_prob - 0.1)\n            \n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += self.population_size\n            \n            self.local_optimization_prob = max(0.05, min(0.3, np.std(scores) / np.mean(scores)))\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, self.population_size)\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n            \n            best_scores.append(np.max(scores))\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "AdaptiveTrendDE", "description": "Introduced a self-adaptive mechanism for differential weight and crossover probability based on fitness improvement trend to enhance convergence speed while maintaining diversity.", "configspace": "", "generation": 19, "fitness": 0.9819641000103331, "feedback": "The algorithm AdaptiveTrendDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.982 with standard deviation 0.007. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "1e746d44-2712-4375-a9df-4443241afc80", "metadata": {"aucs": [0.9832760600916701, 0.9893064820646621, 0.973309757874667], "final_y": [0.167671844883009, 0.1670265791053881, 0.16495762632829036]}, "mutation_prompt": null}
{"id": "5c8a7bbf-34bc-49ff-a325-e6aa3ea4cb08", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass SymmetricPeriodicDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20  # Initial population size\n        self.cross_prob = 0.7  # Crossover probability\n        self.diff_weight = 0.8  # Differential weight\n        self.local_optimization_prob = 0.1  # Probability to apply local optimization\n        self.population_growth_factor = 1.1  # Factor to grow population size\n\n    def _initialize_population(self, lb, ub, population_size):\n        mid_point = (lb + ub) / 2\n        half_range = (ub - lb) / 2\n        return mid_point + np.random.uniform(-half_range, half_range, (population_size, self.dim))\n    \n    def _apply_periodicity_promotion(self, candidate):\n        period = np.random.choice([1, 2, 4])  # Adjusted periods to target specific structures\n        for i in range(self.dim):\n            candidate[i] = candidate[i % period]\n        return candidate\n    \n    def _evaluate_population(self, population, func):\n        return np.array([func(ind) for ind in population])\n    \n    def _differential_evolution_step(self, population, scores, lb, ub, func):\n        avg_score = np.mean(scores)  # Calculate average score\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = np.random.choice(indices, 3, replace=False)\n            \n            mutant = np.clip(population[a] + self.diff_weight * (population[b] - population[c]), lb, ub)\n            \n            # Adjust crossover probability based on score variance and average score\n            score_variance = np.var(scores)\n            self.cross_prob = 0.5 + 0.5 * (score_variance / avg_score)\n            \n            # Adjust differential weight based on population diversity and score variance\n            population_diversity = np.std(population)\n            self.diff_weight = 0.5 + 0.25 * (population_diversity / np.mean([ub - lb])) + 0.25 * (score_variance / avg_score)\n\n            cross_points = np.random.rand(self.dim) < self.cross_prob\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            \n            trial = self._apply_periodicity_promotion(trial)\n            \n            trial_score = func(trial)\n            if trial_score > scores[i]:\n                population[i] = trial\n                scores[i] = trial_score\n        \n        return population, scores\n    \n    def _local_optimization(self, candidate, func, lb, ub):\n        def local_func(x):\n            return -func(x)\n\n        result = minimize(local_func, candidate, bounds=[(lb[j], ub[j]) for j in range(self.dim)],\n                          method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else candidate\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        population = self._initialize_population(lb, ub, population_size)\n        scores = self._evaluate_population(population, func)\n        \n        evaluations = population_size\n        while evaluations < self.budget:\n            # Dynamic population resizing\n            if evaluations > self.budget // 2:\n                population_size = int(self.population_growth_factor * population_size)\n                population = np.resize(population, (population_size, self.dim))\n                scores = np.resize(scores, population_size)\n                for i in range(len(scores)):\n                    if scores[i] == 0:\n                        scores[i] = func(population[i])\n                        evaluations += 1\n\n            population, scores = self._differential_evolution_step(population, scores, lb, ub, func)\n            evaluations += len(population)\n            \n            if np.random.rand() < self.local_optimization_prob:\n                idx = np.random.randint(0, len(population))\n                candidate = population[idx]\n                optimized = self._local_optimization(candidate, func, lb, ub)\n                optimized_score = func(optimized)\n                evaluations += 1\n                if optimized_score > scores[idx]:\n                    population[idx] = optimized\n                    scores[idx] = optimized_score\n        \n        best_idx = np.argmax(scores)\n        return population[best_idx]", "name": "SymmetricPeriodicDE", "description": "Enhanced differential weight adaptation by incorporating both diversity and score variance to improve exploration-exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.9784346575731572, "feedback": "The algorithm SymmetricPeriodicDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.978 with standard deviation 0.012. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "fb0eeb94-13ac-4b45-9ff4-02966597112c", "metadata": {"aucs": [0.9805433367396519, 0.9923742785600806, 0.9623863574197391], "final_y": [0.1665563745036267, 0.1650827856943703, 0.17331859160904162]}, "mutation_prompt": null}
