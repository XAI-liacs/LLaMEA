{"id": "93a6a24f-82e6-48d0-acf1-78a20a80bc80", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.population = None\n        self.lb = None\n        self.ub = None\n        self.fitness = None\n        self.best_solution = None\n        self.best_fitness = float('-inf')\n\n    def quasi_oppositional_init(self):\n        midpoint = (self.lb + self.ub) / 2\n        self.population = midpoint + np.random.rand(self.population_size, self.dim) * (self.ub - self.lb) / 2\n        opposite_population = midpoint - (self.population - midpoint)\n        self.population = np.vstack((self.population, opposite_population))\n        self.population = np.clip(self.population, self.lb, self.ub)\n\n    def evaluate_population(self, func):\n        self.fitness = np.array([func(ind) for ind in self.population])\n        best_idx = np.argmax(self.fitness)\n        if self.fitness[best_idx] > self.best_fitness:\n            self.best_fitness = self.fitness[best_idx]\n            self.best_solution = self.population[best_idx].copy()\n\n    def differential_evolution_step(self):\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(2 * self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + 0.8 * (b - c), self.lb, self.ub)\n            trial_vector = np.where(np.random.rand(self.dim) < 0.9, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness > self.fitness[i]:\n                self.population[i] = trial_vector\n                self.fitness[i] = trial_fitness\n                if trial_fitness > self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial_vector.copy()\n\n    def periodicity_enforcement(self):\n        for i in range(self.population_size):\n            period = np.random.randint(1, self.dim // 2)\n            for j in range(0, self.dim, period):\n                self.population[i][j:j+period] = np.mean(self.population[i][j:j+period])\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.quasi_oppositional_init()\n        self.evaluate_population(func)\n        evaluations = 2 * self.population_size\n\n        while evaluations < self.budget:\n            self.differential_evolution_step()\n            self.periodicity_enforcement()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.best_solution", "name": "HybridMetaheuristic", "description": "A novel hybrid exploration-exploitation algorithm combining Quasi-Oppositional Differential Evolution with Adaptive Periodicity Enforcement for optimizing multilayer photonic structures.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 56, in __call__\n  File \"<string>\", line 35, in differential_evolution_step\nNameError: name 'func' is not defined\n.", "error": "NameError(\"name 'func' is not defined\")Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 56, in __call__\n  File \"<string>\", line 35, in differential_evolution_step\nNameError: name 'func' is not defined\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "7deb0ec4-814d-4300-8095-2a48b833eac0", "solution": "import numpy as np\n\nclass SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n\n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.spiral_mutation(pop[i], a, b, c)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def spiral_mutation(self, target, a, b, c):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target)\n        mutant = target + self.scaling_factor * diff + spiral_step\n        return mutant", "name": "SADE", "description": "The Spiral Adaptive Differential Evolution (SADE) algorithm utilizes spiral-shaped search trajectories combined with adaptive parameter control for efficient exploration and exploitation in black-box optimization problems.", "configspace": "", "generation": 0, "fitness": 0.781677761268775, "feedback": "The algorithm SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.027. And the mean value of best solutions found was 0.204 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8191808028615737, 0.7559640367740708, 0.7698884441706806], "final_y": [0.20784293708947343, 0.20162644004834485, 0.20191860526040173]}, "mutation_prompt": null}
{"id": "7050c824-1343-4eff-b10f-ccff5ccfced2", "solution": "import numpy as np\n\nclass SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n\n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.spiral_mutation(pop[i], a, b, c)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n                # Update crossover rate adaptively based on improvement\n                self.crossover_rate = min(1.0, self.crossover_rate * 1.1 if trial_fitness < fitness[i] else self.crossover_rate * 0.9)\n\n        return best\n\n    def spiral_mutation(self, target, a, b, c):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target)\n        mutant = target + self.scaling_factor * diff + spiral_step\n        return mutant", "name": "SADE", "description": "An enhanced Spiral Adaptive Differential Evolution (SADE) algorithm that incorporates an adaptive crossover rate to improve convergence efficiency in black-box optimization.", "configspace": "", "generation": 1, "fitness": 0.5360856471978396, "feedback": "The algorithm SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.536 with standard deviation 0.070. And the mean value of best solutions found was 0.382 (0. is the best) with standard deviation 0.046.", "error": "", "parent_id": "7deb0ec4-814d-4300-8095-2a48b833eac0", "metadata": {"aucs": [0.634469577257663, 0.4887423048434897, 0.4850450594923661], "final_y": [0.31713381266645646, 0.41379549904142665, 0.41645432498274326]}, "mutation_prompt": null}
{"id": "92de259f-55b7-4eac-830b-dbc70aa95219", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.population = None\n        self.lb = None\n        self.ub = None\n        self.fitness = None\n        self.best_solution = None\n        self.best_fitness = float('-inf')\n\n    def quasi_oppositional_init(self):\n        midpoint = (self.lb + self.ub) / 2\n        self.population = midpoint + np.random.rand(self.population_size, self.dim) * (self.ub - self.lb) / 2\n        opposite_population = midpoint - (self.population - midpoint)\n        self.population = np.vstack((self.population, opposite_population))\n        self.population = np.clip(self.population, self.lb, self.ub)\n\n    def evaluate_population(self, func):\n        self.fitness = np.array([func(ind) for ind in self.population])\n        best_idx = np.argmax(self.fitness)\n        if self.fitness[best_idx] > self.best_fitness:\n            self.best_fitness = self.fitness[best_idx]\n            self.best_solution = self.population[best_idx].copy()\n\n    def differential_evolution_step(self, func):  # Changed line\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(2 * self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + 0.8 * (b - c), self.lb, self.ub)\n            trial_vector = np.where(np.random.rand(self.dim) < 0.9, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness > self.fitness[i]:\n                self.population[i] = trial_vector\n                self.fitness[i] = trial_fitness\n                if trial_fitness > self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial_vector.copy()\n\n    def periodicity_enforcement(self):\n        for i in range(self.population_size):\n            period = np.random.randint(1, self.dim // 2)\n            for j in range(0, self.dim, period):\n                self.population[i][j:j+period] = np.mean(self.population[i][j:j+period])\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.quasi_oppositional_init()\n        self.evaluate_population(func)\n        evaluations = 2 * self.population_size\n\n        while evaluations < self.budget:\n            self.differential_evolution_step(func)\n            self.periodicity_enforcement()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid exploration-exploitation algorithm combining Quasi-Oppositional Differential Evolution with Adaptive Periodicity Enforcement for optimizing multilayer photonic structures, fixing the NameError by passing `func` as a parameter.", "configspace": "", "generation": 1, "fitness": 0.6972082176747457, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.697 with standard deviation 0.069. And the mean value of best solutions found was 0.237 (0. is the best) with standard deviation 0.036.", "error": "", "parent_id": "93a6a24f-82e6-48d0-acf1-78a20a80bc80", "metadata": {"aucs": [0.6034656403418992, 0.7225353616413221, 0.7656236510410159], "final_y": [0.28617174081492225, 0.2228550646413875, 0.20075361138399406]}, "mutation_prompt": null}
{"id": "a3bca232-5129-48cb-947b-b2c2266480bd", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.population = None\n        self.lb = None\n        self.ub = None\n        self.fitness = None\n        self.best_solution = None\n        self.best_fitness = float('-inf')\n\n    def quasi_oppositional_init(self):\n        midpoint = (self.lb + self.ub) / 2\n        self.population = midpoint + np.random.rand(self.population_size, self.dim) * (self.ub - self.lb) / 2\n        opposite_population = midpoint - (self.population - midpoint)\n        self.population = np.vstack((self.population, opposite_population))\n        self.population = np.clip(self.population, self.lb, self.ub)\n\n    def evaluate_population(self, func):\n        self.fitness = np.array([func(ind) for ind in self.population])\n        best_idx = np.argmax(self.fitness)\n        if self.fitness[best_idx] > self.best_fitness:\n            self.best_fitness = self.fitness[best_idx]\n            self.best_solution = self.population[best_idx].copy()\n\n    def differential_evolution_step(self, func):  # Changed line\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(2 * self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + 0.8 * (b - c), self.lb, self.ub)\n            trial_vector = np.where(np.random.rand(self.dim) < 0.9, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness > self.fitness[i]:\n                self.population[i] = trial_vector\n                self.fitness[i] = trial_fitness\n                if trial_fitness > self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial_vector.copy()\n\n    def periodicity_enforcement(self):\n        for i in range(self.population_size):\n            period = np.random.randint(1, self.dim // 2)\n            for j in range(0, self.dim, period):\n                self.population[i][j:j+period] = np.mean(self.population[i][j:j+period])\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.quasi_oppositional_init()\n        self.evaluate_population(func)\n        evaluations = 2 * self.population_size\n\n        while evaluations < self.budget:\n            self.differential_evolution_step(func)  # Ensure func is passed here as well\n            self.periodicity_enforcement()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.best_solution", "name": "HybridMetaheuristic", "description": "A novel hybrid exploration-exploitation algorithm combining Quasi-Oppositional Differential Evolution with Adaptive Periodicity Enforcement for optimizing multilayer photonic structures, now ensuring correct function reference in DE step.", "configspace": "", "generation": 1, "fitness": 0.65553101527752, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.656 with standard deviation 0.006. And the mean value of best solutions found was 0.253 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "93a6a24f-82e6-48d0-acf1-78a20a80bc80", "metadata": {"aucs": [0.6477514630560626, 0.6554395769696966, 0.6634020058068009], "final_y": [0.278308966983434, 0.23387857014921298, 0.24539023232365254]}, "mutation_prompt": null}
{"id": "ca767e16-515c-4876-b6ba-303b9c18b8d8", "solution": "import numpy as np\n\nclass PAFA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.alpha = 0.5\n        self.beta_base = 1.0\n        self.gamma = 1.0\n        self.func_evals = 0\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n\n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                for j in range(self.population_size):\n                    if fitness[j] < fitness[i]:\n                        rij = np.linalg.norm(pop[i] - pop[j])\n                        beta = self.beta_base * np.exp(-self.gamma * rij ** 2)\n                        pop[i] += beta * (pop[j] - pop[i]) + self.alpha * (np.random.rand(self.dim) - 0.5)\n                        pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n                        fitness[i] = func(pop[i])\n                        self.func_evals += 1\n\n                        if fitness[i] < fitness[best_idx]:\n                            best_idx = i\n                            best = pop[i]\n                        \n                        if self.func_evals >= self.budget:\n                            break\n            \n            # Periodicity enforcement after each full population update\n            for i in range(self.population_size):\n                pop[i] = self.periodic_adjustment(pop[i], bounds)\n\n        return best\n    \n    def periodic_adjustment(self, individual, bounds):\n        # Encourage periodic patterns by adding a small sinusoidal adjustment\n        period_factor = (bounds[:, 1] - bounds[:, 0]) / 4\n        for d in range(self.dim):\n            individual[d] += 0.1 * period_factor[d] * np.sin(2 * np.pi * individual[d] / period_factor[d])\n        return np.clip(individual, bounds[:, 0], bounds[:, 1])", "name": "PAFA", "description": "The Periodic Adaptive Firefly Algorithm (PAFA) integrates periodicity-enhanced exploration with adaptive attractiveness scaling to efficiently navigate complex black box optimization landscapes.", "configspace": "", "generation": 1, "fitness": 0.4867224235254401, "feedback": "The algorithm PAFA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.487 with standard deviation 0.035. And the mean value of best solutions found was 0.410 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "7deb0ec4-814d-4300-8095-2a48b833eac0", "metadata": {"aucs": [0.4790492047375766, 0.5326581823560975, 0.448459883482646], "final_y": [0.42071622498536876, 0.3822094756469999, 0.4281910971703303]}, "mutation_prompt": null}
{"id": "da71f172-352f-430e-80e1-1b422f534126", "solution": "import numpy as np\n\nclass AdaptiveLayeredDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.population = None\n        self.lb = None\n        self.ub = None\n        self.fitness = None\n        self.best_solution = None\n        self.best_fitness = float('-inf')\n        self.layer_groups = [1] * dim\n\n    def initialize_population(self):\n        self.population = self.lb + np.random.rand(self.population_size, self.dim) * (self.ub - self.lb)\n\n    def evaluate_population(self, func):\n        self.fitness = np.array([func(ind) for ind in self.population])\n        best_idx = np.argmax(self.fitness)\n        if self.fitness[best_idx] > self.best_fitness:\n            self.best_fitness = self.fitness[best_idx]\n            self.best_solution = self.population[best_idx].copy()\n\n    def differential_evolution_step(self, func):\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + 0.8 * (b - c), self.lb, self.ub)\n\n            group_sizes = np.unique(self.layer_groups, return_counts=True)[1]\n            sorted_indices = np.argsort(group_sizes)\n            trial_vector = self.population[i].copy()\n\n            for group_size in sorted_indices:\n                change_indices = np.where(self.layer_groups == group_size)[0]\n                if np.random.rand() < 0.9:\n                    trial_vector[change_indices] = mutant_vector[change_indices]\n\n            trial_fitness = func(trial_vector)\n            if trial_fitness > self.fitness[i]:\n                self.population[i] = trial_vector\n                self.fitness[i] = trial_fitness\n                if trial_fitness > self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial_vector.copy()\n\n    def adapt_layer_groups(self):\n        group_sizes = np.unique(self.layer_groups, return_counts=True)[1]\n        most_common_size = np.argmax(group_sizes)\n        for i in range(len(self.layer_groups)):\n            if np.random.rand() < 0.1:\n                self.layer_groups[i] = most_common_size\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.initialize_population()\n        self.evaluate_population(func)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.differential_evolution_step(func)\n            self.adapt_layer_groups()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.best_solution", "name": "AdaptiveLayeredDE", "description": "Adaptive Layered Differential Evolution (ALDE) employs a dynamic layer grouping and adaptive search strategy for optimizing multilayer photonic structures by balancing exploration and exploitation.", "configspace": "", "generation": 1, "fitness": 0.5698778772523795, "feedback": "The algorithm AdaptiveLayeredDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.570 with standard deviation 0.017. And the mean value of best solutions found was 0.296 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "93a6a24f-82e6-48d0-acf1-78a20a80bc80", "metadata": {"aucs": [0.5470277939904377, 0.5752877901598239, 0.5873180476068769], "final_y": [0.2674712932590829, 0.3036410817563533, 0.3174572167180061]}, "mutation_prompt": null}
{"id": "7b0fab5d-3814-4d7a-9fab-44c1e776fc18", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.population = None\n        self.lb = None\n        self.ub = None\n        self.fitness = None\n        self.best_solution = None\n        self.best_fitness = float('-inf')\n\n    def quasi_oppositional_init(self):\n        midpoint = (self.lb + self.ub) / 2\n        self.population = midpoint + np.random.rand(self.population_size, self.dim) * (self.ub - self.lb) / 2\n        opposite_population = midpoint - (self.population - midpoint)\n        self.population = np.vstack((self.population, opposite_population))\n        self.population = np.clip(self.population, self.lb, self.ub)\n\n    def evaluate_population(self, func):\n        self.fitness = np.array([func(ind) for ind in self.population])\n        best_idx = np.argmax(self.fitness)\n        if self.fitness[best_idx] > self.best_fitness:\n            self.best_fitness = self.fitness[best_idx]\n            self.best_solution = self.population[best_idx].copy()\n\n    def differential_evolution_step(self, func):  # Change: Added 'func' parameter\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(2 * self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + 0.8 * (b - c), self.lb, self.ub)\n            trial_vector = np.where(np.random.rand(self.dim) < 0.9, mutant_vector, self.population[i])\n            trial_fitness = func(trial_vector)\n            if trial_fitness > self.fitness[i]:\n                self.population[i] = trial_vector\n                self.fitness[i] = trial_fitness\n                if trial_fitness > self.best_fitness:\n                    self.best_fitness = trial_fitness\n                    self.best_solution = trial_vector.copy()\n\n    def periodicity_enforcement(self):\n        for i in range(self.population_size):\n            period = np.random.randint(1, self.dim // 2)\n            for j in range(0, self.dim, period):\n                self.population[i][j:j+period] = np.mean(self.population[i][j:j+period])\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.quasi_oppositional_init()\n        self.evaluate_population(func)\n        evaluations = 2 * self.population_size\n\n        while evaluations < self.budget:\n            self.differential_evolution_step(func)  # Change: Added 'func' parameter\n            self.periodicity_enforcement()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid algorithm using Quasi-Oppositional Differential Evolution with Adaptive Periodicity Enforcement and corrected differential evolution step implementation for optimizing multilayer photonic structures.", "configspace": "", "generation": 1, "fitness": 0.6977224423333298, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.698 with standard deviation 0.015. And the mean value of best solutions found was 0.244 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "93a6a24f-82e6-48d0-acf1-78a20a80bc80", "metadata": {"aucs": [0.7074117022677802, 0.677146154294068, 0.7086094704381414], "final_y": [0.25210104344011375, 0.2242548456240936, 0.2558589180457872]}, "mutation_prompt": null}
{"id": "08983339-c443-4696-a84d-ea639fdfc901", "solution": "import numpy as np\n\nclass SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n\n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.spiral_mutation(pop[i], a, b, c)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def spiral_mutation(self, target, a, b, c):\n        diff = b - c\n        self.spiral_factor = min(0.5, self.spiral_factor + 0.01)  # Adaptively increasing spiral factor\n        spiral_step = self.spiral_factor * (a - target)\n        mutant = target + self.scaling_factor * diff + spiral_step\n        return mutant", "name": "SADE", "description": "Enhanced Spiral Adaptive Differential Evolution (E-SADE) introduces adaptive spiral factor for better convergence control in black-box optimization.", "configspace": "", "generation": 1, "fitness": 0.8872086552549837, "feedback": "The algorithm SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.028. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7deb0ec4-814d-4300-8095-2a48b833eac0", "metadata": {"aucs": [0.9260572454867655, 0.8615600059422174, 0.8740087143359682], "final_y": [0.16496490368068817, 0.16488573077949498, 0.1650478800782792]}, "mutation_prompt": null}
{"id": "49940f2a-beb6-4010-8aa0-b15a97cc14c0", "solution": "import numpy as np\n\nclass SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n\n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.spiral_mutation(pop[i], a, b, c)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Dynamically adjust spiral factor\n            self.spiral_factor = 0.1 + 0.9 * (self.func_evals / self.budget)\n\n        return best\n\n    def spiral_mutation(self, target, a, b, c):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target)\n        mutant = target + self.scaling_factor * diff + spiral_step\n        return mutant", "name": "SADE", "description": "Enhanced Spiral Adaptive Differential Evolution (SADE) with Dynamically Adjusted Spiral Factor for improved convergence in black-box optimization.", "configspace": "", "generation": 1, "fitness": 0.8551997716193531, "feedback": "The algorithm SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.012. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7deb0ec4-814d-4300-8095-2a48b833eac0", "metadata": {"aucs": [0.8615264728635057, 0.8389366638900629, 0.8651361781044906], "final_y": [0.16494104376133478, 0.16506070323694688, 0.1650869734006315]}, "mutation_prompt": null}
{"id": "ab9881da-d07f-4c22-91ec-13b360843c3a", "solution": "import numpy as np\n\nclass CoherentParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30\n        self.population = None\n        self.velocities = None\n        self.lb = None\n        self.ub = None\n        self.fitness = None\n        self.personal_best_positions = None\n        self.personal_best_fitness = None\n        self.global_best_position = None\n        self.global_best_fitness = float('-inf')\n        self.inertia_weight = 0.7\n        self.cognitive_coefficient = 1.5\n        self.social_coefficient = 1.5\n\n    def initialize(self):\n        self.population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        self.velocities = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('-inf'))\n        self.personal_best_positions = self.population.copy()\n        self.personal_best_fitness = self.fitness.copy()\n\n    def evaluate_population(self, func):\n        for i in range(self.population_size):\n            fit = func(self.population[i])\n            if fit > self.personal_best_fitness[i]:\n                self.personal_best_fitness[i] = fit\n                self.personal_best_positions[i] = self.population[i].copy()\n            if fit > self.global_best_fitness:\n                self.global_best_fitness = fit\n                self.global_best_position = self.population[i].copy()\n\n    def update_velocities_and_positions(self):\n        for i in range(self.population_size):\n            cognitive_component = self.cognitive_coefficient * np.random.rand(self.dim) * (self.personal_best_positions[i] - self.population[i])\n            social_component = self.social_coefficient * np.random.rand(self.dim) * (self.global_best_position - self.population[i])\n            self.velocities[i] = self.inertia_weight * self.velocities[i] + cognitive_component + social_component\n            self.population[i] = np.clip(self.population[i] + self.velocities[i], self.lb, self.ub)\n\n    def periodicity_enforcement(self):\n        for i in range(self.population_size):\n            period = np.random.randint(1, self.dim // 2)\n            for j in range(0, self.dim, period):\n                averaged_value = np.mean(self.population[i][j:j+period])\n                self.population[i][j:j+period] = averaged_value\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.initialize()\n        self.evaluate_population(func)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self.update_velocities_and_positions()\n            self.periodicity_enforcement()\n            self.evaluate_population(func)\n            evaluations += self.population_size\n\n        return self.global_best_position", "name": "CoherentParticleSwarmOptimization", "description": "An adaptive swarm-inspired algorithm, named Coherent Particle Swarm Optimization (CPSO), blends adaptive velocity controls with periodic pattern reinforcement to enhance solution precision for complex photonic structure optimization.", "configspace": "", "generation": 1, "fitness": 0.8785980932583923, "feedback": "The algorithm CoherentParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.037. And the mean value of best solutions found was 0.200 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "93a6a24f-82e6-48d0-acf1-78a20a80bc80", "metadata": {"aucs": [0.9025912894661979, 0.825828896685554, 0.9073740936234248], "final_y": [0.18930935908843027, 0.21954163040657615, 0.19141705897861605]}, "mutation_prompt": null}
{"id": "cf5b94b3-ca18-4b85-88cf-bd3236dd1ad8", "solution": "import numpy as np\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target)\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced Spiral Adaptive Differential Evolution (E-SADE) introduces periodicity-guided mutation and adaptive scaling factors for improved global and local search balance in multilayer photonic structure optimization.", "configspace": "", "generation": 1, "fitness": 0.901914553522229, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.018. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "7deb0ec4-814d-4300-8095-2a48b833eac0", "metadata": {"aucs": [0.9228300898601407, 0.9048404454605462, 0.8780731252460005], "final_y": [0.16775140272907785, 0.16944574502133603, 0.17054696250397083]}, "mutation_prompt": null}
{"id": "fef9a058-7fc4-4b08-91d3-ab570d64b483", "solution": "import numpy as np\n\nclass SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        opp_pop = bounds[:, 0] + bounds[:, 1] - pop  # Quasi-oppositional initialization\n        fitness = np.apply_along_axis(func, 1, pop)\n        opp_fitness = np.apply_along_axis(func, 1, opp_pop)\n        self.func_evals += 2 * self.population_size\n        combined_pop = np.vstack((pop, opp_pop))\n        combined_fitness = np.hstack((fitness, opp_fitness))\n        best_idx = np.argmin(combined_fitness)\n        best = combined_pop[best_idx]\n\n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.spiral_mutation(pop[i], a, b, c)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def spiral_mutation(self, target, a, b, c):\n        diff = b - c\n        self.spiral_factor = min(0.5, self.spiral_factor + 0.01)  # Adaptively increasing spiral factor\n        spiral_step = self.spiral_factor * (a - target)\n        mutant = target + self.scaling_factor * diff + spiral_step\n        return mutant", "name": "SADE", "description": "Enhanced Spiral Adaptive Differential Evolution (E-SADE) with Quasi-Oppositional Initialization and Adaptive Spiral Factor for Improved Global Exploration and Local Exploitation.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 98 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 98 is out of bounds for axis 0 with size 50')", "parent_id": "08983339-c443-4696-a84d-ea639fdfc901", "metadata": {}, "mutation_prompt": null}
{"id": "f0ea521c-2428-47f5-88cd-f16cec0a8bb6", "solution": "import numpy as np\n\nclass SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n\n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.spiral_mutation(pop[i], a, b, c)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def spiral_mutation(self, target, a, b, c):\n        diff = b - c\n        self.spiral_factor = min(0.5, self.spiral_factor + 0.02)  # Adjusted adaptive increase of spiral factor\n        spiral_step = self.spiral_factor * (a - target)\n        mutant = target + self.scaling_factor * diff + spiral_step\n        return mutant", "name": "SADE", "description": "Enhanced SADE introduces a dynamic spiral factor increase mechanism for improved fine-tuning in black-box optimization.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 78 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 78 is out of bounds for axis 0 with size 50')", "parent_id": "08983339-c443-4696-a84d-ea639fdfc901", "metadata": {}, "mutation_prompt": null}
{"id": "b3e440bc-103d-4fe0-b02c-662bb3b30a03", "solution": "import numpy as np\n\nclass SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        opo_pop = bounds[:, 0] + bounds[:, 1] - pop  # Quasi-oppositional initialization\n        pop = np.vstack((pop, opo_pop))[:self.population_size]  # Limit population size\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n\n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.spiral_mutation(pop[i], a, b, c)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def spiral_mutation(self, target, a, b, c):\n        diff = b - c\n        self.spiral_factor = min(0.5, self.spiral_factor + 0.01)  # Adaptively increasing spiral factor\n        spiral_step = self.spiral_factor * (a - target)\n        mutant = target + self.scaling_factor * diff + spiral_step\n        return mutant", "name": "SADE", "description": "Enhanced Spiral Adaptive Differential Evolution with Quasi-Oppositional Initialization (E-SADE-QOI) employs quasi-oppositional initialization to improve exploration and convergence in black-box optimization.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 67 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 67 is out of bounds for axis 0 with size 50')", "parent_id": "08983339-c443-4696-a84d-ea639fdfc901", "metadata": {}, "mutation_prompt": null}
{"id": "78a3d6ae-d339-42f5-8217-56384a3c0f36", "solution": "import numpy as np\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target)\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.7 + 0.3 * periodic_factor)  # Change made here\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "E-SADE with enhanced spiral factor for better exploiting constructive interference in layered structures.", "configspace": "", "generation": 2, "fitness": 0.9196579809715555, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.029. And the mean value of best solutions found was 0.174 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "cf5b94b3-ca18-4b85-88cf-bd3236dd1ad8", "metadata": {"aucs": [0.8784851279326702, 0.9396381971508958, 0.9408506178311005], "final_y": [0.1777948375742291, 0.1724224462376711, 0.17195392030905543]}, "mutation_prompt": null}
{"id": "4a1f9704-28c3-4853-bf4e-48314572d93e", "solution": "import numpy as np\n\nclass SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n\n        while self.func_evals < self.budget:\n            if self.func_evals % 100 == 0:\n                self.population_size = max(10, self.population_size - 1)  # Reduce population size over time\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.spiral_mutation(pop[i], a, b, c)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def spiral_mutation(self, target, a, b, c):\n        diff = b - c\n        self.spiral_factor = min(0.5, self.spiral_factor + 0.01)  # Adaptively increasing spiral factor\n        spiral_step = self.spiral_factor * (a - target)\n        mutant = target + self.scaling_factor * diff + spiral_step\n        return mutant", "name": "SADE", "description": "Enhanced Spiral Adaptive Differential Evolution (E-SADE) with dynamic population size adjustment for improved global exploration and convergence in black-box optimization.", "configspace": "", "generation": 2, "fitness": 0.9362578339272414, "feedback": "The algorithm SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.936 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "08983339-c443-4696-a84d-ea639fdfc901", "metadata": {"aucs": [0.9449551823534161, 0.9244184729649492, 0.939399846463359], "final_y": [0.16485649281676318, 0.16495946675665496, 0.16496825707930862]}, "mutation_prompt": null}
{"id": "e2b43399-92ba-4766-9596-bedb05ca20a9", "solution": "import numpy as np\n\nclass E_SADE_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, best)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, best):\n        diff = b - c\n        spiral_step = (self.spiral_factor * np.linalg.norm(target - best)) * (a - target)\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE_v2", "description": "E_SADE_v2 introduces a dynamic spiral factor based on the best solution's progress to enhance convergence speed and avoid local optima.", "configspace": "", "generation": 2, "fitness": 0.5990782855725704, "feedback": "The algorithm E_SADE_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.599 with standard deviation 0.082. And the mean value of best solutions found was 0.293 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "cf5b94b3-ca18-4b85-88cf-bd3236dd1ad8", "metadata": {"aucs": [0.5191625018653072, 0.7122237589296693, 0.5658485959227348], "final_y": [0.30274910120141374, 0.262094820625685, 0.31556836297102764]}, "mutation_prompt": null}
{"id": "4d9538a0-2db6-473f-844c-13ee23fe77e3", "solution": "import numpy as np\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.periodic_perturbation = 0.05  # Added periodic perturbation\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target)\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        perturbation = self.periodic_perturbation * np.sin(2 * np.pi * i / self.population_size)  # Add perturbation\n        mutant = target + adaptive_scaling * diff + spiral_step + perturbation\n        return mutant", "name": "E_SADE", "description": "Enhanced Spiral Adaptive Differential Evolution with periodic perturbation for improved exploration in photonic structure optimization.", "configspace": "", "generation": 2, "fitness": 0.9362369971896225, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.936 with standard deviation 0.007. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "cf5b94b3-ca18-4b85-88cf-bd3236dd1ad8", "metadata": {"aucs": [0.9271824373838421, 0.9380899513654368, 0.9434386028195885], "final_y": [0.16905961805306513, 0.17229136924188615, 0.17157973914574765]}, "mutation_prompt": null}
{"id": "0dc810a1-ee62-47f8-932a-3295be8f51d8", "solution": "import numpy as np\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "E-SADE is enhanced by incorporating a dynamic spiral factor adjustment based on fitness improvement to balance exploration and exploitation more effectively.", "configspace": "", "generation": 2, "fitness": 0.9379897085416992, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.938 with standard deviation 0.011. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "cf5b94b3-ca18-4b85-88cf-bd3236dd1ad8", "metadata": {"aucs": [0.9232114979349282, 0.9409511954978745, 0.9498064321922951], "final_y": [0.1665402901830858, 0.17236385248078345, 0.17033901029760268]}, "mutation_prompt": null}
{"id": "1e624de6-77e4-4d5e-b3de-5712e1fa906a", "solution": "import numpy as np\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                # Modify the spiral factor based on population diversity\n                self.spiral_factor = 0.1 + 0.5 * np.std(pop)\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target)\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "E-SADE with Adaptive Spiral Factor Scaling (E-SADE-ASF) introduces dynamic spiral factor scaling based on population diversity for enhanced exploration and convergence in black-box optimization.", "configspace": "", "generation": 2, "fitness": 0.7715573077257041, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.772 with standard deviation 0.246. And the mean value of best solutions found was 0.269 (0. is the best) with standard deviation 0.138.", "error": "", "parent_id": "cf5b94b3-ca18-4b85-88cf-bd3236dd1ad8", "metadata": {"aucs": [0.4239532221874397, 0.9441947884099051, 0.9465239125797673], "final_y": [0.4646098296013351, 0.1704423863505402, 0.17316301361058029]}, "mutation_prompt": null}
{"id": "7f47fd3d-c92f-40d6-86ee-4b771440a2a8", "solution": "import numpy as np\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(self.periodicity_enhanced_func, 1, pop, func)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n\n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.spiral_mutation(pop[i], a, b, c)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = self.periodicity_enhanced_func(trial, func)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def spiral_mutation(self, target, a, b, c):\n        diff = b - c\n        self.spiral_factor = min(0.5, self.spiral_factor + 0.01)  # Adaptively increasing spiral factor\n        spiral_step = self.spiral_factor * (a - target)\n        mutant = target + self.scaling_factor * diff + spiral_step\n        return mutant\n\n    def periodicity_enhanced_func(self, x, func):\n        # Encourage periodicity by penalizing deviations from periodic patterns\n        period_penalty = np.std(np.diff(x))  # Penalize variability in differences\n        return func(x) + 0.1 * period_penalty  # Add penalty to original function", "name": "E_SADE", "description": "Enhanced Spiral Adaptive Differential Evolution (E-SADE) with periodicity-encouraged cost function and adaptive spiral factor for better convergence and exploitation in multilayer photonic structure optimization.", "configspace": "", "generation": 2, "fitness": 0.9295855123342592, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.003. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "08983339-c443-4696-a84d-ea639fdfc901", "metadata": {"aucs": [0.9289571054633291, 0.933391001562346, 0.9264084299771023], "final_y": [0.17339529499757278, 0.17293621442681062, 0.17258981902302784]}, "mutation_prompt": null}
{"id": "709a38e0-94bb-4473-8040-2cfbdd82963c", "solution": "import numpy as np\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * np.abs(periodic_factor))  # Change 1\n        mutant = target + adaptive_scaling * diff + spiral_step * np.random.rand()  # Change 2\n        self.spiral_factor *= 0.99  # Change 3\n        return mutant", "name": "E_SADE", "description": "Enhanced E-SADE with a dynamic spiral factor adjustment and improved adaptive scaling for better exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8639226220715056, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.110. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "0dc810a1-ee62-47f8-932a-3295be8f51d8", "metadata": {"aucs": [0.7193515366916978, 0.9864711579666572, 0.8859451715561621], "final_y": [0.2193102104493564, 0.16485592624933765, 0.1748017616480404]}, "mutation_prompt": null}
{"id": "a5b8351d-99b4-41bc-9178-c52b0dcc6144", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "E-SADE enhanced with adaptive periodic adjustment and local search integration to improve convergence by leveraging periodicity and local refinement.", "configspace": "", "generation": 3, "fitness": 0.9044682662550286, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.058. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "0dc810a1-ee62-47f8-932a-3295be8f51d8", "metadata": {"aucs": [0.976513517718924, 0.8356794196750725, 0.9012118613710891], "final_y": [0.16485693238655774, 0.1775624709871454, 0.17026318980821054]}, "mutation_prompt": null}
{"id": "abed0d4a-6ceb-4600-8dac-c013a2e73a19", "solution": "import numpy as np\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * (i + 0.5) / self.population_size)  # Adjusted periodic factor\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "E_SADE is refined by adjusting the periodic factor to enhance adaptive scaling for improved exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8976105393123435, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.037. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "0dc810a1-ee62-47f8-932a-3295be8f51d8", "metadata": {"aucs": [0.945349711583454, 0.8926450205416826, 0.8548368858118935], "final_y": [0.16590959280201723, 0.16998036007398554, 0.17459569358810711]}, "mutation_prompt": null}
{"id": "89a81a63-0d7c-49bc-afcd-7fe3fb653ae1", "solution": "import numpy as np\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Change in spiral_step calculation\n        spiral_step = self.spiral_factor * (a - target) * ((fitness[i] - np.min(fitness)) / (np.min(fitness) + 1e-10))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "E_SADE with enhanced spiral factor adjustment based on relative fitness improvement to improve balance between exploration and exploitation.", "configspace": "", "generation": 3, "fitness": 0.8485264823607298, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.022. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "0dc810a1-ee62-47f8-932a-3295be8f51d8", "metadata": {"aucs": [0.8736003623055354, 0.8200701359779863, 0.851908948798668], "final_y": [0.17942901897109276, 0.17940264036479392, 0.18822161966230888]}, "mutation_prompt": null}
{"id": "0e140a96-3df8-4a0d-b72e-d008387e7d89", "solution": "import numpy as np\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step - 0.05 * np.sin(2 * np.pi * i / self.population_size)\n        return mutant", "name": "E_SADE", "description": "E-SADE is enhanced by adjusting the spiral factor dynamically based on the improvement in fitness, allowing better balance between exploration and exploitation.", "configspace": "", "generation": 3, "fitness": 0.8901774427066624, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.043. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "0dc810a1-ee62-47f8-932a-3295be8f51d8", "metadata": {"aucs": [0.9480969351511374, 0.8768138437008285, 0.8456215492680215], "final_y": [0.16869013892721274, 0.17062707190492077, 0.17656170673950566]}, "mutation_prompt": null}
{"id": "4d30c4e3-d444-47aa-b62b-334b45960d52", "solution": "import numpy as np\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate * (0.5 + 0.5 * np.sin(2 * np.pi * i / self.population_size)), mutant, pop[i]) # Changed line\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Incorporate periodicity-driven crossover rate to enhance solution diversity and convergence in E-SADE.", "configspace": "", "generation": 3, "fitness": 0.8878719019389077, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.006. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "0dc810a1-ee62-47f8-932a-3295be8f51d8", "metadata": {"aucs": [0.8847540208816026, 0.8965488440905995, 0.8823128408445213], "final_y": [0.17496267146323574, 0.17000080455590294, 0.16771093796301273]}, "mutation_prompt": null}
{"id": "f88c2d8b-4403-40c8-a194-3e2cde289b00", "solution": "import numpy as np\n\nclass SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n\n        while self.func_evals < self.budget:\n            if self.func_evals % 100 == 0:\n                self.population_size = max(10, self.population_size - 1)  # Reduce population size over time\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.spiral_mutation(pop[i], a, b, c)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Dynamically adjust crossover rate based on population diversity\n            diversity = np.std(pop, axis=0).mean()\n            self.crossover_rate = 0.7 + 0.2 * (1 - diversity)\n\n        return best\n\n    def spiral_mutation(self, target, a, b, c):\n        diff = b - c\n        self.spiral_factor = min(0.5, self.spiral_factor + 0.01)  # Adaptively increasing spiral factor\n        spiral_step = self.spiral_factor * (a - target)\n        mutant = target + self.scaling_factor * diff + spiral_step\n        return mutant", "name": "SADE", "description": "Fine-tune the crossover rate dynamically based on population diversity to enhance convergence.", "configspace": "", "generation": 3, "fitness": 0.8130359831014048, "feedback": "The algorithm SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.183. And the mean value of best solutions found was 0.232 (0. is the best) with standard deviation 0.095.", "error": "", "parent_id": "4a1f9704-28c3-4853-bf4e-48314572d93e", "metadata": {"aucs": [0.5555002528602646, 0.9260693709487448, 0.9575383254952051], "final_y": [0.366250733963598, 0.16507556763952225, 0.16486164373909895]}, "mutation_prompt": null}
{"id": "f93a7e1b-cfc4-4664-8745-af785cee76d2", "solution": "import numpy as np\n\nclass SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.func_evals < self.budget:\n            if self.func_evals % 100 == 0:\n                self.population_size = max(10, self.population_size - 1)  # Reduce population size over time\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.spiral_mutation(pop[i], a, b, c)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n                        best_fitness = trial_fitness\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def spiral_mutation(self, target, a, b, c):\n        diff = b - c\n        self.spiral_factor = min(0.5, self.spiral_factor + 0.01 * (1 - self.func_evals / self.budget))  # Modifying line\n        spiral_step = self.spiral_factor * (a - target)\n        mutant = target + self.scaling_factor * diff + spiral_step\n        return mutant", "name": "SADE", "description": "Improved E-SADE by adapting spiral factor increase based on current best fitness improvement for enhanced convergence.", "configspace": "", "generation": 3, "fitness": 0.9353134459492608, "feedback": "The algorithm SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.935 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4a1f9704-28c3-4853-bf4e-48314572d93e", "metadata": {"aucs": [0.9408586657842261, 0.9276072061219695, 0.9374744659415868], "final_y": [0.16490033500403667, 0.16488938259125052, 0.1648962600617193]}, "mutation_prompt": null}
{"id": "740caadf-114b-4b95-92c1-a28988fd1aed", "solution": "import numpy as np\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        adaptive_scaling += 0.2 * np.random.rand()  # Increase diversity\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced E-SADE by increasing population diversity through adaptive spiral factor and differential mutation scaling.", "configspace": "", "generation": 3, "fitness": 0.8872747004036489, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.042. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "0dc810a1-ee62-47f8-932a-3295be8f51d8", "metadata": {"aucs": [0.9288132058538436, 0.9039358396208583, 0.8290750557362446], "final_y": [0.1692194958810136, 0.17494542419062198, 0.17196596571422362]}, "mutation_prompt": null}
{"id": "d3c3b330-0f44-4884-ace2-0da8554027ef", "solution": "import numpy as np\n\nclass PSADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.periodic_factor = 0.1\n        self.symbiotic_factor = 0.2\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.symbiotic_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def symbiotic_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        periodic_step = self.periodic_factor * np.sin(2 * np.pi * i / self.population_size)\n        symbiotic_step = self.symbiotic_factor * np.random.uniform(-1, 1, self.dim)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_step)\n        mutant = target + adaptive_scaling * diff + symbiotic_step\n        return mutant", "name": "PSADE", "description": "Periodic Symbiotic Adaptive Differential Evolution (PSADE) enhances exploration by integrating symbiotic relationships with a periodic adaptation of control parameters to balance exploration and exploitation dynamically.", "configspace": "", "generation": 3, "fitness": 0.7964228154641123, "feedback": "The algorithm PSADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.050. And the mean value of best solutions found was 0.196 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "0dc810a1-ee62-47f8-932a-3295be8f51d8", "metadata": {"aucs": [0.8602989371330927, 0.7381184926145827, 0.7908510166446615], "final_y": [0.18524553904466712, 0.2132826116243305, 0.19026911510920164]}, "mutation_prompt": null}
{"id": "46a0ac98-5750-4ed4-935f-0e1b7cef91cb", "solution": "import numpy as np\n\nclass SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.func_evals < self.budget:\n            if self.func_evals % 100 == 0:\n                self.population_size = max(10, self.population_size - 1)  # Reduce population size over time\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.spiral_mutation(pop[i], a, b, c)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n                        best_fitness = trial_fitness\n\n                if self.func_evals >= self.budget:\n                    break\n\n            self.crossover_rate = 0.9 * (1 - best_fitness)  # Modifying line\n\n        return best\n\n    def spiral_mutation(self, target, a, b, c):\n        diff = b - c\n        self.spiral_factor = min(0.5, self.spiral_factor + 0.01 * (1 - self.func_evals / self.budget))\n        spiral_step = self.spiral_factor * (a - target)\n        mutant = target + self.scaling_factor * diff + spiral_step\n        return mutant", "name": "SADE", "description": "Enhance the SADE algorithm by dynamically adjusting the crossover rate based on current best fitness improvement to bolster exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.8758319887268439, "feedback": "The algorithm SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.092. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "f93a7e1b-cfc4-4664-8745-af785cee76d2", "metadata": {"aucs": [0.9297801639844112, 0.7458663930913648, 0.9518494091047557], "final_y": [0.16488702595475513, 0.21772296949657943, 0.16488606444651355]}, "mutation_prompt": null}
{"id": "31e1ce05-7f40-46c5-b801-654eae108b38", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.cos(2 * np.pi * i / self.population_size)  # Changed from sin to cos\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced periodicity in mutation using cosine for improved convergence precision.", "configspace": "", "generation": 4, "fitness": 0.981296292801006, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.981 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a5b8351d-99b4-41bc-9178-c52b0dcc6144", "metadata": {"aucs": [0.9732702854579514, 0.9860601541963504, 0.9845584387487164], "final_y": [0.16485627493161525, 0.16485618020083193, 0.1648597068565495]}, "mutation_prompt": null}
{"id": "5faace63-74cd-41e9-af2d-7e77f09c50f0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            diversity = np.std(pop, axis=0).mean()  # Line updated for diversity measurement\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness, diversity)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness, diversity):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        enhanced_spiral = spiral_step * (1 + 0.1 * diversity)  # Line updated for enhanced spiral step\n        mutant = target + adaptive_scaling * diff + enhanced_spiral  # Line updated to use enhanced spiral\n        return mutant", "name": "E_SADE", "description": "Enhanced E-SADE by integrating adaptive spiral factor adjustment and introducing diversity preservation to explore diverse solutions.", "configspace": "", "generation": 4, "fitness": 0.9571683247884554, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.957 with standard deviation 0.019. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a5b8351d-99b4-41bc-9178-c52b0dcc6144", "metadata": {"aucs": [0.9295980461809612, 0.9712751021578394, 0.9706318260265656], "final_y": [0.1818787356526408, 0.16486127708472986, 0.16485626507401163]}, "mutation_prompt": null}
{"id": "4d0a09ea-9e6f-4215-9085-57729700a8bd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.2 # Adjusted spiral factor for improved diversity-driven exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced E-SADE by increasing spiral factor based on diversity metric to improve exploration and convergence.  ", "configspace": "", "generation": 4, "fitness": 0.8979814389251356, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.110. And the mean value of best solutions found was 0.196 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "a5b8351d-99b4-41bc-9178-c52b0dcc6144", "metadata": {"aucs": [0.7423637934864379, 0.9664725468919735, 0.9851079763969957], "final_y": [0.25781339118751434, 0.1648570957794684, 0.16485807056300228]}, "mutation_prompt": null}
{"id": "2a9c0a44-1b35-450e-9469-d1a23ee93e73", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor) * (np.min(fitness) / fitness[i])\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced periodicity-guided mutation by incorporating fitness-based weight adaptation for improved convergence.", "configspace": "", "generation": 4, "fitness": 0.9752208318907275, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a5b8351d-99b4-41bc-9178-c52b0dcc6144", "metadata": {"aucs": [0.9894912379860851, 0.9585851202913952, 0.9775861373947023], "final_y": [0.1648593910557694, 0.16485952698509887, 0.16485866016944206]}, "mutation_prompt": null}
{"id": "aaaa31f4-a0cf-48a9-9405-befca38aba01", "solution": "import numpy as np\n\nclass SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.func_evals < self.budget:\n            if self.func_evals % 100 == 0:\n                self.population_size = max(10, self.population_size - 1)  # Reduce population size over time\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.spiral_mutation(pop[i], a, b, c)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n                        best_fitness = trial_fitness\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def spiral_mutation(self, target, a, b, c):\n        diff = b - c\n        self.spiral_factor = max(0.1, self.spiral_factor - 0.01 * (self.func_evals / self.budget))  # Modifying line\n        spiral_step = self.spiral_factor * (a - target)\n        mutant = target + self.scaling_factor * diff + spiral_step\n        return mutant", "name": "SADE", "description": "Adaptive Spiral Factor Decay in SADE, gradually reducing spiral influence as evaluations near budget for enhanced convergence stability.", "configspace": "", "generation": 4, "fitness": 0.877818807535184, "feedback": "The algorithm SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.083. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "f93a7e1b-cfc4-4664-8745-af785cee76d2", "metadata": {"aucs": [0.7611808133776845, 0.9334859780035374, 0.9387896312243301], "final_y": [0.21699316665906432, 0.16488179029701744, 0.16509007311430612]}, "mutation_prompt": null}
{"id": "ed069ffb-4f2c-4420-a1e4-32e60572b473", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.2  # Increased spiral factor to improve exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Improved E-SADE by increasing the spiral factor to enhance exploration and convergence towards optimal periodic solutions.", "configspace": "", "generation": 4, "fitness": 0.9764540857209494, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.976 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a5b8351d-99b4-41bc-9178-c52b0dcc6144", "metadata": {"aucs": [0.9748393555571382, 0.9805670630578196, 0.9739558385478904], "final_y": [0.1648583241164534, 0.16485729868582255, 0.16486295080524394]}, "mutation_prompt": null}
{"id": "43127daa-dce1-4064-a1c3-c189f83449ed", "solution": "import numpy as np\n\nclass SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.func_evals < self.budget:\n            if self.func_evals % 100 == 0:\n                self.population_size = max(10, self.population_size - 1)  # Reduce population size over time\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.spiral_mutation(pop[i], a, b, c)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n                        best_fitness = trial_fitness\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def spiral_mutation(self, target, a, b, c):\n        diff = b - c\n        self.scaling_factor = self.scaling_factor + 0.05 * (np.sin(self.func_evals))  # Modifying line\n        self.spiral_factor = min(0.5, self.spiral_factor + 0.02 * (1 - self.func_evals / self.budget))  # Modifying line\n        spiral_step = self.spiral_factor * (a - target)\n        mutant = target + self.scaling_factor * diff + spiral_step\n        return mutant", "name": "SADE", "description": "Enhanced mutation strategy in DE by dynamically adapting scaling and spiral factors for improved convergence.", "configspace": "", "generation": 4, "fitness": 0.9263080760847465, "feedback": "The algorithm SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.023. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f93a7e1b-cfc4-4664-8745-af785cee76d2", "metadata": {"aucs": [0.8950994887207637, 0.9360131270709788, 0.947811612462497], "final_y": [0.16498026114021036, 0.16487067346319884, 0.16487496388618428]}, "mutation_prompt": null}
{"id": "8a003381-22fa-482c-999d-aba36aac61eb", "solution": "import numpy as np\n\nclass SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.func_evals < self.budget:\n            if self.func_evals % 100 == 0:\n                self.population_size = max(10, self.population_size - 1)  # Reduce population size over time\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.spiral_mutation(pop[i], a, b, c)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n                        best_fitness = trial_fitness\n\n                if self.func_evals >= self.budget:\n                    break\n            \n            # Adapt crossover rate and scaling factor based on budget progress\n            self.crossover_rate = 0.7 + 0.2 * (self.func_evals / self.budget)\n            self.scaling_factor = 0.4 + 0.1 * (1 - self.func_evals / self.budget)\n\n        return best\n\n    def spiral_mutation(self, target, a, b, c):\n        diff = b - c\n        self.spiral_factor = min(0.5, self.spiral_factor + 0.01 * (1 - self.func_evals / self.budget))  # Modifying line\n        spiral_step = self.spiral_factor * (a - target)\n        mutant = target + self.scaling_factor * diff + spiral_step\n        return mutant", "name": "SADE", "description": "Enhanced SADE by introducing adaptive crossover rate and dynamic scaling factor for improved exploration and convergence.", "configspace": "", "generation": 4, "fitness": 0.9219198851287468, "feedback": "The algorithm SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f93a7e1b-cfc4-4664-8745-af785cee76d2", "metadata": {"aucs": [0.9156542982407468, 0.9263645956027837, 0.9237407615427098], "final_y": [0.16509934117699332, 0.1648752913936814, 0.16489973495314292]}, "mutation_prompt": null}
{"id": "525dc7dc-a01d-4755-98ff-4038c7b1c413", "solution": "import numpy as np\n\nclass SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while self.func_evals < self.budget:\n            if self.func_evals % 100 == 0:\n                self.population_size = max(10, self.population_size - 1)  # Reduce population size over time\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.spiral_mutation(pop[i], a, b, c)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n                        best_fitness = trial_fitness\n\n                if self.func_evals >= self.budget:\n                    break\n\n        return best\n\n    def spiral_mutation(self, target, a, b, c):\n        diff = b - c\n        self.spiral_factor = min(0.5, self.spiral_factor + 0.01 * (1 - self.func_evals / self.budget))\n        periodicity_bias = np.sin(2 * np.pi * target)  # Adding line for periodicity bias\n        spiral_step = self.spiral_factor * (a - target + periodicity_bias)  # Modifying line\n        mutant = target + self.scaling_factor * diff + spiral_step\n        return mutant", "name": "SADE", "description": "Enhanced SADE by incorporating a periodicity bias in the mutation strategy to leverage constructive interference.", "configspace": "", "generation": 4, "fitness": 0.9392309978002236, "feedback": "The algorithm SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.939 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f93a7e1b-cfc4-4664-8745-af785cee76d2", "metadata": {"aucs": [0.9264716399680412, 0.9537028338580447, 0.937518519574585], "final_y": [0.16488056247252447, 0.16486522715998542, 0.1648712009143104]}, "mutation_prompt": null}
{"id": "f0b0eb6d-f035-471d-ace3-598b6fa7662f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.2  # Increased spiral factor to improve exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                adaptive_crossover_rate = self.crossover_rate * (1 - fitness[i] / np.max(fitness))  # change 1\n                trial = np.where(np.random.rand(self.dim) < adaptive_crossover_rate, mutant, pop[i])  # change 2\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "E-SADE with adaptive crossover rate to enhance exploitation and convergence.", "configspace": "", "generation": 5, "fitness": 0.9681872162148211, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.016. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ed069ffb-4f2c-4420-a1e4-32e60572b473", "metadata": {"aucs": [0.9736647480490421, 0.9458982517600294, 0.9849986488353917], "final_y": [0.16485772290166845, 0.1648566188656071, 0.16485741139916865]}, "mutation_prompt": null}
{"id": "f1e5b6a1-062a-45b8-8903-fd947a6076f6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.15  # Increased spiral factor for improved exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.cos(2 * np.pi * i / self.population_size)  # Changed from sin to cos\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced spiral factor adaptation for improved exploration-exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.9754743865169946, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "31e1ce05-7f40-46c5-b801-654eae108b38", "metadata": {"aucs": [0.9873726510355458, 0.9647213225360048, 0.9743291859794334], "final_y": [0.16486016886568422, 0.16485734415293207, 0.1648564085301173]}, "mutation_prompt": null}
{"id": "981b23bf-663c-4789-9201-12039cc84d70", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Adjust the spiral factor based on the variance of fitness\n        fitness_variance = np.var(fitness)\n        spiral_step = self.spiral_factor * fitness_variance * (a - target)\n        periodic_factor = np.cos(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced spiral factor adaptation based on fitness variance to improve exploration and convergence.", "configspace": "", "generation": 5, "fitness": 0.9372640720079887, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.937 with standard deviation 0.050. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "31e1ce05-7f40-46c5-b801-654eae108b38", "metadata": {"aucs": [0.868245257282663, 0.9580839666722848, 0.9854629920690182], "final_y": [0.18187832015838823, 0.16485702788906176, 0.16485939247577497]}, "mutation_prompt": null}
{"id": "49f2bc4b-959c-4f85-9df7-a8037cf86bdf", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.05  # Reduced initial spiral factor\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if self.func_evals < self.budget // 2:  # Trigger local search sooner\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (0.5 + 0.5 * np.cos(2 * np.pi * i / self.population_size)) * (a - target)  # Adaptive spiral\n        periodic_factor = np.cos(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Introduce adaptive scaling of the spiral factor and refine local search trigger to improve convergence precision.", "configspace": "", "generation": 5, "fitness": 0.9626302235400228, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.032. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "31e1ce05-7f40-46c5-b801-654eae108b38", "metadata": {"aucs": [0.9178031853968546, 0.984650555293116, 0.9854369299300976], "final_y": [0.16485659443657252, 0.16485584468827097, 0.16485660320161077]}, "mutation_prompt": null}
{"id": "cc0e716c-fcc4-44a9-b0ba-fd2d965bbe91", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.2  # Increased spiral factor to improve exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement with multiple restarts\n            if self.func_evals < self.budget:\n                restart_attempts = 3\n                for _ in range(restart_attempts):\n                    res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                    if res.fun < fitness[best_idx]:\n                        best = res.x\n                        fitness[best_idx] = res.fun\n                        self.func_evals += res.nfev\n                    if self.func_evals >= self.budget:\n                        break\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced local search by using multiple restarts to refine the best solution found during optimization.", "configspace": "", "generation": 5, "fitness": 0.9795533545209381, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.980 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ed069ffb-4f2c-4420-a1e4-32e60572b473", "metadata": {"aucs": [0.9858637096419843, 0.9689868930667896, 0.9838094608540402], "final_y": [0.16485835507635982, 0.16485743729930247, 0.16485608998587853]}, "mutation_prompt": null}
{"id": "748974b7-ea79-4925-80dd-8123fb3db83e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = (self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))) / 2.0  # Modified\n        periodic_factor = np.cos(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Introduced an adaptive spiral_factor based on fitness to enhance local search and convergence.", "configspace": "", "generation": 5, "fitness": 0.9817113750965946, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.982 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "31e1ce05-7f40-46c5-b801-654eae108b38", "metadata": {"aucs": [0.9844531840438484, 0.9723796589722008, 0.9883012822737344], "final_y": [0.16485729239915614, 0.164857693009415, 0.16485600267550393]}, "mutation_prompt": null}
{"id": "4cef06e1-e2ef-4c16-b290-ac7ff8fb075d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        adaptive_spiral_factor = self.spiral_factor * (1 + 0.5 * np.cos(2 * np.pi * i / self.population_size))\n        spiral_step = adaptive_spiral_factor * (a - target) * (fitness[i] / np.min(fitness)) \n        periodic_factor = np.cos(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced E_SADE by incorporating adaptive spiral factor to dynamically adjust exploration and exploitation.", "configspace": "", "generation": 5, "fitness": 0.9739568391059844, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "31e1ce05-7f40-46c5-b801-654eae108b38", "metadata": {"aucs": [0.9660712406416805, 0.9715939475216878, 0.9842053291545846], "final_y": [0.16485677317868408, 0.16485726925627053, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "525d4aae-8626-41e9-a216-06c223022df2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Increased spiral factor slightly for improved exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Tweaked spiral factor increment strategy for improved exploration and convergence.", "configspace": "", "generation": 5, "fitness": 0.9856188096810228, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.986 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ed069ffb-4f2c-4420-a1e4-32e60572b473", "metadata": {"aucs": [0.9863460177579196, 0.9863050821305642, 0.9842053291545846], "final_y": [0.16485650867398505, 0.16485706386182597, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "31f1c25c-ded4-4db2-8afc-92566583b697", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        adaptive_spiral_factor = self.spiral_factor * (1 + np.sin(2 * np.pi * i / self.population_size))\n        spiral_step = adaptive_spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.cos(2 * np.pi * i / self.population_size)  # Changed from sin to cos\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced periodicity in mutation using cosine and adaptive spiral factor for improved exploration and convergence.", "configspace": "", "generation": 5, "fitness": 0.9673796150947803, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.018. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "31e1ce05-7f40-46c5-b801-654eae108b38", "metadata": {"aucs": [0.9723093814354908, 0.9433978827067043, 0.9864315811421462], "final_y": [0.16485673472519136, 0.16485703166319554, 0.16485867399494647]}, "mutation_prompt": null}
{"id": "5ae0fe42-5816-4b50-9104-c26cab48c21f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.2  # Increased spiral factor to improve exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor) * np.exp(-fitness[i] / np.mean(fitness))\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced mutation step by introducing exponential scaling to improve exploration and convergence precision.", "configspace": "", "generation": 5, "fitness": 0.9813675287085868, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.981 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ed069ffb-4f2c-4420-a1e4-32e60572b473", "metadata": {"aucs": [0.9843985927153752, 0.9754986642558007, 0.9842053291545846], "final_y": [0.16485762496611944, 0.1648571275364772, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "88edc318-3aa6-4ee7-8b8f-75d51f447308", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness)) * np.clip(fitness[i], 0.1, 1.0)  # Modified\n        periodic_factor = np.cos(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Refined adaptive spiral_factor calculation by incorporating dynamic scaling for better convergence.", "configspace": "", "generation": 6, "fitness": 0.9703481201741196, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "748974b7-ea79-4925-80dd-8123fb3db83e", "metadata": {"aucs": [0.9597514922391304, 0.9680392886385883, 0.9832535796446404], "final_y": [0.1648614338237222, 0.16485939036669262, 0.1648574457385602]}, "mutation_prompt": null}
{"id": "27ce2937-1b13-44d5-97e5-2b12819b779f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = (self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))) / 2.0  # Modified\n        periodic_factor = np.cos(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor * np.sin(fitness[i]))  # Changed line\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced adaptive scaling with cosine factor for improved solution exploitation.", "configspace": "", "generation": 6, "fitness": 0.9763534813628331, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.976 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "748974b7-ea79-4925-80dd-8123fb3db83e", "metadata": {"aucs": [0.9585632322589895, 0.9860939701341753, 0.9844032416953342], "final_y": [0.16485802979840947, 0.16485771435887087, 0.1648589521395024]}, "mutation_prompt": null}
{"id": "b532f119-59f9-4240-8117-0e66bedc354e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Increased spiral factor slightly for improved exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B', options={'ftol': 1e-9})\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced local search by incorporating local optimization weights, promoting better convergence.", "configspace": "", "generation": 6, "fitness": 0.9677146027233391, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.015. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "525d4aae-8626-41e9-a216-06c223022df2", "metadata": {"aucs": [0.9886044173444956, 0.9519232743296513, 0.9626161164958706], "final_y": [0.16485788848829475, 0.1648603656089319, 0.1648577217670235]}, "mutation_prompt": null}
{"id": "669f9b1d-42c1-4fb4-880c-d6f854e1ad5c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = (self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness)) * (1 + np.cos(2 * np.pi * self.func_evals / self.budget))) / 2.0  # Modified\n        periodic_factor = np.cos(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced periodicity-guided mutation by introducing dynamic spiral factor based on iteration count to improve convergence.", "configspace": "", "generation": 6, "fitness": 0.9767850313961389, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.977 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "748974b7-ea79-4925-80dd-8123fb3db83e", "metadata": {"aucs": [0.9816991184277754, 0.9626639221168124, 0.9859920536438291], "final_y": [0.16485618851003225, 0.16485716144361928, 0.1648585179312585]}, "mutation_prompt": null}
{"id": "1ebb3d89-35df-4b68-87af-4585d2bb6288", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Initial spiral factor\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Adjust spiral factor dynamically based on the fraction of the budget used\n        self.spiral_factor = 0.22 * (1.0 - self.func_evals / self.budget)\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhance exploration by dynamically adjusting the spiral factor based on the search progress.", "configspace": "", "generation": 6, "fitness": 0.9779525850487852, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.978 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "525d4aae-8626-41e9-a216-06c223022df2", "metadata": {"aucs": [0.985180477277788, 0.9638881001936885, 0.9847891776748792], "final_y": [0.16485706072430384, 0.16486250975294314, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "21e83982-449a-49f3-bc46-02eb776cfe25", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.1\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n                        \n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        dynamic_spiral = self.spiral_factor * (1 + np.sin(2 * np.pi * i / self.population_size))\n        modular_preservation = np.mean([a, b, c], axis=0) * 0.1\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * np.cos(2 * np.pi * i / self.population_size))\n        mutant = target + adaptive_scaling * diff + dynamic_spiral * (a - target) + modular_preservation\n        return mutant", "name": "E_SADE", "description": "Enhanced E_SADE with dynamic spiral factor and reinforced modular preservation to improve exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.9477846203139547, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.948 with standard deviation 0.039. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "748974b7-ea79-4925-80dd-8123fb3db83e", "metadata": {"aucs": [0.8937168975213486, 0.9651800018179247, 0.9844569616025908], "final_y": [0.16485610906398074, 0.16485723820791698, 0.16485599346265656]}, "mutation_prompt": null}
{"id": "45113302-fa69-4a3a-9efb-6ead5a33b4b5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Increased spiral factor slightly for improved exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Modify the spiral factor based on average fitness difference for adaptability\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.mean(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Improved convergence by adjusting the spiral factor based on the mean fitness difference to enhance adaptability.", "configspace": "", "generation": 6, "fitness": 0.9785540438590901, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.979 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "525d4aae-8626-41e9-a216-06c223022df2", "metadata": {"aucs": [0.985149817792441, 0.9651945487278697, 0.9853177650569592], "final_y": [0.16485610201676848, 0.16485724969045878, 0.16485653862456062]}, "mutation_prompt": null}
{"id": "9657115c-58ff-4f2f-aea5-36175d176f52", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Increased spiral factor slightly for improved exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        self.spiral_factor = 0.25  # Adjusted spiral factor for improved convergence\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced periodicity adaptation through dynamic spiral factor for better convergence.", "configspace": "", "generation": 6, "fitness": 0.9725230470520617, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "525d4aae-8626-41e9-a216-06c223022df2", "metadata": {"aucs": [0.987163838680541, 0.9595401861898323, 0.970865116285812], "final_y": [0.16485730252223862, 0.16485891993038027, 0.1648558725606385]}, "mutation_prompt": null}
{"id": "e157e914-6779-4c34-a0c8-b8a91dcfe552", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Increased spiral factor slightly for improved exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        diversity_factor = np.std(fitness) / np.mean(fitness)  # Line changed\n        spiral_step = diversity_factor * self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))  # Line changed\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Introduced a dynamic spiral factor based on population diversity to enhance exploration and convergence.", "configspace": "", "generation": 6, "fitness": 0.9597573352365476, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "525d4aae-8626-41e9-a216-06c223022df2", "metadata": {"aucs": [0.9672843159408221, 0.9487463926076257, 0.963241297161195], "final_y": [0.1648560866301988, 0.16485601340816558, 0.1648573407210958]}, "mutation_prompt": null}
{"id": "d5b36fc8-53c1-4089-957d-3fe2e0a952bd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.initial_spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                self.spiral_factor = self.initial_spiral_factor * (1 - self.func_evals / self.budget)\n                mutant = self.diversity_preserving_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def diversity_preserving_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        random_displacement = np.random.uniform(-0.1, 0.1, self.dim)\n        mutant = target + adaptive_scaling * diff + spiral_step + random_displacement\n        return mutant", "name": "E_SADE", "description": "Improved E_SADE by adjusting spiral factor dynamically based on iteration progress and incorporating diversity preservation to enhance exploration and convergence.", "configspace": "", "generation": 6, "fitness": 0.9684677756996063, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.022. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "525d4aae-8626-41e9-a216-06c223022df2", "metadata": {"aucs": [0.9871621339803106, 0.9369107732275724, 0.9813304198909358], "final_y": [0.16485847233157436, 0.16485909744522664, 0.1648575774618567]}, "mutation_prompt": null}
{"id": "9bc5a5c6-5826-4c69-aba3-f7e95e39b3ca", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Increased spiral factor slightly for improved exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Modify the spiral factor based on standard deviation of fitness for improved adaptability\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / (np.std(fitness) + 1e-10))  # Changed line\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced adaptability of the spiral factor by basing it on the standard deviation of fitness values, improving solution convergence.", "configspace": "", "generation": 7, "fitness": 0.9675767499992186, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "45113302-fa69-4a3a-9efb-6ead5a33b4b5", "metadata": {"aucs": [0.9506667580472095, 0.9668141429670533, 0.9852493489833933], "final_y": [0.16486193782392944, 0.16485592104386404, 0.16485998558763093]}, "mutation_prompt": null}
{"id": "0f884afd-3556-4ab8-a693-9166089b1f26", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, best, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, best, i, fitness):\n        diff = b - c\n        best_global_fitness = np.min(fitness)  # Change 1\n        spiral_step = self.spiral_factor * (a - target) * (best_global_fitness / np.mean(fitness))  # Change 2\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor) * (fitness[i] / best_global_fitness)  # Change 3\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced exploration and convergence by adjusting the spiral factor dynamically based on the best global fitness and incorporating a fitness-based population scaling adaptation.", "configspace": "", "generation": 7, "fitness": 0.9633737782263035, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "45113302-fa69-4a3a-9efb-6ead5a33b4b5", "metadata": {"aucs": [0.9612814209792689, 0.9699609862079772, 0.9588789274916641], "final_y": [0.16486630631851962, 0.1648576043847495, 0.16485769176912268]}, "mutation_prompt": null}
{"id": "5934294a-f2dd-4c98-a649-28db6c8aed74", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Increased spiral factor slightly for improved exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Modify the spiral factor based on average fitness difference for adaptability\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.mean(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step * np.cos(2 * np.pi * i / self.population_size)\n        return mutant", "name": "E_SADE", "description": "Enhance solution quality by modifying the spiral factor to periodically adjust based on average fitness and improve diversity.", "configspace": "", "generation": 7, "fitness": 0.9592328688463595, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "45113302-fa69-4a3a-9efb-6ead5a33b4b5", "metadata": {"aucs": [0.9849150227112037, 0.9316250704999198, 0.961158513327955], "final_y": [0.1648582420825847, 0.1818804950148526, 0.16485611460149552]}, "mutation_prompt": null}
{"id": "b8b33dcb-8012-4f89-b4f3-73ab97739351", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Increased spiral factor slightly for improved exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Modify the spiral factor based on the fitness variance for adaptability\n        spiral_step = self.spiral_factor * (a - target) * (np.var(fitness) / np.mean(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhance search adaptability by dynamically adjusting the spiral factor based on the fitness variance.", "configspace": "", "generation": 7, "fitness": 0.9595628043777431, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.023. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "45113302-fa69-4a3a-9efb-6ead5a33b4b5", "metadata": {"aucs": [0.9308333007164037, 0.9862138143605297, 0.9616412980562957], "final_y": [0.18188571374995, 0.16485688532550458, 0.16486029887061426]}, "mutation_prompt": null}
{"id": "47ae0b4e-24ba-4f57-b1d6-28847cf0d935", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Increased spiral factor slightly for improved exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Modify the spiral factor based on average fitness difference for adaptability\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.mean(fitness))\n        periodic_factor = np.sin(4 * np.pi * i / self.population_size)  # Refined periodicity factor\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced adaptability by refining the periodicity factor in the mutation mechanism to guide solutions towards optimal periodic configurations.", "configspace": "", "generation": 7, "fitness": 0.9569035454768612, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.957 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "45113302-fa69-4a3a-9efb-6ead5a33b4b5", "metadata": {"aucs": [0.9662437025977518, 0.9718736376017888, 0.9325932962310433], "final_y": [0.1648648617901729, 0.16485892355835585, 0.16486091052965246]}, "mutation_prompt": null}
{"id": "cb3e2c97-20d4-4a02-96fa-bbe71fb13944", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Increased spiral factor slightly for improved exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Modify the spiral factor based on the standard deviation of fitness for adaptability\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.std(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Fine-tuned adaptive spiral factor by using standard deviation of fitness for enhanced convergence.", "configspace": "", "generation": 7, "fitness": 0.954511967132691, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.955 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "45113302-fa69-4a3a-9efb-6ead5a33b4b5", "metadata": {"aucs": [0.9596880339395891, 0.9682775383869493, 0.9355703290715349], "final_y": [0.16485796158041155, 0.16485759274100698, 0.16486178792916906]}, "mutation_prompt": null}
{"id": "0a4a94d5-e17a-4bf6-8d72-99e552f4ab52", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Initial spiral factor\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Adjust spiral factor dynamically based on the fraction of the budget used and periodicity\n        adaptive_period = np.sin(2 * np.pi * self.func_evals / self.budget)\n        self.spiral_factor = 0.22 * (1.0 - self.func_evals / self.budget) * adaptive_period\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhance exploration by adjusting the spiral factor based on both search progress and periodicity for improved adaptability.", "configspace": "", "generation": 7, "fitness": 0.9535466369874938, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "1ebb3d89-35df-4b68-87af-4585d2bb6288", "metadata": {"aucs": [0.9548763602595991, 0.9564966061023386, 0.9492669446005435], "final_y": [0.16486015449273217, 0.16485942520449015, 0.1648589209239787]}, "mutation_prompt": null}
{"id": "b3f6fc50-ac19-4747-b98d-f0bc534efd4a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Increased spiral factor slightly for improved exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                # Dynamically adjust crossover rate based on fitness improvement\n                adaptive_crossover_rate = self.crossover_rate * (1 + (fitness[i] - np.min(fitness)) / (np.max(fitness) - np.min(fitness)))\n                trial = np.where(np.random.rand(self.dim) < adaptive_crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Modify the spiral factor based on average fitness difference for adaptability\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.mean(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhance solution refinement by dynamically adjusting the crossover rate based on the fitness improvement, improving exploration-exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.9637867109971174, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "45113302-fa69-4a3a-9efb-6ead5a33b4b5", "metadata": {"aucs": [0.9859408698978256, 0.944868766230818, 0.9605504968627088], "final_y": [0.16485645527640147, 0.16486254830012437, 0.16485620143351076]}, "mutation_prompt": null}
{"id": "b81b3514-2c26-499c-af90-6c380dd72168", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Periodicity-based local search\n            if self.func_evals < self.budget:\n                res = minimize(func, best + 0.1 * np.sin(2 * np.pi * np.arange(self.dim) / self.dim), bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.mean(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhance local refinement by integrating a periodicity-based local search phase for improved convergence in multiple minima landscapes.", "configspace": "", "generation": 7, "fitness": 0.9513332568311826, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.018. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "45113302-fa69-4a3a-9efb-6ead5a33b4b5", "metadata": {"aucs": [0.9746503448022382, 0.9316250704999198, 0.9477243551913903], "final_y": [0.16485711068219067, 0.1818804950148526, 0.16485725480046098]}, "mutation_prompt": null}
{"id": "7bdbace2-77b7-40cd-9d3b-d38b3f50b78d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Initial spiral factor\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                # Sinusoidal adaptation of crossover rate\n                self.crossover_rate = 0.9 * (0.5 + 0.5 * np.sin(2 * np.pi * i / self.population_size))\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Adjust spiral factor dynamically based on the fraction of the budget used\n        self.spiral_factor = 0.22 * (1.0 - self.func_evals / self.budget)\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Improved exploration by incorporating a sinusoidal adaptation in the crossover rate to balance exploration and exploitation.", "configspace": "", "generation": 7, "fitness": 0.976375096312021, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.976 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "1ebb3d89-35df-4b68-87af-4585d2bb6288", "metadata": {"aucs": [0.9870772566117177, 0.9571938466513229, 0.9848541856730224], "final_y": [0.1648564146894852, 0.16485872544025104, 0.16485650399011698]}, "mutation_prompt": null}
{"id": "726af0f2-bd9e-4590-833e-798322cd5ed9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Initial spiral factor\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            # Dynamic adjustment of population size\n            self.population_size = int(50 * (1.0 - self.func_evals / self.budget)) + 5\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                # Sinusoidal adaptation of crossover rate\n                self.crossover_rate = 0.9 * (0.5 + 0.5 * np.sin(2 * np.pi * i / self.population_size))\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Adjust spiral factor dynamically based on the fraction of the budget used\n        self.spiral_factor = 0.22 * (1.0 - self.func_evals / self.budget)\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Improved exploration by dynamically adapting population size based on remaining budget to maintain diversity and exploration.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 52 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 52 is out of bounds for axis 0 with size 50')", "parent_id": "7bdbace2-77b7-40cd-9d3b-d38b3f50b78d", "metadata": {}, "mutation_prompt": null}
{"id": "7b370273-de33-484b-9502-5427b27c76a5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n        self.fitness_history = []\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        self.fitness_history.append(np.min(fitness))\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.dynamic_spiral_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n                self.fitness_history.append(np.min(fitness))\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def dynamic_spiral_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        fitness_improvement = max(self.fitness_history[-5:]) - min(self.fitness_history[-5:]) if len(self.fitness_history) > 5 else 0\n        spiral_step = self.spiral_factor * (a - target) * fitness_improvement  # Modified line\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE_Improved", "description": "Introduce a dynamic spiral factor based on historical fitness improvement, enhancing adaptability and convergence in the search space.", "configspace": "", "generation": 8, "fitness": 0.9431602219682961, "feedback": "The algorithm E_SADE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.943 with standard deviation 0.030. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "9bc5a5c6-5826-4c69-aba3-f7e95e39b3ca", "metadata": {"aucs": [0.9136502662503839, 0.9316250704999198, 0.9842053291545846], "final_y": [0.18813225673675948, 0.1818804950148526, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "5c34b381-1d95-4eff-9cae-c6530dfa5f99", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Increased spiral factor slightly for improved exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Modify the spiral factor based on maximum fitness for improved adaptability\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / (np.max(fitness) + 1e-10))  # Changed line\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced convergence by adjusting the spiral factor with a more dynamic component based on the maximum fitness value.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "9bc5a5c6-5826-4c69-aba3-f7e95e39b3ca", "metadata": {}, "mutation_prompt": null}
{"id": "db93637c-900c-4482-b23a-49335ea6976b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Initial spiral factor\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                # Sinusoidal adaptation of crossover rate\n                self.crossover_rate = 0.9 * (0.5 + 0.5 * np.sin(2 * np.pi * i / self.population_size))\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Adjust spiral factor dynamically based on the harmonic mean of the fitness values\n        harmonic_mean_fitness = len(fitness) / np.sum(1.0 / fitness)\n        self.spiral_factor = 0.22 * (1.0 - self.func_evals / self.budget) * (fitness[i] / harmonic_mean_fitness)\n        spiral_step = self.spiral_factor * (a - target)\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Improved spiral factor adaptation by integrating the harmonic mean of fitness values for enhanced convergence stability.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 52 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 52 is out of bounds for axis 0 with size 50')", "parent_id": "7bdbace2-77b7-40cd-9d3b-d38b3f50b78d", "metadata": {}, "mutation_prompt": null}
{"id": "75fdcfbf-ee35-476e-bbeb-64ec599d9e46", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Initial spiral factor\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                # Sinusoidal adaptation of crossover rate\n                self.crossover_rate = 0.85 * (0.5 + 0.5 * np.sin(2 * np.pi * i / self.population_size))\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Adjust spiral factor dynamically based on the fraction of the budget used\n        self.spiral_factor = 0.22 * (1.0 - self.func_evals / self.budget)\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / np.min(fitness))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.6 + 0.4 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced E_SADE by introducing adaptive periodicity focus and dynamic scaling to balance global exploration and local exploitation.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "7bdbace2-77b7-40cd-9d3b-d38b3f50b78d", "metadata": {}, "mutation_prompt": null}
{"id": "b2c98246-cf52-48d2-af5e-b3bba6b2313e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        diversity_factor = np.std(fitness) / np.mean(fitness)\n        spiral_step = self.spiral_factor * (a - target) * diversity_factor\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor * diversity_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhancing solution refinement by dynamically adapting spiral and scaling factors based on evolving population diversity metrics.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 51 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 51 is out of bounds for axis 0 with size 50')", "parent_id": "9bc5a5c6-5826-4c69-aba3-f7e95e39b3ca", "metadata": {}, "mutation_prompt": null}
{"id": "3f39ac36-5753-4ad6-a59a-e5efea682ec9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Increased spiral factor slightly for improved exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Modify the spiral factor based on standard deviation of fitness for improved adaptability\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / (np.std(fitness) + 1e-10))  # Changed line\n        periodic_factor = np.cos(2 * np.pi * i / self.population_size)  # Changed line\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced periodic adaptation by incorporating a cosine function for smoother exploration around optimal periodic solutions.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 52 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 52 is out of bounds for axis 0 with size 50')", "parent_id": "9bc5a5c6-5826-4c69-aba3-f7e95e39b3ca", "metadata": {}, "mutation_prompt": null}
{"id": "343bf63e-309d-4793-b9d9-54b2c6e0815c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n            # Dynamic crossover rate adjustment based on diversity\n            self.crossover_rate = 0.9 * (1 - np.std(fitness) / (np.mean(fitness) + 1e-10))\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / (np.std(fitness) + 1e-10))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Introducing a dynamic crossover rate adjustment based on population fitness diversity to enhance exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "9bc5a5c6-5826-4c69-aba3-f7e95e39b3ca", "metadata": {}, "mutation_prompt": null}
{"id": "8110d21e-5954-4b19-8e74-4e67d465ebf2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                # Adaptive control of crossover rate\n                diversity_factor = np.std(pop)\n                adaptive_crossover_rate = self.crossover_rate * (1 + 0.5 * diversity_factor)\n                trial = np.where(np.random.rand(self.dim) < adaptive_crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / (np.std(fitness) + 1e-10))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Introduced adaptive control of the crossover rate based on the diversity of the population to enhance exploration and convergence.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 52 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 52 is out of bounds for axis 0 with size 50')", "parent_id": "9bc5a5c6-5826-4c69-aba3-f7e95e39b3ca", "metadata": {}, "mutation_prompt": null}
{"id": "602af286-891c-4a0b-ae1b-22551d7a3061", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Increased spiral factor slightly for improved exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Modify the spiral factor based on standard deviation of fitness for improved adaptability\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / (np.mean(fitness) + 1e-10))  # Changed line\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Refined spiral factor adjustment by incorporating dynamic re-evaluation based on mean fitness to better balance search dynamics.", "configspace": "", "generation": 8, "fitness": 0.982845614375735, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.983 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9bc5a5c6-5826-4c69-aba3-f7e95e39b3ca", "metadata": {"aucs": [0.9773642693382191, 0.9852223336983255, 0.9859502400906606], "final_y": [0.16485668785146534, 0.16485677256350162, 0.16485661817325492]}, "mutation_prompt": null}
{"id": "3a67f1f0-bf73-4d37-8fb9-048ec3379de6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                self.crossover_rate = 0.5 + 0.4 * np.std(fitness) / (np.mean(fitness) + 1e-10)  # Changed line\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / (np.mean(fitness) + 1e-10))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Introduced a dynamic crossover rate adjustment based on current population diversity to enhance exploration and convergence.", "configspace": "", "generation": 9, "fitness": 0.97808117931234, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.978 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "602af286-891c-4a0b-ae1b-22551d7a3061", "metadata": {"aucs": [0.965807321848731, 0.9850819973472902, 0.9833542187409986], "final_y": [0.16486247763444195, 0.16485607873972896, 0.1648588870569453]}, "mutation_prompt": null}
{"id": "03f8b3e5-2169-4ac3-85de-544733d59e1c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            diversity = np.std(fitness) / (np.mean(fitness) + 1e-10)  # Added line\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.dynamic_periodicity_mutation(pop[i], a, b, c, i, fitness, diversity)  # Modified line\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def dynamic_periodicity_mutation(self, target, a, b, c, i, fitness, diversity):  # Modified line\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * diversity  # Modified line\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE_Enhanced", "description": "Introduce a dynamic periodic scaling factor based on fitness diversity to enhance exploration adaptability and convergence.", "configspace": "", "generation": 9, "fitness": 0.9522477513424666, "feedback": "The algorithm E_SADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.952 with standard deviation 0.031. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "602af286-891c-4a0b-ae1b-22551d7a3061", "metadata": {"aucs": [0.9564674947810554, 0.9125856012874854, 0.9876901579588592], "final_y": [0.1648589483957208, 0.18813154936372545, 0.1648559542130399]}, "mutation_prompt": null}
{"id": "b87e9d3b-2eeb-4557-aee6-443b884b6b4a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / (np.mean(fitness) + 1e-10))\n        periodic_factor = np.sin(2 * np.pi * (i + fitness[i]) / self.population_size)  # Changed line\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Refined exploration by introducing fitness-adaptive periodicity in spiral factor adjustment to enhance convergence.", "configspace": "", "generation": 9, "fitness": 0.9709301648407247, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.971 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "602af286-891c-4a0b-ae1b-22551d7a3061", "metadata": {"aucs": [0.961481752140951, 0.964725779316233, 0.98658296306499], "final_y": [0.16485726283648483, 0.1648566945071398, 0.16485692231907467]}, "mutation_prompt": null}
{"id": "c29017bc-6a9e-4549-bb65-2e83dbd4d8fd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n        self.fitness_history = []\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        self.fitness_history.append(np.min(fitness))\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.dynamic_spiral_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n                self.fitness_history.append(np.min(fitness))\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def dynamic_spiral_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        fitness_improvement = max(self.fitness_history[-5:]) - min(self.fitness_history[-5:]) if len(self.fitness_history) > 5 else 0\n        variance_factor = np.var(fitness)  # Added line\n        spiral_step = self.spiral_factor * (a - target) * fitness_improvement * (1 + variance_factor) # Modified line\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE_Improved", "description": "Enhance adaptability in the dynamic spiral mutation by incorporating variance-based scaling for improved exploration.", "configspace": "", "generation": 9, "fitness": 0.9131422390173801, "feedback": "The algorithm E_SADE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.025. And the mean value of best solutions found was 0.188 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "7b370273-de33-484b-9502-5427b27c76a5", "metadata": {"aucs": [0.9302618081579603, 0.9313717087254983, 0.8777932001686815], "final_y": [0.18187853249963282, 0.1818829096512804, 0.20044530771662694]}, "mutation_prompt": null}
{"id": "21157993-d24f-41db-a0b1-43342b4d34ee", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n        self.fitness_history = []\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        self.fitness_history.append(np.min(fitness))\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.dynamic_spiral_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n                self.fitness_history.append(np.min(fitness))\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def dynamic_spiral_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        fitness_improvement = max(self.fitness_history[-5:]) - min(self.fitness_history[-5:]) if len(self.fitness_history) > 5 else 0\n        spiral_step = self.spiral_factor * (a - target) * np.var(self.fitness_history[-5:])  # Modified line\n        periodic_factor = np.cos(2 * np.pi * i / self.population_size)  # Modified line\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE_Improved", "description": "Enhance dynamic adaptation by adjusting the spiral factor based on recent fitness variance and fine-tune convergence with improved periodic factor scaling.", "configspace": "", "generation": 9, "fitness": 0.8677132076661866, "feedback": "The algorithm E_SADE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.007. And the mean value of best solutions found was 0.191 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "7b370273-de33-484b-9502-5427b27c76a5", "metadata": {"aucs": [0.8663654915520862, 0.8770850159785553, 0.8596891154679187], "final_y": [0.16485609212131458, 0.2004453498532398, 0.20725437508116962]}, "mutation_prompt": null}
{"id": "9dff7673-faf4-4fdc-9201-3254e32f9c0b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n        self.fitness_history = []\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        self.fitness_history.append(np.min(fitness))\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.dynamic_spiral_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n                self.fitness_history.append(np.min(fitness))\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def dynamic_spiral_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        fitness_improvement = max(self.fitness_history[-5:]) - min(self.fitness_history[-5:]) if len(self.fitness_history) > 5 else 0\n        spiral_step = self.spiral_factor * (a - target) * fitness_improvement\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        sinusoidal_perturbation = np.sin(2 * np.pi * i / 10)  # Modified line for periodic perturbation\n        mutant = target + adaptive_scaling * diff + spiral_step * sinusoidal_perturbation\n        return mutant", "name": "E_SADE_Improved", "description": "Introduce periodic sinusoidal perturbation in dynamic spiral mutation for enhanced exploration.", "configspace": "", "generation": 9, "fitness": 0.939424822256877, "feedback": "The algorithm E_SADE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.939 with standard deviation 0.062. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7b370273-de33-484b-9502-5427b27c76a5", "metadata": {"aucs": [0.8514196813487367, 0.9834388682498765, 0.9834159171720178], "final_y": [0.1648650845419921, 0.16485627458249819, 0.16485639673290875]}, "mutation_prompt": null}
{"id": "d9a0e759-a390-4f87-bc9d-7500d07125cb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE_Enhanced:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.6  # Changed line\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.3  # Changed line\n        self.func_evals = 0\n        self.fitness_history = []\n        self.chaos_map = self.init_chaos_map()  # Added line\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        self.fitness_history.append(np.min(fitness))\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.dynamic_spiral_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n                self.fitness_history.append(np.min(fitness))\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def dynamic_spiral_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        fitness_improvement = max(self.fitness_history[-5:]) - min(self.fitness_history[-5:]) if len(self.fitness_history) > 5 else 0\n        spiral_step = self.spiral_factor * (a - target) * fitness_improvement\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        chaos_factor = self.chaos_map[i]  # Added line\n        mutant = target + adaptive_scaling * diff + spiral_step * chaos_factor  # Modified line\n        return mutant\n\n    def init_chaos_map(self):  # Added lines\n        chaos_map = np.random.rand(self.population_size)\n        for i in range(1, len(chaos_map)):\n            chaos_map[i] = 4 * chaos_map[i-1] * (1 - chaos_map[i-1])  # Logistic map\n        return chaos_map", "name": "E_SADE_Enhanced", "description": "Integrate adaptive mechanisms with chaotic maps for enhanced exploration while leveraging periodic constraints for improved convergence.", "configspace": "", "generation": 9, "fitness": 0.9354896655636411, "feedback": "The algorithm E_SADE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.935 with standard deviation 0.037. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "7b370273-de33-484b-9502-5427b27c76a5", "metadata": {"aucs": [0.9127468822933046, 0.9056731861280493, 0.9880489282695696], "final_y": [0.1756883990058452, 0.16485648989593427, 0.1648563008956193]}, "mutation_prompt": null}
{"id": "89234aa1-3fc8-411e-81fb-d77cbea13eb9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Increased spiral factor slightly for improved exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Modify spiral factor based on relative fitness improvement for better adaptation\n        spiral_step = self.spiral_factor * (a - target) * (1 + np.abs(fitness[i] - np.mean(fitness)) / (np.mean(fitness) + 1e-10))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Introduce fitness-dependent adaptive spiral factor adjustment to enhance exploration and convergence balance.", "configspace": "", "generation": 9, "fitness": 0.9760390621768407, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.976 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "602af286-891c-4a0b-ae1b-22551d7a3061", "metadata": {"aucs": [0.984280248676594, 0.9624032869861561, 0.9814336508677717], "final_y": [0.1648563952006975, 0.1648564183686021, 0.16485644937295607]}, "mutation_prompt": null}
{"id": "3e21ed2f-f905-409f-9d3c-6160c53a20b0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22  # Increased spiral factor slightly for improved exploration\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Modify the spiral factor based on standard deviation of fitness for improved adaptability\n        spiral_step = self.spiral_factor * (a - target) * (np.var(fitness) / (np.mean(fitness) + 1e-10))  # Changed line\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Refine mutation by dynamically adjusting spiral factor based on variance of fitness to improve convergence.", "configspace": "", "generation": 9, "fitness": 0.9555803515131552, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.956 with standard deviation 0.030. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "602af286-891c-4a0b-ae1b-22551d7a3061", "metadata": {"aucs": [0.9140019212428664, 0.9685338041420145, 0.9842053291545846], "final_y": [0.16486233398004269, 0.1648563158219326, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "4cd564df-e073-44a2-a55d-7f9d03147a6f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.adaptive_crossover_rate(fitness), mutant, pop[i])  # Changed line\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.adaptive_spiral_factor(fitness) * (a - target) * (fitness[i] / (np.mean(fitness) + 1e-10))  # Changed line\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant\n    \n    def adaptive_spiral_factor(self, fitness):  # Changed line\n        return self.spiral_factor * (1 + 0.1 * np.std(fitness))\n\n    def adaptive_crossover_rate(self, fitness):  # New line\n        return self.crossover_rate * (1 - 0.1 * np.std(fitness))\n", "name": "E_SADE", "description": "Enhanced differential evolution with adaptive spiral dynamics, dynamically adjusting spiral and crossover rates based on fitness variance for balanced exploration and exploitation.", "configspace": "", "generation": 9, "fitness": 0.9824507020457145, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.982 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "602af286-891c-4a0b-ae1b-22551d7a3061", "metadata": {"aucs": [0.9869394709224015, 0.9762073060601572, 0.9842053291545846], "final_y": [0.16485591019401213, 0.16485776196292756, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "ea08f75e-51d0-4071-8b90-6e1c85f474ef", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                # Enhanced mutation with mirroring\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.adaptive_crossover_rate(fitness), mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        # Introduced mirroring for periodicity\n        spiral_step = self.adaptive_spiral_factor(fitness) * (a - target) * (fitness[i] / (np.mean(fitness) + 1e-10))  \n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        mirrored_step = np.abs(diff) * periodic_factor  # New line\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step + mirrored_step  # Changed line\n        return mutant\n    \n    def adaptive_spiral_factor(self, fitness):\n        return self.spiral_factor * (1 + 0.1 * np.std(fitness))\n\n    def adaptive_crossover_rate(self, fitness):\n        return self.crossover_rate * (1 - 0.1 * np.std(fitness))", "name": "E_SADE", "description": "Enhanced adaptive differential evolution with periodic and mirrored mutation to improve convergence and solution robustness.", "configspace": "", "generation": 10, "fitness": 0.9636214979023733, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.031. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4cd564df-e073-44a2-a55d-7f9d03147a6f", "metadata": {"aucs": [0.9199190092315762, 0.986042890262635, 0.9849025942129086], "final_y": [0.16485645398941007, 0.16486412165138664, 0.16485664647425635]}, "mutation_prompt": null}
{"id": "477d74c4-1484-4b1b-a2f9-f836796f99eb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass Enhanced_E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n\n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.periodicity_induced_crossover_rate(i), mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.adaptive_spiral_factor(fitness) * (a - target) * (fitness[i] / (np.mean(fitness) + 1e-10))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant\n\n    def adaptive_spiral_factor(self, fitness):\n        return self.spiral_factor * (1 + 0.1 * np.std(fitness))\n\n    def periodicity_induced_crossover_rate(self, index):\n        return self.crossover_rate * (0.5 + 0.5 * np.cos(2 * np.pi * index / self.population_size))", "name": "Enhanced_E_SADE", "description": "Enhanced adaptive differential evolution with periodicity-induced crossover and localized spiral dynamics to improve global and local search balance.", "configspace": "", "generation": 10, "fitness": 0.9603051384432798, "feedback": "The algorithm Enhanced_E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4cd564df-e073-44a2-a55d-7f9d03147a6f", "metadata": {"aucs": [0.9600146674488329, 0.9542462603379069, 0.9666544875430992], "final_y": [0.1648561068190928, 0.16485641450279687, 0.16485815655640512]}, "mutation_prompt": null}
{"id": "52e3ba86-3345-4f5c-95ee-b9585bf3863d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                self.crossover_rate = 0.5 + 0.4 * np.std(fitness) / (np.mean(fitness) + 1e-10)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / (np.mean(fitness) + 1e-10))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor) * (1 + 0.5 * np.std(fitness) / (np.mean(fitness) + 1e-10))  # Changed line\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced exploration balance by dynamically adjusting scaling factor based on population diversity.", "configspace": "", "generation": 10, "fitness": 0.9820069507689918, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.982 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3a67f1f0-bf73-4d37-8fb9-048ec3379de6", "metadata": {"aucs": [0.9835771671639847, 0.9790876074021067, 0.9833560777408842], "final_y": [0.16485644213687645, 0.16485878725957492, 0.16485595866334302]}, "mutation_prompt": null}
{"id": "d1686efc-caef-46bf-b048-3aa2db3fb247", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n\n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                self.crossover_rate = 0.5 + 0.4 * np.std(fitness) / (np.mean(fitness) + 1e-10)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.adaptive_spiral_factor(fitness) * (a - target) * (fitness[i] / (np.mean(fitness) + 1e-10))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant\n\n    def adaptive_spiral_factor(self, fitness):\n        return self.spiral_factor * (1 + np.std(fitness) / (np.mean(fitness) + 1e-10))", "name": "E_SADE", "description": "Refined E_SADE introduces adaptive spiral factors based on fitness variance and implements oppositional strategies for balanced exploration and exploitation.", "configspace": "", "generation": 10, "fitness": 0.9783491791607801, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.978 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3a67f1f0-bf73-4d37-8fb9-048ec3379de6", "metadata": {"aucs": [0.9853130017762487, 0.9824251979968108, 0.9673093377092807], "final_y": [0.1648596535503951, 0.16485943016564053, 0.16485808774466426]}, "mutation_prompt": null}
{"id": "dec8bfad-78a7-431b-ac39-0fd10b8bab4b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                self.crossover_rate = 0.5 + 0.4 * np.std(fitness) / (np.mean(fitness) + 1e-10)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        self.spiral_factor = 0.22 + 0.1 * np.std(fitness) / (np.mean(fitness) + 1e-10)  # Changed line\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / (np.mean(fitness) + 1e-10))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced E_SADE by incorporating dynamic spiral factor adjustment based on the current population's diversity to improve solution convergence. ", "configspace": "", "generation": 10, "fitness": 0.9742782507180214, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3a67f1f0-bf73-4d37-8fb9-048ec3379de6", "metadata": {"aucs": [0.9685695936229336, 0.9721548160961627, 0.9821103424349682], "final_y": [0.164857029516828, 0.16485720211587374, 0.16485719672337795]}, "mutation_prompt": null}
{"id": "a7bd4065-c370-4cb4-8161-3b3e310289db", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            # Dynamic population resizing based on fitness variance\n            self.population_size = max(20, int(50 * (1 - np.std(fitness))))  # Changed line\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.adaptive_crossover_rate(fitness), mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.adaptive_spiral_factor(fitness) * (a - target) * (fitness[i] / (np.mean(fitness) + 1e-10))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant\n    \n    def adaptive_spiral_factor(self, fitness):\n        return self.spiral_factor * (1 + 0.1 * np.std(fitness))\n\n    def adaptive_crossover_rate(self, fitness):\n        return self.crossover_rate * (1 - 0.1 * np.std(fitness))", "name": "E_SADE", "description": "Enhanced differential evolution with adaptive spiral dynamics, introducing dynamic population resizing based on fitness variance to balance exploration and convergence.", "configspace": "", "generation": 10, "fitness": 0.9836266447914882, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.984 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4cd564df-e073-44a2-a55d-7f9d03147a6f", "metadata": {"aucs": [0.9835780038291632, 0.9815834635901425, 0.9857184669551586], "final_y": [0.16485678340475096, 0.16485668128919773, 0.16485615222557137]}, "mutation_prompt": null}
{"id": "8c76479d-4c11-4efb-bbf7-8afda99fb004", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                self.crossover_rate = 0.5 + 0.4 * np.std(fitness) / (np.mean(fitness) + 1e-10)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        self.spiral_factor = 0.22 * (0.5 + 0.5 * np.std(fitness) / (np.mean(fitness) + 1e-10))  # Changed line\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / (np.mean(fitness) + 1e-10))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced E_SADE by introducing a dynamic spiral factor adjustment based on current population diversity for improved exploration and convergence.", "configspace": "", "generation": 10, "fitness": 0.9852269474573182, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.985 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3a67f1f0-bf73-4d37-8fb9-048ec3379de6", "metadata": {"aucs": [0.9847247119235846, 0.9894947633179568, 0.9814613671304132], "final_y": [0.16486103758738557, 0.16485657457625258, 0.1648575774618567]}, "mutation_prompt": null}
{"id": "be22e595-276e-4fba-9e62-3648b9f0cac8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.diversity_driven_periodicity_mutation(pop[i], a, b, c, i, fitness)  # Changed line\n                trial = np.where(np.random.rand(self.dim) < self.adaptive_crossover_rate(fitness), mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def diversity_driven_periodicity_mutation(self, target, a, b, c, i, fitness):  # Changed line\n        diff = b - c\n        diversity_factor = np.std(fitness)  # New line\n        spiral_step = self.adaptive_spiral_factor(fitness) * (a - target) * (fitness[i] / (np.mean(fitness) + 1e-10))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step * (1 + diversity_factor)  # Changed line\n        return mutant\n    \n    def adaptive_spiral_factor(self, fitness): \n        return self.spiral_factor * (1 + 0.1 * np.std(fitness))\n\n    def adaptive_crossover_rate(self, fitness):\n        return self.crossover_rate * (1 - 0.1 * np.std(fitness))", "name": "E_SADE", "description": "Enhanced differential evolution with adaptive spiral dynamics and diversity-driven periodic enhancement to improve exploration and convergence.", "configspace": "", "generation": 10, "fitness": 0.9782754561140762, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.978 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4cd564df-e073-44a2-a55d-7f9d03147a6f", "metadata": {"aucs": [0.9689672633070292, 0.9852675729027557, 0.9805915321324434], "final_y": [0.16485952370997103, 0.1648563734462387, 0.16485777556160874]}, "mutation_prompt": null}
{"id": "9185754f-59e1-4533-984f-6806f4b7e85c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                fitness_median = np.median(fitness)  # Changed line\n                self.crossover_rate = 0.5 + 0.4 * np.std(fitness) / (fitness_median + 1e-10)\n                trial = np.where(np.random.rand(self.dim) < self.crossover_rate, mutant, pop[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.spiral_factor * (a - target) * (fitness[i] / (np.mean(fitness) + 1e-10))\n        periodic_factor = np.sin(2 * np.pi * i / self.population_size)\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant", "name": "E_SADE", "description": "Enhanced dynamic crossover rate by incorporating fitness variance relative to median for more robust exploration.", "configspace": "", "generation": 10, "fitness": 0.9653549829344475, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3a67f1f0-bf73-4d37-8fb9-048ec3379de6", "metadata": {"aucs": [0.9614006443161561, 0.9499997355431631, 0.9846645689440237], "final_y": [0.1648644461656814, 0.16485662868054918, 0.16485613926677423]}, "mutation_prompt": null}
{"id": "0986990d-02bf-48c5-9789-d53bce51dd02", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass E_SADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.scaling_factor = 0.5\n        self.crossover_rate = 0.9\n        self.spiral_factor = 0.22\n        self.func_evals = 0\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, self.dim))\n        fitness = np.apply_along_axis(func, 1, pop)\n        self.func_evals += self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        while self.func_evals < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = self.periodicity_guided_mutation(pop[i], a, b, c, i, fitness)\n                trial = np.where(np.random.rand(self.dim) < self.adaptive_crossover_rate(fitness), mutant, pop[i])  # Changed line\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                self.func_evals += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if self.func_evals >= self.budget:\n                    break\n\n            # Local search enhancement\n            if self.func_evals < self.budget:\n                res = minimize(func, best, bounds=bounds, method='L-BFGS-B')\n                if res.fun < fitness[best_idx]:\n                    best = res.x\n                    fitness[best_idx] = res.fun\n                    self.func_evals += res.nfev\n\n        return best\n\n    def periodicity_guided_mutation(self, target, a, b, c, i, fitness):\n        diff = b - c\n        spiral_step = self.adaptive_spiral_factor(fitness) * (a - target) * (fitness[i] / (np.mean(fitness) + 1e-10))  # Changed line\n        periodic_factor = np.sin(4 * np.pi * i / self.population_size)  # Modified periodicity frequency\n        adaptive_scaling = self.scaling_factor * (0.5 + 0.5 * periodic_factor)\n        mutant = target + adaptive_scaling * diff + spiral_step\n        return mutant\n    \n    def adaptive_spiral_factor(self, fitness):  # Unchanged line\n        return self.spiral_factor * (1 + 0.1 * np.std(fitness))\n\n    def adaptive_crossover_rate(self, fitness):  # New line\n        return self.crossover_rate * (1 - 0.2 * np.std(fitness))  # Increased sensitivity to fitness variance", "name": "E_SADE", "description": "Improved E_SADE by enhancing periodicity influence and making crossover more sensitive to fitness variance.", "configspace": "", "generation": 10, "fitness": 0.9797800048626147, "feedback": "The algorithm E_SADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.980 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4cd564df-e073-44a2-a55d-7f9d03147a6f", "metadata": {"aucs": [0.9852099864873323, 0.9669196374569281, 0.987210390643584], "final_y": [0.1648577686353283, 0.16485606049028734, 0.16485686374031894]}, "mutation_prompt": null}
