{"id": "f3740c86-546f-414c-8eb7-8bd84c95f519", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "2a95ce90-95ab-42e1-9d65-f66f57134bc6", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # changed line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                mutation_factor = 0.1 * np.random.randn(self.dim)  # new line\n                swarm[i] += self.velocity[i] + mutation_factor  # changed line\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations > self.budget // 2:  # new line\n                self.population_size = min(self.population_size + 1, 50)  # new line\n            \n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces dynamic population size adjustment and velocity mutation to improve exploration and convergence.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "f3740c86-546f-414c-8eb7-8bd84c95f519", "metadata": {}, "mutation_prompt": null}
{"id": "be6ddbbb-b1b3-4bf0-b8d4-d69c21576d39", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                if np.random.rand() < 0.1 * adaptive_factor:  # Adaptive mutation\n                    self.velocity[i] += np.random.normal(0, 0.1, self.dim)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive mutation to enhance exploration and prevent premature convergence.", "configspace": "", "generation": 1, "fitness": 0.822356010575655, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.016. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f3740c86-546f-414c-8eb7-8bd84c95f519", "metadata": {"aucs": [0.8002613609017455, 0.8275714557996189, 0.8392352150256004], "final_y": [0.1522350522030561, 0.1408164302849514, 0.14172925290574756]}, "mutation_prompt": null}
{"id": "4f8fbf20-fe6c-4283-96d8-58a7e980a6c8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 2.0  # Modified social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Added velocity clamping\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration and exploitation by adaptive coefficients and velocity clamping for improved convergence.", "configspace": "", "generation": 1, "fitness": 0.8487328595158697, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.025. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "f3740c86-546f-414c-8eb7-8bd84c95f519", "metadata": {"aucs": [0.8841745060908729, 0.8275232365591538, 0.8345008358975824], "final_y": [0.11363141983003822, 0.1372411810667068, 0.13367730172796233]}, "mutation_prompt": null}
{"id": "5036f9d3-f855-405d-96c0-d0ef6fd47d94", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Introduce local search for perturbation\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                local_search_pos = np.clip(swarm[i] + perturbation, lb, ub)\n                local_search_value = func(local_search_pos)\n                evaluations += 1\n                if local_search_value < f_value:\n                    swarm[i] = local_search_pos\n                    f_value = local_search_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrates local search with particle perturbation to enhance convergence speed and solution quality.", "configspace": "", "generation": 1, "fitness": 0.8119151885600774, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.031. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "f3740c86-546f-414c-8eb7-8bd84c95f519", "metadata": {"aucs": [0.7824046271914112, 0.7991010491666899, 0.8542398893221312], "final_y": [0.15110550819745772, 0.15005412520311456, 0.1269952019982169]}, "mutation_prompt": null}
{"id": "8cb3ea9c-97ca-46ba-8cfe-056451f87afb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * adaptive_factor  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive social coefficient to balance exploration and exploitation dynamically.", "configspace": "", "generation": 1, "fitness": 0.8291880931835149, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.031. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f3740c86-546f-414c-8eb7-8bd84c95f519", "metadata": {"aucs": [0.8502485356221686, 0.85142730069588, 0.7858884432324962], "final_y": [0.13522691232613704, 0.13255083554344793, 0.14798121012563703]}, "mutation_prompt": null}
{"id": "80e03c8a-9d82-4bb7-917c-3cc7a980861d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 2.0 * adaptive_factor  # Modified social coefficient to be adaptive\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Added velocity clamping\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive social coefficient for improved dynamic adjustment between exploration and exploitation.", "configspace": "", "generation": 2, "fitness": 0.8877893159300109, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.013. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "4f8fbf20-fe6c-4283-96d8-58a7e980a6c8", "metadata": {"aucs": [0.8800183308918113, 0.8775909530070135, 0.905758663891208], "final_y": [0.11907212262951816, 0.11838608569566211, 0.11621861400830069]}, "mutation_prompt": null}
{"id": "1979d7fa-658c-407f-a832-ba826cda1a25", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor  # Modified cognitive coefficient\n            social_coeff = 2.0\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Added velocity clamping\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incremental improvement through adaptive cognitive coefficient based on the iteration progress.", "configspace": "", "generation": 2, "fitness": 0.8796094706391981, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.013. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "4f8fbf20-fe6c-4283-96d8-58a7e980a6c8", "metadata": {"aucs": [0.8643815927128778, 0.8790549295488438, 0.8953918896558726], "final_y": [0.12286490678367556, 0.12204109587811907, 0.11565596096009456]}, "mutation_prompt": null}
{"id": "7fb822a8-b49a-4c41-a2cb-16a1628c9c42", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.noise_factor = 0.05 * (np.sqrt(dim))  # New noise factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 2.0\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += self.velocity[i]\n\n                # Introduce diversity with Gaussian noise\n                if np.random.rand() < adaptive_factor:\n                    swarm[i] += self.noise_factor * np.random.normal(size=self.dim)\n                \n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced a diversity-enhancing strategy using Gaussian noise and adaptive thresholds for improved convergence.", "configspace": "", "generation": 2, "fitness": 0.885694271437519, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.012. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "4f8fbf20-fe6c-4283-96d8-58a7e980a6c8", "metadata": {"aucs": [0.8698322725872589, 0.8996589363515904, 0.8875916053737075], "final_y": [0.11865874653330644, 0.11457745082167237, 0.11148035970234116]}, "mutation_prompt": null}
{"id": "d77f63c1-26b1-41d4-baaa-c3c8e9c19e69", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 2.0  # Modified social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                dynamic_clamp = 0.1 * (ub - lb) * adaptive_factor  # Dynamic velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -dynamic_clamp, dynamic_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced adaptive mechanism by introducing dynamic velocity clamping for better convergence.", "configspace": "", "generation": 2, "fitness": 0.8851026209706299, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.003. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "4f8fbf20-fe6c-4283-96d8-58a7e980a6c8", "metadata": {"aucs": [0.8816823927402522, 0.883944325122847, 0.8896811450487901], "final_y": [0.11703912137535499, 0.12080412362073079, 0.11857646062656602]}, "mutation_prompt": null}
{"id": "98dd94c4-7def-4be2-9d83-0fa08b3e2bfb", "solution": "# Description: Enhanced adaptive balance between exploration and exploitation by dynamic social coefficient.\n# Code:\nimport numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Modified to dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Added velocity clamping\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced adaptive balance between exploration and exploitation by dynamic social coefficient.", "configspace": "", "generation": 2, "fitness": 0.8885646131038344, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.016. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "4f8fbf20-fe6c-4283-96d8-58a7e980a6c8", "metadata": {"aucs": [0.8683479246217762, 0.8893567280438077, 0.9079891866459189], "final_y": [0.1254725355513453, 0.12165493617453915, 0.11440778051785516]}, "mutation_prompt": null}
{"id": "9379fac6-eb23-4854-b875-f18c9c089129", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Changed inertia weight schedule\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced adaptive balance between exploration and exploitation by dynamic social coefficient, with improved inertia weight scheduling.", "configspace": "", "generation": 3, "fitness": 0.9182350967340942, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.009. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "98dd94c4-7def-4be2-9d83-0fa08b3e2bfb", "metadata": {"aucs": [0.9212888645859408, 0.906525721504586, 0.9268907041117557], "final_y": [0.1126931558613875, 0.11573755431473454, 0.11005576100175485]}, "mutation_prompt": null}
{"id": "dfd2edd4-0c21-4ec3-a1f0-65f39589cebd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = (0.9 - 0.4 * adaptive_factor)  # Changed constant to dynamic inertia decay\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced adaptive balance between exploration and exploitation by inclusion of dynamic inertia decay.", "configspace": "", "generation": 3, "fitness": 0.914579792844678, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.011. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "98dd94c4-7def-4be2-9d83-0fa08b3e2bfb", "metadata": {"aucs": [0.8987143212336248, 0.9219451502971767, 0.9230799070032323], "final_y": [0.11710839403770823, 0.11229632147892332, 0.11181851297740297]}, "mutation_prompt": null}
{"id": "e5801735-813d-4908-8304-f4cc291dd41d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * adaptive_factor  # Changed line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = 0.8 * (inertia_weight * self.velocity[i] +  # Changed line\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved adaptive balance by introducing a dynamic inertia weight and velocity scaling factor.", "configspace": "", "generation": 3, "fitness": 0.9142658174253833, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.015. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "98dd94c4-7def-4be2-9d83-0fa08b3e2bfb", "metadata": {"aucs": [0.9202625894155169, 0.8931195508723585, 0.9294153119882744], "final_y": [0.11059663241229611, 0.12029640926230034, 0.11087551217044211]}, "mutation_prompt": null}
{"id": "562c80a7-9780-4e3f-9122-7b9ac061df62", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Modified to dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.2 * (ub - lb), 0.2 * (ub - lb))  # Updated velocity clamping\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced adaptive balance between exploration and exploitation by dynamic social coefficient and improved velocity update strategy.", "configspace": "", "generation": 3, "fitness": 0.9063578970367967, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.026. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "98dd94c4-7def-4be2-9d83-0fa08b3e2bfb", "metadata": {"aucs": [0.8719735420913863, 0.9117918366049543, 0.9353083124140492], "final_y": [0.12060747867250188, 0.11184355798342183, 0.11103944480542816]}, "mutation_prompt": null}
{"id": "84bdfb99-fd4a-4052-81c5-9c2842b9f90c", "solution": "# Description: Introduce dynamic inertia weight for enhanced exploration and exploitation balance.\n# Code:\nimport numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Changed to dynamic inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Modified to dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Added velocity clamping\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic inertia weight for enhanced exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.9237144613522079, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.009. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "98dd94c4-7def-4be2-9d83-0fa08b3e2bfb", "metadata": {"aucs": [0.9286183562425318, 0.9109065340561773, 0.9316184937579147], "final_y": [0.10976932025215724, 0.1162822807445465, 0.11010763272320323]}, "mutation_prompt": null}
{"id": "76c9cc05-af7d-408a-a96e-5f487bb1b646", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Changed to dynamic inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Modified to dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                velocity_clamp = 0.1 * adaptive_factor  # Adaptive velocity clamping\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp * (ub - lb), velocity_clamp * (ub - lb))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate adaptive velocity clamping to improve convergence stability.", "configspace": "", "generation": 4, "fitness": 0.9110590671044131, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.006. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "84bdfb99-fd4a-4052-81c5-9c2842b9f90c", "metadata": {"aucs": [0.906852839815245, 0.9192268230092204, 0.907097538488774], "final_y": [0.11710973613748399, 0.11323136255269572, 0.11727115531279464]}, "mutation_prompt": null}
{"id": "c467fda8-c08d-4cc3-a5c2-79046fc497bd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                # Adaptive mutation strategy\n                if np.random.rand() < 0.1 * adaptive_factor:  # Added mutation strategy\n                    swarm[i] += np.random.normal(0, 0.1 * (ub - lb), self.dim)  # Added mutation application\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive mutation strategy to enhance convergence speed and solution quality.", "configspace": "", "generation": 4, "fitness": 0.9056283688478347, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.016. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "84bdfb99-fd4a-4052-81c5-9c2842b9f90c", "metadata": {"aucs": [0.8853241203933876, 0.9081990464585532, 0.9233619396915635], "final_y": [0.11442139981299826, 0.11309072365564121, 0.1124718385729967]}, "mutation_prompt": null}
{"id": "0ce5e771-29d3-4857-8d56-52927f59c3bd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Changed to dynamic inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Modified to dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.01 * np.random.normal(size=self.dim))  # Added random mutation to velocity\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Added velocity clamping\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a small random mutation to the velocity update to enhance exploration capabilities.", "configspace": "", "generation": 4, "fitness": 0.9145213169355572, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.006. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "84bdfb99-fd4a-4052-81c5-9c2842b9f90c", "metadata": {"aucs": [0.9060783205766183, 0.9180726691486899, 0.9194129610813633], "final_y": [0.11460606353969782, 0.1137069368271999, 0.11140009931786699]}, "mutation_prompt": null}
{"id": "ab5a928d-ce1b-4a6d-b3cc-554d0b09fa65", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += self.velocity[i]\n                \n                # Enhanced mutation for local search\n                mutation_strength = 0.05 * adaptive_factor\n                swarm[i] += mutation_strength * np.random.randn(self.dim)\n                \n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance local search through hybrid mutation operator for improved convergence.", "configspace": "", "generation": 4, "fitness": 0.9082844297798346, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.015. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "84bdfb99-fd4a-4052-81c5-9c2842b9f90c", "metadata": {"aucs": [0.8997451940266551, 0.8956970229192407, 0.9294110723936079], "final_y": [0.11700343046702821, 0.11973259831683425, 0.11153862166787543]}, "mutation_prompt": null}
{"id": "642e09e6-adda-47df-b0e7-da7bab752ec8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Changed to dynamic inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = (1.5 + 0.5 * adaptive_factor) * (1 - adaptive_factor)  # Added decay factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Added velocity clamping\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate a decay factor in social coefficient to enhance convergence in later stages.", "configspace": "", "generation": 4, "fitness": 0.8939689004609127, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.020. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "84bdfb99-fd4a-4052-81c5-9c2842b9f90c", "metadata": {"aucs": [0.8663713081399711, 0.9042060294617306, 0.9113293637810366], "final_y": [0.11209714884302246, 0.11725460225864404, 0.11461728208897437]}, "mutation_prompt": null}
{"id": "7234fd56-165c-4c4d-995a-bc7671e70327", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor  # Modified to adaptive cognitive coefficient\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive cognitive coefficient for refined exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.9099329273493795, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.015. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "84bdfb99-fd4a-4052-81c5-9c2842b9f90c", "metadata": {"aucs": [0.9075514770159191, 0.8934442015419557, 0.9288031034902637], "final_y": [0.11706071808688046, 0.1214895490676946, 0.11025892468658116]}, "mutation_prompt": null}
{"id": "f3375641-8404-485d-9e3d-2065d456cb8a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Changed to dynamic inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Modified to dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb) * adaptive_factor, 0.1 * (ub - lb) * adaptive_factor)  # Added velocity clamping\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic self-adaptive boundary scaling for improved convergence.", "configspace": "", "generation": 5, "fitness": 0.9099947934685447, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.021. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "84bdfb99-fd4a-4052-81c5-9c2842b9f90c", "metadata": {"aucs": [0.8810176374422467, 0.9196458564636452, 0.9293208864997424], "final_y": [0.12362590907475057, 0.11264963020106789, 0.11055612605515241]}, "mutation_prompt": null}
{"id": "fb8ac594-7a9c-4f64-a84a-8349fabb6cec", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor  # Modified to dynamic cognitive coefficient\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Implement a dynamic cognitive coefficient for improved adaptation to exploitation levels.", "configspace": "", "generation": 5, "fitness": 0.9154833101979051, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.008. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "84bdfb99-fd4a-4052-81c5-9c2842b9f90c", "metadata": {"aucs": [0.9049243028659397, 0.918316309630392, 0.9232093180973833], "final_y": [0.11719947964877864, 0.11292732204519906, 0.110764657935145]}, "mutation_prompt": null}
{"id": "940b9948-91a1-4216-8d77-7b5ae9e26c91", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Changed to dynamic inertia weight\n            learning_factor = 1 + 0.5 * adaptive_factor  # Introduce dynamic learning factor\n            cognitive_coeff = 1.5 * learning_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Modified to dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Added velocity clamping\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate a dynamic learning factor to enhance convergence speed and solution accuracy.", "configspace": "", "generation": 5, "fitness": 0.9092474271747154, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.012. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "84bdfb99-fd4a-4052-81c5-9c2842b9f90c", "metadata": {"aucs": [0.9164850857768942, 0.8917677291241126, 0.9194894666231392], "final_y": [0.11218188365485582, 0.12032766865850908, 0.11279847539839216]}, "mutation_prompt": null}
{"id": "8e5e765f-b12f-40a0-a03f-7cb5c8f64aaf", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Changed to dynamic inertia weight\n            cognitive_coeff = 2.0 - 0.5 * adaptive_factor  # Modified to time-varying cognitive coefficient\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Modified to dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Added velocity clamping\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance global convergence by introducing a time-varying cognitive coefficient.", "configspace": "", "generation": 5, "fitness": 0.9098901025803093, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.014. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "84bdfb99-fd4a-4052-81c5-9c2842b9f90c", "metadata": {"aucs": [0.9254075883424737, 0.8914569812755643, 0.9128057381228901], "final_y": [0.1106914052841047, 0.12147400322098645, 0.11716808378284116]}, "mutation_prompt": null}
{"id": "cf25d448-6db2-48e1-9652-f5a813d45ba3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)  # Modified cognitive coefficient\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive learning rates for enhanced solution diversity and convergence speed.", "configspace": "", "generation": 6, "fitness": 0.9194389740828416, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.003. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "84bdfb99-fd4a-4052-81c5-9c2842b9f90c", "metadata": {"aucs": [0.9229391813483309, 0.9201740728352477, 0.9152036680649464], "final_y": [0.11289472927594568, 0.11219752031370267, 0.11010770561038585]}, "mutation_prompt": null}
{"id": "41051a6e-ebdc-478a-9597-30d9086274fc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  \n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive learning rate for enhanced convergence speed.", "configspace": "", "generation": 6, "fitness": 0.9245764714500625, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.006. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "84bdfb99-fd4a-4052-81c5-9c2842b9f90c", "metadata": {"aucs": [0.9180323749490782, 0.9232959085378852, 0.9324011308632238], "final_y": [0.11037603012088781, 0.11319561984653903, 0.10993847263023471]}, "mutation_prompt": null}
{"id": "c7ce0455-928e-4588-b159-36b959e4f2ef", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                learning_rate = 1.0 - (global_best_value / (1.0 + np.abs(global_best_value)))  # Self-adaptive learning rate\n                self.velocity[i] = learning_rate * np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce self-adaptive learning rates for improved convergence speed.", "configspace": "", "generation": 6, "fitness": 0.887123129132395, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.038. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "84bdfb99-fd4a-4052-81c5-9c2842b9f90c", "metadata": {"aucs": [0.8333708881199478, 0.9090982044064375, 0.9189002948708], "final_y": [0.13966190649950638, 0.11564631959661598, 0.11323396881083381]}, "mutation_prompt": null}
{"id": "ec640e8a-7c6c-4673-8cab-1ae77b287bd6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Changed to dynamic inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Modified to dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Added velocity clamping\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Introduce adaptive learning rate based on convergence speed\n            if np.std(personal_best_value) < 0.01:\n                inertia_weight *= 0.95\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive learning rate based on convergence speed to improve solution refinement.", "configspace": "", "generation": 6, "fitness": 0.9099709695305558, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.012. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "84bdfb99-fd4a-4052-81c5-9c2842b9f90c", "metadata": {"aucs": [0.917559508677214, 0.8927575626372024, 0.9195958372772507], "final_y": [0.10984805568968992, 0.12047517206233715, 0.11364674681154807]}, "mutation_prompt": null}
{"id": "8e8a95d1-7292-4b98-ab42-2a8532bf035b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Changed to dynamic inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Modified to dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  # Added velocity clamping\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Competitive learning: reinitialize worst performing particles\n            worst_indices = np.argsort(personal_best_value)[-int(0.1 * self.population_size):]\n            for idx in worst_indices:\n                swarm[idx] = np.random.uniform(lb, ub, self.dim)\n                personal_best[idx] = swarm[idx]\n                personal_best_value[idx] = func(swarm[idx])\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce competitive learning for improved convergence in dynamic environments.", "configspace": "", "generation": 6, "fitness": 0.913879998615025, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "84bdfb99-fd4a-4052-81c5-9c2842b9f90c", "metadata": {"aucs": [0.9104044380325471, 0.9023416687613024, 0.9288938890512255], "final_y": [0.11127649062561129, 0.1165944453941129, 0.11106060057582356]}, "mutation_prompt": null}
{"id": "73e749b1-5a0f-4d37-b317-6f9999c516c1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  \n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n            self.population_size = int((10 + 2 * int(np.sqrt(self.dim))) * (1 + 0.1 * adaptive_factor))  # Dynamic swarm size\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic swarm size for enhanced exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "41051a6e-ebdc-478a-9597-30d9086274fc", "metadata": {}, "mutation_prompt": null}
{"id": "cd30e195-d9c5-49d6-a4ff-21ddcefb6275", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.2 * adaptive_factor  # Enhanced adaptive inertia\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            # Dynamic adjustment of population size\n            self.population_size = min(self.population_size + 1, 50)\n            swarm = np.resize(swarm, (self.population_size, self.dim))\n            self.velocity = np.resize(self.velocity, (self.population_size, self.dim))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic population size and enhanced adaptive inertia for improved exploration-exploitation balance.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "41051a6e-ebdc-478a-9597-30d9086274fc", "metadata": {}, "mutation_prompt": null}
{"id": "6d851b7c-e98d-47c4-add0-0994525a074d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 * adaptive_factor**2  # Dynamic scaling of inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Implement a dynamic scaling of the inertia weight for improved balance between exploration and exploitation.", "configspace": "", "generation": 7, "fitness": 0.915626297945574, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "41051a6e-ebdc-478a-9597-30d9086274fc", "metadata": {"aucs": [0.9243355793708835, 0.9218234731859645, 0.9007198412798744], "final_y": [0.11114846509760379, 0.11289107804446763, 0.11433121240193522]}, "mutation_prompt": null}
{"id": "ff7437a4-c4e4-47ca-8e2e-aa67ea9607c4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  \n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0 and self.population_size > 10:  # Reduce population size dynamically\n                self.population_size -= 1\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic population size reduction to enhance exploration-exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.8998798360250183, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.033. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "41051a6e-ebdc-478a-9597-30d9086274fc", "metadata": {"aucs": [0.8539507672650716, 0.9141271442540246, 0.9315615965559587], "final_y": [0.1305488259053489, 0.1134806156254522, 0.11138521752693886]}, "mutation_prompt": null}
{"id": "14ae60a6-229a-4271-8821-cad16da13c1f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by modifying the inertia weight formula for better convergence.", "configspace": "", "generation": 7, "fitness": 0.9246355787984926, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.009. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "41051a6e-ebdc-478a-9597-30d9086274fc", "metadata": {"aucs": [0.9135715736300493, 0.9254879566350951, 0.9348472061303332], "final_y": [0.11145060623629854, 0.11212715270906926, 0.10984715833375291]}, "mutation_prompt": null}
{"id": "164eac1e-858e-4073-b0b3-523f970505d1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n            \n            # Dynamically adjust population size\n            self.population_size = int(10 + adaptive_factor * 5 * np.sqrt(self.dim))\n            swarm = np.vstack((swarm, np.random.uniform(lb, ub, (self.population_size - len(swarm), self.dim))))\n            self.velocity = np.vstack((self.velocity, np.zeros((self.population_size - len(self.velocity), self.dim))))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive population size to balance exploration and exploitation dynamically.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {}, "mutation_prompt": null}
{"id": "47c2463f-4da9-4d92-995c-3054df2fab3b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * adaptive_factor * (ub - lb), 0.1 * adaptive_factor * (ub - lb))  # Adaptive velocity clipping\n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine velocity clipping to be adaptive based on the current evaluation stage for enhanced exploration.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {}, "mutation_prompt": null}
{"id": "49385aab-866b-4efb-b4fd-b17a44db650b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = (1 - (evaluations / self.budget) ** 2)  # Nonlinear decay in adaptive factor\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.2 * (ub - lb), 0.2 * (ub - lb))  # Enhanced clamping\n                swarm[i] += learning_rate * self.velocity[i]  \n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improve convergence by introducing a nonlinear decay in adaptive factors and enhancing velocity clamping.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {}, "mutation_prompt": null}
{"id": "1faaea6d-6baa-4c2d-aeac-198ee0512597", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor \n            velocity_scaling = 0.1 + 0.4 * adaptive_factor  # New adaptive velocity scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_scaling * (ub - lb), velocity_scaling * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Enhanced survival selection: Retain top performers\n            sort_indices = np.argsort(personal_best_value)\n            swarm = personal_best[sort_indices[:self.population_size]]  # Retain top solutions\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive velocity scaling and enhanced survival selection to improve convergence.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {}, "mutation_prompt": null}
{"id": "0a775e39-f51c-466d-b396-8bf974ac8db4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget)**2  # Use a nonlinear time-varying factor\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a nonlinear time-varying inertia weight to balance exploration and exploitation more effectively.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {}, "mutation_prompt": null}
{"id": "72ba38f0-10be-45f6-b031-6bf19c8a45a2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * (1 + 0.5 * adaptive_factor)  # Dynamic adjustment of cognitive coefficient\n            social_coeff = 1.5 * (1 + 0.5 * adaptive_factor)  # Dynamic adjustment of social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic adjustment of cognitive and social coefficients for enhanced exploration and convergence.", "configspace": "", "generation": 9, "fitness": 0.8929457747599358, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.020. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9154380462357244, 0.8660731169618122, 0.8973261610822706], "final_y": [0.11239843924924042, 0.115525689917793, 0.10981984624144703]}, "mutation_prompt": null}
{"id": "65142aed-1b36-4157-adf9-80ce00e5973e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor ** 2  # Nonlinear adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce nonlinear adaptive learning rate to improve convergence speed.", "configspace": "", "generation": 9, "fitness": 0.8923499086471526, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.004. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8967424540794736, 0.8932773225288477, 0.8870299493331365], "final_y": [0.11987815160948911, 0.11188337225809686, 0.10980879170606739]}, "mutation_prompt": null}
{"id": "ffa5a2a4-12be-4eee-b642-ada7d043b4eb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 * (0.9 - 0.5 * adaptive_factor)  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)  # Modify cognitive coefficient\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce inertia weight decay and dynamic cognitive-social balance for enhanced convergence.", "configspace": "", "generation": 9, "fitness": 0.8791387000581509, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.005. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8789272384257586, 0.8733677835579712, 0.8851210781907232], "final_y": [0.12286522416274215, 0.11210667429925092, 0.11009237512226688]}, "mutation_prompt": null}
{"id": "510de5e7-ce0c-431a-ab47-a65723d57767", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted inertia weight formula\n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor  # Dynamic cognitive coefficient\n            social_coeff = 1.5 + 1.0 * adaptive_factor  # Dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive inertia weight and dynamic social cognitive coefficients for improved swarm coordination.", "configspace": "", "generation": 9, "fitness": 0.8867088710988638, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.026. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9224339349274137, 0.8732786862719341, 0.8644139920972436], "final_y": [0.11006032193960269, 0.11686324402171455, 0.11018875061779643]}, "mutation_prompt": null}
{"id": "b3435a3c-6dff-4e95-b111-ba8319775bc9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neigh_size = max(2, self.population_size // 5)  # Define a neighborhood size\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjust inertia weight formula\n            cognitive_coeff = 1.7 * adaptive_factor\n            social_coeff = 1.3 + 0.7 * adaptive_factor  \n\n            for i in range(self.population_size):\n                # Dynamic neighborhood topology\n                neighbors_idx = np.random.choice(self.population_size, self.neigh_size, replace=False)\n                neighborhood_best = personal_best[neighbors_idx[np.argmin(personal_best_value[neighbors_idx])]]\n                \n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                mutation_coeff = 0.1 * adaptive_factor  # Introduce adaptive mutation\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (neighborhood_best - swarm[i]) +\n                                    mutation_coeff * r3 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += 0.5 * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate diversity promotion and enhanced convergence by using dynamic neighborhood topology and adaptive mutation.", "configspace": "", "generation": 9, "fitness": 0.8636352454154567, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.021. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8347065486383356, 0.8705825756327906, 0.8856166119752433], "final_y": [0.12724665961963133, 0.1175828082600372, 0.11078168719655779]}, "mutation_prompt": null}
{"id": "4958e2ed-3ee1-40a4-b07e-7550372d69b4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 2.0 + 0.5 * adaptive_factor  # Modified social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic adjustment to the social coefficient for improved global exploration.", "configspace": "", "generation": 10, "fitness": 0.9209040672817009, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.014. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9252653377168836, 0.9022011251322697, 0.9352457389959494], "final_y": [0.1098837960982395, 0.11516870025929982, 0.10991681236866291]}, "mutation_prompt": null}
{"id": "ee67f95d-8a58-4c49-99d4-69f5dc0eb240", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        elite_member = global_best  # Introduce elite_member\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (elite_member - swarm[i]))  # Use elite_member\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best and elite member\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    elite_member = swarm[i]  # Update elite_member\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce elite selection to improve convergence by tracking an elite member in the swarm.", "configspace": "", "generation": 10, "fitness": 0.9166299322000482, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.016. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8948295776176803, 0.9240446622202433, 0.9310155567622209], "final_y": [0.12092571224013249, 0.11167312745083113, 0.11162340254923153]}, "mutation_prompt": null}
{"id": "b2abeb35-ac67-4f6a-a7a4-bb7d87fa2b43", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = (1.5 + 0.5 * adaptive_factor) * adaptive_factor  # Introduce decay factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a decay factor to the social coefficient for improved balance between exploration and exploitation.", "configspace": "", "generation": 10, "fitness": 0.9222734345835942, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.005. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9222212188415662, 0.9156673085296186, 0.9289317763795978], "final_y": [0.11015854181149953, 0.11211840744764434, 0.11009278294943425]}, "mutation_prompt": null}
{"id": "3e4a9f13-5c64-4e1d-b877-52d816fb7e4f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + adaptive_factor  # Changed line: Adjusted social coefficient scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive social coefficient scaling to enhance convergence.", "configspace": "", "generation": 10, "fitness": 0.8851419050561139, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.038. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8308728982007612, 0.9103428780358513, 0.914209938931729], "final_y": [0.14041773976582772, 0.11442040296022837, 0.11241923473069138]}, "mutation_prompt": null}
{"id": "ca9d3e82-8793-4442-9a57-290e9907ec7a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Modified inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 2.0 - 0.5 * adaptive_factor  \n\n            neighborhood_radius = 0.1 * adaptive_factor  # New dynamic neighborhood search parameter\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # New adaptive mutation strategy\n                if np.random.rand() < adaptive_factor:\n                    mutation_vector = np.random.uniform(-neighborhood_radius, neighborhood_radius, self.dim)\n                    swarm[i] += mutation_vector\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic neighborhood search and adaptive mutation strategy to enhance exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.8889758633675245, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.043. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8310622530107945, 0.9011796332098525, 0.9346857038819268], "final_y": [0.13993773065607318, 0.11625323326926451, 0.1097427916068523]}, "mutation_prompt": null}
{"id": "fe991e92-d35c-4dbd-9dd2-5bb2f250a3b1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * (1 - adaptive_factor)  # Change line\n            social_coeff = 2.0 - 0.5 * adaptive_factor  # Change line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2**2 * (global_best - swarm[i]))  # Change line\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic social and cognitive coefficients along with a novel velocity update strategy for enhanced convergence.", "configspace": "", "generation": 11, "fitness": 0.8816584112402461, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.036. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8310517073060251, 0.9040612271853574, 0.9098622992293559], "final_y": [0.13455643912479498, 0.1137907199254452, 0.11166592703483547]}, "mutation_prompt": null}
{"id": "b039be84-76fb-4f0b-807a-02c8c00da7c8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb + adaptive_factor * (ub - lb) / 2, ub - adaptive_factor * (ub - lb) / 2)  # Adaptive boundary shrinkage\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive boundary shrinkage mechanism to improve convergence speed.", "configspace": "", "generation": 11, "fitness": 0.8707277191138036, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.053. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8004817422774241, 0.8838764708040863, 0.9278249442599007], "final_y": [0.11527861514961191, 0.11693796810410517, 0.11003552701555497]}, "mutation_prompt": null}
{"id": "0f24c42d-6212-4605-b935-a97d0c38e129", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n            \n            self.population_size = 10 + int(adaptive_factor * (2 * np.sqrt(self.dim)))  # Dynamic population size\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic population size adjustment to adapt exploration and exploitation over time for improved convergence.", "configspace": "", "generation": 11, "fitness": 0.917729198769084, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.010. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9276809154932152, 0.9048167366416848, 0.920689944172352], "final_y": [0.11011663293147889, 0.1165563102319197, 0.10980628951798654]}, "mutation_prompt": null}
{"id": "7f82b6f5-793d-428c-84d2-18d4b8f89483", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 1.0 * adaptive_factor  # Change social coefficient to be more dynamic\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine particle movement by introducing a dynamic social coefficient to enhance convergence.", "configspace": "", "generation": 11, "fitness": 0.9136092742900092, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.006. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9181070921312952, 0.904952359009014, 0.9177683717297181], "final_y": [0.11027779552455053, 0.11627779417822048, 0.11390872891427428]}, "mutation_prompt": null}
{"id": "c453518a-3922-470b-9484-ddd0977c20e5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  \n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor  # Introduce dynamic cognitive coefficient\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  \n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic cognitive coefficient for improved solution refinement in AdaptiveSwarmGradientDescent.", "configspace": "", "generation": 11, "fitness": 0.8942730253251061, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.015. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.882414791564093, 0.9157856806404465, 0.8846186037707788], "final_y": [0.12357559131568141, 0.1125156879772985, 0.11790404949166766]}, "mutation_prompt": null}
{"id": "e0747862-85e1-479b-940f-be711472f787", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Probabilistic restart mechanism\n                if np.random.random() < 0.01:  \n                    global_best = np.random.uniform(lb, ub, self.dim)  \n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate diversity improvement by updating global best with a probabilistic restart mechanism to avoid stagnation.", "configspace": "", "generation": 12, "fitness": 0.8218857815757689, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.010. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8150006571244535, 0.8355503377492435, 0.8151063498536097], "final_y": [0.15056264864922075, 0.1344024172224525, 0.1324489302114703]}, "mutation_prompt": null}
{"id": "9e563067-2170-460d-a9bd-99fbbb2cd097", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.7 + 0.3 * adaptive_factor  # Adjust learning rate formula\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by adjusting the learning rate formula for faster adaptation.", "configspace": "", "generation": 12, "fitness": 0.8557986244917318, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.028. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8273974529962744, 0.8455014244182011, 0.8944969960607201], "final_y": [0.13956640928614805, 0.13777843152740543, 0.12031382491551623]}, "mutation_prompt": null}
{"id": "c494a07c-de7f-49c0-9d9f-be647ff1ceb0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.2 + 0.8 * adaptive_factor  # Adjust social coefficient range\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by dynamically adjusting social coefficient range for better global exploration.", "configspace": "", "generation": 12, "fitness": 0.8859654094782402, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.024. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8953730176032801, 0.8523939520466123, 0.9101292587848282], "final_y": [0.11988734160089132, 0.1384643126804227, 0.11849284055659937]}, "mutation_prompt": null}
{"id": "68d2de8a-b691-4c49-9ba6-d56de02bd17c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * (adaptive_factor ** 1.5)  # Introduce nonlinear adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a nonlinear adaptive learning rate to improve exploration and convergence.", "configspace": "", "generation": 12, "fitness": 0.9037800228400447, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.018. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9100571890454983, 0.9220687662007448, 0.879214113273891], "final_y": [0.11538447411941788, 0.11286740043879429, 0.1200002094511885]}, "mutation_prompt": null}
{"id": "7422c0af-24ad-4258-96fb-07f3380ddc6f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * (adaptive_factor ** 2)  # Nonlinear adaptive learning rate\n                velocity_scaling = 0.1 + 0.9 * (adaptive_factor ** 2)  # Nonlinear velocity scaling\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_scaling * (ub - lb), velocity_scaling * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a nonlinear adaptive learning rate and velocity scaling to improve convergence.", "configspace": "", "generation": 12, "fitness": 0.8489612593403871, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.061. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8632378585858088, 0.9151956263231009, 0.7684502931122517], "final_y": [0.1298562570527655, 0.11676170898135751, 0.15050322535154703]}, "mutation_prompt": null}
{"id": "0d1626f8-fc48-4a62-9715-d2a9c3f3bde5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                \n                # Introduce adaptive neighborhood search radius\n                neighborhood_radius = 0.05 * (ub - lb) * adaptive_factor\n                swarm[i] += np.random.uniform(-neighborhood_radius, neighborhood_radius, self.dim)\n                \n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive neighborhood search radius to enhance local exploration and convergence.", "configspace": "", "generation": 13, "fitness": 0.9055807496494136, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.015. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9191635934340971, 0.8842512517518429, 0.9133274037623007], "final_y": [0.1103208378333862, 0.12404503690424995, 0.11382201401781578]}, "mutation_prompt": null}
{"id": "c911be0c-5878-4cc5-9842-7eb65562cf19", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= 0.99  # Introduce velocity decay\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce velocity decay to improve convergence efficiency and solution stability.", "configspace": "", "generation": 13, "fitness": 0.9076263228865517, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.013. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9009685861839904, 0.8955181747026089, 0.9263922077730555], "final_y": [0.11700238293255738, 0.11544944422833137, 0.10982600187504099]}, "mutation_prompt": null}
{"id": "0ce97e11-0b8b-441d-90ee-923fb8b9c5f1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                crossover_rate = 0.5 + 0.4 * adaptive_factor  # Introduce adaptive crossover rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive crossover rate to balance exploration and exploitation.", "configspace": "", "generation": 13, "fitness": 0.9131523247780248, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.008. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9163154630920557, 0.902480605035196, 0.9206609062068228], "final_y": [0.11040671198537777, 0.11628811851584764, 0.11243778810978444]}, "mutation_prompt": null}
{"id": "8935c4d5-5000-4fe3-93df-92c9aedc080d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Introduce adaptive social convergence\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive social convergence to better refine exploration-exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.9037257467966685, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.005. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9023723075858244, 0.8980549371056785, 0.9107499956985023], "final_y": [0.11853037831422164, 0.12013288793575327, 0.11126067459320432]}, "mutation_prompt": null}
{"id": "81c10a8c-5bf8-423b-b78c-3502dff57864", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        \n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  \n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  \n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Differential local search strategy\n                if np.random.rand() < 0.3:  # Apply local search with certain probability\n                    idxs = np.random.choice(self.population_size, 3, replace=False)\n                    donor = personal_best[idxs[0]] + 0.8 * (personal_best[idxs[1]] - personal_best[idxs[2]])\n                    donor = np.clip(donor, lb, ub)\n                    f_donor = func(donor)\n                    evaluations += 1\n                    if f_donor < personal_best_value[i]:\n                        personal_best[i] = donor\n                        personal_best_value[i] = f_donor\n\n                f_value = func(swarm[i])  \n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce local search with differential strategy to enhance convergence and exploration balance.", "configspace": "", "generation": 13, "fitness": 0.8818801714022388, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.040. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8255574018642152, 0.916292706569604, 0.9037904057728973], "final_y": [0.13976453495737207, 0.11180032783923433, 0.1140784122475268]}, "mutation_prompt": null}
{"id": "a3ea8bfe-8c71-4a5f-b259-4b84989870e2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  \n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor  # Changed line\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  \n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic cognitive and social coefficients for enhanced convergence control.", "configspace": "", "generation": 14, "fitness": 0.9169807763768115, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.009. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9248995645505654, 0.9038398064992109, 0.9222029580806582], "final_y": [0.10974968970246757, 0.11654178216262712, 0.11030963061790067]}, "mutation_prompt": null}
{"id": "53d81a57-6490-4e01-b2a6-2c433e44d64b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor**2  # Nonlinear adjustment\n            social_coeff = 1.5 + 0.5 * np.sin(adaptive_factor * np.pi)  # Sinusoidal adjustment\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                mutation = np.random.normal(0, 0.01, self.dim) * adaptive_factor  # Enhanced local search\n                swarm[i] += learning_rate * self.velocity[i] + mutation  # Apply mutation\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce nonlinear adaptive coefficients and enhanced local search through mutation for improved convergence.", "configspace": "", "generation": 14, "fitness": 0.9077712988477176, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.007. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.901277423464296, 0.9173829223977772, 0.9046535506810796], "final_y": [0.11572347460458388, 0.11236387431781059, 0.11835466278736717]}, "mutation_prompt": null}
{"id": "87abcf65-c40e-4d31-933e-72f3edb8377c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 2.0 * (adaptive_factor ** 2)  # Nonlinear adjustment\n            social_coeff = 1.5 + (0.5 * adaptive_factor ** 3)  # Nonlinear adjustment\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by introducing nonlinear adjustments to the cognitive and social coefficients.", "configspace": "", "generation": 14, "fitness": 0.901525863885774, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.028. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8650369637417266, 0.9058647656205884, 0.9336758622950073], "final_y": [0.12616049611339708, 0.117151060313191, 0.1102587352062272]}, "mutation_prompt": null}
{"id": "4798a40c-6a02-4f7d-8e82-c458299c9a89", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            diversity = np.std(swarm, axis=0).mean() / (ub - lb).mean()  # Measure diversity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + diversity)  # Adjust cognitive coeff\n            social_coeff = 1.5 + 0.5 * adaptive_factor * (1 - diversity)  # Adjust social coeff\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic adjustment of cognitive and social coefficients based on the swarm's diversity.", "configspace": "", "generation": 14, "fitness": 0.9055994508725242, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.002. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.905442150129704, 0.9086767693746488, 0.9026794331132201], "final_y": [0.11697035774334275, 0.11364275343548358, 0.11826854865421577]}, "mutation_prompt": null}
{"id": "b4d71a8b-170a-4530-a2da-1969b660473b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            diversity = np.mean(np.linalg.norm(swarm - np.mean(swarm, axis=0), axis=1))  # Calculate swarm diversity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + diversity)  # Dynamic adjustment based on diversity\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic adjustment of cognitive and social coefficients based on swarm diversity.", "configspace": "", "generation": 14, "fitness": 0.9103907199372286, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.012. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8981714139324627, 0.9056753292618213, 0.9273254166174021], "final_y": [0.11703651957367056, 0.11624831367357102, 0.1112458243450215]}, "mutation_prompt": null}
{"id": "361e1f68-edf8-4e53-b382-7fbdf1944da2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Adaptive local search step\n                local_search_step = (global_best - swarm[i]) * 0.1 * adaptive_factor\n                swarm[i] += local_search_step\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence efficiency by integrating an adaptive local search step.", "configspace": "", "generation": 15, "fitness": 0.9158449335649719, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.023. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8840439513101136, 0.9263206523708148, 0.9371701970139872], "final_y": [0.12425450770070778, 0.11165538857227864, 0.10967708820673983]}, "mutation_prompt": null}
{"id": "8bf379df-f277-4e7e-b64d-4d945030e844", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  \n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor  # Adjusted for better exploration\n            social_coeff = 1.5 * adaptive_factor  # Adjusted for better exploitation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.05 * (ub - lb), 0.05 * (ub - lb))  # Tighter velocity constraint\n                swarm[i] += learning_rate * self.velocity[i]  \n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic social-cognitive balance and improved velocity constraint to enhance convergence.", "configspace": "", "generation": 15, "fitness": 0.8992059600798044, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.006. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8954211991967442, 0.8948282425486547, 0.9073684384940142], "final_y": [0.11708101365766066, 0.12133820719578081, 0.11706349146074113]}, "mutation_prompt": null}
{"id": "5eee0627-ae1c-4b03-bfa0-8fcf60da7827", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n            \n            dynamic_pop_size = int(self.population_size * adaptive_factor) + 1  # Dynamic population size\n\n            for i in range(self.population_size):\n                if i < dynamic_pop_size:  # Apply only to dynamic population\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    learning_rate = 0.5 + 0.5 * adaptive_factor\n\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                    swarm[i] += learning_rate * self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                    if evaluations >= self.budget:\n                        break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic population sizing to improve convergence speed and solution quality.", "configspace": "", "generation": 15, "fitness": 0.9131300760721711, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.020. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8846502446131571, 0.9236992657321444, 0.9310407178712121], "final_y": [0.1237375064715156, 0.11222053946053745, 0.11009490042623216]}, "mutation_prompt": null}
{"id": "d8c257c3-9729-4dfd-b67f-13b3c52f2a6d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor * np.exp(-0.01 * evaluations)  # Introduce decay function\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a decay function for learning rate to gradually reduce its impact over iterations.", "configspace": "", "generation": 15, "fitness": 0.9146077973812351, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.018. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8897240954183848, 0.9208667216337155, 0.9332325750916052], "final_y": [0.11748015175289894, 0.11209713506703511, 0.10993868296368403]}, "mutation_prompt": null}
{"id": "3a148d34-467d-4392-b4b1-6bf16d5dd8c8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n\n            dynamic_population_size = max(5, int(self.population_size * adaptive_factor)) # Dynamic resizing\n\n            for i in range(dynamic_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                velocity_clamp = 0.1 * (ub - lb) * adaptive_factor  # Adaptive clamping\n                self.velocity[i] = np.clip(self.velocity[i], \n                                           -velocity_clamp, velocity_clamp)\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate dynamic population resizing and adaptive velocity clamping for enhanced convergence.", "configspace": "", "generation": 15, "fitness": 0.9153158036354335, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.011. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9045309811600235, 0.9312377550026221, 0.9101786747436551], "final_y": [0.11239300254348894, 0.10988179247581797, 0.11380508760470864]}, "mutation_prompt": null}
{"id": "b070a69d-58ef-4968-b7a2-a42b8c62b16d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            # Dynamic population adjustment\n            self.population_size = 10 + 2 * int(np.sqrt(dim * adaptive_factor))  # Adjust population size\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic population size adjustment to enhance adaptability and convergence.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'dim' is not defined\").", "error": "NameError(\"name 'dim' is not defined\")", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {}, "mutation_prompt": null}
{"id": "772204d5-49f7-4eba-8aa1-efe240348896", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor \n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            # Adaptive inertia weight normalization\n            inertia_weight /= (0.5 + 0.5 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  \n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive inertia weight normalization to maintain balance between exploration and exploitation.", "configspace": "", "generation": 16, "fitness": 0.8920221134626002, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.008. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9021433930041961, 0.8815791742415888, 0.8923437731420155], "final_y": [0.11651218041435007, 0.12093553504445553, 0.11440062749829294]}, "mutation_prompt": null}
{"id": "792a17e4-5e84-44eb-bfc3-ec2a9d3d060a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(0.5 * (10 + 2 * np.sqrt(dim) + self.budget / dim))  # Adjusted dynamic population size\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic population size adjustment to enhance diversity and convergence.", "configspace": "", "generation": 16, "fitness": 0.8917862334988683, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.008. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8875385140186841, 0.9036213936720856, 0.8841987928058355], "final_y": [0.1122931998368335, 0.11217879530596919, 0.11689358228374314]}, "mutation_prompt": null}
{"id": "e8b5f3ba-8b89-452a-b5f4-da2fd9b4f3aa", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * (1.2 - adaptive_factor)  # Adjust cognitive coeff\n            social_coeff = 1.5 + 0.5 * (1.1 - adaptive_factor)  # Adjust social coeff\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improve convergence by introducing dynamic social and cognitive coefficients based on evaluation progress.", "configspace": "", "generation": 16, "fitness": 0.8900155925758456, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.010. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9022827233546983, 0.89072824989944, 0.8770358044733986], "final_y": [0.11690593772816327, 0.11877482250841498, 0.11839465387559323]}, "mutation_prompt": null}
{"id": "8cbe0292-c6ba-4822-853a-cf0d30f24e82", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.3 * adaptive_factor  # Modified social coefficient adjustment\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive social coefficient adjustment to balance exploration and exploitation.", "configspace": "", "generation": 16, "fitness": 0.8952596885800291, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.024. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9295682737429848, 0.8750831355218993, 0.8811276564752032], "final_y": [0.10983554086737546, 0.11593148270745846, 0.11838157926759485]}, "mutation_prompt": null}
{"id": "cdaa56c2-a6fc-41f4-b8ec-f131a112bbc0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n            \n            # Dynamic adjustment of population size\n            if evaluations % 10 == 0:  # Example of adjusting population size periodically\n                self.population_size = max(10, int(self.population_size * (0.9 + 0.2 * np.random.rand())))\n                swarm.resize((self.population_size, self.dim))\n                personal_best = np.resize(personal_best, (self.population_size, self.dim))\n                personal_best_value = np.resize(personal_best_value, self.population_size)\n                self.velocity = np.zeros((self.population_size, self.dim))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic population size adjustment mechanism for better adaptability.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('cannot resize an array that references or is referenced\\nby another array in this way.\\nUse the np.resize function or refcheck=False').", "error": "ValueError('cannot resize an array that references or is referenced\\nby another array in this way.\\nUse the np.resize function or refcheck=False')", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {}, "mutation_prompt": null}
{"id": "a9996323-bb7f-46b0-9de3-60b463d170fa", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = self.initial_population_size\n        swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            # Adapt population size dynamically\n            population_size = self.initial_population_size + int(0.1 * evaluations / self.budget * self.initial_population_size)\n\n            for i in range(population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic population size and learning rate adaptation based on convergence speed to enhance exploration and exploitation balance.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {}, "mutation_prompt": null}
{"id": "3043d25a-a13f-44e6-9c07-56630c6b808f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.8 * adaptive_factor  # Modify social coefficient formula\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate a dynamic social coefficient formula to enhance convergence.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {}, "mutation_prompt": null}
{"id": "e18b3c2b-ee58-4e8e-a8d0-550dc999271d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor  # Dynamic cognitive coefficient\n            social_coeff = 1.5 + 0.5 * adaptive_factor \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by introducing a dynamic cognitive coefficient for improved convergence.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {}, "mutation_prompt": null}
{"id": "5d5228bc-f748-464a-9b10-4ef49ead70b6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                update_rate = 0.1 + 0.9 * adaptive_factor  # Dynamic update rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i] * update_rate + global_best * (1 - update_rate)  # Apply dynamic update rate\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic personal and global best update rate based on convergence progress.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {}, "mutation_prompt": null}
{"id": "27c4b31a-ae50-4ccc-a157-1d93e007a344", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            # Dynamic population size adjustment\n            self.population_size = int(10 + 40 * (1 - adaptive_factor))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  \n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate a dynamic population size adjustment based on convergence rate to enhance solution diversity.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {}, "mutation_prompt": null}
{"id": "a1e447e9-21e3-457b-be31-a8cb41582f25", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n\n            # Dynamic topology: periodically adapt the global_best selection\n            if evaluations % (self.budget // 5) == 0:  \n                neighbor_best = [personal_best[np.random.choice(range(self.population_size))] for _ in swarm]\n                global_best_candidate = np.random.choice(neighbor_best)\n                global_best_candidate_value = func(global_best_candidate)\n                evaluations += 1\n                if global_best_candidate_value < global_best_value:\n                    global_best = global_best_candidate\n                    global_best_value = global_best_candidate_value\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine exploration and convergence by introducing a dynamic topology change for improved diversity.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('a must be 1-dimensional').", "error": "ValueError('a must be 1-dimensional')", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {}, "mutation_prompt": null}
{"id": "0a6b24ba-7eba-4cd7-9347-24dc02d97491", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n            exploration_factor = 0.9 + 0.1 * adaptive_factor  # Introduce adaptive exploration factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    exploration_factor * social_coeff * r2 * (global_best - swarm[i]))  # Apply adaptive exploration factor\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive exploration factor to improve swarm diversity and enhance convergence.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('a must be 1-dimensional').", "error": "ValueError('a must be 1-dimensional')", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {}, "mutation_prompt": null}
{"id": "c053c564-90d6-462c-b349-ae8b0cc0cc57", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence speed by introducing an adaptive exploration-exploitation balance.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('a must be 1-dimensional').", "error": "ValueError('a must be 1-dimensional')", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {}, "mutation_prompt": null}
{"id": "5aad89db-af1b-4b0f-91c8-9b1a624c2890", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  \n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor  # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  \n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine exploration by adjusting the balance between cognitive and social components for improved convergence.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('a must be 1-dimensional').", "error": "ValueError('a must be 1-dimensional')", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {}, "mutation_prompt": null}
{"id": "98f1b0aa-30cb-401b-9f99-f2c24bfe20b2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                random_perturbation = np.random.uniform(-0.01, 0.01, self.dim)  # New line added\n                swarm[i] += learning_rate * self.velocity[i] + random_perturbation  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate random perturbation in position update for enhanced exploration.", "configspace": "", "generation": 19, "fitness": 0.9123160528555916, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.008. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9238328450420499, 0.9041890549196019, 0.9089262586051231], "final_y": [0.1098157215306631, 0.11642428640320512, 0.11416178605232985]}, "mutation_prompt": null}
{"id": "0fdece44-7eda-4cd7-ac6a-c406f55cc8e8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = np.random.uniform(0.6, 1.0) * 0.8 - 0.4 * adaptive_factor  # Stochastic inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a stochastic inertia weight to enhance exploration and avoid local optima.", "configspace": "", "generation": 19, "fitness": 0.9122405074406531, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.019. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9298516661282012, 0.8865091123764657, 0.9203607438172923], "final_y": [0.10983356553969015, 0.11747989314629714, 0.11106249964804671]}, "mutation_prompt": null}
{"id": "3d0933cd-a0d4-4d27-9ba3-7cb120f1b163", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor**2  # Nonlinearly decrease cognitive coefficient\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate nonlinearly decreasing cognitive and social coefficients for improved convergence.", "configspace": "", "generation": 19, "fitness": 0.9075622282438722, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.001. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9070224462765252, 0.9062364676216437, 0.9094277708334478], "final_y": [0.11312235821577632, 0.11739382150804534, 0.11356763933080716]}, "mutation_prompt": null}
{"id": "193887c9-6977-43fe-9382-1c2d91b64b2f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n\n            # Adjust population size adaptively\n            self.population_size = int((10 + 2 * np.sqrt(self.dim)) * (1 + 0.2 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (self.population_size, self.dim))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % len(personal_best)] - swarm[i % len(swarm)]) +\n                                    social_coeff * r2 * (global_best - swarm[i % len(swarm)]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i % len(swarm)] += learning_rate * self.velocity[i]\n                swarm[i % len(swarm)] = np.clip(swarm[i % len(swarm)], lb, ub)\n\n                # Introduce turbulence for diversity\n                if np.random.rand() < 0.1 * adaptive_factor:\n                    swarm[i % len(swarm)] += np.random.normal(0, 0.1 * (ub - lb), self.dim)\n\n                f_value = func(swarm[i % len(swarm)])\n                evaluations += 1\n                if f_value < personal_best_value[i % len(personal_best_value)]:\n                    personal_best[i % len(personal_best)] = swarm[i % len(swarm)]\n                    personal_best_value[i % len(personal_best_value)] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i % len(swarm)]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce diversity and dynamic adjustment by adding turbulence and adaptive population size for improved convergence.", "configspace": "", "generation": 19, "fitness": 0.899811278567157, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.019. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8761690466443545, 0.9219525284434379, 0.9013122606136789], "final_y": [0.12379049014802745, 0.11204407019299922, 0.11867967823039327]}, "mutation_prompt": null}
{"id": "10ac33ff-43e9-4fdc-9e9b-bde5f7e7429a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + adaptive_factor  # Change: Increase dynamic adaptation of social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamically adaptive social coefficient to enhance convergence towards the global best solution.", "configspace": "", "generation": 19, "fitness": 0.9098757904617778, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.021. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8831323564362973, 0.9129340655278179, 0.9335609494212183], "final_y": [0.12347653402795522, 0.11168612636955222, 0.11014673811120002]}, "mutation_prompt": null}
{"id": "604a9223-ce8b-456a-85e4-8ae2003388e2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  \n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor + 0.2 * (1 - adaptive_factor)  # Dynamic adjustment\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  \n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))  \n                swarm[i] += learning_rate * self.velocity[i]  \n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic adjustment of social coefficient based on convergence rate for improved global convergence.", "configspace": "", "generation": 20, "fitness": 0.9240304182170437, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.004. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9260572104289542, 0.9178840891072797, 0.9281499551148968], "final_y": [0.10962076731913617, 0.11625133539271804, 0.1107319482974145]}, "mutation_prompt": null}
{"id": "3e9c5ab9-06c7-46f7-9707-ce55ad04ec02", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor  # Modify inertia weight formula\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + adaptive_factor  # Dynamic adjustment of social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor  # Introduce adaptive learning rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.2 * (ub - lb), 0.2 * (ub - lb))  # More flexible clipping\n                swarm[i] += learning_rate * self.velocity[i]  # Apply adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamically adjusted social coefficient and a more flexible velocity clipping mechanism to improve convergence and exploration.", "configspace": "", "generation": 20, "fitness": 0.8941376987531074, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.010. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9069727924780469, 0.8823988632056273, 0.8930414405756482], "final_y": [0.1175793789936731, 0.12668365975044948, 0.11909390398930231]}, "mutation_prompt": null}
{"id": "b7620bf9-8d9e-4a40-a945-0199dca00697", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * (adaptive_factor**2)  # Nonlinear damping\n            social_coeff = 1.5 + 0.5 * (1 - np.exp(-2 * adaptive_factor))  # Dynamic scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improve exploitation by introducing nonlinear damping and dynamic social influence scaling.", "configspace": "", "generation": 20, "fitness": 0.9132798034449098, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.004. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.9156974332749693, 0.9072911289197438, 0.9168508481400162], "final_y": [0.10998871378642772, 0.11639855041172598, 0.11494799124666855]}, "mutation_prompt": null}
{"id": "faf4e791-fd61-4114-a8d5-202586ff9a2d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  \n\n            if evaluations % 50 == 0:  # Dynamic population resizing\n                self.population_size = max(5, self.population_size - 1)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_factor = np.random.normal(0, 0.1, self.dim)  # Adaptive neighborhood exploration\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i] + neighborhood_factor) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive neighborhood exploration and dynamic population resizing for enhanced convergence.", "configspace": "", "generation": 20, "fitness": 0.9026286347312866, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.022. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.8957217199948955, 0.8800876856732287, 0.9320764985257357], "final_y": [0.12091286228993836, 0.1266894723535189, 0.11161341235483202]}, "mutation_prompt": null}
{"id": "cbe563f5-5356-4ca3-ab1e-63c9e4e71ca1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.4 * adaptive_factor\n\n            diversity = np.mean(np.std(swarm, axis=0))\n            cognitive_coeff = 1.5 * adaptive_factor * diversity  # Modify cognitive coefficient\n            social_coeff = (1.5 + 0.5 * adaptive_factor) * (1 - diversity)  # Modify social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                learning_rate = 0.5 + 0.5 * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic cognitive and social coefficients influenced by swarm diversity for enhanced exploration and convergence.", "configspace": "", "generation": 20, "fitness": 0.8559445737063925, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.082. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "14ae60a6-229a-4271-8821-cad16da13c1f", "metadata": {"aucs": [0.7397274889406771, 0.9196095966696873, 0.908496635508813], "final_y": [0.16996642830433295, 0.11256733545756592, 0.11747841422280614]}, "mutation_prompt": null}
