{"id": "506fc3a5-ac85-42d4-b1a4-ef753743d91e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "1805dcd3-fc7b-4a51-8a4c-b77a64000bb2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.max_velocity = 0.1 * (func.bounds.ub - func.bounds.lb)  # New line\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.4 * adaptive_factor  # Modified line\n            social_coeff = 1.6  # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -self.max_velocity, self.max_velocity)  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces dynamic learning rates and velocity clamping to improve convergence and solution quality.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "506fc3a5-ac85-42d4-b1a4-ef753743d91e", "metadata": {}, "mutation_prompt": null}
{"id": "1f03d23a-a8b8-49af-b684-afd83d8dfba8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Changed line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces a dynamic social coefficient to improve convergence speed and solution quality.", "configspace": "", "generation": 1, "fitness": 0.8182437310615533, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.023. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "506fc3a5-ac85-42d4-b1a4-ef753743d91e", "metadata": {"aucs": [0.7900006629174314, 0.8195636354994524, 0.8451668947677763], "final_y": [0.15433051740362846, 0.14331789662145622, 0.13522964143865923]}, "mutation_prompt": null}
{"id": "a1b0955c-703a-4468-af63-c7f0270758b6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.alpha = 1.5  # Levy flight parameter\n\n    def levy_flight(self, step_size):\n        # Levy distribution for flight distances\n        return np.random.standard_normal(self.dim) * (step_size ** -self.alpha)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                # Incorporate Levy flight\n                levy_step = self.levy_flight(adaptive_factor)\n                swarm[i] += self.velocity[i] + levy_step\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrating Levy Flights with Adaptive Swarm Gradient Descent (L-ASGD) enhances exploration and exploitation by introducing stochastic, non-Gaussian search patterns.", "configspace": "", "generation": 1, "fitness": 0.8224166070624935, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.007. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "506fc3a5-ac85-42d4-b1a4-ef753743d91e", "metadata": {"aucs": [0.8156591205355497, 0.8312315467026568, 0.820359153949274], "final_y": [0.14023231503783573, 0.13946855588603524, 0.13525630962663238]}, "mutation_prompt": null}
{"id": "2098ba5d-c50b-4a46-bfef-4a38717b9ad9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * adaptive_factor  # Changed line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Refines exploration by adjusting social coefficient based on evaluation progress for improved convergence.", "configspace": "", "generation": 1, "fitness": 0.8411741678498935, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.048. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "506fc3a5-ac85-42d4-b1a4-ef753743d91e", "metadata": {"aucs": [0.8685255603699895, 0.8808158481188095, 0.7741810950608814], "final_y": [0.11840415947583915, 0.12172979344858881, 0.15402070278483337]}, "mutation_prompt": null}
{"id": "d85ad07d-fa8d-4de4-9286-bb20fdd672e6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor)  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Adaptive mutation\n                if np.random.rand() < 0.1:  # 10% chance\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (E-ASGD): Introduces dynamic adjustment of inertia weight and adaptive mutation to improve exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.8550978860270392, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.009. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "506fc3a5-ac85-42d4-b1a4-ef753743d91e", "metadata": {"aucs": [0.8438580221886532, 0.8645809436814603, 0.8568546922110041], "final_y": [0.13319735213110928, 0.13177245225022838, 0.13089318599013744]}, "mutation_prompt": null}
{"id": "27e3b24a-01ec-4566-9edb-3103fac3729b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor)  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * (1 + 0.5 * np.exp(-evaluations / self.budget))\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Adaptive mutation\n                if np.random.rand() < 0.1:  # 10% chance\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive cognitive coefficient scaling based on personal best improvement rate.", "configspace": "", "generation": 2, "fitness": 0.8684945717876618, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.025. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "d85ad07d-fa8d-4de4-9286-bb20fdd672e6", "metadata": {"aucs": [0.8336791510039003, 0.8809288070632445, 0.8908757572958407], "final_y": [0.1295545624281108, 0.12328641896670556, 0.12014084330633479]}, "mutation_prompt": null}
{"id": "becb8f66-b85b-4047-80ce-23545fd3bfd6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor)  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            learning_rate = 0.1 + 0.9 * adaptive_factor  # Adaptive learning rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]  # Applied adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Adaptive mutation\n                if np.random.rand() < 0.1:  # 10% chance\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced an adaptive learning rate to balance exploration and exploitation more effectively.", "configspace": "", "generation": 2, "fitness": 0.8912159043230478, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.011. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d85ad07d-fa8d-4de4-9286-bb20fdd672e6", "metadata": {"aucs": [0.8895495064525608, 0.8786857248932495, 0.9054124816233328], "final_y": [0.12273141929555365, 0.12545980606117502, 0.11749568804916855]}, "mutation_prompt": null}
{"id": "70a93c07-b880-46d4-a0fc-98d30c2d6b79", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor)  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor**0.5  # Non-linear decay for cognitive coefficient\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Adaptive mutation\n                if np.random.rand() < 0.1:  # 10% chance\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a non-linear decay factor for cognitive coefficient to refine exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.8623698728318582, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.022. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "d85ad07d-fa8d-4de4-9286-bb20fdd672e6", "metadata": {"aucs": [0.8305521115135596, 0.8782733699396768, 0.8782841370423383], "final_y": [0.14265702143081038, 0.1275760314127431, 0.1277038381668707]}, "mutation_prompt": null}
{"id": "008c30f1-2aa2-48b1-8835-6af0e33a3c74", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor)  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Dynamic mutation based on progress\n                mutation_rate = 0.1 * (1 - evaluations / self.budget)\n                if np.random.rand() < mutation_rate:  # Dynamic mutation rate\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "E-ASGD with Dynamic Mutation Rate: Integrates a dynamic mutation rate based on the evaluation progress to enhance exploration efficiency.", "configspace": "", "generation": 2, "fitness": 0.8856192204401102, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.005. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "d85ad07d-fa8d-4de4-9286-bb20fdd672e6", "metadata": {"aucs": [0.8909408154551308, 0.886080760333389, 0.8798360855318104], "final_y": [0.12385655863467893, 0.12081781460381102, 0.1250511170004287]}, "mutation_prompt": null}
{"id": "577f12c2-6d6b-476c-a397-db59e7fc66e4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor)  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Adaptive mutation\n                mutation_prob = 0.1 * (1 - adaptive_factor)  # Decreasing mutation probability\n                if np.random.rand() < mutation_prob:  # Changed line\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced a decreasing adaptive mutation probability to balance exploration throughout the optimization process.", "configspace": "", "generation": 2, "fitness": 0.8591896585824667, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.027. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "d85ad07d-fa8d-4de4-9286-bb20fdd672e6", "metadata": {"aucs": [0.8204647465889363, 0.8769075831635548, 0.8801966459949088], "final_y": [0.14687860423570498, 0.12316028280238123, 0.12028588693808562]}, "mutation_prompt": null}
{"id": "519213d0-eb81-4301-9304-d4d9e1d3e5b8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(np.pi * adaptive_factor)  # Adjusted inertia weight\n            cognitive_coeff = 1.7 * adaptive_factor  # Adjusted cognitive coefficient\n            social_coeff = 1.3  # Adjusted social coefficient\n\n            learning_rate = 0.05 + 0.95 * adaptive_factor  # Adjusted adaptive learning rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:  # Increased mutation probability\n                    mutation = np.random.normal(0, 0.15, self.dim)  # Increased mutation strength\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration-exploitation balance through dynamic parameter adjustments and diversity introduction.", "configspace": "", "generation": 3, "fitness": 0.8459759030450594, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.034. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "becb8f66-b85b-4047-80ce-23545fd3bfd6", "metadata": {"aucs": [0.7990033630784723, 0.8784788870693406, 0.8604454589873652], "final_y": [0.1538722372155964, 0.12331825074173752, 0.12296433125145323]}, "mutation_prompt": null}
{"id": "873bca35-d291-4f17-87f6-2108fb736d75", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor)  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            learning_rate = 0.1 + 0.9 * adaptive_factor  # Adaptive learning rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]  # Applied adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Adaptive mutation\n                if np.random.rand() < 0.1:  # 10% chance\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation * np.random.random(), lb, ub)  # Stochastic perturbation\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced stochastic perturbation to enhance diversity and avoid local optima.", "configspace": "", "generation": 3, "fitness": 0.87370889070279, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.017. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "becb8f66-b85b-4047-80ce-23545fd3bfd6", "metadata": {"aucs": [0.8700804039227165, 0.8963136250141895, 0.8547326431714644], "final_y": [0.13060459008763858, 0.1218354783665706, 0.12395201161484437]}, "mutation_prompt": null}
{"id": "34218531-e37f-4b8f-a219-4773b5d428f6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor)  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            learning_rate = 0.1 + 0.9 * adaptive_factor  # Adaptive learning rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]  # Applied adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Adaptive mutation\n                if np.random.rand() < 0.1 * adaptive_factor:  # Mutation rate adjusted by adaptive factor\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved exploration by adjusting mutation rate based on adaptive factor.", "configspace": "", "generation": 3, "fitness": 0.8661507263970186, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.038. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "becb8f66-b85b-4047-80ce-23545fd3bfd6", "metadata": {"aucs": [0.8242636315278256, 0.8585053089651346, 0.9156832386980958], "final_y": [0.1352777359142644, 0.12500381325113297, 0.11265101948948275]}, "mutation_prompt": null}
{"id": "54d5ef70-945d-4fd2-8db2-4737db8e03a7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        # Momentum term initialization\n        momentum = np.zeros((self.population_size, self.dim))\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor)  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            learning_rate = 0.1 + 0.9 * adaptive_factor  # Adaptive learning rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                momentum[i] = 0.9 * momentum[i] + self.velocity[i]  # Momentum term\n                swarm[i] += learning_rate * momentum[i]  # Applied adaptive learning rate with momentum\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Adaptive mutation\n                if np.random.rand() < 0.1:  # 10% chance\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced a momentum-like term to improve convergence speed and stability.", "configspace": "", "generation": 3, "fitness": 0.8641353882852582, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.054. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "becb8f66-b85b-4047-80ce-23545fd3bfd6", "metadata": {"aucs": [0.788723370867778, 0.8949543964213409, 0.9087283975666556], "final_y": [0.16030280335457392, 0.11859043140648906, 0.11521691478903962]}, "mutation_prompt": null}
{"id": "75add07d-7f47-4716-b1f9-715d28c4e963", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(np.pi * adaptive_factor)  # Changed to cosine for diversity\n            cognitive_coeff = 2.0 - adaptive_factor  # Modified to introduce more exploration initially\n            social_coeff = 1.5 + 0.5 * np.cos(np.pi * adaptive_factor)  # Time-varying social coefficient\n\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n\n            neighborhood_size = min(5, self.population_size // 2)  # Dynamic neighborhood size\n            for i in range(self.population_size):\n                neighbors = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))  # Local best used instead of global\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.1:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm intelligence by integrating a dynamic neighborhood strategy and time-varying acceleration coefficients.  ", "configspace": "", "generation": 3, "fitness": 0.8662833032601333, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.019. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "becb8f66-b85b-4047-80ce-23545fd3bfd6", "metadata": {"aucs": [0.8518107236906606, 0.8538915152427434, 0.893147670846996], "final_y": [0.13186133816276802, 0.13317477896297603, 0.11588699978619055]}, "mutation_prompt": null}
{"id": "c19f904c-04a6-48d5-9a21-2fc7139f88e5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.1:\n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration by dynamically adjusting population size and hybridizing mutation strategies.", "configspace": "", "generation": 4, "fitness": 0.9093671083169329, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.011. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "873bca35-d291-4f17-87f6-2108fb736d75", "metadata": {"aucs": [0.9007793810938233, 0.9022847795290326, 0.9250371643279428], "final_y": [0.11804966437332742, 0.11667574694614646, 0.11281831646228768]}, "mutation_prompt": null}
{"id": "982be18a-e69e-442e-83bf-b1cb8e5ab344", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor)  # Adjusted inertia weight\n            cognitive_coeff = 1.7 * adaptive_factor  # Adjusted cognitive coefficient\n            social_coeff = 1.3  # Adjusted social coefficient\n\n            learning_rate = 0.1 + 0.9 * adaptive_factor  # Adaptive learning rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]  # Applied adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Adaptive mutation\n                if np.random.rand() < 0.1:  # 10% chance\n                    mutation_strength = adaptive_factor * 0.1  # Variable mutation strength\n                    mutation = np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation * np.random.random(), lb, ub)  # Stochastic perturbation\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent by introducing variable mutation strengths and adjusted coefficients to balance exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.8889567424819175, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.029. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "873bca35-d291-4f17-87f6-2108fb736d75", "metadata": {"aucs": [0.8477529290612149, 0.9092302614135653, 0.9098870369709722], "final_y": [0.13571275360453705, 0.1153196846753467, 0.11518459683009152]}, "mutation_prompt": null}
{"id": "f5747496-68a2-42ee-b05d-97f2b474c7d6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.cos(np.pi * adaptive_factor)  # Change sine to cosine\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)  # Altered cognitive coefficient\n            social_coeff = 1.5 * (1.5 - adaptive_factor)  # Altered social coefficient\n\n            learning_rate = 0.2 + 0.8 * adaptive_factor  # Slightly adjusted learning rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:  # Increase mutation probability\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation * np.random.random(), lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic topology adjustment and probabilistic selection to enhance exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.8988786660602485, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.007. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "873bca35-d291-4f17-87f6-2108fb736d75", "metadata": {"aucs": [0.8936625095663435, 0.8938431276835501, 0.9091303609308516], "final_y": [0.12051223534422995, 0.1194876347704249, 0.11658897527962253]}, "mutation_prompt": null}
{"id": "176db79c-5a24-4618-bbc1-a11ff6cb59d9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor)  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            learning_rate = 0.1 + 0.9 * adaptive_factor  # Adaptive learning rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]  # Applied adaptive learning rate\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Adaptive mutation\n                if np.random.rand() < 0.1:  # 10% chance\n                    mutation = np.random.normal(0, 0.1 * adaptive_factor, self.dim)  # Non-linear mutation\n                    swarm[i] = np.clip(swarm[i] + mutation * np.random.random(), lb, ub)  # Stochastic perturbation\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced non-linear adaptive mutation to enhance exploration capability.", "configspace": "", "generation": 4, "fitness": 0.9075796734305527, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.018. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "873bca35-d291-4f17-87f6-2108fb736d75", "metadata": {"aucs": [0.8859231853852454, 0.9073685337733676, 0.9294473011330447], "final_y": [0.11850003853079616, 0.11730126226288728, 0.11184423072954708]}, "mutation_prompt": null}
{"id": "004be90a-6787-4f6a-b934-388465d5f0ac", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            velocity_scaling = 0.8 * np.log(evaluations + 1)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i] * velocity_scaling\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:  # Increased chance\n                    chaos_factor = np.random.uniform(-0.2, 0.2, self.dim)\n                    swarm[i] = np.clip(swarm[i] + chaos_factor, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration through chaotic perturbation and adaptive velocity scaling for improved convergence.", "configspace": "", "generation": 4, "fitness": 0.8236889619291411, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.053. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "873bca35-d291-4f17-87f6-2108fb736d75", "metadata": {"aucs": [0.7491304129397572, 0.871567998603224, 0.8503684742444423], "final_y": [0.1771485468148175, 0.1270776268548649, 0.13163615254328698]}, "mutation_prompt": null}
{"id": "3905d84c-778a-449a-bbbe-865bd769a546", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:  # Change 2\n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved inertia and mutation strategy to enhance convergence and exploration balance.", "configspace": "", "generation": 5, "fitness": 0.9124687346585496, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.013. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c19f904c-04a6-48d5-9a21-2fc7139f88e5", "metadata": {"aucs": [0.9281542222465579, 0.9118171074194283, 0.8974348743096627], "final_y": [0.11050421467535343, 0.11448024849483984, 0.12100829993806994]}, "mutation_prompt": null}
{"id": "13c32ef8-593f-462f-a904-fa603a100814", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            learning_rate = 0.2 + 0.8 * adaptive_factor  # Modified line\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.1:\n                    mutation = np.random.normal(0, 0.2, self.dim)  # Modified line\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined swarm exploration by enhancing adaptive learning rate and mutation diversity.", "configspace": "", "generation": 5, "fitness": 0.8890429888114166, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.034. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c19f904c-04a6-48d5-9a21-2fc7139f88e5", "metadata": {"aucs": [0.8408428200004615, 0.914245559903789, 0.9120405865299993], "final_y": [0.13027257350152222, 0.1183114855232279, 0.11388578787160075]}, "mutation_prompt": null}
{"id": "b311fb86-12eb-4750-8c82-fd9ff4aac9fc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.sin(np.pi * adaptive_factor)\n            cognitive_coeff = 1.5 * adaptive_factor + 0.5\n            social_coeff = 1.5 + 0.3 * adaptive_factor\n            learning_rate = 0.1 + 0.8 * adaptive_factor\n\n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:\n                    mutation = np.random.normal(0, 0.1 * adaptive_factor, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved convergence by integrating an adaptive mutation mechanism and fine-tuning inertia and learning rates.", "configspace": "", "generation": 5, "fitness": 0.9031926145476791, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.019. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c19f904c-04a6-48d5-9a21-2fc7139f88e5", "metadata": {"aucs": [0.8763488922841026, 0.9157154222822081, 0.9175135290767265], "final_y": [0.1243389347717262, 0.11257625544730965, 0.11386221611358771]}, "mutation_prompt": null}
{"id": "f6e61d80-095b-424d-a698-6fd222691d88", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.1:\n                    mutation_scale = 0.1 * adaptive_factor  # Change made here\n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, mutation_scale, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-mutation_scale, mutation_scale, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved convergence by introducing adaptive mutation scale based on current evaluations.", "configspace": "", "generation": 5, "fitness": 0.8868046653005646, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.021. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c19f904c-04a6-48d5-9a21-2fc7139f88e5", "metadata": {"aucs": [0.8566471258394402, 0.9015006815899139, 0.9022661884723397], "final_y": [0.13301053102519655, 0.11968591385358862, 0.1198735625020696]}, "mutation_prompt": null}
{"id": "8a7dda8f-3d58-4489-b71c-b3d56c4f4636", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.1:\n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.1 * adaptive_factor, self.dim)  # Changed line\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined exploitation by incorporating adaptive mutation variance to enhance local search precision.", "configspace": "", "generation": 5, "fitness": 0.8624923956590855, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.055. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "c19f904c-04a6-48d5-9a21-2fc7139f88e5", "metadata": {"aucs": [0.788385145520607, 0.8801020595979951, 0.9189899818586547], "final_y": [0.1581067361598284, 0.12634940951473073, 0.11155132139816881]}, "mutation_prompt": null}
{"id": "54397607-09a2-471f-96ce-edffa159f49a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * np.sin(np.pi * adaptive_factor)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor + 0.5  # Change 2\n            social_coeff = 1.7  # Change 3\n            learning_rate = 0.1 + 0.6 * adaptive_factor  # Change 4\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:  # Change 5\n                    mutation = np.random.uniform(-0.05, 0.05, self.dim)  # Change 6\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n                # Elite selection and local search (Change 7-8)\n                if i == 0 and evaluations < self.budget:\n                    elite = personal_best[np.argmin(personal_best_value)]\n                    local_search = elite + np.random.uniform(-0.01, 0.01, self.dim)\n                    local_search = np.clip(local_search, lb, ub)\n                    local_value = func(local_search)\n                    evaluations += 1\n                    if local_value < global_best_value:\n                        global_best = local_search\n                        global_best_value = local_value\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced adaptive inertia and mutation strategy with elite selection and local search for improved convergence and exploration.", "configspace": "", "generation": 6, "fitness": 0.9019372814236748, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.019. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "3905d84c-778a-449a-bbbe-865bd769a546", "metadata": {"aucs": [0.8803849362421329, 0.8983465385625394, 0.927080369466352], "final_y": [0.12272007868253232, 0.12146646866733668, 0.11011643595491072]}, "mutation_prompt": null}
{"id": "5ec42d4a-c47e-4542-b8d0-8a4ae6fe90e1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= 0.95  # Change 2: Introduced velocity damping \n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:  # Change 2\n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced velocity damping to enhance convergence by reducing oscillatory behavior of particles.", "configspace": "", "generation": 6, "fitness": 0.9020979292986615, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.029. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "3905d84c-778a-449a-bbbe-865bd769a546", "metadata": {"aucs": [0.8653136476050004, 0.9041470888569056, 0.9368330514340786], "final_y": [0.13133453180164145, 0.12137270012524282, 0.11251529123619186]}, "mutation_prompt": null}
{"id": "51f46145-7b3d-4c4a-8cb9-4bb6b83eedb2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor)\n            cognitive_coeff = 1.5 * (1 - np.argsort(personal_best_value) / self.initial_population_size)  # Change here\n            social_coeff = 1.5\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff[i % self.initial_population_size] * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:\n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration with variable cognitive coefficient based on fitness ranking.", "configspace": "", "generation": 6, "fitness": 0.9022820956652696, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.006. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3905d84c-778a-449a-bbbe-865bd769a546", "metadata": {"aucs": [0.8987903535757341, 0.9105023281375412, 0.8975536052825337], "final_y": [0.1186762095954983, 0.11642237966290137, 0.12038265519404845]}, "mutation_prompt": null}
{"id": "a434ea9c-4b7b-417a-b121-c723c6fc9ef2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:  # Change 2\n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.1 * adaptive_factor, self.dim)  # Change 3\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration by introducing non-linear inertia and adaptive mutation strategies.", "configspace": "", "generation": 6, "fitness": 0.9039991332418128, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.017. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3905d84c-778a-449a-bbbe-865bd769a546", "metadata": {"aucs": [0.8818336081618751, 0.907158231208527, 0.9230055603550363], "final_y": [0.12175051018312699, 0.11629033284644019, 0.11357494203408458]}, "mutation_prompt": null}
{"id": "2bdad25d-e301-4677-952d-1e1967c32f64", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.5 * np.cos(np.pi * adaptive_factor)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2 - 0.1 * adaptive_factor:  # Change 2\n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhancing swarm diversity and convergence by dynamic inertia adjustment and mutation frequency modulation.", "configspace": "", "generation": 6, "fitness": 0.9012370342067384, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.011. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3905d84c-778a-449a-bbbe-865bd769a546", "metadata": {"aucs": [0.8897337733214489, 0.898491392762369, 0.9154859365363972], "final_y": [0.1213712089182225, 0.11683180190424014, 0.11381888379168625]}, "mutation_prompt": null}
{"id": "5c08a2c8-7365-4ace-b40d-7fbaafc9f350", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:  # Change 2\n                    mutation_intensity = 0.1 * (1 - adaptive_factor)  # Change 3\n                    mutation = np.random.normal(0, mutation_intensity, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced diversity through dynamic adaptive mutation rates and velocity perturbation for improved convergence.", "configspace": "", "generation": 7, "fitness": 0.8749440826082218, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.031. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "a434ea9c-4b7b-417a-b121-c723c6fc9ef2", "metadata": {"aucs": [0.9149238977215592, 0.8704626503472412, 0.8394456997558648], "final_y": [0.1145276072959508, 0.11733025957735466, 0.12353412987728807]}, "mutation_prompt": null}
{"id": "7c0c2e49-a7f6-4966-9445-a02ed9ff79d7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.5 * np.sin(2 * np.pi * adaptive_factor**2)  # Change 1\n            cognitive_coeff = 1.2 * adaptive_factor  # Change 2\n            social_coeff = 1.7  # Change 3\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.4 * adaptive_factor))  # Change 4\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            neighborhood_size = int(0.1 * current_population_size)  # Change 5\n            for i in range(current_population_size):\n                neighbors = np.random.choice(current_population_size, neighborhood_size, replace=False)\n                local_best = swarm[neighbors[np.argmin([func(swarm[n]) for n in neighbors])]]  # Change 6\n\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random()  # Change 7\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    r3 * (local_best - swarm[i]))  # Change 8\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:  # Change 9\n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.05 * adaptive_factor, self.dim)  # Change 10\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.05, 0.05, self.dim)  # Change 11\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration with dynamic population scaling and adaptive neighborhood search for improved convergence.", "configspace": "", "generation": 7, "fitness": 0.8412123111295084, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.009. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a434ea9c-4b7b-417a-b121-c723c6fc9ef2", "metadata": {"aucs": [0.845238714658227, 0.8285598786729631, 0.8498383400573353], "final_y": [0.12267056794177589, 0.13404806303496974, 0.12943445431142575]}, "mutation_prompt": null}
{"id": "459d60a1-736c-48c7-89e0-b8e20110338b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15: \n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.1 * adaptive_factor, self.dim)  \n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration by introducing non-linear inertia and adaptive mutation strategies.", "configspace": "", "generation": 7, "fitness": 0.8784508184126264, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.005. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a434ea9c-4b7b-417a-b121-c723c6fc9ef2", "metadata": {"aucs": [0.8838355566964832, 0.8787192890349125, 0.8727976095064833], "final_y": [0.1261627133220542, 0.12297933486104173, 0.1262968182910369]}, "mutation_prompt": null}
{"id": "488295b5-8727-4308-877d-a2f1698dcb9a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Change 1\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:\n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.1 * adaptive_factor, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1 * adaptive_factor, 0.1 * adaptive_factor, self.dim)  # Change 2\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm adaptation with dynamic velocity scaling and mutation strategy.", "configspace": "", "generation": 7, "fitness": 0.8486126383553719, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.016. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a434ea9c-4b7b-417a-b121-c723c6fc9ef2", "metadata": {"aucs": [0.8585018425539418, 0.8613804477304787, 0.8259556247816953], "final_y": [0.13036455038574024, 0.12113513839382606, 0.14059674574220793]}, "mutation_prompt": null}
{"id": "f0c09d51-c844-4a4e-8c8c-b74823f19615", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * (1 + 0.5 * np.cos(np.pi * adaptive_factor))  # Change 1\n            social_coeff = 1.5\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:\n                    mutation = np.random.normal(0, 0.1 * adaptive_factor**2, self.dim)  # Change 2\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic cognitive coefficient scaling and improved mutation strategy to enhance convergence.", "configspace": "", "generation": 7, "fitness": 0.8560283658870369, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.013. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a434ea9c-4b7b-417a-b121-c723c6fc9ef2", "metadata": {"aucs": [0.8734447336018341, 0.8539681989329163, 0.8406721651263602], "final_y": [0.1258052174860287, 0.11897918126977891, 0.1313251911478016]}, "mutation_prompt": null}
{"id": "20214e3d-09ef-431f-ae05-e965eb63836b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15: \n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.1 * adaptive_factor, self.dim)  \n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if np.random.rand() < 0.1: \n                    random_walk = np.random.uniform(-0.05, 0.05, self.dim)\n                    swarm[i] = np.clip(swarm[i] + random_walk, lb, ub)\n                \n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance diversity by introducing localized random walks in the swarm's movement strategy.", "configspace": "", "generation": 8, "fitness": 0.8865228588813278, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.004. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "459d60a1-736c-48c7-89e0-b8e20110338b", "metadata": {"aucs": [0.8898079759164184, 0.8807672216799594, 0.8889933790476056], "final_y": [0.1234422945438245, 0.12676887898782307, 0.12324711583263781]}, "mutation_prompt": null}
{"id": "6686202d-a3b4-46da-a595-f6fff567b72a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            learning_rate = 0.1 + 0.9 * np.exp(-adaptive_factor)  # Change 1\n\n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15: \n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.1 * adaptive_factor, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved convergence by adjusting the learning rate decay to utilize exponential growth for better fine-tuning in late stages.", "configspace": "", "generation": 8, "fitness": 0.9066852491562338, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.014. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "459d60a1-736c-48c7-89e0-b8e20110338b", "metadata": {"aucs": [0.9168907523833679, 0.8870749192779744, 0.9160900758073593], "final_y": [0.11062419348044605, 0.11672690538485941, 0.11497449330822818]}, "mutation_prompt": null}
{"id": "909f8ba5-8def-4850-93da-d57d21a14032", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)  # Change 2\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15: \n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.1 * adaptive_factor, self.dim)  \n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate dynamic social coefficient adjustment for improved convergence.", "configspace": "", "generation": 8, "fitness": 0.9079470604770169, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.015. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "459d60a1-736c-48c7-89e0-b8e20110338b", "metadata": {"aucs": [0.8874024712194798, 0.9148359532771982, 0.9216027569343725], "final_y": [0.12060832964960133, 0.11630034265418221, 0.1135804039821664]}, "mutation_prompt": null}
{"id": "8c48a240-393e-45d8-9ae1-efd6756fd3ad", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + adaptive_factor)  # Change 1\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15: \n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.1 * adaptive_factor, self.dim)  \n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved global search capability by dynamically adjusting social learning coefficient based on adaptive factor.", "configspace": "", "generation": 8, "fitness": 0.8761735824619548, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.019. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "459d60a1-736c-48c7-89e0-b8e20110338b", "metadata": {"aucs": [0.8506879424949256, 0.897240637344995, 0.8805921675459435], "final_y": [0.13450144430202116, 0.11693763645483723, 0.12595413644585274]}, "mutation_prompt": null}
{"id": "75094c28-db13-4500-8df6-a98e677bf089", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor * np.random.rand(self.dim)  # Change 2\n            social_coeff = 1.5\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15: \n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.1 * adaptive_factor, self.dim)  \n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration by introducing non-linear inertia and adaptive mutation strategies with dynamic emotion-driven coefficients.", "configspace": "", "generation": 8, "fitness": 0.9071122058860804, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.006. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "459d60a1-736c-48c7-89e0-b8e20110338b", "metadata": {"aucs": [0.911676827322985, 0.910700701959019, 0.8989590883762375], "final_y": [0.11095766913695604, 0.1163185316350056, 0.11984023668212374]}, "mutation_prompt": null}
{"id": "600e6a77-fc7b-4ebc-8277-7196a23cbfc6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor**1.5  # Change 1\n\n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15: \n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.1 * adaptive_factor, self.dim)  \n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a nonlinear decay factor to the learning rate for enhanced exploration-exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.8900274689937167, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.016. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "909f8ba5-8def-4850-93da-d57d21a14032", "metadata": {"aucs": [0.901769853578461, 0.8668920897852006, 0.9014204636174883], "final_y": [0.11492927102379769, 0.12805498113119118, 0.11336007393648873]}, "mutation_prompt": null}
{"id": "2099e536-eee0-4d24-a670-235caa5f6050", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)  # Change 2\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15: \n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.1 * adaptive_factor, self.dim)  \n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations < self.budget and np.random.rand() < 0.05:  # Random restart mechanism\n                swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity with a random restart mechanism for better exploration.", "configspace": "", "generation": 9, "fitness": 0.8737233052526344, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.020. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "909f8ba5-8def-4850-93da-d57d21a14032", "metadata": {"aucs": [0.850058654180288, 0.8718830188708508, 0.8992282427067644], "final_y": [0.12436078969848208, 0.11893428237722303, 0.11567591785165132]}, "mutation_prompt": null}
{"id": "22b786c3-34d0-4e38-b33b-c4ef50cf475c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor) + np.random.uniform(-0.1, 0.1)  # Change 2\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15: \n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.1 * adaptive_factor, self.dim)  \n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance global search by modulating social influence with randomness.", "configspace": "", "generation": 9, "fitness": 0.879759980986525, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.027. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "909f8ba5-8def-4850-93da-d57d21a14032", "metadata": {"aucs": [0.916420916010756, 0.8509360427590021, 0.8719229841898167], "final_y": [0.1141915700361531, 0.1309549642810094, 0.1195013353661668]}, "mutation_prompt": null}
{"id": "72964862-0a04-4201-9121-45b70c32bf89", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)  # Change 2\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15: \n                    if np.random.rand() < 0.5:\n                        mutation_rate = 0.1 * adaptive_factor * np.random.rand()  # Change 3\n                        mutation = np.random.normal(0, mutation_rate, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by dynamically scaling mutation rate with a random factor.", "configspace": "", "generation": 9, "fitness": 0.8977944252229427, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.008. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "909f8ba5-8def-4850-93da-d57d21a14032", "metadata": {"aucs": [0.8981599055608674, 0.887704020107478, 0.9075193500004826], "final_y": [0.1121987109853505, 0.11946424674216127, 0.11464970830268739]}, "mutation_prompt": null}
{"id": "45e1e9c6-5b61-4a8a-b4b6-bbd38ebf51a1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n\n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:\n                    if np.random.rand() < 0.5:\n                        mutation = np.random.normal(0, 0.1 * adaptive_factor, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n                if np.random.rand() < 0.01:  # Added line for stochastic diffusion\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce stochastic diffusion to occasionally explore distant regions of the search space.", "configspace": "", "generation": 9, "fitness": 0.849149883609964, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.062. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "909f8ba5-8def-4850-93da-d57d21a14032", "metadata": {"aucs": [0.7616634886749027, 0.8900362952671514, 0.8957498668878379], "final_y": [0.1713611231622142, 0.11268591786864002, 0.11559859682027207]}, "mutation_prompt": null}
{"id": "d01da024-3fa4-41a3-9bcf-9032531626e3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15: \n                    if np.random.rand() < 0.5:\n                        mutation_rate = 0.1 * adaptive_factor * np.random.rand()\n                        mutation = np.random.normal(0, mutation_rate, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim) * (1 - (global_best_value / np.max(personal_best_value)))  # Change 1\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improve convergence by introducing adaptive perturbation based on global best value.", "configspace": "", "generation": 10, "fitness": 0.8906877479749026, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.024. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "72964862-0a04-4201-9121-45b70c32bf89", "metadata": {"aucs": [0.8627447362959385, 0.8878609099899581, 0.9214575976388113], "final_y": [0.12628594890815248, 0.12093621557082479, 0.11267317745146399]}, "mutation_prompt": null}
{"id": "0633b858-5ef4-4972-ac60-7b5bca4fb747", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = (f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10)\n                    mutation_rate = 0.1 * adaptive_factor * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic fitness-based mutation strategy to enhance local search and convergence speed.", "configspace": "", "generation": 10, "fitness": 0.9132868752722066, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.004. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "72964862-0a04-4201-9121-45b70c32bf89", "metadata": {"aucs": [0.9085266011710021, 0.9141533537019435, 0.9171806709436745], "final_y": [0.11249320709541955, 0.11305807413059243, 0.11165762088558984]}, "mutation_prompt": null}
{"id": "de5efd96-7489-4c6b-bd7d-cda81ce4632a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.5 * np.sin(np.pi * adaptive_factor**2)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15: \n                    if np.random.rand() < 0.5:\n                        mutation_rate = 0.2 * adaptive_factor * np.random.rand()  # Change 2\n                        mutation = np.random.normal(0, mutation_rate, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive inertia weight and mutation strategy to improve exploration and convergence.", "configspace": "", "generation": 10, "fitness": 0.9066345187722674, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.010. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "72964862-0a04-4201-9121-45b70c32bf89", "metadata": {"aucs": [0.8955498585884725, 0.9043464821014556, 0.9200072156268742], "final_y": [0.11201018159890885, 0.11648017916666398, 0.1131562615986541]}, "mutation_prompt": null}
{"id": "3fb1fe75-c901-4568-bdc1-0230cf06b548", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        last_improvement = evaluations  # Initialize to track when last improvement occurred\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    last_improvement = evaluations  # Track when improvement occurs\n\n                if np.random.rand() < 0.15: \n                    if np.random.rand() < 0.5:\n                        performance_factor = 1 + (evaluations - last_improvement) / self.budget  # New line: dynamic mutation based on performance\n                        mutation_rate = 0.1 * adaptive_factor * np.random.rand() * performance_factor\n                        mutation = np.random.normal(0, mutation_rate, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by introducing dynamic mutation based on performance history.", "configspace": "", "generation": 10, "fitness": 0.9035691975129175, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.010. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "72964862-0a04-4201-9121-45b70c32bf89", "metadata": {"aucs": [0.9056019991501644, 0.8899422283951973, 0.9151633649933906], "final_y": [0.10986116173026639, 0.12246135816633519, 0.11229617132998615]}, "mutation_prompt": null}
{"id": "57bfe763-0b86-449a-8bfa-5afcf45926d1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.5 * np.sin(np.pi * adaptive_factor**2)  # Change 1\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)  # Change 2\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15: \n                    if np.random.rand() < 0.5:\n                        mutation_rate = 0.15 * adaptive_factor * np.random.rand()  # Change 3\n                        mutation = np.random.normal(0, mutation_rate, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                    else:\n                        mutation = np.random.uniform(-0.1, 0.1, self.dim)\n                        swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic inertia weight oscillation and integrated dynamic mutation rate for improved convergence and exploration.", "configspace": "", "generation": 10, "fitness": 0.8977130796141036, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.006. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "72964862-0a04-4201-9121-45b70c32bf89", "metadata": {"aucs": [0.9001653187714872, 0.9036488024934307, 0.8893251175773927], "final_y": [0.1162739678704563, 0.11660818808241213, 0.11623713410211878]}, "mutation_prompt": null}
{"id": "6824b348-a01b-43f8-94a1-2ab0222afa10", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = (f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10)\n                    mutation_rate = 0.1 * adaptive_factor * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01:  # New line added\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a small probability of random reinitialization to escape local optima and improve exploration.", "configspace": "", "generation": 11, "fitness": 0.9005862507935122, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.008. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "0633b858-5ef4-4972-ac60-7b5bca4fb747", "metadata": {"aucs": [0.8979331583926586, 0.9108844975911312, 0.8929410963967467], "final_y": [0.11189485441603986, 0.11472624665380415, 0.11512847372200108]}, "mutation_prompt": null}
{"id": "3b48b966-867c-4dd2-a75f-19c4eeccc281", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = (f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10)\n                    mutation_rate = 0.1 * adaptive_factor * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive exploration-exploitation balancing factor for improved solution quality.", "configspace": "", "generation": 11, "fitness": 0.8857566532688633, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.004. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "0633b858-5ef4-4972-ac60-7b5bca4fb747", "metadata": {"aucs": [0.8909345176072626, 0.8853619941458801, 0.8809734480534475], "final_y": [0.11743496445153123, 0.12034878113834391, 0.1248322087572431]}, "mutation_prompt": null}
{"id": "68f61ca5-bbd5-43a9-ab45-551cea5a8058", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Changed 5 lines below\n                if np.random.rand() < 0.2:\n                    rank = np.argsort(personal_best_value).argsort()[i % self.initial_population_size]\n                    mutation_strength = (f_value - global_best_value) / (rank + 1 + 1e-10)\n                    mutation_rate = 0.1 * adaptive_factor * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a stochastic rank-based mutation strategy to enhance exploration diversity and convergence robustness.", "configspace": "", "generation": 11, "fitness": 0.8873753623387571, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.026. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "0633b858-5ef4-4972-ac60-7b5bca4fb747", "metadata": {"aucs": [0.8524132646116229, 0.9132822410181143, 0.8964305813865343], "final_y": [0.1282423422609178, 0.1119101977847583, 0.11429016981691464]}, "mutation_prompt": null}
{"id": "bae79a0d-2215-4a7c-ae8d-1886c3ef5ebd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    0.5 * cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +  # Modified line\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = np.tanh((f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10))  # Modified line\n                    mutation_rate = 0.1 * adaptive_factor * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine the mutation strategy and improve velocity update for enhanced exploration and convergence.", "configspace": "", "generation": 11, "fitness": 0.8991338206899001, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.019. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "0633b858-5ef4-4972-ac60-7b5bca4fb747", "metadata": {"aucs": [0.8950229532163497, 0.878664455651591, 0.9237140532017598], "final_y": [0.11698743590972194, 0.12065018205146338, 0.11147761908351517]}, "mutation_prompt": null}
{"id": "3cdddff1-e38a-4c97-aa43-e38ad993acaf", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = (f_value - global_best_value) / (np.std(personal_best_value) + 1e-10)\n                    mutation_rate = 0.1 * adaptive_factor * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by introducing adaptive mutation noise based on dynamic population variance.", "configspace": "", "generation": 11, "fitness": 0.8837137952103445, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.005. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "0633b858-5ef4-4972-ac60-7b5bca4fb747", "metadata": {"aucs": [0.877261048709758, 0.8893597531133342, 0.8845205838079417], "final_y": [0.12530593029434278, 0.11731482737534915, 0.12199882816587371]}, "mutation_prompt": null}
{"id": "9a0eae75-7614-454a-9695-e1c227cf24fc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Adjusted mutation strategy\n                if np.random.rand() < 0.25:\n                    mutation_strength = (f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10)\n                    mutation_rate = 0.15 * adaptive_factor * mutation_strength\n                    mutation = np.random.laplace(0, mutation_rate, self.dim)  # Change 1\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.02:  # Change 2 and 3\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration through hybrid mutation and adaptive randomization to efficiently escape local optima.", "configspace": "", "generation": 12, "fitness": 0.8910934680519595, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.013. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "6824b348-a01b-43f8-94a1-2ab0222afa10", "metadata": {"aucs": [0.8754913134799105, 0.8908711460032485, 0.9069179446727194], "final_y": [0.1287867986287451, 0.11837871243092546, 0.1132356268698601]}, "mutation_prompt": null}
{"id": "a80de81b-3ba8-4920-93f5-ace87b81ac82", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = (f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10)\n                    diversity = np.std(swarm, axis=0).mean()  # New line added\n                    mutation_rate = 0.1 * adaptive_factor * mutation_strength * diversity\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01:\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive mutation rate based on the diversity of the swarm to enhance exploration and convergence.", "configspace": "", "generation": 12, "fitness": 0.8835131943099818, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.029. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "6824b348-a01b-43f8-94a1-2ab0222afa10", "metadata": {"aucs": [0.9048254449189953, 0.84217124469565, 0.9035428933153], "final_y": [0.11572460631999792, 0.1394678420083525, 0.11964251459287667]}, "mutation_prompt": null}
{"id": "058403d4-459e-4c06-8d07-f19b9aaa3f14", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2) if np.random.rand() > 0.05 else 0.9 # Adjusted line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = (f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10)\n                    mutation_rate = 0.1 * adaptive_factor * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01:\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adjust inertia weight dynamically based on global improvement to balance exploration and exploitation.", "configspace": "", "generation": 12, "fitness": 0.8686021612567981, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.049. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "6824b348-a01b-43f8-94a1-2ab0222afa10", "metadata": {"aucs": [0.807453731544048, 0.87224763776155, 0.9261051144647964], "final_y": [0.15341464905145308, 0.12868906320732543, 0.11117389837959657]}, "mutation_prompt": null}
{"id": "5901ff9f-a3a2-44e7-946e-5ca4ded22274", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = (f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10)\n                    mutation_rate = 0.1 * adaptive_factor * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):  # Changed line\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by dynamically adjusting probability of reinitialization based on progress.", "configspace": "", "generation": 12, "fitness": 0.9025073868869372, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.004. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "6824b348-a01b-43f8-94a1-2ab0222afa10", "metadata": {"aucs": [0.9064707174426385, 0.9042179316941968, 0.8968335115239763], "final_y": [0.11337125156211458, 0.11386553035453495, 0.11114660882084748]}, "mutation_prompt": null}
{"id": "0c131522-77d9-4475-a2e8-e54061e3dd16", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.3:  # Changed probability of mutation from 0.2 to 0.3\n                    mutation_strength = (f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10)\n                    mutation_rate = 0.1 * adaptive_factor * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01:\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved exploration by increasing the mutation probability for better global search capabilities.", "configspace": "", "generation": 12, "fitness": 0.8983460151280119, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.005. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6824b348-a01b-43f8-94a1-2ab0222afa10", "metadata": {"aucs": [0.9058474126851925, 0.8944684820364599, 0.8947221506623834], "final_y": [0.11054250805303656, 0.11788296002140808, 0.1153505920230754]}, "mutation_prompt": null}
{"id": "3888afb9-cd01-43a2-a2e3-efd751a150ad", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 1.1 * adaptive_factor  # Changed line\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = (f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10)\n                    mutation_rate = 0.15 * adaptive_factor * mutation_strength  # Changed line\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by dynamically adjusting both mutation and learning rates based on progress.", "configspace": "", "generation": 13, "fitness": 0.9078113141499303, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.007. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "5901ff9f-a3a2-44e7-946e-5ca4ded22274", "metadata": {"aucs": [0.9150888309390841, 0.9095431099774713, 0.8988020015332355], "final_y": [0.11341684793672147, 0.11670146450416385, 0.11320282783576141]}, "mutation_prompt": null}
{"id": "65011a29-3525-48a0-9d64-40989a58d921", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = (f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10)\n                    mutation_rate = 0.1 * adaptive_factor * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * adaptive_factor:  # Changed line\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by introducing a dynamic mutation rate that decreases linearly over time.", "configspace": "", "generation": 13, "fitness": 0.9018460353730581, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.009. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5901ff9f-a3a2-44e7-946e-5ca4ded22274", "metadata": {"aucs": [0.8947625799790326, 0.8964375352084512, 0.9143379909316902], "final_y": [0.11070242009442854, 0.12040012232175201, 0.11238466434956318]}, "mutation_prompt": null}
{"id": "d4bc391c-2f8c-4910-bd86-07af581dc102", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = (f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10)\n                    mutation_rate = 0.1 * (1 - adaptive_factor) * mutation_strength  # Changed line\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improve convergence by adjusting mutation rate based on exploration progress.", "configspace": "", "generation": 13, "fitness": 0.9095274642398317, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.014. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5901ff9f-a3a2-44e7-946e-5ca4ded22274", "metadata": {"aucs": [0.893194970430277, 0.9087134134478105, 0.9266740088414074], "final_y": [0.11673498173679908, 0.1162993871555219, 0.10984340111262958]}, "mutation_prompt": null}
{"id": "291edbeb-7ff3-459e-9063-bdcbd7e020ee", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = (f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10)\n                    mutation_rate = 0.1 * adaptive_factor * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):  # Changed line\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n                else:  # Added line for adaptive mutation\n                    swarm[i] += adaptive_factor * np.random.normal(0, 0.1, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive mutation to enhance exploration based on individual progress toward a global best.", "configspace": "", "generation": 13, "fitness": 0.886728158235098, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.010. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5901ff9f-a3a2-44e7-946e-5ca4ded22274", "metadata": {"aucs": [0.8736031613408755, 0.8992347210803848, 0.8873465922840337], "final_y": [0.1238971813489621, 0.11858899631738296, 0.11534239329065343]}, "mutation_prompt": null}
{"id": "4ba61128-86ce-47da-bf84-b4cb71ac75a1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = (f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10)\n                    mutation_rate = 0.1 * adaptive_factor * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate * 2, self.dim)  # Changed line\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor): \n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine swarm selection by enhancing mutation strategy to improve solution diversity.", "configspace": "", "generation": 13, "fitness": 0.8836879198601029, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.024. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "5901ff9f-a3a2-44e7-946e-5ca4ded22274", "metadata": {"aucs": [0.8500954525554244, 0.8987891441148539, 0.9021791629100302], "final_y": [0.12968877559854342, 0.12032934455405808, 0.11545473619373303]}, "mutation_prompt": null}
{"id": "b5261245-aa72-4217-8b78-ccd7a7801825", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = (f_value - np.mean(personal_best_value)) / (np.max(personal_best_value) - global_best_value + 1e-10)  # Changed line\n                    mutation_rate = 0.1 * (1 - adaptive_factor) * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improve mutation exploration by dynamically adjusting mutation rate with respect to the best and average population fitness.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_id": "d4bc391c-2f8c-4910-bd86-07af581dc102", "metadata": {}, "mutation_prompt": null}
{"id": "89d1691d-c65e-404c-9c20-8c038e1c64d9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.cos(np.pi * adaptive_factor**3)  # Changed line (1)\n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor  # Changed line (2)\n            social_coeff = 1.0 + 0.5 * np.sin(np.pi * adaptive_factor)  # Changed line (3)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.3:  # Changed line (4)\n                    mutation_strength = (f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10)\n                    mutation_rate = 0.2 * (1 - adaptive_factor) * mutation_strength  # Changed line (5)\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by dynamically adjusting both mutation rate and inertia based on an adaptive exploration-exploitation balance mechanism.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_id": "d4bc391c-2f8c-4910-bd86-07af581dc102", "metadata": {}, "mutation_prompt": null}
{"id": "dc7bf13d-0a06-4dfb-8ebf-16ccbac70352", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            neighborhood_influence = np.random.uniform(0.1, 0.3) * adaptive_factor  # New line\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighbor_index = np.random.choice(current_population_size)  # New line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) + \n                                    neighborhood_influence * (swarm[neighbor_index] - swarm[i]))  # Modified line\n                                    \n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = (f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10)\n                    mutation_rate = 0.1 * (1 - adaptive_factor) * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by introducing dynamic neighborhood influence and adaptive velocity scaling to the swarm.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_id": "d4bc391c-2f8c-4910-bd86-07af581dc102", "metadata": {}, "mutation_prompt": null}
{"id": "36f1e267-af3d-4a45-aff9-539a93f0db2a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = (f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10)\n                    mutation_rate = 0.1 * (1 - adaptive_factor**2) * mutation_strength  # Changed line\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by incrementally reducing mutation rate as evaluations progress.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_id": "d4bc391c-2f8c-4910-bd86-07af581dc102", "metadata": {}, "mutation_prompt": null}
{"id": "7033a32b-f567-45d2-9422-007f4ff62836", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = (f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10)\n                    mutation_rate = 0.1 * (1 - adaptive_factor) * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n\n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n                    if np.random.rand() < 0.05:  # New line introducing perturbation\n                        global_best += np.random.normal(0, 0.01, self.dim)  # New line to improve diversity\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance solution diversity and convergence by introducing random global best perturbation and dynamic learning rate adaptation.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_id": "d4bc391c-2f8c-4910-bd86-07af581dc102", "metadata": {}, "mutation_prompt": null}
{"id": "886bb3fc-0fbb-4282-a1bf-0e9479c8584a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    f_diff = np.max(personal_best_value) - global_best_value + 1e-10\n                    mutation_strength = max(0, (f_value - np.mean(personal_best_value)) / f_diff)  # Changed line\n                    mutation_rate = 0.1 * (1 - adaptive_factor) * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance mutation adaptability by correctly normalizing mutation strength to avoid negative scales.", "configspace": "", "generation": 15, "fitness": 0.8946098594427149, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.018. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b5261245-aa72-4217-8b78-ccd7a7801825", "metadata": {"aucs": [0.9173278265839608, 0.8738004203171734, 0.8927013314270105], "final_y": [0.1116885462384255, 0.12130059870495968, 0.1161082175470064]}, "mutation_prompt": null}
{"id": "c075e188-c238-4cd3-85d9-bc789317ac56", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    # Normalized mutation strength to prevent negative scale\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.1 * (1 - adaptive_factor) * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine mutation exploration by normalizing mutation strength to prevent negative scale values.", "configspace": "", "generation": 15, "fitness": 0.9107169101650544, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.008. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "b5261245-aa72-4217-8b78-ccd7a7801825", "metadata": {"aucs": [0.9101764519227418, 0.9018001139205006, 0.9201741646519209], "final_y": [0.11086016154465306, 0.11669167133253544, 0.11033760187495345]}, "mutation_prompt": null}
{"id": "1c0bc8f4-528f-449f-bbe9-cfb497a6e9d5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = (f_value - np.mean(personal_best_value)) / \\\n                                        (np.max(personal_best_value) - global_best_value + 1e-10)\n                    mutation_rate = np.clip(0.1 * (1 - adaptive_factor) * mutation_strength, 0, 1)  # Changed line\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by refining the mutation strategy using a bounded mutation rate for stability.", "configspace": "", "generation": 15, "fitness": 0.9034515993933665, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.003. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b5261245-aa72-4217-8b78-ccd7a7801825", "metadata": {"aucs": [0.902521688943348, 0.9074223998929758, 0.9004107093437757], "final_y": [0.11511729159145856, 0.11707833644942456, 0.11691498571758774]}, "mutation_prompt": null}
{"id": "c0cd965d-e523-4caa-ab73-ab0dd46cd757", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    mutation_strength = max(0.1, (f_value - np.mean(personal_best_value)) / (np.max(personal_best_value) - global_best_value + 1e-10))  # Changed line\n                    mutation_rate = 0.1 * (1 - adaptive_factor) * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    random_walk_strength = 0.05 * adaptive_factor  # Changed line\n                    swarm[i] = np.clip(swarm[i] + np.random.uniform(-random_walk_strength, random_walk_strength, self.dim), lb, ub)  # Changed line\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance mutation strategy by ensuring mutation strength is always positive and improving exploration with random walks.", "configspace": "", "generation": 15, "fitness": 0.9053894489174227, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.013. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b5261245-aa72-4217-8b78-ccd7a7801825", "metadata": {"aucs": [0.8877725697580848, 0.9090760599360934, 0.9193197170580896], "final_y": [0.11777470292473302, 0.11470189712723144, 0.11275292143139459]}, "mutation_prompt": null}
{"id": "bbb029de-aa64-4bd2-960f-432fa2bcbd3b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2 * adaptive_factor:  # Changed line\n                    mutation_strength = max(0, (f_value - global_best_value) / (np.max(personal_best_value) - global_best_value + 1e-10))  # Changed line\n                    mutation_rate = 0.1 * adaptive_factor * mutation_strength  # Changed line\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by refining mutation strength calculation and introducing a dynamic mutation probability.", "configspace": "", "generation": 15, "fitness": 0.8921708594129897, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.007. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b5261245-aa72-4217-8b78-ccd7a7801825", "metadata": {"aucs": [0.8858312608037527, 0.8880240986416215, 0.9026572187935948], "final_y": [0.12358090063508942, 0.12149676761610029, 0.1132521592771436]}, "mutation_prompt": null}
{"id": "2c7ffcbb-fe0f-4891-87d2-ef8773da2497", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(2 * np.pi * adaptive_factor**2)  # Modified line\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    # Normalized mutation strength to prevent negative scale\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.1 * (1 - adaptive_factor) * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive inertia weight fluctuation for better exploration and exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.8785207421089144, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.022. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "c075e188-c238-4cd3-85d9-bc789317ac56", "metadata": {"aucs": [0.8509621081885422, 0.8788953732935767, 0.905704744844624], "final_y": [0.13649137704113967, 0.12697488502794907, 0.11274394267006427]}, "mutation_prompt": null}
{"id": "5c511255-cfb9-4559-acd7-450d69b912ab", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget)**1.5  # Non-linear cooling\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.1 * (1 - adaptive_factor) * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a non-linear adaptive cooling schedule to enhance swarm diversity and exploration capabilities.", "configspace": "", "generation": 16, "fitness": 0.893081210085407, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.011. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c075e188-c238-4cd3-85d9-bc789317ac56", "metadata": {"aucs": [0.9047310089744052, 0.8957676095569833, 0.8787450117248323], "final_y": [0.1133606141999326, 0.11978923580801859, 0.119203920818169]}, "mutation_prompt": null}
{"id": "7f46907a-8881-4b39-8d4a-a156186e6cb1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor**2)  # Modified\n            cognitive_coeff = 1.8 * adaptive_factor  # Modified\n            social_coeff = 1.0 + 0.3 * np.cos(np.pi * adaptive_factor)  # Modified\n            learning_rate = 0.15 + 0.85 * adaptive_factor  # Modified\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.1 * (1 - adaptive_factor) * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm convergence by optimizing learning rates and exploration to improve adaptive mutation strategy.", "configspace": "", "generation": 16, "fitness": 0.9024110926275517, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.015. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c075e188-c238-4cd3-85d9-bc789317ac56", "metadata": {"aucs": [0.8873232243111142, 0.8979035749239879, 0.9220064786475531], "final_y": [0.11822649096430993, 0.11862661940315622, 0.1109501674758856]}, "mutation_prompt": null}
{"id": "5f536bfb-cc11-41fe-ab68-522dfe8a2354", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        prev_global_best_value = global_best_value\n        global_convergence_rate = 0\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.6 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    # Dynamic mutation strength scaling based on global best convergence rate\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    global_convergence_rate = abs(global_best_value - prev_global_best_value) / (prev_global_best_value + 1e-10)\n                    mutation_rate = 0.1 * (1 - adaptive_factor) * mutation_strength * (1 + global_convergence_rate)\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n            prev_global_best_value = global_best_value\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance diversity by introducing dynamic mutation strength scaling based on global best convergence rate.", "configspace": "", "generation": 16, "fitness": 0.8889800087457903, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.026. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c075e188-c238-4cd3-85d9-bc789317ac56", "metadata": {"aucs": [0.8569260461719368, 0.8904186424905434, 0.9195953375748905], "final_y": [0.1283777653321977, 0.12218558977310856, 0.11106606693907584]}, "mutation_prompt": null}
{"id": "06c463f1-3a40-477d-8399-251b08e39a61", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            diversity = np.mean(np.std(swarm, axis=0)) / (np.max(ub) - np.min(lb))\n            inertia_weight = 0.5 + 0.3 * np.sin(np.pi * adaptive_factor**3) + 0.2 * diversity\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.0 + 0.5 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    # Modified mutation rate based on diversity\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.1 * (1 - adaptive_factor) * mutation_strength * diversity\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic inertia weight and mutation rate based on the swarm's diversity to enhance exploration and exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.8844726640379711, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.025. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c075e188-c238-4cd3-85d9-bc789317ac56", "metadata": {"aucs": [0.8562074084208087, 0.8794192279644624, 0.9177913557286422], "final_y": [0.12803871132066602, 0.11986619480919114, 0.11052332415259614]}, "mutation_prompt": null}
{"id": "b7645fd0-68b3-43c0-9622-5b42d5c4d40e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.5 * np.sin(np.pi * adaptive_factor**2)  # Modified\n            cognitive_coeff = 2.0 * adaptive_factor  # Modified\n            social_coeff = 1.2 + 0.2 * np.cos(np.pi * adaptive_factor)  # Modified\n            learning_rate = 0.2 + 0.8 * adaptive_factor  # Modified\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.4 * adaptive_factor))  # Modified\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.25:  # Modified\n                    mutation_strength = (f_value - np.median(personal_best_value)) / (np.max(personal_best_value) - np.min(personal_best_value) + 1e-10)  # Modified\n                    mutation_rate = 0.15 * (1 - adaptive_factor) * mutation_strength  # Modified\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm convergence by refining inertia, cognitive, and social coefficients and introducing dynamic mutation strategies.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_id": "7f46907a-8881-4b39-8d4a-a156186e6cb1", "metadata": {}, "mutation_prompt": null}
{"id": "68949a91-d6e6-4e6b-8222-69c53a762bd5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.8 * adaptive_factor\n            social_coeff = 1.0 + 0.3 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.15 + 0.85 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.3:  # Modified\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.05 * (1 - adaptive_factor) * mutation_strength  # Modified\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine velocity update and swarm mutation to enhance exploration and convergence.", "configspace": "", "generation": 17, "fitness": 0.9000330958352741, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.012. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "7f46907a-8881-4b39-8d4a-a156186e6cb1", "metadata": {"aucs": [0.8838068320684294, 0.910441556168169, 0.9058508992692238], "final_y": [0.12435083061694929, 0.11386888997443789, 0.11543493101978097]}, "mutation_prompt": null}
{"id": "c5adcaad-70d0-45ed-911e-bffc7893fbdb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor**2)  # Modified\n            cognitive_coeff = 1.8 * adaptive_factor  # Modified\n            social_coeff = 1.0 + 0.3 * np.cos(np.pi * adaptive_factor)  # Modified\n            learning_rate = 0.15 + 0.85 * adaptive_factor  # Modified\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= 0.9 + 0.1 * np.cos(np.pi * adaptive_factor)  # New line\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.1 * (1 - adaptive_factor) * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive deceleration by dynamically adjusting velocity decay based on evaluation progress.", "configspace": "", "generation": 17, "fitness": 0.885776362677578, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.019. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "7f46907a-8881-4b39-8d4a-a156186e6cb1", "metadata": {"aucs": [0.8869703376994647, 0.8623306365761059, 0.9080281137571635], "final_y": [0.12359169075590681, 0.13135800435285072, 0.11452162227617046]}, "mutation_prompt": null}
{"id": "d033e230-eb45-4a7c-b5c5-30b7c3d674ef", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor**2)  # Modified\n            cognitive_coeff = 1.9 * adaptive_factor  # Modified\n            social_coeff = 0.9 + 0.5 * np.cos(np.pi * adaptive_factor)  # Modified\n            learning_rate = 0.15 + 0.85 * adaptive_factor  # Modified\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.2:\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.1 * (1 - adaptive_factor) * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.01 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improve convergence speed and accuracy by refining adaptive factors for cognitive and social coefficients.", "configspace": "", "generation": 17, "fitness": 0.8908477907116185, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.018. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "7f46907a-8881-4b39-8d4a-a156186e6cb1", "metadata": {"aucs": [0.8665228738348136, 0.8946892214091863, 0.9113312768908555], "final_y": [0.12559771228779937, 0.12065245661058277, 0.11414420020619176]}, "mutation_prompt": null}
{"id": "ecadb201-7fd7-4a4d-b3e4-bc416f761c1c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.sin(np.pi * adaptive_factor**2)  # Modified coefficient\n            cognitive_coeff = 1.6 * adaptive_factor  # Modified coefficient\n            social_coeff = 1.2 + 0.2 * np.cos(np.pi * adaptive_factor)  # Modified coefficient\n            learning_rate = 0.1 + 0.9 * adaptive_factor  # Modified coefficient\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.6 * adaptive_factor))  # Modified population scaling\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_influence = 0.5 + 0.5 * np.random.rand()  # New term for diversity\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) * neighborhood_influence)\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.2 * (1 - adaptive_factor) * mutation_strength  # Modified mutation rate\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.02 * (1 - adaptive_factor):  # Modified reinitialization probability\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine swarm dynamics by introducing adaptive diversity control based on convergence rate and dynamic neighborhood influence adjustment.", "configspace": "", "generation": 17, "fitness": 0.9080371921856997, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.014. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "7f46907a-8881-4b39-8d4a-a156186e6cb1", "metadata": {"aucs": [0.9075979626054118, 0.891725912778124, 0.9247877011735633], "final_y": [0.11283293718057463, 0.12293045728368657, 0.11152219469722413]}, "mutation_prompt": null}
{"id": "5f497775-6565-4938-8619-37a3350aa610", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.6 * (adaptive_factor ** 0.5)  # Modified coefficient\n            social_coeff = 1.2 + 0.2 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.6 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_influence = 0.5 + 0.5 * np.random.rand()\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) * neighborhood_influence)\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.2 * (1 - adaptive_factor) * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.02 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a nonlinear time-varying cognitive coefficient for improved convergence in varied problem landscapes.", "configspace": "", "generation": 18, "fitness": 0.8928945302204881, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.014. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "ecadb201-7fd7-4a4d-b3e4-bc416f761c1c", "metadata": {"aucs": [0.9043944383561668, 0.873451734585848, 0.9008374177194499], "final_y": [0.11762237805841969, 0.12180689371108, 0.11216950594899866]}, "mutation_prompt": null}
{"id": "d9a0764a-9bdd-4093-8880-7025b21af166", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.sin(np.pi * adaptive_factor**2) + 0.2 * (1 - global_best_value)  # Modified coefficient\n            cognitive_coeff = 1.6 * adaptive_factor  # Modified coefficient\n            social_coeff = 1.2 + 0.2 * np.cos(np.pi * adaptive_factor)  # Modified coefficient\n            learning_rate = 0.1 + 0.9 * adaptive_factor  # Modified coefficient\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.6 * adaptive_factor))  # Modified population scaling\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_influence = 0.5 + 0.5 * np.random.rand()  # New term for diversity\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) * neighborhood_influence)\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.2 * (1 - adaptive_factor) * mutation_strength  # Modified mutation rate\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.02 * (1 - adaptive_factor):  # Modified reinitialization probability\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic inertia weight adjustment based on fitness improvement rate for added convergence precision.", "configspace": "", "generation": 18, "fitness": 0.8893487625281722, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.006. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ecadb201-7fd7-4a4d-b3e4-bc416f761c1c", "metadata": {"aucs": [0.8817809297718073, 0.8902511768406326, 0.8960141809720765], "final_y": [0.11735734004747655, 0.12092726418826583, 0.11632254756413074]}, "mutation_prompt": null}
{"id": "02d1585d-38c5-4e97-9348-dd680b499290", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * np.sin(np.pi * adaptive_factor**2)\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.2 + 0.2 * np.cos(np.pi * adaptive_factor) \n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.6 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_influence = 0.5 + 0.5 * np.random.rand()\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) * neighborhood_influence)\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = np.sqrt((f_value - min_pbv) / (max_pbv - min_pbv + 1e-10))  # Modified mutation strength\n                    mutation_rate = 0.2 * (1 - adaptive_factor) * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.02 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarming dynamics by refining local-global balance through adaptive velocity scaling and diversity-induced mutation.", "configspace": "", "generation": 18, "fitness": 0.8918687526809678, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.009. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "ecadb201-7fd7-4a4d-b3e4-bc416f761c1c", "metadata": {"aucs": [0.8927432023998197, 0.8800223683378099, 0.9028406873052736], "final_y": [0.11574177257593066, 0.12149672975020054, 0.11262697479384409]}, "mutation_prompt": null}
{"id": "444a7e0c-2d13-4691-9822-8aa96ef455dd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor**2)  # Modified coefficient\n            cognitive_coeff = 1.6 * adaptive_factor\n            social_coeff = 1.2 + 0.2 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.1 + 0.9 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.6 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_influence = 0.5 + 0.5 * np.random.rand()\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) * neighborhood_influence)\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.2 * (1 - adaptive_factor) * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.02 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm exploration by dynamically varying inertia and mutating global best to prevent premature convergence.", "configspace": "", "generation": 18, "fitness": 0.8725201382564993, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.033. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "ecadb201-7fd7-4a4d-b3e4-bc416f761c1c", "metadata": {"aucs": [0.8251925110758418, 0.8965554810262407, 0.8958124226674153], "final_y": [0.14548083354748542, 0.11687607746435136, 0.11356122680664493]}, "mutation_prompt": null}
{"id": "d5730be0-8586-4e7d-b547-8ba42289bc5a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.5 * np.sin(np.pi * adaptive_factor**1.5)  # Adjusted coefficient\n            cognitive_coeff = 1.4 * adaptive_factor  # Adjusted coefficient\n            social_coeff = 1.5 + 0.2 * np.cos(np.pi * adaptive_factor)  # Adjusted coefficient\n            learning_rate = 0.1 + 0.8 * adaptive_factor  # Adjusted coefficient\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))  # Adjusted scaling\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_influence = 0.6 + 0.4 * np.random.rand()  # Adjusted term for diversity\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) * neighborhood_influence)\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.12:  # Adjusted mutation probability\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.25 * (1 - adaptive_factor) * mutation_strength  # Adjusted mutation rate\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.03 * (1 - adaptive_factor):  # Adjusted reinitialization probability\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm algorithm with improved neighborhood influence and dynamic inertia adapting based on exploration-exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.8987465353451856, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.019. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "ecadb201-7fd7-4a4d-b3e4-bc416f761c1c", "metadata": {"aucs": [0.8873717629511678, 0.8826831091827294, 0.9261847339016596], "final_y": [0.1234055465613152, 0.11937215270101897, 0.11083880394030388]}, "mutation_prompt": null}
{"id": "f70ca5e7-bdb7-44f7-8e95-6bb5d2b4bda5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.5 * np.sin(np.pi * adaptive_factor**1.5)  # Adjusted coefficient\n            cognitive_coeff = 1.4 * adaptive_factor  # Adjusted coefficient\n            social_coeff = 1.5 + 0.2 * np.cos(np.pi * adaptive_factor)  # Adjusted coefficient\n            learning_rate = 0.1 + 0.8 * adaptive_factor  # Adjusted coefficient\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))  # Adjusted scaling\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_influence = 0.6 + 0.4 * np.random.rand()  # Adjusted term for diversity\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) * neighborhood_influence)\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.12:  # Adjusted mutation probability\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.25 * (1 - adaptive_factor) * mutation_strength  # Adjusted mutation rate\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.03 * (1 - adaptive_factor):  # Adjusted reinitialization probability\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if np.abs(global_best_value - f_value) < 1e-6:  # Added early stopping criterion\n                    return global_best, global_best_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm algorithm with an early stopping mechanism based on convergence detection and modified dynamic inertia adapting to improve convergence speed and solution quality.", "configspace": "", "generation": 19, "fitness": 0.825102134012598, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.108. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.043.", "error": "", "parent_id": "d5730be0-8586-4e7d-b547-8ba42289bc5a", "metadata": {"aucs": [0.6737438162512668, 0.9133748424046025, 0.8881877433819249], "final_y": [0.21185908847573987, 0.11699778427327123, 0.12329986616628752]}, "mutation_prompt": null}
{"id": "97043fd2-01f9-4348-a9d9-2d1d79900d1d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.5 * np.sin(np.pi * adaptive_factor**1.5)  # Adjusted coefficient\n            cognitive_coeff = 1.4 * adaptive_factor  # Adjusted coefficient\n            social_coeff = 1.5 + 0.2 * np.cos(np.pi * adaptive_factor)  # Adjusted coefficient\n            learning_rate = 0.1 + 0.8 * adaptive_factor  # Adjusted coefficient\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))  # Adjusted scaling\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_influence = 0.6 + 0.4 * np.random.rand()  # Adjusted term for diversity\n                local_search_bias = np.random.uniform(-0.05, 0.05, self.dim)  # New local search bias\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) * neighborhood_influence + \n                                    local_search_bias)  # Enhanced update\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.12:  # Adjusted mutation probability\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    fitness_variance = np.var(personal_best_value)  # New fitness variance\n                    mutation_rate = 0.25 * (1 - adaptive_factor) * mutation_strength * fitness_variance  # Refined mutation rate\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.03 * (1 - adaptive_factor):  # Adjusted reinitialization probability\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive mutation based on fitness variance and enhance velocity update with local search bias.", "configspace": "", "generation": 19, "fitness": 0.8795595761681412, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.004. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d5730be0-8586-4e7d-b547-8ba42289bc5a", "metadata": {"aucs": [0.8801584808481588, 0.8741090068421824, 0.8844112408140823], "final_y": [0.12696297412230506, 0.12683041094706804, 0.12666088077182058]}, "mutation_prompt": null}
{"id": "501f0c1c-39a0-492f-a0e8-b0235feae7da", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor**1.3)  # Modified coefficient\n            cognitive_coeff = 1.2 * adaptive_factor  # Modified coefficient\n            social_coeff = 1.7 + 0.1 * np.cos(np.pi * adaptive_factor)  # Modified coefficient\n            learning_rate = 0.15 + 0.7 * adaptive_factor  # Modified coefficient\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.6 * adaptive_factor))  # Modified scaling\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_influence = 0.7 + 0.3 * np.random.rand()  # Modified term for diversity\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) * neighborhood_influence)\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:  # Modified mutation probability\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.2 * (1 - adaptive_factor) * mutation_strength  # Modified mutation rate\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.04 * (1 - adaptive_factor):  # Modified reinitialization probability\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm algorithm with adaptive velocity scaling, dynamic neighborhood size, and improved mutation for balanced exploration-exploitation.", "configspace": "", "generation": 19, "fitness": 0.9184737673550343, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.010. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d5730be0-8586-4e7d-b547-8ba42289bc5a", "metadata": {"aucs": [0.9059473700922673, 0.9187279064627228, 0.9307460255101129], "final_y": [0.11923249228336552, 0.11403789972990352, 0.11213952815239547]}, "mutation_prompt": null}
{"id": "51dcef23-d220-48a4-8617-b511f56199ec", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.5 * np.sin(np.pi * adaptive_factor**1.5)\n            cognitive_coeff = 1.4 * adaptive_factor\n            social_coeff = 1.5 + 0.2 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.15 + 0.75 * adaptive_factor  # Adjusted learning rate\n\n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_influence = 0.6 + 0.4 * np.random.rand()\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) * neighborhood_influence)\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.12:\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.25 * (1 - adaptive_factor) * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.03 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved swarm algorithm with adaptive factors tuned for enhanced convergence and exploration-exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.9006912266758853, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.022. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "d5730be0-8586-4e7d-b547-8ba42289bc5a", "metadata": {"aucs": [0.8904482794901011, 0.8801461924352336, 0.9314792081023211], "final_y": [0.11385218316617896, 0.12678966250999468, 0.1112836741767872]}, "mutation_prompt": null}
{"id": "39d4dfd7-26a2-4c88-9025-d5c00fe23c7c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.4 + 0.5 * np.sin(np.pi * adaptive_factor**1.5)  # Adjusted coefficient\n            cognitive_coeff = 1.4 * adaptive_factor  # Adjusted coefficient\n            social_coeff = 1.5 + 0.2 * np.cos(np.pi * adaptive_factor)  # Adjusted coefficient\n            learning_rate = 0.1 + 0.8 * adaptive_factor  # Adjusted coefficient\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.5 * adaptive_factor))  # Adjusted scaling\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_influence = 0.6 + 0.4 * np.random.rand()  # Adjusted term for diversity\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) * neighborhood_influence)\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.14:  # Adjusted mutation probability\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.25 * (1 - adaptive_factor) * mutation_strength  # Adjusted mutation rate\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.03 * (1 - adaptive_factor):  # Adjusted reinitialization probability\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Slightly increased the mutation probability to enhance diversity and escape local optima.", "configspace": "", "generation": 19, "fitness": 0.9045374834964083, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.015. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "d5730be0-8586-4e7d-b547-8ba42289bc5a", "metadata": {"aucs": [0.8853629224738044, 0.9075872013519546, 0.9206623266634657], "final_y": [0.12582079791435108, 0.11543171208606484, 0.11251493832029924]}, "mutation_prompt": null}
{"id": "d55cbdc7-379b-44bd-9bac-72052ab1a166", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor**1.3)\n            cognitive_coeff = 1.2 * adaptive_factor\n            social_coeff = 1.7 + 0.1 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.15 + 0.7 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.6 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_influence = 0.7 + 0.3 * np.random.rand()\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) * neighborhood_influence)\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.2 * (1 - adaptive_factor * np.mean(self.velocity)) * mutation_strength  # Modified mutation rate\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.04 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved mutation strategy by adjusting mutation rate based on both adaptive factor and diversity within the swarm.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_id": "501f0c1c-39a0-492f-a0e8-b0235feae7da", "metadata": {}, "mutation_prompt": null}
{"id": "f0d1d6d0-cb18-4fb9-a61e-925078508ca6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor**1.3)\n            cognitive_coeff = 1.2 * adaptive_factor\n            social_coeff = 1.7 + 0.1 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.15 + 0.7 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.6 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_influence = 0.7 + 0.3 * np.random.rand()\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) * neighborhood_influence)\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15 * (1 - adaptive_factor):  # Modified mutation probability\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.2 * (1 - adaptive_factor) * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.04 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic mutation probability based on adaptive factor to improve exploration-exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.9128458587628137, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "501f0c1c-39a0-492f-a0e8-b0235feae7da", "metadata": {"aucs": [0.9062428244748812, 0.9048265712015034, 0.927468180612056], "final_y": [0.11757343167699574, 0.11782907582817248, 0.11291149656152522]}, "mutation_prompt": null}
{"id": "7b91b2ae-d590-4fdc-b688-8f1643f55a76", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * adaptive_factor**1.2)  # Modified coefficient\n            cognitive_coeff = 1.2 * adaptive_factor\n            social_coeff = 1.7 + 0.1 * np.cos(np.pi * adaptive_factor)\n            learning_rate = 0.15 + 0.7 * adaptive_factor\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.6 * adaptive_factor))\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_influence = 0.7 + 0.3 * np.random.rand()\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) * neighborhood_influence)\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.2 * (1 - adaptive_factor) * mutation_strength\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.04 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introducing dynamic inertia scaling for improved convergence speed in AdaptiveSwarmGradientDescent.", "configspace": "", "generation": 20, "fitness": 0.9112858731833828, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.020. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "501f0c1c-39a0-492f-a0e8-b0235feae7da", "metadata": {"aucs": [0.9203245281898781, 0.8831262951488668, 0.9304067962114034], "final_y": [0.11100655711943996, 0.12685419385817587, 0.1124973152410712]}, "mutation_prompt": null}
{"id": "07030318-5134-4ab3-be26-755a9a9bf0dc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * np.exp(-3 * adaptive_factor)  # Modified coefficient\n            cognitive_coeff = 1.2 * adaptive_factor  # Modified coefficient\n            social_coeff = 1.7 + 0.1 * np.cos(np.pi * adaptive_factor)  # Modified coefficient\n            learning_rate = 0.15 + 0.7 * adaptive_factor  # Modified coefficient\n            \n            current_population_size = int(self.initial_population_size * (1 + 0.6 * adaptive_factor))  # Modified scaling\n            self.velocity = np.resize(self.velocity, (current_population_size, self.dim))\n            swarm = np.resize(swarm, (current_population_size, self.dim))\n            \n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_influence = 0.7 + 0.3 * np.random.rand()  # Modified term for diversity\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) * neighborhood_influence)\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.15:  # Modified mutation probability\n                    min_pbv = np.min(personal_best_value)\n                    max_pbv = np.max(personal_best_value)\n                    mutation_strength = (f_value - min_pbv) / (max_pbv - min_pbv + 1e-10)\n                    mutation_rate = 0.3 * (1 - adaptive_factor) * mutation_strength  # Modified mutation rate\n                    mutation = np.random.normal(0, mutation_rate, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.04 * (1 - adaptive_factor):  # Modified reinitialization probability\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Further refined swarm algorithm with exponentially decaying inertia and enhanced mutation mechanism for improved convergence.", "configspace": "", "generation": 20, "fitness": 0.907678460427403, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.021. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "501f0c1c-39a0-492f-a0e8-b0235feae7da", "metadata": {"aucs": [0.919913646193369, 0.8784339816506234, 0.9246877534382161], "final_y": [0.11458192392896893, 0.12680347941982173, 0.1124728473494283]}, "mutation_prompt": null}
{"id": "35196cd0-bdba-4fb4-94a1-db6209cd7021", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * np.sin(adaptive_factor * np.pi)  # Adjusted strategy\n            cognitive_coeff = 1.1 + 0.5 * adaptive_factor  # Adjusted strategy\n            social_coeff = 1.8 + 0.2 * np.cos(adaptive_factor * np.pi)  # Adjusted strategy\n            learning_rate = 0.2 + 0.6 * adaptive_factor  # Adjusted strategy\n            \n            current_population_size = self.initial_population_size  # Fixed population size\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                neighborhood_influence = 0.8 + 0.2 * np.random.rand()\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.initial_population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) * neighborhood_influence)\n                swarm[i] += learning_rate * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.initial_population_size]:\n                    personal_best[i % self.initial_population_size] = swarm[i]\n                    personal_best_value[i % self.initial_population_size] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if np.random.rand() < 0.12:  # Reduced mutation probability\n                    mutation_strength = 0.3 * np.random.rand() * (1 - adaptive_factor)  # Adjusted mutation strength\n                    mutation = np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i] + mutation, lb, ub)\n                \n                if np.random.rand() < 0.05 * (1 - adaptive_factor):\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced adaptive swarm algorithm with dynamic inertia and mutation strategies that improve global convergence and diversity.", "configspace": "", "generation": 20, "fitness": 0.892295382493549, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.030. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "501f0c1c-39a0-492f-a0e8-b0235feae7da", "metadata": {"aucs": [0.8530120963016162, 0.8997198342285337, 0.9241542169504967], "final_y": [0.1319908982531388, 0.12022523366409232, 0.11367830132398726]}, "mutation_prompt": null}
