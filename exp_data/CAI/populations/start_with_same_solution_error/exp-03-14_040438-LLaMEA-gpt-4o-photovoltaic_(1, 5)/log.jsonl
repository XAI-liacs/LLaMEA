{"id": "382b74e4-4be9-42a3-816c-887a2723ca66", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "4e209480-d433-46a4-a2e7-b2af53856a71", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor + 0.5\n            social_coeff = 1.5 * (1 - adaptive_factor) + 0.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces dynamic cognitive and social coefficients for improved convergence.", "configspace": "", "generation": 1, "fitness": 0.8956327882325693, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.039. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "382b74e4-4be9-42a3-816c-887a2723ca66", "metadata": {"aucs": [0.8451396340193785, 0.9022388263941604, 0.9395199042841686], "final_y": [0.12649229519943328, 0.11643017700755676, 0.1097172108192418]}, "mutation_prompt": null}
{"id": "ff324817-cd3f-49a7-8b21-a57eb796f970", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.diversity_rate = 0.1  # New parameter for diversity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.0 + 0.5 * adaptive_factor  # Updated learning rate\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                if np.random.random() < self.diversity_rate:  # Diversity mechanism\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces dynamic learning rates and a diversity-preserving mechanism for improved exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.8838706301670194, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.053. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "382b74e4-4be9-42a3-816c-887a2723ca66", "metadata": {"aucs": [0.811853442316066, 0.9041070657255207, 0.9356513824594715], "final_y": [0.14924560938426612, 0.11854764685637154, 0.11002450359829674]}, "mutation_prompt": null}
{"id": "135c0b2f-a091-4cea-ab9a-613fbe5ad455", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * adaptive_factor  # Adjusted inertia weight range\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    # Reintroduce diversity when new global best found\n                    swarm += np.random.normal(0, 0.1, swarm.shape)\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Integrates dynamic learning rate adjustment and diversity preservation to improve search effectiveness and convergence.", "configspace": "", "generation": 1, "fitness": 0.8447410073461296, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.005. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "382b74e4-4be9-42a3-816c-887a2723ca66", "metadata": {"aucs": [0.8394951790910712, 0.8514973300811062, 0.8432305128662112], "final_y": [0.14076574755263116, 0.12821409439263864, 0.12901918239914223]}, "mutation_prompt": null}
{"id": "818bb534-b79d-4dcc-ac0e-7cdc633f9bd3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1, 1, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Incorporates dynamic population size and adaptive mutation to better balance exploration and exploitation.", "configspace": "", "generation": 1, "fitness": 0.9016405881415296, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.022. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "382b74e4-4be9-42a3-816c-887a2723ca66", "metadata": {"aucs": [0.8722739159146601, 0.907070565977604, 0.9255772825323245], "final_y": [0.1273612404976272, 0.11973721815425598, 0.1122782067352015]}, "mutation_prompt": null}
{"id": "f3f0c7c0-e9bb-44f6-8fa4-c25211bc06bd", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Use elite guiding strategy\n            elite_indices = np.argsort(personal_best_value)[:3]\n            elite_avg = np.mean(personal_best[elite_indices], axis=0)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i] + adaptive_factor * (elite_avg - swarm[i])\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces an elite guiding strategy and adaptive mutation to boost exploration and convergence speed.", "configspace": "", "generation": 1, "fitness": 0.8595676194659706, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.019. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "382b74e4-4be9-42a3-816c-887a2723ca66", "metadata": {"aucs": [0.8796410062789957, 0.8654900019351641, 0.8335718501837521], "final_y": [0.12611584989522495, 0.124744875237365, 0.14093747654112754]}, "mutation_prompt": null}
{"id": "b9abd057-0736-4663-8f64-886af71de836", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Enhanced Adaptive mutation for new members\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-0.5, 0.5, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        np.tanh(cognitive_coeff * r1 * (personal_best[i] - swarm[i])) + \n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Swarm Gradient Descent with Improved Velocity Update and Adaptive Mutation Strategy.", "configspace": "", "generation": 2, "fitness": 0.9162603406885691, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.015. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "818bb534-b79d-4dcc-ac0e-7cdc633f9bd3", "metadata": {"aucs": [0.8987464806623418, 0.9138418778702114, 0.936192663533154], "final_y": [0.11712275918127002, 0.11621724506762876, 0.10999992721990337]}, "mutation_prompt": null}
{"id": "b922b109-9297-4062-9888-99e2a88ee2b5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor * 0.99  # Decay factor added\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1, 1, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined Adaptive Swarm Gradient Descent (RASGD): Introduces inertia weight decay for better convergence as iterations progress.", "configspace": "", "generation": 2, "fitness": 0.923564194501779, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.004. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "818bb534-b79d-4dcc-ac0e-7cdc633f9bd3", "metadata": {"aucs": [0.9185885056936466, 0.925010960816496, 0.9270931169951939], "final_y": [0.11451475707637748, 0.1116401468451591, 0.11281341299362346]}, "mutation_prompt": null}
{"id": "70da6a23-d77c-4583-a6ff-8ec068cb46f5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1, 1, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n\n                    # Elite preservation by retaining a fraction of the global best\n                    if np.random.rand() < 0.1:  # Preserve elite member occasionally\n                        swarm[i] = global_best\n                    else:\n                        swarm[i] += self.velocity[i]\n\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Enhanced Adaptive Swarm Gradient Descent (IEASGD): Introduces elite preservation and velocity adjustment for better convergence.", "configspace": "", "generation": 2, "fitness": 0.9003467565556954, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.002. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "818bb534-b79d-4dcc-ac0e-7cdc633f9bd3", "metadata": {"aucs": [0.8999824469116515, 0.9032926653382664, 0.8977651574171682], "final_y": [0.12314185685931534, 0.12058401171407052, 0.11934075388778664]}, "mutation_prompt": null}
{"id": "c2ee9ed7-00a0-4d88-a48e-93aedf66a0f6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * adaptive_factor  # Changed line\n            cognitive_coeff = 2.0 * adaptive_factor  # Changed line\n            social_coeff = 1.0 + adaptive_factor  # Changed line\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            elite_threshold = int(0.2 * current_population_size)  # New line\n            elite_indices = np.argpartition(personal_best_value, elite_threshold)[:elite_threshold]  # New line\n            elite_individuals = personal_best[elite_indices]  # New line\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1, 1, (current_population_size, self.dim))\n                else:\n                    r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Changed line\n                    elite_influence = elite_individuals[np.random.randint(elite_individuals.shape[0])]  # New line\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]) +  # Changed line\n                                        0.5 * r3 * (elite_influence - swarm[i]))  # New line\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Dynamic Hybrid Swarm Descent (DHSD): Combines adaptive velocity update with elite individual guidance for enhanced solution convergence in black-box optimization.", "configspace": "", "generation": 2, "fitness": 0.9023731531529492, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.008. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "818bb534-b79d-4dcc-ac0e-7cdc633f9bd3", "metadata": {"aucs": [0.8998777473989733, 0.9129139258429652, 0.8943277862169088], "final_y": [0.11740510412872263, 0.11627862940265643, 0.12378577947956226]}, "mutation_prompt": null}
{"id": "b7fe9451-6b82-4161-913b-c45de9b072ac", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * adaptive_factor  # Enhanced inertia adaptive range\n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor  # Enhanced cognitive adaptation\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-adaptive_factor, adaptive_factor, (current_population_size, self.dim))  # Dynamic velocity scaling\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced inertia weight adaptation and dynamic velocity scaling for improved convergence and exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.8968495749788871, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.027. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "818bb534-b79d-4dcc-ac0e-7cdc633f9bd3", "metadata": {"aucs": [0.8872729539677677, 0.8701947502401073, 0.933081020728786], "final_y": [0.12094028240859589, 0.128829200482783, 0.11252330090937634]}, "mutation_prompt": null}
{"id": "a9371199-56a8-48ee-9a33-1a562582fa52", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor * 0.98  # Decay factor slightly reduced\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic inertia weight with adaptive mutation factor to enhance exploration and convergence. ", "configspace": "", "generation": 3, "fitness": 0.9005618889939425, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.012. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "b922b109-9297-4062-9888-99e2a88ee2b5", "metadata": {"aucs": [0.9134148589914985, 0.8844571866964253, 0.9038136212939036], "final_y": [0.11762135725864775, 0.11648533292869434, 0.11031998968045009]}, "mutation_prompt": null}
{"id": "b08b65b4-a5a5-4654-b13f-9f953fb75870", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor * 0.99  # Decay factor added\n\n            # Changes start here\n            cognitive_coeff = 1.5 * adaptive_factor + 0.5\n            social_coeff = 1.5 * (1 - adaptive_factor) + 0.5\n            # Changes end here\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1, 1, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced RASGD with adaptive cognitive and social coefficients for improved exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8745971999905926, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.010. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b922b109-9297-4062-9888-99e2a88ee2b5", "metadata": {"aucs": [0.8603547919566152, 0.8800231134842816, 0.8834136945308807], "final_y": [0.11648356232511481, 0.11658834648330674, 0.11180495385629896]}, "mutation_prompt": null}
{"id": "efcc3fe1-0a68-4d0e-bc94-d2448a32ddc7", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor * 0.98  # Decay factor modified\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * adaptive_factor  # Social coefficient decay\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1, 1, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Refines inertia weight and social coefficient with a decay factor for improved convergence dynamics.", "configspace": "", "generation": 3, "fitness": 0.8909733517684423, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.018. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b922b109-9297-4062-9888-99e2a88ee2b5", "metadata": {"aucs": [0.8942439172373932, 0.8676489577238561, 0.9110271803440775], "final_y": [0.12047166449708324, 0.13032476439782625, 0.11543231687361899]}, "mutation_prompt": null}
{"id": "63763b23-4ca2-4abd-a06a-48f36c69969d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor * 0.99  # Decay factor added\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Adjusted for dynamic exploration-exploitation balance\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1, 1, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces dynamic social coefficient adjustment based on evaluations for improved exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8789250134819223, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.009. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b922b109-9297-4062-9888-99e2a88ee2b5", "metadata": {"aucs": [0.8864543110432961, 0.8660369985141249, 0.8842837308883456], "final_y": [0.12372677374284902, 0.11570636049846239, 0.11162405923619956]}, "mutation_prompt": null}
{"id": "714bd4e7-caf8-40d7-94ed-c624b4b70ebf", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.momentum = 0.9  # Added momentum factor\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor * 0.99\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1, 1, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    # Modified velocity update with momentum\n                    self.velocity[i] = (self.momentum * self.velocity[i] +\n                                        inertia_weight * (cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                                          social_coeff * r2 * (global_best - swarm[i])))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced RASGD with momentum-based velocity update for improved exploration.", "configspace": "", "generation": 3, "fitness": 0.8967486722697706, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.024. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b922b109-9297-4062-9888-99e2a88ee2b5", "metadata": {"aucs": [0.9169664382199088, 0.8637503225484892, 0.9095292560409137], "final_y": [0.11685973686631634, 0.12102905309088607, 0.11013621960147169]}, "mutation_prompt": null}
{"id": "f0344abe-64a1-4159-a9d9-76c2954f28a0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor * 0.98  # Decay factor slightly reduced\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 * (1 + 0.5 * adaptive_factor)  # Adjusted social coefficient\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence by incorporating adaptive learning rates for cognitive and social coefficients.", "configspace": "", "generation": 4, "fitness": 0.8911868139743815, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.017. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "a9371199-56a8-48ee-9a33-1a562582fa52", "metadata": {"aucs": [0.872855239892763, 0.9147072629112926, 0.8859979391190891], "final_y": [0.12184355664966062, 0.11626474318715097, 0.1260784601767314]}, "mutation_prompt": null}
{"id": "63d53438-f25c-45cf-853d-9a601d3ba3b2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor * 0.95  # Slightly adjusted decay factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 7)  # Adjusted size increase\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration through adaptive inertia weight and dynamic population size adjustment.", "configspace": "", "generation": 4, "fitness": 0.9071221247049888, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.023. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a9371199-56a8-48ee-9a33-1a562582fa52", "metadata": {"aucs": [0.8856128824580156, 0.8965926235661204, 0.9391608680908305], "final_y": [0.12362452930971612, 0.11648874455622993, 0.11016308530640939]}, "mutation_prompt": null}
{"id": "e2a17d53-5367-43aa-93f3-e93d7e0f87d0", "solution": "import numpy as np\n\nclass AdaptiveSwarmChaosDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.alpha = 0.5  # Self-adaptive learning rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor * 0.98\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * np.sin(evaluations)  # Chaos-based dynamic adjustment\n\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                else:\n                    # Introduce self-adaptive mutation\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.alpha * self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n                # Update self-adaptive learning rate\n                self.alpha = 0.9 * self.alpha + 0.1 * (global_best_value / (1 + np.abs(global_best_value)))\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmChaosDescent", "description": "Enhanced exploration and convergence by introducing self-adaptive learning rates and chaos-based dynamic inertia.", "configspace": "", "generation": 4, "fitness": 0.8036794559401651, "feedback": "The algorithm AdaptiveSwarmChaosDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.011. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "a9371199-56a8-48ee-9a33-1a562582fa52", "metadata": {"aucs": [0.7955697246252487, 0.8195046384622042, 0.7959640047330425], "final_y": [0.14830929994357112, 0.1463341232194193, 0.12881520770225463]}, "mutation_prompt": null}
{"id": "5264f2ea-eacb-4399-a3df-3f22a8600441", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.5 * adaptive_factor * 0.98  # Self-adaptive strategy for faster reduction\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm by introducing a self-adaptive strategy for inertia weight reduction to improve convergence speed.", "configspace": "", "generation": 4, "fitness": 0.924512481818554, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.014. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "a9371199-56a8-48ee-9a33-1a562582fa52", "metadata": {"aucs": [0.9215291510823811, 0.9094960123744812, 0.9425122819988002], "final_y": [0.11192662905662276, 0.11627598398105954, 0.11014216416853251]}, "mutation_prompt": null}
{"id": "7331907a-edd4-4590-acdc-5bf18f76c157", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor * 0.98  # Decay factor slightly reduced\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    stochastic_perturbation = np.random.normal(0, 0.1, self.dim)  # Stochastic perturbation\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]) +\n                                        stochastic_perturbation)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration by introducing a stochastic perturbation during velocity update.", "configspace": "", "generation": 4, "fitness": 0.8946079415720346, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.027. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "a9371199-56a8-48ee-9a33-1a562582fa52", "metadata": {"aucs": [0.8638737572711592, 0.8901243824065693, 0.9298256850383748], "final_y": [0.13233412126071364, 0.12176341998323847, 0.1111026690997593]}, "mutation_prompt": null}
{"id": "d5b1280d-dd34-47e2-b9c3-2377499ca68b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.5 * adaptive_factor * 0.98  # Self-adaptive strategy for faster reduction\n            cognitive_coeff = 1.5 * (1 + adaptive_factor)  # Adaptive learning rate adjustment\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive learning rate adjustment for cognitive and social coefficients to enhance convergence.", "configspace": "", "generation": 5, "fitness": 0.9036416150655211, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.009. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5264f2ea-eacb-4399-a3df-3f22a8600441", "metadata": {"aucs": [0.8919655963541294, 0.9136898223522473, 0.9052694264901866], "final_y": [0.11803232072044723, 0.11688705919027642, 0.11220203897441583]}, "mutation_prompt": null}
{"id": "29b7abcf-10b5-4a1c-a193-daadf6e53302", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            \n            # Hybrid inertia weight with dynamic adjustment\n            inertia_weight = 0.5 + 0.3 * np.sin(np.pi * adaptive_factor)\n            cognitive_coeff = 1.5 * adaptive_factor\n            # Dynamic social coefficient for enhanced exploration\n            social_coeff = 1.0 + 1.0 * np.cos(np.pi * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a hybrid inertia weight and dynamic social coefficient to enhance convergence and diversity.", "configspace": "", "generation": 5, "fitness": 0.8950432096138791, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.037. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "5264f2ea-eacb-4399-a3df-3f22a8600441", "metadata": {"aucs": [0.8457100864590192, 0.9052670430221347, 0.9341524993604831], "final_y": [0.11557677693155544, 0.11650846050064989, 0.11213163361682366]}, "mutation_prompt": null}
{"id": "0ccee05f-0122-4210-be12-c847363b96cb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * adaptive_factor  # Adjusted inertia strategy\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.5\n\n            # Dynamic topology adaptation using Levy flights\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                levy_flight = np.random.standard_cauchy(self.dim) * adaptive_factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    levy_flight)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n            if evaluations >= self.budget:\n                break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm with dynamic topology adaptation using Levy flights for improved exploration and convergence.", "configspace": "", "generation": 5, "fitness": 0.9142493171750757, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.017. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "5264f2ea-eacb-4399-a3df-3f22a8600441", "metadata": {"aucs": [0.8900629769991764, 0.9271539332737382, 0.9255310412523123], "final_y": [0.11148840610928556, 0.11445129175330382, 0.11056813063991255]}, "mutation_prompt": null}
{"id": "dd0340a1-52d4-45cb-8adc-886d5b8b77a0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * adaptive_factor * 0.98  # Self-adaptive strategy for faster reduction\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved swarm convergence by refining the inertia weight reduction formula for enhanced exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.8924769763076336, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.050. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "5264f2ea-eacb-4399-a3df-3f22a8600441", "metadata": {"aucs": [0.8238640108485313, 0.9127107153708102, 0.9408562027035589], "final_y": [0.14601325553148214, 0.11624351980266479, 0.11010851710256431]}, "mutation_prompt": null}
{"id": "6e0966a7-a6af-4810-a709-02f2b8d51bb0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.5 * adaptive_factor * 0.98  # Self-adaptive strategy for faster reduction\n            learning_factor = 1 + 0.1 * adaptive_factor  # Dynamic learning factor adjustment\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate a dynamic learning factor to enhance convergence precision.", "configspace": "", "generation": 5, "fitness": 0.9174425526995309, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.021. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "5264f2ea-eacb-4399-a3df-3f22a8600441", "metadata": {"aucs": [0.9178627254089438, 0.8915174755433467, 0.9429474571463025], "final_y": [0.11067407983914102, 0.12105317053854892, 0.11015187254244285]}, "mutation_prompt": null}
{"id": "db3f93b1-582b-45cf-812c-9ffefa28a24f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Adjusted inertia weight\n            learning_factor = 1 + 0.2 * adaptive_factor  # Modified dynamic learning factor\n            cognitive_coeff = 2.0 * adaptive_factor * learning_factor  # Increased cognitive influence\n            social_coeff = 1.0 + 0.5 * adaptive_factor  # Hybrid social coefficient\n\n            current_population_size = self.population_size + int(adaptive_factor * 3)  # Reduced expansion\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.0, 1.0, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration and exploitation balance using dynamically adjusted particle diversity and hybrid learning coefficients.", "configspace": "", "generation": 6, "fitness": 0.8946145481253761, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.018. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6e0966a7-a6af-4810-a709-02f2b8d51bb0", "metadata": {"aucs": [0.8685304788500824, 0.9063124708449111, 0.9090006946811352], "final_y": [0.12669059198185795, 0.11751060134697999, 0.11753665400767022]}, "mutation_prompt": null}
{"id": "f00939fc-52cf-41ad-8bca-e88b6959e2b8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Modify the inertia weight to enhance exploration at the start and exploitation towards the end\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Changed line\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 2.0 * adaptive_factor * learning_factor  # Changed line\n            social_coeff = 1.5\n\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive inertia weight deceleration strategy to balance exploration and exploitation more effectively.", "configspace": "", "generation": 6, "fitness": 0.9164882814510809, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.014. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "6e0966a7-a6af-4810-a709-02f2b8d51bb0", "metadata": {"aucs": [0.9187184180477859, 0.8983573370899223, 0.9323890892155343], "final_y": [0.11451606916639834, 0.11734873043449023, 0.11216267194056262]}, "mutation_prompt": null}
{"id": "15e6c0eb-f241-4642-82b6-405687543cc8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.5 * adaptive_factor * 0.98  # Self-adaptive strategy for faster reduction\n            learning_factor = 1 + 0.1 * adaptive_factor  # Dynamic learning factor adjustment\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Localized random search around the global best\n            for _ in range(2):  # Changing this line\n                local_candidate = global_best + np.random.uniform(-0.1, 0.1, self.dim)  # And this line\n                local_candidate = np.clip(local_candidate, lb, ub)\n                f_local = func(local_candidate)\n                evaluations += 1\n                if f_local < global_best_value:\n                    global_best = local_candidate\n                    global_best_value = f_local\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration with localized random search around the global best.", "configspace": "", "generation": 6, "fitness": 0.90478726125021, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.028. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "6e0966a7-a6af-4810-a709-02f2b8d51bb0", "metadata": {"aucs": [0.8727201183197968, 0.9013145335334438, 0.9403271318973893], "final_y": [0.12691731919011995, 0.1163478618471181, 0.11005210416181599]}, "mutation_prompt": null}
{"id": "95e05008-5b46-457b-91ef-29c59eed45e1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.5 * adaptive_factor * 0.98  # Self-adaptive strategy for faster reduction\n            learning_factor = 1 + 0.1 * adaptive_factor  # Dynamic learning factor adjustment\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i] + np.random.normal(0, 0.1, self.dim)  # Adding Gaussian noise\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce diversity by adding Gaussian noise to swarm updates for broader exploration.  ", "configspace": "", "generation": 6, "fitness": 0.8985323880012142, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.013. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "6e0966a7-a6af-4810-a709-02f2b8d51bb0", "metadata": {"aucs": [0.8888934274638536, 0.8891459355814979, 0.917557800958291], "final_y": [0.12451304744054903, 0.12362245058938326, 0.11241723849620167]}, "mutation_prompt": null}
{"id": "cff224d8-1d94-400f-b1f8-b4743746c106", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Chaotic sequence for inertia weight\n            inertia_weight = 0.7 + chaos_seq * adaptive_factor * 0.98  # Chaotic self-adaptive strategy\n            learning_factor = 1 + 0.1 * adaptive_factor  # Dynamic learning factor adjustment\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a chaotic inertia weight to enhance exploration and convergence balance.", "configspace": "", "generation": 6, "fitness": 0.9271939367580977, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.927 with standard deviation 0.010. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "6e0966a7-a6af-4810-a709-02f2b8d51bb0", "metadata": {"aucs": [0.9346390979434818, 0.9137846245067175, 0.9331580878240939], "final_y": [0.11200901633971094, 0.11635481368178668, 0.11213490873617893]}, "mutation_prompt": null}
{"id": "852a3ca0-6739-4040-b80b-e85a55941cd6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Chaotic sequence for inertia weight\n            inertia_weight = 0.7 + chaos_seq * adaptive_factor * 0.98  # Chaotic self-adaptive strategy\n            learning_factor = 1 + 0.1 * adaptive_factor  # Dynamic learning factor adjustment\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                    swarm[i] = new_member  # Introduce newly mutated member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate an adaptive chaotic mutation strategy for enhanced exploration and convergence rate.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "cff224d8-1d94-400f-b1f8-b4743746c106", "metadata": {}, "mutation_prompt": null}
{"id": "76b75ade-a9ba-4831-8e10-0674506ac4a8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.stagnation_counter = np.zeros(self.population_size)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Chaotic sequence for inertia weight\n            inertia_weight = 0.7 + chaos_seq * adaptive_factor * 0.98  # Chaotic self-adaptive strategy\n            learning_factor = 1 + 0.1 * adaptive_factor  # Dynamic learning factor adjustment\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n                        self.stagnation_counter[i] = 0\n                    else:\n                        self.stagnation_counter[i] += 1\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                # Replace stagnated particles\n                if self.stagnation_counter[i] > 5:\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n                    self.velocity[i] = np.zeros(self.dim)\n                    self.stagnation_counter[i] = 0\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity by replacing stagnated particles with new random particles.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "cff224d8-1d94-400f-b1f8-b4743746c106", "metadata": {}, "mutation_prompt": null}
{"id": "dd99f2ac-c9ea-45ae-a7cf-a33e3a0f5e94", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Chaotic sequence for inertia weight\n            inertia_weight = 0.7 + chaos_seq * adaptive_factor * 0.98  # Chaotic self-adaptive strategy\n            learning_factor = 1 + 0.1 * adaptive_factor  # Dynamic learning factor adjustment\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] = 0.5 * (swarm[i] + self.velocity[i])  # Adaptive crossover\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a chaotic inertia weight and adaptive crossover for enhanced exploration and convergence balance.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "cff224d8-1d94-400f-b1f8-b4743746c106", "metadata": {}, "mutation_prompt": null}
{"id": "7cc71c5b-ceb9-47cc-9f4d-629eee50dd70", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Chaotic sequence for inertia weight\n            inertia_weight = 0.7 + chaos_seq * adaptive_factor * 0.98  # Chaotic self-adaptive strategy\n            learning_factor = 1 + 0.1 * adaptive_factor  # Dynamic learning factor adjustment\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim) + chaos_seq * (ub - lb) * adaptive_factor\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate adaptive chaotic mutation for increased exploration in later iterations.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "cff224d8-1d94-400f-b1f8-b4743746c106", "metadata": {}, "mutation_prompt": null}
{"id": "7380e6a9-6f55-4a85-8c0a-f65716fd5822", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Chaotic sequence for inertia weight\n            inertia_weight = 0.7 + chaos_seq * adaptive_factor * 0.98  # Chaotic self-adaptive strategy\n            learning_factor = 1 + 0.1 * adaptive_factor  # Dynamic learning factor adjustment\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    neighbor_idx = np.random.choice(self.population_size)  # Probabilistic neighborhood interaction\n                    self.velocity[i] *= (0.5 + 0.5 * np.random.random())  # Adaptive velocity scaling\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[neighbor_idx]))  # Updated line\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce probabilistic neighborhood interaction and adaptive velocity scaling to enhance exploration-exploitation balance.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "cff224d8-1d94-400f-b1f8-b4743746c106", "metadata": {}, "mutation_prompt": null}
{"id": "1ab4cfaf-dd68-401e-b845-757cc8dd2ebb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Chaotic sequence for inertia weight\n            inertia_weight = 0.7 + chaos_seq * adaptive_factor * 0.98  # Chaotic self-adaptive strategy\n            learning_factor = 1 + 0.1 * adaptive_factor  # Dynamic learning factor adjustment\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * chaos_seq  # Change applied here\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                    swarm[i] = new_member  # Introduce newly mutated member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance the diversity of swarm by applying chaotic sequence to new member initialization.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "852a3ca0-6739-4040-b80b-e85a55941cd6", "metadata": {}, "mutation_prompt": null}
{"id": "9cf5474b-fff6-4d7e-bfa2-e3f200bac769", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Chaotic sequence for inertia weight\n            inertia_weight = 0.7 + chaos_seq * adaptive_factor * 0.98  # Chaotic self-adaptive strategy\n            learning_factor = 1 + 0.1 * adaptive_factor  # Dynamic learning factor adjustment\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                    swarm[i] = new_member  # Introduce newly mutated member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance adaptive chaotic mutation strategy to improve exploration without exceeding population index bounds.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "852a3ca0-6739-4040-b80b-e85a55941cd6", "metadata": {}, "mutation_prompt": null}
{"id": "8e6e2a8f-1a4f-4ca9-aac2-c1b2f49e3b28", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Chaotic sequence for inertia weight\n            inertia_weight = 0.7 + chaos_seq * adaptive_factor * 0.98  # Chaotic self-adaptive strategy\n            learning_factor = 1 + 0.1 * adaptive_factor  # Dynamic learning factor adjustment\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                    swarm[i] = new_member  # Introduce newly mutated member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i % self.population_size] = (inertia_weight * self.velocity[i % self.population_size] +\n                                        cognitive_coeff * r1 * (personal_best[i % self.population_size] - swarm[i % self.population_size]) +\n                                        social_coeff * r2 * (global_best - swarm[i % self.population_size]))\n                    swarm[i % self.population_size] += self.velocity[i % self.population_size]\n                    swarm[i % self.population_size] = np.clip(swarm[i % self.population_size], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i % self.population_size])\n                    evaluations += 1\n                    if f_value < personal_best_value[i % self.population_size]:\n                        personal_best[i % self.population_size] = swarm[i % self.population_size]\n                        personal_best_value[i % self.population_size] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i % self.population_size]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a boundary check for index i to prevent out-of-bounds errors during population updates.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "852a3ca0-6739-4040-b80b-e85a55941cd6", "metadata": {}, "mutation_prompt": null}
{"id": "d63b3021-47a5-4e22-9b64-dd5535157c47", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Chaotic sequence for inertia weight\n            inertia_weight = 0.7 + chaos_seq * adaptive_factor * 0.98  # Chaotic self-adaptive strategy\n            learning_factor = 1 + 0.1 * adaptive_factor  # Dynamic learning factor adjustment\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= len(swarm):  # Fix index error for out of bounds\n                    # Adaptive mutation for new members with increased variability\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                    swarm = np.vstack((swarm, new_member))  # Introduce newly mutated member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance dynamic population size management to avoid index errors during evaluation.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "852a3ca0-6739-4040-b80b-e85a55941cd6", "metadata": {}, "mutation_prompt": null}
{"id": "0f9e26d8-e30b-4e9d-b0b0-b00d0dea9ef9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.7 + chaos_seq * adaptive_factor * 0.98\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            current_population_size = self.population_size\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = np.random.uniform(lb, ub, self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance the chaotic mutation strategy with a stabilized population size adjustment to prevent index errors.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "852a3ca0-6739-4040-b80b-e85a55941cd6", "metadata": {}, "mutation_prompt": null}
{"id": "07ea20e1-08f4-41e3-8c63-e1b81c4952ca", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Chaotic sequence for inertia weight\n            inertia_weight = 0.7 + chaos_seq * adaptive_factor * 0.98  # Chaotic self-adaptive strategy\n            learning_factor = 1 + 0.1 * adaptive_factor  # Dynamic learning factor adjustment\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (chaos_seq + 0.1)  # Slightly adjusted chaotic sequence\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                    swarm[i] = new_member  # Introduce newly mutated member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity by dynamically adjusting chaotic sequence for new members and adding velocity reset.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "1ab4cfaf-dd68-401e-b845-757cc8dd2ebb", "metadata": {}, "mutation_prompt": null}
{"id": "293247e9-080d-4ce4-b027-d4388e085bb3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Chaotic sequence for inertia weight\n            inertia_weight = 0.7 + chaos_seq * adaptive_factor * 0.98  # Chaotic self-adaptive strategy\n            learning_factor = 1 + 0.1 * adaptive_factor  # Dynamic learning factor adjustment\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * min(chaos_seq, 0.5)  # Change applied here\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                    swarm[i] = new_member  # Introduce newly mutated member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Modify the adaptive mutation strategy to limit the chaotic sequence impact for new member initialization.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "1ab4cfaf-dd68-401e-b845-757cc8dd2ebb", "metadata": {}, "mutation_prompt": null}
{"id": "61b8b7c8-a76c-4100-a1b9-122a927a3aee", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.7 + chaos_seq * adaptive_factor * 0.98\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            # Correct population size adjustment\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))  # Refined sequence\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))  # Corrected size\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Use a chaotic sequence to enhance population diversity and improve convergence by refining chaotic sequence application and velocity handling.", "configspace": "", "generation": 9, "fitness": 0.8676979348054488, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.025. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "1ab4cfaf-dd68-401e-b845-757cc8dd2ebb", "metadata": {"aucs": [0.9023758124179047, 0.8463030295064098, 0.854414962492032], "final_y": [0.11687363557202368, 0.13568991793360252, 0.13139483264946372]}, "mutation_prompt": null}
{"id": "6fec0ede-b491-4e86-b6be-ba9ece07ea91", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Chaotic sequence for inertia weight\n            inertia_weight = 0.7 + chaos_seq * adaptive_factor * 0.98  # Chaotic self-adaptive strategy\n            learning_factor = 1 + 0.1 * adaptive_factor  # Dynamic learning factor adjustment\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            # Dynamic population size adjustment\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.population_size)  # Change applied here\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    # Adaptive mutation for new members with increased variability\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * chaos_seq\n                    self.velocity = np.random.uniform(-1.5, 1.5, (current_population_size, self.dim))\n                    swarm[i] = new_member  # Introduce newly mutated member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Evaluate and update personal best\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    # Update global best\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adjust population size and index bounds to prevent out-of-bounds errors in the swarm update process.", "configspace": "", "generation": 9, "fitness": 0.8179750044686317, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.029. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "1ab4cfaf-dd68-401e-b845-757cc8dd2ebb", "metadata": {"aucs": [0.7762962695747038, 0.8386998714016118, 0.8389288724295795], "final_y": [0.14962854278818982, 0.13489603039289177, 0.12120171880720931]}, "mutation_prompt": null}
{"id": "66b2d071-a302-48f9-890d-8b958b18f64c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = np.random.rand(self.dim)  # Changed from scalar to vector for element-wise mutation\n            inertia_weight = 0.7 + 0.3 * adaptive_factor  # Adjusted to remove chaotic influence\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            current_population_size = self.population_size + int(adaptive_factor * 5)\n\n            for i in range(self.population_size):  # Fixed index range to avoid out-of-bounds errors\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate chaotic sequence into the initialization and mutation phases for enhanced exploration while maintaining adaptive velocity updates.", "configspace": "", "generation": 9, "fitness": 0.8627119354511517, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.014. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "1ab4cfaf-dd68-401e-b845-757cc8dd2ebb", "metadata": {"aucs": [0.8638351172172254, 0.8456225889047805, 0.8786781002314492], "final_y": [0.11850916568381586, 0.11760479696023762, 0.11909555783586367]}, "mutation_prompt": null}
{"id": "bebd8bfe-5986-44b9-8c91-67418f3383f4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.7 + (chaos_seq * adaptive_factor * 1.05)  # Refined line: Adjusted multiplier\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Leverage a refined inertia weight calculation to improve exploration and convergence balance by making dynamic adjustments based on the chaotic sequence.", "configspace": "", "generation": 10, "fitness": 0.9254787743359004, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.006. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "61b8b7c8-a76c-4100-a1b9-122a927a3aee", "metadata": {"aucs": [0.9290238972196878, 0.9297760945968698, 0.9176363311911439], "final_y": [0.112798509522677, 0.11169549822161184, 0.11143682839558655]}, "mutation_prompt": null}
{"id": "f9bf5bfb-1281-4604-a153-9e0fcdbdf167", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.9 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Adjusted chaos scale\n            inertia_weight = 0.8 + chaos_seq * adaptive_factor * 0.9  # Modified inertia\n            learning_factor = 1 + 0.2 * adaptive_factor  # Enhanced learning flexibility\n            cognitive_coeff = 1.8 * adaptive_factor * learning_factor  # Increased cognitive influence\n            social_coeff = 1.7  # Slightly increased social coefficient\n\n            # Correct population size adjustment\n            current_population_size = min(self.population_size + int(adaptive_factor * 6), self.budget - evaluations)  # Modified adaptive increase\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))  # Adjusted new member scaling\n                    self.velocity = np.random.uniform(-2.0, 2.0, (self.population_size, self.dim))  # Broadened velocity range\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate chaotic sequence with adaptive learning coefficients and dynamic population adjustment for enhanced diversity and convergence.", "configspace": "", "generation": 10, "fitness": 0.9052511589658309, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.010. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "61b8b7c8-a76c-4100-a1b9-122a927a3aee", "metadata": {"aucs": [0.9197958824189953, 0.8967232171478324, 0.8992343773306649], "final_y": [0.1124116678200634, 0.11648773964976178, 0.11237901285855978]}, "mutation_prompt": null}
{"id": "bf460764-8e2e-47ee-9f77-0576b739a198", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.7 + chaos_seq * adaptive_factor * 0.98\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]) +\n                                        chaos_seq * np.random.randn(self.dim))  # Added chaotic perturbation\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate a chaotic perturbation in the velocity update to improve solution exploration.", "configspace": "", "generation": 10, "fitness": 0.9068523424551712, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.007. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "61b8b7c8-a76c-4100-a1b9-122a927a3aee", "metadata": {"aucs": [0.9062627173416776, 0.8983296881386514, 0.9159646218851848], "final_y": [0.1109643743878409, 0.11846579902750987, 0.11489422835989782]}, "mutation_prompt": null}
{"id": "8242bd72-b898-4836-a85b-1bcd7c63815f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.5 + 0.4 * np.cos(evaluations / self.budget * np.pi)  # Modified line\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            # Correct population size adjustment\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))  # Refined sequence\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))  # Corrected size\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic inertia weight to improve exploration and exploitation balance in swarm optimization.", "configspace": "", "generation": 10, "fitness": 0.8948018974560613, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.007. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "61b8b7c8-a76c-4100-a1b9-122a927a3aee", "metadata": {"aucs": [0.8882280271637729, 0.9050781875137115, 0.8910994776906995], "final_y": [0.11832349425355748, 0.11633243467197008, 0.11346002229190166]}, "mutation_prompt": null}
{"id": "0b6bb9e2-8340-4910-b209-4485f121bba3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.7 + chaos_seq * adaptive_factor * 0.98\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Modified line\n\n            # Correct population size adjustment\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))  # Refined sequence\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))  # Corrected size\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance global exploration by incorporating time-varying acceleration coefficients, improving search diversity and convergence.", "configspace": "", "generation": 10, "fitness": 0.9141184073513716, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.022. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "61b8b7c8-a76c-4100-a1b9-122a927a3aee", "metadata": {"aucs": [0.9411053061250269, 0.9141070119040476, 0.8871429040250405], "final_y": [0.11031008809283971, 0.11180392150864993, 0.12478641619343123]}, "mutation_prompt": null}
{"id": "d48a8565-2aa0-4e61-a253-44f1b66cce39", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.7 + (chaos_seq * adaptive_factor * 1.05)\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n            \n            # New line: Initialize neighborhood influence\n            neighborhood_influence = 0.1 + 0.9 * adaptive_factor\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                    # Adjusted line: Include neighborhood influence in velocity update\n                    neighbor_influence = neighborhood_influence * r3 * (personal_best[np.random.randint(self.population_size)] - swarm[i])\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]) +\n                                        neighbor_influence)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a decentralized swarm interaction by incorporating a neighborhood influence factor to enhance local search capabilities and avoid premature convergence.", "configspace": "", "generation": 11, "fitness": 0.8773394676086502, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.027. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "bebd8bfe-5986-44b9-8c91-67418f3383f4", "metadata": {"aucs": [0.8462649694631939, 0.9117207866684627, 0.874032646694294], "final_y": [0.13168110285032608, 0.11182992382693446, 0.11078427037189298]}, "mutation_prompt": null}
{"id": "149171b6-5163-4920-aba1-e4c19965de62", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.7 + (chaos_seq * adaptive_factor * 1.05)  # Refined line: Adjusted multiplier\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    persistence_factor = 0.9 * (1 - adaptive_factor) * chaos_seq  # New line: Introduce persistence factor\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]) +\n                                        persistence_factor * self.velocity[i])  # Modify velocity with persistence\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive chaotic persistence factor to fine-tune velocity updates for enhanced convergence.", "configspace": "", "generation": 11, "fitness": 0.8678753760338523, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.014. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "bebd8bfe-5986-44b9-8c91-67418f3383f4", "metadata": {"aucs": [0.8544060069405934, 0.8876953766611981, 0.8615247444997655], "final_y": [0.13477259920413054, 0.12123063665591516, 0.12487906874815358]}, "mutation_prompt": null}
{"id": "847bb82f-c2e2-40a1-8ea0-332d3df5c7f8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.8 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Line 1 changed\n            inertia_weight = 0.7 + (chaos_seq * adaptive_factor * 1.05)\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.6 * adaptive_factor * learning_factor  # Line 2 changed\n            social_coeff = 1.5\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1.2 + np.abs(chaos_seq))  # Line 3 changed\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine swarm initialization and chaos sequence to enhance global exploration in early iterations.", "configspace": "", "generation": 11, "fitness": 0.8992470669595303, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.015. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "bebd8bfe-5986-44b9-8c91-67418f3383f4", "metadata": {"aucs": [0.9006765907403661, 0.8807789296094598, 0.9162856805287649], "final_y": [0.11562136032180026, 0.12161364253333207, 0.10969716047475664]}, "mutation_prompt": null}
{"id": "9b7be540-9c34-484c-8d24-84fcac248345", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.7 + (chaos_seq * adaptive_factor * 1.05)\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += self.q_coefficient * adaptive_factor * q_rand * (global_best - swarm[i])\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "A hybrid swarm algorithm blending dynamic chaos-induced exploration with quantum-inspired search strategies to enhance convergence speed and precision.", "configspace": "", "generation": 11, "fitness": 0.9006830863815495, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.017. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "bebd8bfe-5986-44b9-8c91-67418f3383f4", "metadata": {"aucs": [0.8809287660894789, 0.8985223309809504, 0.922598162074219], "final_y": [0.1189062975812476, 0.11540442055009381, 0.11087303839960949]}, "mutation_prompt": null}
{"id": "eed16d43-0852-4998-bc45-80fdc7429107", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.7 + (chaos_seq * adaptive_factor * 1.05)\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5 * (1 - adaptive_factor)  # Changed line: Introduced dynamic social coefficient\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic social coefficient adjustment based on current evaluations to enhance convergence towards global best positions.", "configspace": "", "generation": 11, "fitness": 0.8533619034700237, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.040. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "bebd8bfe-5986-44b9-8c91-67418f3383f4", "metadata": {"aucs": [0.7961655028528731, 0.8824727735029052, 0.8814474340542927], "final_y": [0.13082665851195818, 0.11989271453064598, 0.12539640809371244]}, "mutation_prompt": null}
{"id": "83a678d3-8101-4ce4-8c6a-1b3304a5c37a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.7 + (chaos_seq * adaptive_factor * 1.05)\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.normal(0, 1, self.dim)  # Change 1\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += self.q_coefficient * adaptive_factor * q_rand * (global_best - swarm[i])\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced hybrid swarm algorithm utilizing chaotic search space expansion and adaptive quantum dynamics to boost convergence accuracy.", "configspace": "", "generation": 12, "fitness": 0.8967541360277572, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.015. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "9b7be540-9c34-484c-8d24-84fcac248345", "metadata": {"aucs": [0.8909061219913198, 0.8826152607161918, 0.9167410253757603], "final_y": [0.11590303114726763, 0.12656150502410912, 0.11467451487385583]}, "mutation_prompt": null}
{"id": "cbad318d-5dea-4850-bcf5-2630b1d4f299", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.7 + (chaos_seq * adaptive_factor * 1.05)\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += self.q_coefficient * adaptive_factor**2 * q_rand * (global_best - swarm[i])  # Modified line\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced dynamic adaptation of quantum-inspired coefficients for refined local exploration and global convergence.", "configspace": "", "generation": 12, "fitness": 0.9122066718212594, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.003. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "9b7be540-9c34-484c-8d24-84fcac248345", "metadata": {"aucs": [0.9080074180996718, 0.913447065751561, 0.9151655316125451], "final_y": [0.11233019013883128, 0.11687244094027827, 0.11241556032275235]}, "mutation_prompt": null}
{"id": "3883f27d-ea91-4f67-87fa-c09f75a3b811", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.9 + (chaos_seq * adaptive_factor * 1.05)  # Adjusted from 0.7 to 0.9\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += self.q_coefficient * adaptive_factor * q_rand * (global_best - swarm[i])\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "A minor refinement to the AdaptiveSwarmGradientDescent algorithm, enhancing the inertia weight scaling to slightly improve convergence precision and stability.", "configspace": "", "generation": 12, "fitness": 0.9127220208653327, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.014. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "9b7be540-9c34-484c-8d24-84fcac248345", "metadata": {"aucs": [0.9038628020121224, 0.9020727946900813, 0.9322304658937943], "final_y": [0.11536395692040113, 0.1201832562692674, 0.11114455440553794]}, "mutation_prompt": null}
{"id": "f82b575c-2981-4294-8927-3dae0bec88bb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.7 + (chaos_seq * adaptive_factor * 1.05)\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    stochastic_perturbation = np.random.normal(0, 0.1, self.dim)  # New line\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]) +\n                                        stochastic_perturbation)  # Modified line\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += self.q_coefficient * adaptive_factor * q_rand * (global_best - swarm[i])\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "An enhanced hybrid swarm algorithm incorporating stochastic perturbation in velocity to improve diversity and escape local optima.", "configspace": "", "generation": 12, "fitness": 0.8998289490043655, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.012. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "9b7be540-9c34-484c-8d24-84fcac248345", "metadata": {"aucs": [0.912701648242781, 0.9034232684366135, 0.8833619303337021], "final_y": [0.11482837273396818, 0.11960604858717838, 0.12553006402098765]}, "mutation_prompt": null}
{"id": "1b736ed6-dfc0-415f-8986-066f053f58c4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n        self.adaptive_memory = np.zeros(dim)  # Adaptive memory for enhanced exploration\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.7 + (chaos_seq * adaptive_factor * 1.05)\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i] + self.adaptive_memory * adaptive_factor * np.random.rand(self.dim)  # Modified line\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += self.q_coefficient * adaptive_factor * q_rand * (global_best - swarm[i])\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "An enhanced hybrid swarm algorithm integrating adaptive memory-based chaotic exploration and quantum-inspired learning for improved convergence and precision.", "configspace": "", "generation": 12, "fitness": 0.8842997211623808, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.024. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "9b7be540-9c34-484c-8d24-84fcac248345", "metadata": {"aucs": [0.8868671673657661, 0.8535323676819349, 0.9124996284394413], "final_y": [0.12308926067221837, 0.13618388138872595, 0.1123695444854581]}, "mutation_prompt": null}
{"id": "2b6466bc-186f-466c-8359-79d4c1841522", "solution": "import numpy as np\n\nclass EnhancedSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.8  # Increased quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.85 + (chaos_seq * adaptive_factor * 1.15)  # Further adjusted for better exploration\n            learning_factor = 1 + 0.15 * adaptive_factor\n            cognitive_coeff = 1.7 * adaptive_factor * learning_factor\n            social_coeff = 1.6\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Enhanced quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += self.q_coefficient * adaptive_factor * q_rand * (global_best - swarm[i])\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedSwarmGradientDescent", "description": "An enhanced metaheuristic algorithm integrating adaptive inertia and chaos factors with a diversity-promoting mechanism for global convergence improvement.", "configspace": "", "generation": 13, "fitness": 0.8976503358305385, "feedback": "The algorithm EnhancedSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.006. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3883f27d-ea91-4f67-87fa-c09f75a3b811", "metadata": {"aucs": [0.9025857539356674, 0.8893350408926008, 0.9010302126633475], "final_y": [0.11872066193993691, 0.11984678176807817, 0.11815253248653657]}, "mutation_prompt": null}
{"id": "af6932e6-f85e-4311-a291-2fdb44ca1802", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.9 + (chaos_seq * adaptive_factor * 1.05)  # Adjusted from 0.7 to 0.9\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Dynamically scaled\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += self.q_coefficient * adaptive_factor * q_rand * (global_best - swarm[i])\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved AdaptiveSwarmGradientDescent by enhancing velocity update rules using dynamic social coefficient scaling for better convergence.", "configspace": "", "generation": 13, "fitness": 0.8846148618002507, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.020. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "3883f27d-ea91-4f67-87fa-c09f75a3b811", "metadata": {"aucs": [0.8661944042456378, 0.8748784622206953, 0.912771718934419], "final_y": [0.13175788779351782, 0.11915691157806008, 0.11227356183102688]}, "mutation_prompt": null}
{"id": "bbd16d53-947c-4f70-b97d-04ddd2091811", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.9 + (chaos_seq * adaptive_factor * 1.05)\n            learning_factor = 1 + 0.5 * adaptive_factor  # Adjusted from 0.1 to 0.5\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.2 + 0.3 * np.var(personal_best_value)  # Adjusted to be dynamic\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += self.q_coefficient * adaptive_factor * q_rand * (global_best - swarm[i])\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined AdaptiveSwarmGradientDescent with dynamic learning factor scaling based on particle performance variance to enhance convergence speed and precision.", "configspace": "", "generation": 13, "fitness": 0.8993932865822803, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.024. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "3883f27d-ea91-4f67-87fa-c09f75a3b811", "metadata": {"aucs": [0.8825709823314037, 0.8817449903366982, 0.9338638870787391], "final_y": [0.12707872313413815, 0.11837461583727438, 0.11048940297678267]}, "mutation_prompt": null}
{"id": "c4be05c6-70cd-475c-966d-12adc3095c22", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.9 + (chaos_seq * adaptive_factor * 1.05)  # Adjusted from 0.7 to 0.9\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += self.q_coefficient * adaptive_factor * q_rand * (global_best - swarm[i])\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "A minor refinement to AdaptiveSwarmGradientDescent, enhancing exploration by dynamically scaling cognitive and social coefficients.", "configspace": "", "generation": 13, "fitness": 0.9079730189861945, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.006. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3883f27d-ea91-4f67-87fa-c09f75a3b811", "metadata": {"aucs": [0.9019790577839372, 0.9065397308163363, 0.9154002683583102], "final_y": [0.11463712965580541, 0.12025439092826329, 0.11538240179226511]}, "mutation_prompt": null}
{"id": "ce567ac7-8201-4c79-8e9d-8195ed3a177f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.9 + (chaos_seq * adaptive_factor * 1.05)  # Adjusted from 0.7 to 0.9\n            learning_factor = 1 + 0.1 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * learning_factor\n            social_coeff = 1.5\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    q_coeff_dynamic = self.q_coefficient * (0.5 + 0.5 * adaptive_factor)  # Dynamic quantum coefficient\n                    swarm[i] += q_coeff_dynamic * adaptive_factor * q_rand * (global_best - swarm[i])\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced an adaptive quantum-inspired coefficient for better exploration-exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.8915013855796233, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.019. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3883f27d-ea91-4f67-87fa-c09f75a3b811", "metadata": {"aucs": [0.873951554229073, 0.8820301557672428, 0.9185224467425545], "final_y": [0.12122495318189608, 0.12034166529288748, 0.11339552477964632]}, "mutation_prompt": null}
{"id": "bcaaab0c-673f-4f0c-bf3c-4b1117fa77cf", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.9 + (chaos_seq * adaptive_factor * 1.05)  # Adjusted from 0.7 to 0.9\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += self.q_coefficient * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined AdaptiveSwarmGradientDescent by optimizing quantum-inspired influence and improving velocity update with chaotic perturbation.", "configspace": "", "generation": 14, "fitness": 0.8932216108672493, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.022. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c4be05c6-70cd-475c-966d-12adc3095c22", "metadata": {"aucs": [0.8642861870880891, 0.8989468754123806, 0.9164317701012782], "final_y": [0.12675534654648468, 0.11904487560282062, 0.11248281964441476]}, "mutation_prompt": null}
{"id": "da3070b7-a188-4e9c-82e8-8e8ebb338201", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.9 + (chaos_seq * adaptive_factor * 1.05)  # Adjusted from 0.7 to 0.9\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.6 * (0.3 + adaptive_factor)\n            social_coeff = 1.3 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    velocity_update = (inertia_weight * self.velocity[i] +\n                                       cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                       social_coeff * r2 * (global_best - swarm[i]))\n                    self.velocity[i] = velocity_update * (1 + chaos_seq)\n\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += self.q_coefficient * adaptive_factor * q_rand * (global_best - swarm[i])\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved adaptive exploration via chaos-driven velocity updates and harmonized quantum influences for robust optimization.", "configspace": "", "generation": 14, "fitness": 0.8615593231476338, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.013. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c4be05c6-70cd-475c-966d-12adc3095c22", "metadata": {"aucs": [0.8483026545408098, 0.878965505989653, 0.8574098089124389], "final_y": [0.11390535675204938, 0.11162351585268016, 0.12511327546231388]}, "mutation_prompt": null}
{"id": "61424e12-c4e5-49ae-9bc8-d806fa54fd32", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        def levy_flight(Lambda):\n            sigma = (np.math.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2) /\n                     (np.math.gamma((1 + Lambda) / 2) * Lambda * 2 ** ((Lambda - 1) / 2))) ** (1 / Lambda)\n            u = np.random.normal(0, 1, self.dim) * sigma\n            v = np.random.normal(0, 1, self.dim)\n            step = u / abs(v) ** (1 / Lambda)\n            return step\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.9 + (chaos_seq * adaptive_factor * 1.05)\n\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += self.q_coefficient * adaptive_factor * q_rand * (global_best - swarm[i])\n                    \n                    # Levy flight influence\n                    swarm[i] += levy_flight(1.5) * adaptive_factor\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced AdaptiveSwarmGradientDescent integrating Lvy flights for better exploration and diverse search paths.", "configspace": "", "generation": 14, "fitness": 0.8923059744324265, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.013. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c4be05c6-70cd-475c-966d-12adc3095c22", "metadata": {"aucs": [0.9106935441557826, 0.8849550481085853, 0.8812693310329116], "final_y": [0.11378794450020258, 0.12005423753687205, 0.11533609343756257]}, "mutation_prompt": null}
{"id": "35654bbd-9435-4196-af7e-2f671425cac2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.9 + (chaos_seq * adaptive_factor * 1.05)  # Adjusted from 0.7 to 0.9\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + np.random.uniform(-0.1, 0.1)  # Turbulence\n\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += self.q_coefficient * adaptive_factor * q_rand * (global_best - swarm[i])\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces turbulence to the velocity update for improved exploration by using chaos-enhanced inertia weight.", "configspace": "", "generation": 14, "fitness": 0.8668641214976304, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.022. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "c4be05c6-70cd-475c-966d-12adc3095c22", "metadata": {"aucs": [0.8663184073014323, 0.8944841871681465, 0.8397897700233125], "final_y": [0.11860679728866474, 0.11637557968037981, 0.13562357602660668]}, "mutation_prompt": null}
{"id": "400c9f79-3b98-4edf-af9f-dafdcc70f1d5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.9 + (chaos_seq * adaptive_factor * 1.05)  # Adjusted from 0.7 to 0.9\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient * adaptive_factor * q_rand * (global_best - swarm[i]) \n                                 * (0.5 + adaptive_factor))  # Adjusted line\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "A minor refinement to AdaptiveSwarmGradientDescent, enhancing exploitation by adjusting the quantum-inspired coefficient dynamically based on evaluation progress.", "configspace": "", "generation": 14, "fitness": 0.8931238725115166, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.010. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c4be05c6-70cd-475c-966d-12adc3095c22", "metadata": {"aucs": [0.8800773774001811, 0.894429348827238, 0.9048648913071305], "final_y": [0.124548386922262, 0.11783169467841936, 0.11378356872198592]}, "mutation_prompt": null}
{"id": "65816c54-b49d-49eb-a30d-1d232453f933", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.7 + (0.4 * adaptive_factor ** 2)  # Non-linear inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.1 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced AdaptiveSwarmGradientDescent by introducing non-linear inertia scaling and dynamic q_coeff adjustment for improved convergence.", "configspace": "", "generation": 15, "fitness": 0.9090313900891096, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.013. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "bcaaab0c-673f-4f0c-bf3c-4b1117fa77cf", "metadata": {"aucs": [0.8938893936339649, 0.906536175448463, 0.9266686011849008], "final_y": [0.12034082187494222, 0.11084746882687813, 0.11150249952701652]}, "mutation_prompt": null}
{"id": "05025a35-d02d-49ff-af62-779982768e79", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.9 + (chaos_seq * adaptive_factor * 1.05)  # Adjusted from 0.7 to 0.9\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.03 * np.random.randn(self.dim)  # Updated noise factor\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += self.q_coefficient * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.7  # Adjusted scaling factor\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced AdaptiveSwarmGradientDescent by improving velocity update strategy and introducing adaptive quantum influence with dynamic chaotic perturbation.", "configspace": "", "generation": 15, "fitness": 0.899127649836295, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.034. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "bcaaab0c-673f-4f0c-bf3c-4b1117fa77cf", "metadata": {"aucs": [0.854259080849328, 0.907936467495017, 0.9351874011645398], "final_y": [0.1261602423998044, 0.11864665028916377, 0.11016812418812039]}, "mutation_prompt": null}
{"id": "f597d95a-f827-4c5a-b79e-c6d8e7e7f20e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.6 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Adjusted from 0.7 to 0.6\n            inertia_weight = 0.8 + (chaos_seq * adaptive_factor * 1.05)  # Adjusted from 0.9 to 0.8\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += self.q_coefficient * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced AdaptiveSwarmGradientDescent by introducing dynamic inertia weight scaling and refined chaotic perturbation for improved global exploration.", "configspace": "", "generation": 15, "fitness": 0.8946462994873273, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.007. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "bcaaab0c-673f-4f0c-bf3c-4b1117fa77cf", "metadata": {"aucs": [0.8856429133538035, 0.9032569217588313, 0.8950390633493474], "final_y": [0.12272272986161448, 0.11835216684982974, 0.123070160304808]}, "mutation_prompt": null}
{"id": "60fb568c-0890-403b-a1d6-9cc2b8969e11", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.9 + (chaos_seq * adaptive_factor * 1.05)  # Adjusted from 0.7 to 0.9\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += self.q_coefficient * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8 + 0.01 * np.random.randn(self.dim)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced Gaussian perturbation to enhance local search precision in quantum-inspired influence.", "configspace": "", "generation": 15, "fitness": 0.8597297473013308, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.019. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "bcaaab0c-673f-4f0c-bf3c-4b1117fa77cf", "metadata": {"aucs": [0.8482066994904173, 0.8445532826260809, 0.8864292597874943], "final_y": [0.13573176425064493, 0.1269720705667129, 0.12110541190783553]}, "mutation_prompt": null}
{"id": "00093c26-925e-492d-b501-875326d3cb45", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.9 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Changed value from 0.7 to 0.9\n            inertia_weight = 0.9 + (chaos_seq * adaptive_factor * 1.05)  # Adjusted from 0.7 to 0.9\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += self.q_coefficient * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced AdaptiveSwarmGradientDescent by adjusting chaotic perturbation to further diversify the search space.", "configspace": "", "generation": 15, "fitness": 0.8573482309908158, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.028. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "bcaaab0c-673f-4f0c-bf3c-4b1117fa77cf", "metadata": {"aucs": [0.8617970811691238, 0.8212404563592651, 0.8890071554440582], "final_y": [0.13084013526755733, 0.14803325846155313, 0.12488163879102487]}, "mutation_prompt": null}
{"id": "25fdc8d5-5985-4850-8140-2488616cd13d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.8 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Refined chaos sequence\n            inertia_weight = 0.7 + (0.4 * adaptive_factor ** 2)  # Non-linear inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.15 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8  # Refined quantum influence\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Enhanced AdaptiveSwarmGradientDescent by refining quantum influence and chaos sequence to enhance exploration and convergence.", "configspace": "", "generation": 16, "fitness": 0.8956436009799443, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.027. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "65816c54-b49d-49eb-a30d-1d232453f933", "metadata": {"aucs": [0.8633058013250794, 0.9297175576876522, 0.8939074439271015], "final_y": [0.13367907231489395, 0.11167411778252312, 0.12322828675380926]}, "mutation_prompt": null}
{"id": "4adae281-03e4-4e0c-9d39-c4795780123e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.7 + (0.4 * adaptive_factor ** 2)  # Non-linear inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.1 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * chaos_seq\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive quantum coefficient and chaos-based velocity perturbation for enhanced exploration and convergence.", "configspace": "", "generation": 16, "fitness": 0.8767344489485404, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.019. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "65816c54-b49d-49eb-a30d-1d232453f933", "metadata": {"aucs": [0.8720959725510049, 0.8560748208367919, 0.9020325534578243], "final_y": [0.1270248076173368, 0.11581802311385014, 0.12108105688978343]}, "mutation_prompt": null}
{"id": "c7ebfec5-4674-4598-9a74-216fdf12dfc9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.7 + (0.4 * adaptive_factor ** 2)  # Non-linear inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            swarm_diversity = np.std(swarm, axis=0).mean()\n            dynamic_q_coef = self.q_coefficient + 0.05 * swarm_diversity  # Change: Dynamic scaling of q_coefficient\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += dynamic_q_coef * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic scaling of the quantum-inspired coefficient based on current swarm diversity to further enhance exploration and convergence.", "configspace": "", "generation": 16, "fitness": 0.8764573561793347, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.030. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "65816c54-b49d-49eb-a30d-1d232453f933", "metadata": {"aucs": [0.8342663651646092, 0.9047457932434977, 0.8903599101298973], "final_y": [0.14013502574670367, 0.11968115747013619, 0.12518647025944363]}, "mutation_prompt": null}
{"id": "607583c9-d8b3-4f4c-a88a-ec9954b23a46", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.9 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Adjusted chaos sequence\n            inertia_weight = 0.7 + (0.4 * adaptive_factor ** 2)  # Non-linear inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.05 * np.random.randn(self.dim)  # Increased momentum\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.1 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Modified Enhanced AdaptiveSwarmGradientDescent by optimizing chaos sequence initialization and introducing a momentum term for improved stability.", "configspace": "", "generation": 16, "fitness": 0.8933405202470333, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.025. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "65816c54-b49d-49eb-a30d-1d232453f933", "metadata": {"aucs": [0.9233794141499659, 0.8954989617041905, 0.8611431848869435], "final_y": [0.11102040268521729, 0.1189249736318857, 0.11981016134995837]}, "mutation_prompt": null}
{"id": "55242ab9-0825-4d2b-b770-8eba9e5ce32f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.7 * (1 - 2 * np.abs(0.5 - np.random.rand()))\n            inertia_weight = 0.7 + 0.4 * np.cos(adaptive_factor * np.pi)  # Cosine-based inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.1 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved inertia calculation using cosine function to enhance exploration capabilities of the swarm.", "configspace": "", "generation": 16, "fitness": 0.8917723430996792, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.012. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "65816c54-b49d-49eb-a30d-1d232453f933", "metadata": {"aucs": [0.8766424105965315, 0.8929984747640856, 0.9056761439384207], "final_y": [0.11550237140345965, 0.11689339068631077, 0.11936618709704339]}, "mutation_prompt": null}
{"id": "03373d26-294f-4c34-a6d6-9b237f6b2187", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.8 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Refined chaos sequence\n            inertia_weight = 0.7 + (0.4 * adaptive_factor ** 2)  # Non-linear inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.15 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8  # Refined quantum influence\n\n                    # Introduce Lvy flight perturbation for enhanced exploration\n                    levy_step = np.random.standard_cauchy(self.dim) * adaptive_factor * 0.01\n                    swarm[i] += levy_step\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved AdaptiveSwarmGradientDescent by introducing Lvy flight perturbation for enhanced global exploration.", "configspace": "", "generation": 17, "fitness": 0.8517999804434936, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.015. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "25fdc8d5-5985-4850-8140-2488616cd13d", "metadata": {"aucs": [0.8563962948225312, 0.8679717730844986, 0.8310318734234508], "final_y": [0.12810608017922498, 0.11999339522215136, 0.13426748488422346]}, "mutation_prompt": null}
{"id": "c4a06b62-f32c-4c73-a9c0-af7730b5fa84", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.9 * np.sin(0.1 * evaluations)  # Adaptive chaotic perturbation\n            inertia_weight = 0.7 + (0.4 * adaptive_factor ** 2)  # Non-linear inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.15 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.9  # Enhanced quantum influence\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive chaotic perturbation and enhanced quantum influence to improve escape from local optima.", "configspace": "", "generation": 17, "fitness": 0.8537293997717441, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.045. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "25fdc8d5-5985-4850-8140-2488616cd13d", "metadata": {"aucs": [0.8936198728266691, 0.791456894179819, 0.8761114323087442], "final_y": [0.11720896911742662, 0.13810644183595666, 0.11339346495030833]}, "mutation_prompt": null}
{"id": "4b43e8ce-cf73-484d-8c77-46b28b774e13", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.8 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Refined chaos sequence\n            inertia_weight = 0.7 + (0.4 * adaptive_factor ** 2)  # Non-linear inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.15 * adaptive_factor * chaos_seq) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8  # Enhanced quantum influence\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced the quantum-inspired influence term with adaptive scaling based on chaos sequence to improve exploration.", "configspace": "", "generation": 17, "fitness": 0.8727488061913414, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.034. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "25fdc8d5-5985-4850-8140-2488616cd13d", "metadata": {"aucs": [0.9177584259020174, 0.8653049518411382, 0.8351830408308689], "final_y": [0.1144614273886575, 0.12565380172169505, 0.13425234049634882]}, "mutation_prompt": null}
{"id": "567ec018-8d9e-4035-a5a2-f6c5df5d83ab", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.8 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Refined chaos sequence\n            inertia_weight = 0.7 + (0.4 * adaptive_factor ** 2)  # Non-linear inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.15 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8  # Refined quantum influence\n\n                    # Stochastic Opposition-based Learning\n                    opposite = lb + ub - swarm[i] + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    opposite = np.clip(opposite, lb, ub)\n                    f_value = func(opposite)\n                    if f_value < personal_best_value[i]:\n                        swarm[i] = opposite\n                        personal_best[i] = opposite\n                        personal_best_value[i] = f_value\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced AdaptiveSwarmGradientDescent by integrating stochastic opposition-based learning to diversify exploration and intensify convergence.", "configspace": "", "generation": 17, "fitness": 0.8859112957464825, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.008. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "25fdc8d5-5985-4850-8140-2488616cd13d", "metadata": {"aucs": [0.8881474271451276, 0.8753739026031593, 0.894212557491161], "final_y": [0.1138480263311007, 0.11552875829480291, 0.11583068607279612]}, "mutation_prompt": null}
{"id": "e40cbe2a-3df8-4000-8aa7-4c53b20183b1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.8 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Refined chaos sequence\n            inertia_weight = 0.9 + (0.3 * adaptive_factor ** 3)  # Refined non-linear inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.15 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8  # Refined quantum influence\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced AdaptiveSwarmGradientDescent by refining the inertia weight non-linearity for better balance between exploration and exploitation.", "configspace": "", "generation": 17, "fitness": 0.8681217766126519, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.016. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "25fdc8d5-5985-4850-8140-2488616cd13d", "metadata": {"aucs": [0.852786086145058, 0.8621803601938082, 0.8893988834990896], "final_y": [0.12550843293569347, 0.12388913054041628, 0.11446637732773512]}, "mutation_prompt": null}
{"id": "ab7042b5-17f2-4d24-80d7-de1f112e8f25", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.8 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Refined chaos sequence\n            inertia_weight = 0.7 + (0.4 * adaptive_factor ** 2)  # Non-linear inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.15 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8  # Refined quantum influence\n\n                    # Chaotic map-based mutation\n                    chaos_factor = 0.2 * (np.sin(2 * np.pi * np.random.rand()) - 0.5)\n                    swarm[i] += chaos_factor * (ub - lb) * np.random.uniform(-1, 1, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced AdaptiveSwarmGradientDescent by employing chaotic map-based mutation to improve diversification and convergence.", "configspace": "", "generation": 18, "fitness": 0.8548778474780582, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.005. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "567ec018-8d9e-4035-a5a2-f6c5df5d83ab", "metadata": {"aucs": [0.8487493587406264, 0.860072893973965, 0.8558112897195829], "final_y": [0.13846025503680304, 0.12097626252241411, 0.11728707528496674]}, "mutation_prompt": null}
{"id": "47bd0dad-d938-43d3-a331-9f5c096860fa", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.8 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Refined chaos sequence\n            inertia_weight = 0.7 + (0.4 * adaptive_factor ** 2)  # Non-linear inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.25 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8  # Refined quantum influence\n\n                    # Stochastic Opposition-based Learning\n                    opposite = lb + ub - swarm[i] + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    opposite = np.clip(opposite, lb, ub)\n                    f_value = func(opposite)\n                    if f_value < personal_best_value[i]:\n                        swarm[i] = opposite\n                        personal_best[i] = opposite\n                        personal_best_value[i] = f_value\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved AdaptiveSwarmGradientDescent by optimizing quantum influence factor to better guide swarm movement.", "configspace": "", "generation": 18, "fitness": 0.8301524202815203, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.030. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "567ec018-8d9e-4035-a5a2-f6c5df5d83ab", "metadata": {"aucs": [0.8072196938525655, 0.8721827686091923, 0.811054798382803], "final_y": [0.15083962558589248, 0.1190817542657846, 0.13396063446361517]}, "mutation_prompt": null}
{"id": "c5a6f892-347d-47ab-9397-d392af9056f8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.8 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Refined chaos sequence\n            inertia_weight = 0.7 + (0.4 * adaptive_factor ** 2)  # Non-linear inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.25 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8  # Adjusted quantum influence\n\n                    # Stochastic Opposition-based Learning\n                    opposite = lb + ub - swarm[i] + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    opposite = np.clip(opposite, lb, ub)\n                    f_value = func(opposite)\n                    if f_value < personal_best_value[i]:\n                        swarm[i] = opposite\n                        personal_best[i] = opposite\n                        personal_best_value[i] = f_value\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced AdaptiveSwarmGradientDescent by adjusting the quantum influence coefficient for improved convergence control.", "configspace": "", "generation": 18, "fitness": 0.87652295170782, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.015. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "567ec018-8d9e-4035-a5a2-f6c5df5d83ab", "metadata": {"aucs": [0.8688384495586892, 0.8627802412415825, 0.8979501643231882], "final_y": [0.1260988021162377, 0.12423405433021095, 0.12049117676232213]}, "mutation_prompt": null}
{"id": "7df3c41d-4ef0-4140-9096-4fb4c2cfec6b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        \n        # Levy flight function\n        def levy_flight(Lambda=1.5):\n            sigma1 = np.power((np.math.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2)) / \n                              (np.math.gamma((1 + Lambda) / 2) * Lambda * np.power(2, (Lambda - 1) / 2)), \n                              1 / Lambda)\n            u = np.random.normal(0, sigma1, self.dim)\n            v = np.random.normal(0, 1, self.dim)\n            return u / np.power(np.abs(v), 1 / Lambda)\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + (0.4 * adaptive_factor ** 2)\n\n            cognitive_coeff = 1.7 * (0.5 + adaptive_factor)  # Adjusted coefficients\n            social_coeff = 1.7 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim)\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i] + 0.01 * levy_flight()  # Added Levy flight for exploration\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.15 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8\n\n                    opposite = lb + ub - swarm[i] + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    opposite = np.clip(opposite, lb, ub)\n                    f_value = func(opposite)\n                    if f_value < personal_best_value[i]:\n                        swarm[i] = opposite\n                        personal_best[i] = opposite\n                        personal_best_value[i] = f_value\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved AdaptiveSwarmGradientDescent by incorporating Levy flights for enhanced exploration and convergence precision.", "configspace": "", "generation": 18, "fitness": 0.8169543746166076, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.817 with standard deviation 0.014. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "567ec018-8d9e-4035-a5a2-f6c5df5d83ab", "metadata": {"aucs": [0.814340840662577, 0.8011427274110746, 0.8353795557761714], "final_y": [0.13658323493903635, 0.14376010202528677, 0.12389208288249054]}, "mutation_prompt": null}
{"id": "d98e9990-8633-4667-baa8-3eeb24e91d9d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.8 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Refined chaos sequence\n            inertia_weight = 0.7 + (0.4 * adaptive_factor ** 2)  # Non-linear inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb * (1 - 0.1 * adaptive_factor), ub * (1 - 0.1 * adaptive_factor))  # Contract search space\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.15 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8\n\n                    # Stochastic Opposition-based Learning\n                    opposite = lb + ub - swarm[i] + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    opposite = np.clip(opposite, lb, ub)\n                    f_value = func(opposite)\n                    if f_value < personal_best_value[i]:\n                        swarm[i] = opposite\n                        personal_best[i] = opposite\n                        personal_best_value[i] = f_value\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration and convergence with adaptive velocity perturbation and dynamic search space contraction.", "configspace": "", "generation": 18, "fitness": 0.8185448499426858, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.819 with standard deviation 0.012. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "567ec018-8d9e-4035-a5a2-f6c5df5d83ab", "metadata": {"aucs": [0.8016607760478929, 0.8313662645162828, 0.822607509263882], "final_y": [0.15090220824530476, 0.12609255725851554, 0.14344545416722843]}, "mutation_prompt": null}
{"id": "21a90051-4635-432f-9ba4-11cd7f0a12d3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.8 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Refined chaos sequence\n            inertia_weight = 0.5 + (0.5 * adaptive_factor ** 2)  # Adjusted non-linear inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.25 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8  # Adjusted quantum influence\n\n                    # Stochastic Opposition-based Learning\n                    opposite = lb + ub - swarm[i] + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    opposite = np.clip(opposite, lb, ub)\n                    f_value = func(opposite)\n                    if f_value < personal_best_value[i]:\n                        swarm[i] = opposite\n                        personal_best[i] = opposite\n                        personal_best_value[i] = f_value\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced AdaptiveSwarmGradientDescent by refining inertia weight for better dynamic balance between exploration and exploitation.", "configspace": "", "generation": 19, "fitness": 0.8577615374183226, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.019. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c5a6f892-347d-47ab-9397-d392af9056f8", "metadata": {"aucs": [0.8341458725709769, 0.880036366637208, 0.8591023730467826], "final_y": [0.12514975884313495, 0.12005052153629892, 0.12448125044702885]}, "mutation_prompt": null}
{"id": "9b20d0f8-ef0a-4451-abfa-840fc37d73c9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.7  # Quantum-inspired coefficient increased slightly\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.9 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # More refined chaos sequence\n            inertia_weight = 0.7 + (0.4 * adaptive_factor ** 2)  # Non-linear inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.25 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8  # Adjusted quantum influence\n\n                    # Stochastic Opposition-based Learning\n                    opposite = lb + ub - swarm[i] + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    opposite = np.clip(opposite, lb, ub)\n                    f_value = func(opposite)\n                    if f_value < personal_best_value[i]:\n                        swarm[i] = opposite\n                        personal_best[i] = opposite\n                        personal_best_value[i] = f_value\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined chaotic sequence and increased quantum influence for better exploration and convergence.", "configspace": "", "generation": 19, "fitness": 0.8474512680203299, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.038. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "c5a6f892-347d-47ab-9397-d392af9056f8", "metadata": {"aucs": [0.8634024446662651, 0.883948981772771, 0.7950023776219537], "final_y": [0.11330122005151344, 0.12017271766340587, 0.13222025092453682]}, "mutation_prompt": null}
{"id": "93096853-3d7c-4774-aecf-672f2d519035", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.9 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # More diverse chaos sequence\n            inertia_weight = 0.8 + (0.35 * adaptive_factor)  # More aggressive inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.25 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8  # Adjusted quantum influence\n\n                    # Stochastic Opposition-based Learning\n                    opposite = lb + ub - swarm[i] + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    opposite = np.clip(opposite, lb, ub)\n                    f_value = func(opposite)\n                    if f_value < personal_best_value[i]:\n                        swarm[i] = opposite\n                        personal_best[i] = opposite\n                        personal_best_value[i] = f_value\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration and exploitation balance in AdaptiveSwarmGradientDescent by refining chaos sequence and inertia weight adaptation.", "configspace": "", "generation": 19, "fitness": 0.8810555121065353, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.014. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c5a6f892-347d-47ab-9397-d392af9056f8", "metadata": {"aucs": [0.8644230599201612, 0.8794004071010774, 0.8993430692983674], "final_y": [0.13050818263114683, 0.12315829676773582, 0.11356389163752556]}, "mutation_prompt": null}
{"id": "34ddcbcc-72dc-4ad5-82c0-e453ce12dc35", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.8 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Refined chaos sequence\n            inertia_weight = 0.6 + (0.3 * adaptive_factor ** 2)  # Adjusted non-linear inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.3 * (0.5 + adaptive_factor)  # Adjusted cognitive coefficient\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.25 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8  # Adjusted quantum influence\n\n                    # Stochastic Opposition-based Learning\n                    opposite = lb + ub - swarm[i] + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    opposite = np.clip(opposite, lb, ub)\n                    f_value = func(opposite)\n                    if f_value < personal_best_value[i]:\n                        swarm[i] = opposite\n                        personal_best[i] = opposite\n                        personal_best_value[i] = f_value\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved AdaptiveSwarmGradientDescent by fine-tuning the inertia weight and cognitive coefficient for better exploration-exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.8508583022099726, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.017. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c5a6f892-347d-47ab-9397-d392af9056f8", "metadata": {"aucs": [0.8561171743309066, 0.8281363974706757, 0.8683213348283355], "final_y": [0.13196665644996253, 0.12163273517837725, 0.13240665909438798]}, "mutation_prompt": null}
{"id": "71064567-d7f5-41bb-849d-2f7a968ccaa0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.9 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # Refined chaos sequence\n            inertia_weight = 0.7 + (0.4 * adaptive_factor ** 2)  # Non-linear inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.25 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8  # Adjusted quantum influence\n\n                    # Stochastic Opposition-based Learning\n                    opposite = lb + ub - swarm[i] + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    opposite = np.clip(opposite, lb, ub)\n                    f_value = func(opposite)\n                    if f_value < personal_best_value[i]:\n                        swarm[i] = opposite\n                        personal_best[i] = opposite\n                        personal_best_value[i] = f_value\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved AdaptiveSwarmGradientDescent by tweaking chaos sequence scaling for enhanced exploration.", "configspace": "", "generation": 19, "fitness": 0.8208399034240741, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.028. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "c5a6f892-347d-47ab-9397-d392af9056f8", "metadata": {"aucs": [0.7937750716488551, 0.8095203838513254, 0.8592242547720418], "final_y": [0.15340814622921506, 0.14121084120154548, 0.12935464201075464]}, "mutation_prompt": null}
{"id": "1ded2bc8-c542-4f0a-8761-18e03f365145", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.9 * np.random.rand()  # Enhance chaos sequence generation\n            inertia_weight = 0.8 + (0.35 * adaptive_factor)  # More aggressive inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.35 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8  # Increased quantum influence\n\n                    # Stochastic Opposition-based Learning\n                    opposite = lb + ub - swarm[i] + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    opposite = np.clip(opposite, lb, ub)\n                    f_value = func(opposite)\n                    if f_value < personal_best_value[i]:\n                        swarm[i] = opposite\n                        personal_best[i] = opposite\n                        personal_best_value[i] = f_value\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved AdaptiveSwarmGradientDescent by enhancing chaos sequence generation and increasing quantum-inspired influence for better convergence.", "configspace": "", "generation": 20, "fitness": 0.862544417054193, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.004. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "93096853-3d7c-4774-aecf-672f2d519035", "metadata": {"aucs": [0.8629715286191564, 0.8572056106320226, 0.8674561119114002], "final_y": [0.13058480058137556, 0.12102915297382622, 0.12145653505096876]}, "mutation_prompt": null}
{"id": "aeabe80b-d8b0-4aec-8531-023318e913f0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.9 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # More diverse chaos sequence\n            inertia_weight = 0.8 + (0.35 * adaptive_factor)  # More aggressive inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.25 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8  # Adjusted quantum influence\n\n                    # Stochastic Opposition-based Learning\n                    # Enhanced boundary calculation for opposition\n                    opposite = lb + 0.5 * (ub - swarm[i]) + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    opposite = np.clip(opposite, lb, ub)\n                    f_value = func(opposite)\n                    if f_value < personal_best_value[i]:\n                        swarm[i] = opposite\n                        personal_best[i] = opposite\n                        personal_best_value[i] = f_value\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence in AdaptiveSwarmGradientDescent by refining opposition-based learning boundaries.", "configspace": "", "generation": 20, "fitness": 0.8545359393595685, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.042. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "93096853-3d7c-4774-aecf-672f2d519035", "metadata": {"aucs": [0.8798492327623884, 0.8889321213468123, 0.7948264639695046], "final_y": [0.12229110311775182, 0.11992733606806172, 0.1327438565912199]}, "mutation_prompt": null}
{"id": "94bc84d0-07fa-41d1-8e6a-42e1697e586e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, dim))  # Changed from zeros to random initialization\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.9 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # More diverse chaos sequence\n            inertia_weight = 0.8 + (0.35 * adaptive_factor)  # More aggressive inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.25 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8  # Adjusted quantum influence\n\n                    # Stochastic Opposition-based Learning\n                    opposite = lb + ub - swarm[i] + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    opposite = np.clip(opposite, lb, ub)\n                    f_value = func(opposite)\n                    if f_value < personal_best_value[i]:\n                        swarm[i] = opposite\n                        personal_best[i] = opposite\n                        personal_best_value[i] = f_value\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration and exploitation in AdaptiveSwarmGradientDescent by optimizing velocity initialization for improved convergence.", "configspace": "", "generation": 20, "fitness": 0.8747313037279691, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.008. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "93096853-3d7c-4774-aecf-672f2d519035", "metadata": {"aucs": [0.886144195411036, 0.8674378853815329, 0.8706118303913385], "final_y": [0.11572165711140259, 0.12652528810660035, 0.11602759047520783]}, "mutation_prompt": null}
{"id": "7ff2a4a0-5fc5-44cd-9886-af2da03d3643", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.9 * (1 - 2 * np.abs(0.5 - np.random.rand()))  # More diverse chaos sequence\n            inertia_weight = 0.8 + (0.35 * adaptive_factor)  # More aggressive inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.25 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * (0.8 + 0.2 * np.sin(evaluations))  # Adjusted quantum influence\n\n                    # Stochastic Opposition-based Learning\n                    opposite = lb + ub - swarm[i] + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    opposite = np.clip(opposite, lb, ub)\n                    f_value = func(opposite)\n                    if f_value < personal_best_value[i]:\n                        swarm[i] = opposite\n                        personal_best[i] = opposite\n                        personal_best_value[i] = f_value\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive quantum influence scaling for enhanced diversity and convergence.", "configspace": "", "generation": 20, "fitness": 0.8368879303241862, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.029. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "93096853-3d7c-4774-aecf-672f2d519035", "metadata": {"aucs": [0.8394897138917274, 0.8006339462442662, 0.8705401308365648], "final_y": [0.13614125944505862, 0.1562565076052459, 0.11842359205844655]}, "mutation_prompt": null}
{"id": "41e53de3-7269-4881-8d4a-46e55f0d4c35", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.q_coefficient = 1.5  # Quantum-inspired coefficient\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            chaos_seq = 0.9 * (1 - 2 * np.abs(0.5 - np.random.rand())) * (1 + 0.1 * adaptive_factor)  # Differential adaptive chaos sequence\n            inertia_weight = 0.8 + (0.35 * adaptive_factor * np.sin(np.pi * adaptive_factor))  # Differential adaptive inertia scaling\n\n            # Dynamically scale learning factors for enhanced exploration\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor)\n            social_coeff = 1.5 * (0.5 + adaptive_factor)\n\n            current_population_size = min(self.population_size + int(adaptive_factor * 5), self.budget - evaluations)\n\n            for i in range(current_population_size):\n                if i >= self.population_size:\n                    new_member = lb + (ub - lb) * np.random.rand(self.dim) * (1 + np.abs(chaos_seq))\n                    self.velocity = np.random.uniform(-1.5, 1.5, (self.population_size, self.dim))\n                    swarm[i % self.population_size] = new_member\n                else:\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i])) + 0.02 * np.random.randn(self.dim)\n                    swarm[i] += self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                    # Quantum-inspired influence\n                    q_rand = 2 * np.random.rand(self.dim) - 1\n                    swarm[i] += (self.q_coefficient + 0.25 * adaptive_factor) * adaptive_factor * q_rand * (global_best - swarm[i]) * 0.8  # Adjusted quantum influence\n\n                    # Stochastic Opposition-based Learning\n                    opposite = lb + ub - swarm[i] + np.random.uniform(-0.1, 0.1, self.dim) * (ub - lb)\n                    opposite = np.clip(opposite, lb, ub)\n                    f_value = func(opposite)\n                    if f_value < personal_best_value[i]:\n                        swarm[i] = opposite\n                        personal_best[i] = opposite\n                        personal_best_value[i] = f_value\n\n                    f_value = func(swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value:\n                        global_best = swarm[i]\n                        global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced differential adaptive chaos and inertia modulation to further enhance convergence efficiency.", "configspace": "", "generation": 20, "fitness": 0.8423395383350026, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.025. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "93096853-3d7c-4774-aecf-672f2d519035", "metadata": {"aucs": [0.8766745235764107, 0.8188489554098278, 0.8314951360187695], "final_y": [0.11916320852019169, 0.14020776027096593, 0.1289417239435987]}, "mutation_prompt": null}
