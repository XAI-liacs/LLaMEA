{"id": "821b83bb-e814-4e38-bc38-848ede9e4d3a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant = np.clip(x_1 + self.f * (x_2 - x_3), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "A hybrid metaheuristic algorithm combining Quasi-Oppositional Differential Evolution (QODE) with Local Search to exploit periodicity and optimize multilayered photonic structures.", "configspace": "", "generation": 0, "fitness": 0.9656425512823072, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": null, "metadata": {"aucs": [0.9694817839602157, 0.9688223766701322, 0.9586234932165741], "final_y": [0.16485629840118055, 0.16485652506917325, 0.1648567372430758]}, "mutation_prompt": null}
{"id": "fb30dd76-101f-4844-9860-e9bb24986e3f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B', options={'maxiter': 10})\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant = np.clip(x_1 + np.random.uniform(0.7, 0.9) * (x_2 - x_3), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "An enhanced hybrid algorithm tweaking local search and mutation dynamics to boost optimization on multilayered photonic structures.", "configspace": "", "generation": 1, "fitness": 0.9631586136039215, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "821b83bb-e814-4e38-bc38-848ede9e4d3a", "metadata": {"aucs": [0.9620299709250586, 0.9688223766701322, 0.9586234932165741], "final_y": [0.16491533610984555, 0.16485652506917325, 0.1648567372430758]}, "mutation_prompt": null}
{"id": "179b989e-943f-4038-9522-bf2d6815fc36", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by adjusting mutation scaling factor based on iteration to improve convergence in optimizing multilayered photonic structures.", "configspace": "", "generation": 1, "fitness": 0.9656484785126404, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "821b83bb-e814-4e38-bc38-848ede9e4d3a", "metadata": {"aucs": [0.9694995656512146, 0.9688223766701322, 0.9586234932165741], "final_y": [0.16485629840118055, 0.16485652506917325, 0.1648567372430758]}, "mutation_prompt": null}
{"id": "0f81d6c3-0502-4035-a13d-3154153fc1c6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                self.f = 0.5 + np.random.rand() * 0.5  # Enhanced differential weight strategy\n                mutant = np.clip(x_1 + self.f * (x_2 - x_3), self.lb, self.ub)\n                self.cr = 0.5 + 0.5 * np.abs(np.sin(evals))  # Dynamic crossover rate\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by adjusting crossover rate dynamically and refining differential weight strategy to better explore and exploit the search space.", "configspace": "", "generation": 1, "fitness": 0.9611496901537447, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "821b83bb-e814-4e38-bc38-848ede9e4d3a", "metadata": {"aucs": [0.9560032005745281, 0.9688223766701322, 0.9586234932165741], "final_y": [0.16485629840118055, 0.16485652506917325, 0.1648567372430758]}, "mutation_prompt": null}
{"id": "8e125bca-84db-4853-8392-7d06462fa537", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            self.cr = 0.9 - 0.7 * evals / self.budget  # Adaptive crossover rate\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant = np.clip(x_1 + self.f * (x_2 - x_3), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE with adaptive crossover rate to improve convergence in Bragg mirror optimization.", "configspace": "", "generation": 1, "fitness": 0.9656425512823072, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "821b83bb-e814-4e38-bc38-848ede9e4d3a", "metadata": {"aucs": [0.9694817839602157, 0.9688223766701322, 0.9586234932165741], "final_y": [0.16485629840118055, 0.16485652506917325, 0.1648567372430758]}, "mutation_prompt": null}
{"id": "fadcb7db-a568-4612-9ce9-7f679fa7272d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def adaptive_mutation(self, current_fitness, best_fitness):\n        return 0.5 + 0.3 * np.exp(-(best_fitness - current_fitness))\n\n    def enhanced_local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='SLSQP')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                current_fitness = func(pop[i])\n                self.f = self.adaptive_mutation(current_fitness, best_fitness)\n                mutant = np.clip(x_1 + self.f * (x_2 - x_3), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.enhanced_local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE algorithm with adaptive mutation factor and enhanced local search to improve convergence and solution quality.", "configspace": "", "generation": 1, "fitness": 0.9305341582175187, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.047. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "821b83bb-e814-4e38-bc38-848ede9e4d3a", "metadata": {"aucs": [0.8641566047658499, 0.9688223766701322, 0.9586234932165741], "final_y": [0.17205737646900532, 0.16485652506917325, 0.1648567372430758]}, "mutation_prompt": null}
{"id": "32913a1e-e1c0-45a4-b364-a215b6a7fad2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Optimized HybridQODE by introducing adaptive crossover probability for enhanced diversity in solution search.", "configspace": "", "generation": 2, "fitness": 0.9666007073439857, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "179b989e-943f-4038-9522-bf2d6815fc36", "metadata": {"aucs": [0.9694995656512146, 0.9665521766333838, 0.9637503797473588], "final_y": [0.16485629840118055, 0.16486110310223723, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "64d7b24c-3c97-4d75-a0f9-41eb826c873a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    pop[i] = np.tile(pop[i][:self.dim//2], 2)  # Enforce periodic boundary conditions\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Refined HybridQODE by integrating periodic boundary conditions to enforce periodicity and improve solution quality.", "configspace": "", "generation": 2, "fitness": 0.94919846324783, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.949 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "179b989e-943f-4038-9522-bf2d6815fc36", "metadata": {"aucs": [0.9366744762205877, 0.9471705337755432, 0.9637503797473588], "final_y": [0.16485600417433388, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "b1dd5bde-6843-42ab-99b9-752dc2db38cb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def chaos_based_adaptation(self, iter_num):\n        return 0.7 * (0.5 * (1 + np.cos(2 * np.pi * iter_num / self.budget)))\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.chaos_based_adaptation(evals)  # Use chaos-based adaptation\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Improved HybridQODE by introducing chaos-based parameter adaptation and periodicity-promoting mutation to enhance solution quality in multilayer photonic structure optimization.", "configspace": "", "generation": 2, "fitness": 0.9601168224727118, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "179b989e-943f-4038-9522-bf2d6815fc36", "metadata": {"aucs": [0.969429553895233, 0.9471705337755432, 0.9637503797473588], "final_y": [0.1648559542086958, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "b7fa9b8b-7e47-4235-bd50-e0d24fa16a0e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                adaptive_cr = self.cr * (0.5 + 0.5 * np.random.rand())  # Adaptive crossover\n                cross_points = np.random.rand(self.dim) < adaptive_cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget and np.random.rand() < 0.5:  # Stochastic local search trigger\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by introducing adaptive crossover probability and employing a stochastic local search trigger to further refine solution exploration.", "configspace": "", "generation": 2, "fitness": 0.9581954915963302, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "179b989e-943f-4038-9522-bf2d6815fc36", "metadata": {"aucs": [0.9636655612660887, 0.9471705337755432, 0.9637503797473588], "final_y": [0.16485751130789705, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "08d9c88b-c1f9-4f02-94f8-2eeb87c09107", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget) + 0.1  # Dynamic crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]) or trial_fitness < best_fitness:  # Elitism in selection\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Improved search space exploration by dynamically adjusting crossover probability and introducing elitism in selection.", "configspace": "", "generation": 2, "fitness": 0.9348047248340287, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.935 with standard deviation 0.030. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "179b989e-943f-4038-9522-bf2d6815fc36", "metadata": {"aucs": [0.893493260979184, 0.9471705337755432, 0.9637503797473588], "final_y": [0.1818795698434228, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "4f36907b-2665-41e3-a53b-0436277676ea", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced adaptive population size to maintain diversity and improve convergence.", "configspace": "", "generation": 3, "fitness": 0.9678131374628647, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "32913a1e-e1c0-45a4-b364-a215b6a7fad2", "metadata": {"aucs": [0.975355404359952, 0.9694554151058693, 0.9586285929227727], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "7ac81d4a-9b6a-4766-8f46-d37bff1b005c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def reinforce_periodicity(self, solution):\n        # Encourage periodic patterns\n        avg_layer_thickness = np.mean(solution.reshape(-1, 2), axis=0)\n        return np.tile(avg_layer_thickness, self.dim // 2)\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_solution = self.reinforce_periodicity(refined_solution)  # Reinforce periodic structure\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE with periodic reinforcement of constructive interference patterns for improved reflectivity optimization.", "configspace": "", "generation": 3, "fitness": 0.9658619298565959, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "32913a1e-e1c0-45a4-b364-a215b6a7fad2", "metadata": {"aucs": [0.9695017815411457, 0.9694554151058693, 0.9586285929227727], "final_y": [0.16485594899964107, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "ebcf8d46-3445-4ab8-833c-e0288ba35a16", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                \n                # Changed line: Apply periodic layer grouping strategy\n                trial = mutant if i % 2 == 0 else pop[i]\n\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by introducing periodic layer grouping to preserve modular characteristics in solutions.", "configspace": "", "generation": 3, "fitness": 0.9658611912266188, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "32913a1e-e1c0-45a4-b364-a215b6a7fad2", "metadata": {"aucs": [0.9694995656512146, 0.9694554151058693, 0.9586285929227727], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "2e3a5e52-a22b-47c4-9cb4-e3a89fda3a9d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Improved local search using BFGS with periodicity constraint\n        def periodic_cost(x):\n            return func(x) + 0.01 * np.sum((x - np.roll(x, 2))**2)\n        result = minimize(periodic_cost, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by incorporating a periodicity constraint and improved local search strategy for layered structure optimization.", "configspace": "", "generation": 3, "fitness": 0.9594572725202167, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "32913a1e-e1c0-45a4-b364-a215b6a7fad2", "metadata": {"aucs": [0.9502878095320084, 0.9694554151058693, 0.9586285929227727], "final_y": [0.16485577191149925, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "a45bedc1-4bc2-43db-a394-148277b763ed", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(len(pop)):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            if evals < self.budget * 0.8:  # Add periodic resampling to escape local minima\n                random_resample_idx = np.random.choice(len(pop), size=int(0.1 * len(pop)), replace=False)\n                for idx in random_resample_idx:\n                    new_pop[idx] = self.lb + (self.ub - self.lb) * np.random.rand(self.dim)\n\n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by incorporating periodic resampling to escape local minima more effectively.", "configspace": "", "generation": 3, "fitness": 0.9585018118617654, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "32913a1e-e1c0-45a4-b364-a215b6a7fad2", "metadata": {"aucs": [0.947421427556654, 0.9694554151058693, 0.9586285929227727], "final_y": [0.1648561149266684, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "bbf6a795-0c6e-4fe2-bb1c-c5849e1cac7d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[np.random.randint(len(pop))])  # Changed line\n\n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced crossover strategy for increased population diversity and exploration efficiency.", "configspace": "", "generation": 4, "fitness": 0.8974296114033193, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.086. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4f36907b-2665-41e3-a53b-0436277676ea", "metadata": {"aucs": [0.9505787534350965, 0.7762278852448368, 0.9654821955300248], "final_y": [0.16485629840118055, 0.1648561480224663, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "ec4a1d98-2e09-4560-aafc-623c8bf62cb7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Aggressively adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / self.budget) ** 1.5))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced a dynamic population size strategy to further maintain diversity and improve convergence, adapting more aggressively with budget exhaustion.", "configspace": "", "generation": 4, "fitness": 0.9628163212564096, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4f36907b-2665-41e3-a53b-0436277676ea", "metadata": {"aucs": [0.975355404359952, 0.9476113638792519, 0.9654821955300248], "final_y": [0.16485629840118055, 0.1648571041277802, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "a518732d-4031-4c42-baa6-3df35755666c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.7 + 0.3 * np.sin(3.14 * evals / self.budget)  # Added line: Chaotic mapping\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced chaotic mapping for mutation vector scaling to enhance exploration and exploitation balance in DE.", "configspace": "", "generation": 4, "fitness": 0.9724219553271699, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.972 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4f36907b-2665-41e3-a53b-0436277676ea", "metadata": {"aucs": [0.9734104881758365, 0.9783731822756482, 0.9654821955300248], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "43a30e58-7ffc-4b73-9ab7-607f88a5abe0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Adjust local search frequency dynamically\n            if evals < self.budget and evals % int(0.1 * self.budget) == 0:  # Changed line: Adjusting frequency\n                for i in range(len(pop)):\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Integrated dynamic local search frequency based on the progress of evaluations to enhance convergence.", "configspace": "", "generation": 4, "fitness": 0.8998276912004194, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.098. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "4f36907b-2665-41e3-a53b-0436277676ea", "metadata": {"aucs": [0.7616284404485948, 0.9723724376226385, 0.9654821955300248], "final_y": [0.1818794420920785, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "e5a5da3b-cbbe-4620-a577-fafe91ff279b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n        self.best_memory = []  # Memory to store best solutions\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                mutant = np.clip(x_1 + f_dynamic * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                        self.best_memory.append(best_solution)  # Store best solution\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n                        self.best_memory.append(best_solution)  # Store best solution\n\n        # Use memory of best solutions to further refine\n        for sol in self.best_memory:\n            refined_solution = self.local_search(sol, func)\n            refined_fitness = func(refined_solution)\n            evals += 1\n            if refined_fitness < best_fitness:\n                best_fitness = refined_fitness\n                best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by introducing memory of previous best solutions to boost convergence efficiency.", "configspace": "", "generation": 4, "fitness": 0.9698281621301398, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4f36907b-2665-41e3-a53b-0436277676ea", "metadata": {"aucs": [0.971629853237756, 0.9723724376226385, 0.9654821955300248], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485603836432328]}, "mutation_prompt": null}
{"id": "45df6b06-9583-41b8-958e-fa2e0b73e028", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def chaotic_mapping(self, evals):\n        return 0.7 + 0.3 * np.sin(6.28 * evals / self.budget)  # Adjusted frequency for dynamic changes\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)\n                chaotic_factor = self.chaotic_mapping(evals)  # Dynamic chaotic factor from separate function\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            if evals % (self.budget // 10) == 0:  # Periodic reinforcement\n                for i in range(len(pop)):\n                    if evals < self.budget:\n                        refined_solution = self.local_search(pop[i], func)\n                        refined_fitness = func(refined_solution)\n                        evals += 1\n                        if refined_fitness < best_fitness:\n                            best_fitness = refined_fitness\n                            best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE with dynamic chaotic mapping and periodic reinforcement for improved convergence.", "configspace": "", "generation": 5, "fitness": 0.9140772059637602, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.081. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a518732d-4031-4c42-baa6-3df35755666c", "metadata": {"aucs": [0.7999185119092063, 0.9797646978057666, 0.9625484081763077], "final_y": [0.1648601667899714, 0.16485600070702955, 0.16485841692191905]}, "mutation_prompt": null}
{"id": "faa19282-8cfc-439b-842a-f855257e1547", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.7 + 0.15 * (np.sin(3.14 * evals / self.budget) + np.sin(6.28 * evals / self.budget))  # Modified line: Chaotic mapping\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced time-varying chaotic sine mix to enhance population diversity and improve convergence dynamics.", "configspace": "", "generation": 5, "fitness": 0.9683765098806957, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a518732d-4031-4c42-baa6-3df35755666c", "metadata": {"aucs": [0.962816423660013, 0.9797646978057666, 0.9625484081763077], "final_y": [0.16485629840118055, 0.16485600070702955, 0.16485841692191905]}, "mutation_prompt": null}
{"id": "5b247b14-fffb-4141-b057-8b52387b9569", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        if not result.success:  # If not successful, introduce random restart\n            perturbation = np.random.uniform(-0.1, 0.1, self.dim)  # One line change\n            return np.clip(solution + perturbation, self.lb, self.ub)\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.7 + 0.3 * np.sin(3.14 * evals / self.budget)  # Added line: Chaotic mapping\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced local search strategy by introducing random restart in the BFGS optimization step to escape local minima.", "configspace": "", "generation": 5, "fitness": 0.971028612983754, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.971 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a518732d-4031-4c42-baa6-3df35755666c", "metadata": {"aucs": [0.9707727329691878, 0.9797646978057666, 0.9625484081763077], "final_y": [0.16485751130789705, 0.16485600070702955, 0.16485841692191905]}, "mutation_prompt": null}
{"id": "bb754638-a467-4c3d-9325-9abc1f594cd7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.7 + 0.3 * np.sin(3.14 * evals / self.budget)  # Added line: Chaotic mapping\n                sigmoid_factor = 1 / (1 + np.exp(-0.1 * (evals - self.budget / 2)))  # Added line: Sigmoid modulation\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * sigmoid_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr / (1 + np.exp(-0.1 * (evals - self.budget / 2)))  # Changed line: Sigmoid-based adaptive crossover \n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by introducing a sigmoid-based adaptive crossover probability and a dynamic chaotic weight adjustment.", "configspace": "", "generation": 5, "fitness": 0.9595016766257142, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a518732d-4031-4c42-baa6-3df35755666c", "metadata": {"aucs": [0.9558701562791023, 0.9600864654217324, 0.9625484081763077], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485841692191905]}, "mutation_prompt": null}
{"id": "463f3751-2dda-4603-a222-d49b88b33f83", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.7 + 0.3 * np.sin(3.14 * evals / self.budget) * np.cos(3.14 * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced mutation by introducing a cosine function for more diverse exploration.", "configspace": "", "generation": 5, "fitness": 0.9724206875523199, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.972 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "a518732d-4031-4c42-baa6-3df35755666c", "metadata": {"aucs": [0.9749489566748855, 0.9797646978057666, 0.9625484081763077], "final_y": [0.16485629840118055, 0.16485600070702955, 0.16485841692191905]}, "mutation_prompt": null}
{"id": "8aa6f94e-901c-4d44-bdb1-2061341b3309", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget) * (best_fitness / (0.1 + best_fitness)))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)\n                chaotic_factor = 0.5 + 0.3 * np.sin(5 * np.pi * evals / self.budget)\n                f_chaos = f_dynamic * chaotic_factor\n                mutant = np.clip(x_1 + f_chaos * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introducing chaos-enhanced dynamic scaling and differential fitness-based population reduction in HybridQODE.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('cannot convert float NaN to integer').", "error": "ValueError('cannot convert float NaN to integer')", "parent_id": "463f3751-2dda-4603-a222-d49b88b33f83", "metadata": {}, "mutation_prompt": null}
{"id": "4263aede-f72d-4af4-b827-8445d7cc21e1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.7 + 0.5 * np.sin(3.14 * evals / (2 * self.budget)) * np.cos(3.14 * evals / (2 * self.budget))  # Modified line (enhanced)\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced with adaptive chaotic factors to improve exploration and convergence.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('cannot convert float NaN to integer').", "error": "ValueError('cannot convert float NaN to integer')", "parent_id": "463f3751-2dda-4603-a222-d49b88b33f83", "metadata": {}, "mutation_prompt": null}
{"id": "c5425345-a23a-455b-bae5-9f0588bf4c6b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.7 + 0.3 * np.sin(3.14 * evals / self.budget) * np.cos(3.14 * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i]) + np.random.normal(0, 0.1, self.dim)  # Added Gaussian perturbation\n\n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n\n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced population diversity by adding a Gaussian perturbation to the trial vector.", "configspace": "", "generation": 6, "fitness": 0.9726608655403531, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "463f3751-2dda-4603-a222-d49b88b33f83", "metadata": {"aucs": [0.9620464655196082, 0.9803856684816544, 0.975550462619797], "final_y": [0.16485629840118055, 0.16485620050124516, 0.16485685793583182]}, "mutation_prompt": null}
{"id": "8d369112-2e5e-4cb7-aa0b-cdef97d1c8f3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))  # Modified line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.6 + 0.4 * np.sin(3.14 * evals / self.budget) * np.cos(3.14 * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced adaptive learning rate and dynamic population size scaling to improve exploration and convergence balance.", "configspace": "", "generation": 6, "fitness": 0.9767235998157169, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.977 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "463f3751-2dda-4603-a222-d49b88b33f83", "metadata": {"aucs": [0.9742346683456989, 0.9803856684816544, 0.975550462619797], "final_y": [0.16485626480181526, 0.16485620050124516, 0.16485685793583182]}, "mutation_prompt": null}
{"id": "bd38b7d9-7625-4ed8-bc44-2fa20589ca7c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Adaptive population size based on remaining budget\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget / 0.9))))  # Modified line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.7 + 0.3 * np.sin(3.14 * evals / self.budget) * np.cos(3.14 * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced adaptive population contraction to enhance convergence speed without compromising exploration. ", "configspace": "", "generation": 6, "fitness": 0.96664795895546, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.015. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "463f3751-2dda-4603-a222-d49b88b33f83", "metadata": {"aucs": [0.9734104252978427, 0.9803856684816544, 0.9461477830868825], "final_y": [0.16485629840118055, 0.16485620050124516, 0.1648594403046183]}, "mutation_prompt": null}
{"id": "d3ca672a-dcc5-4418-b79e-0b180891dccc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)\n                chaotic_factor = 0.6 + 0.4 * np.sin(3.14 * evals / self.budget) * np.cos(3.14 * evals / self.budget)\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget and i % 2 == 0:  # Perform local search every alternate iteration\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by integrating periodic modulation and a multi-phase local search for improved convergence accuracy.", "configspace": "", "generation": 7, "fitness": 0.9660851148143951, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8d369112-2e5e-4cb7-aa0b-cdef97d1c8f3", "metadata": {"aucs": [0.9617862436543566, 0.9802650862980826, 0.9562040144907459], "final_y": [0.16485618987775974, 0.16485652506917325, 0.16485730168119728]}, "mutation_prompt": null}
{"id": "5247527b-0f18-47e7-93e1-7f584c794e7e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.3 * self.budget))))  # Changed line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (0.5 + 0.5 * np.sin(evals * np.pi / self.budget))  # Changed line\n                chaotic_factor = 0.6 + 0.4 * np.sin(3.14 * evals / self.budget)  # Changed line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (0.5 + 0.5 * np.cos(evals * np.pi / self.budget))  # Changed line\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n\n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE with chaotic dynamics and periodicity reinforcement for improved exploration and convergence. ", "configspace": "", "generation": 7, "fitness": 0.9630191423620239, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.012. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8d369112-2e5e-4cb7-aa0b-cdef97d1c8f3", "metadata": {"aucs": [0.9525883262972431, 0.9802650862980826, 0.9562040144907459], "final_y": [0.16485641090464975, 0.16485652506917325, 0.16485730168119728]}, "mutation_prompt": null}
{"id": "9d8f9525-f4e5-4591-ab53-cef4801ea90c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))  # Modified line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.7 + 0.3 * np.sin(2 * 3.14 * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / (1.2 * self.budget))  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced global search by modifying chaotic factor and crossover probability dynamics for better diversity.", "configspace": "", "generation": 7, "fitness": 0.9699627298010817, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8d369112-2e5e-4cb7-aa0b-cdef97d1c8f3", "metadata": {"aucs": [0.9734190886144167, 0.9802650862980826, 0.9562040144907459], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485730168119728]}, "mutation_prompt": null}
{"id": "b4a7d55f-fafb-412c-b03c-72086d1ae047", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))  # Modified line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced mutation strategy by using a sinusoidal chaotic factor for improved exploration.", "configspace": "", "generation": 7, "fitness": 0.970250638028569, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8d369112-2e5e-4cb7-aa0b-cdef97d1c8f3", "metadata": {"aucs": [0.9742828132968784, 0.9802650862980826, 0.9562040144907459], "final_y": [0.16485627853351514, 0.16485652506917325, 0.16485730168119728]}, "mutation_prompt": null}
{"id": "0bf2278a-2a7d-42e9-b2a9-0451f576004e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)\n                chaotic_factor = 0.6 + 0.4 * np.sin(2 * np.pi * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget) + 0.1 * np.random.rand()  # Modified line\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced chaotic perturbation and adaptive crossover to enhance exploration and convergence in hybrid global-local optimization.", "configspace": "", "generation": 7, "fitness": 0.9661717485060728, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8d369112-2e5e-4cb7-aa0b-cdef97d1c8f3", "metadata": {"aucs": [0.9620461447293898, 0.9802650862980826, 0.9562040144907459], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485730168119728]}, "mutation_prompt": null}
{"id": "565908a3-fd97-4a86-a8d4-3e7f41893554", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))  # Modified line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))  # Modified line\n                chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduce adaptive scaling of self.f and integrate sinusoidal asymmetric factor to enhance exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.9648021818930644, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b4a7d55f-fafb-412c-b03c-72086d1ae047", "metadata": {"aucs": [0.9518721610835252, 0.9770810304291805, 0.965453354166488], "final_y": [0.16485768354858754, 0.16485601377698877, 0.16485817338893138]}, "mutation_prompt": null}
{"id": "603b7ecb-4742-4909-8060-1dccf848576a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            # Change: Adjust population size using fitness variance\n            fitness_values = np.array([func(ind) for ind in pop])\n            fitness_variance = np.var(fitness_values)\n            self.pop_size = max(5, int(self.pop_size * (1 + fitness_variance / (1.5 * self.budget))))\n            \n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Improved exploration by dynamically adjusting the population size based on fitness variance.", "configspace": "", "generation": 8, "fitness": 0.9611159462911129, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b4a7d55f-fafb-412c-b03c-72086d1ae047", "metadata": {"aucs": [0.9713461511205156, 0.9639419986679183, 0.9480596890849047], "final_y": [0.16485627853351514, 0.16485964280847687, 0.16485609252473576]}, "mutation_prompt": null}
{"id": "e1f70b58-b5ca-441d-aaf0-e7d935ff0669", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (2 * self.budget))))  # Modified line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)  # Dynamic mutation factor\n                chaotic_factor = 0.6 + 0.4 * np.sin(2 * np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  \n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced time-varying chaotic factor and adaptive population reduction to enhance exploration and convergence.", "configspace": "", "generation": 8, "fitness": 0.9623028138017178, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b4a7d55f-fafb-412c-b03c-72086d1ae047", "metadata": {"aucs": [0.9749067536523306, 0.9639419986679183, 0.9480596890849047], "final_y": [0.16485629840118055, 0.16485964280847687, 0.16485609252473576]}, "mutation_prompt": null}
{"id": "fe220da1-5f7b-46c9-b347-64a0482eba53", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))  # Modified line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                # Modify dynamic mutation factor to consider budget's square root to adapt exploration\n                f_dynamic = self.f * (1 - np.sqrt(evals) / np.sqrt(self.budget))  # Modified line\n                # Introduce a dynamically adjusted chaotic factor using a cosine modulation\n                chaotic_factor = 0.6 + 0.4 * np.cos(np.pi * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Adaptive population and dynamic chaos factor were incorporated to enhance exploration and convergence balance.", "configspace": "", "generation": 8, "fitness": 0.9624529750927279, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b4a7d55f-fafb-412c-b03c-72086d1ae047", "metadata": {"aucs": [0.975357237525361, 0.9639419986679183, 0.9480596890849047], "final_y": [0.16485629840118055, 0.16485964280847687, 0.16485609252473576]}, "mutation_prompt": null}
{"id": "0c90993e-797f-49ee-adfd-247c4aeda9ba", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=60, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def levy_flight(self, step_size):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                (np.math.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v)**(1 / beta)\n        return step_size * step\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / self.budget)))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (1 - evals / self.budget)\n                levy_step = self.levy_flight(f_dynamic)  # Added line\n                mutant = np.clip(x_1 + levy_step * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced adaptive population size and chaotic Levy flight mutation for enhanced exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.9539509028140373, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b4a7d55f-fafb-412c-b03c-72086d1ae047", "metadata": {"aucs": [0.9498510206892888, 0.9639419986679183, 0.9480596890849047], "final_y": [0.1648578354368162, 0.16485964280847687, 0.16485609252473576]}, "mutation_prompt": null}
{"id": "d5bd284a-45d3-403e-83dd-036350645cae", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance adaptiveness by incorporating Levy flights for exploration and dynamic mutation strategies to balance exploration and exploitation.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "565908a3-fd97-4a86-a8d4-3e7f41893554", "metadata": {}, "mutation_prompt": null}
{"id": "6aa56b5a-6124-46ec-b189-e2d40bb3108c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                chaotic_factor = 0.5 + 0.3 * np.sin(2 * np.pi * evals / self.budget)  # Modified line\n                f_dynamic *= (1 + 0.1 * np.cos(np.pi * evals / self.budget))  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            if evals < self.budget:  # Modified condition\n                for i in range(len(pop)):\n                    if evals < self.budget:\n                        refined_solution = self.local_search(pop[i], func)\n                        refined_fitness = func(refined_solution)\n                        evals += 1\n                        if refined_fitness < best_fitness:\n                            best_fitness = refined_fitness\n                            best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance HybridQODE by introducing adaptive chaotic factors and improving exploitation balance through dynamic scaling and periodic local searches.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "565908a3-fd97-4a86-a8d4-3e7f41893554", "metadata": {}, "mutation_prompt": null}
{"id": "5f127740-1116-44be-935f-c722d6784e40", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))  # Modified line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))  # Modified line\n                chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)  # Modified line\n                periodic_factor = np.sin(2 * np.pi * np.sum(x_1) / self.dim)  # New line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * periodic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance adaptive crossover strategy and integrate a periodic solution mechanism for improved convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "565908a3-fd97-4a86-a8d4-3e7f41893554", "metadata": {}, "mutation_prompt": null}
{"id": "b5b7cedc-4547-42ce-9a1d-0759d6c046d5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f  # Differential weight\n        self.cr = cr  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        # Initialize population with quasi-oppositional solutions\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        # Local search using BFGS to fine-tune solutions\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - (evals * 0.9) / (1.5 * self.budget))))  # Modified line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):  # Adjusting loop according to new pop_size\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))  # Modified line\n                chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)  # Modified line\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                cr_dynamic = self.cr * (1 - evals / self.budget)  # Changed line: Adaptive crossover probability\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Evaluate and select\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            # Periodic encouragement via local search\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduce a dynamic adjustment to the population size reduction factor, enhancing diversity and exploration.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "565908a3-fd97-4a86-a8d4-3e7f41893554", "metadata": {}, "mutation_prompt": null}
{"id": "9241780e-ed88-4b09-9c42-dbf37b7643a4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.3 * self.budget))))  # Modified line (1)\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f * (0.5 + 0.5 * np.sin(2 * np.pi * evals / self.budget))  # Modified line (2)\n                chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(2 * np.pi * evals / self.budget)  # Modified line (3)\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Integrate periodic modulation of self.f with dynamic chaotic factors and adapt population size for improved exploration.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "565908a3-fd97-4a86-a8d4-3e7f41893554", "metadata": {}, "mutation_prompt": null}
{"id": "b11e7472-f68d-4a24-bb77-0cf0f346d612", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import levy_stable\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance adaptiveness by incorporating Levy flights for exploration and dynamic mutation strategies to balance exploration and exploitation, with corrected use of the gamma function.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'HybridQODE' object has no attribute 'local_search'\").", "error": "AttributeError(\"'HybridQODE' object has no attribute 'local_search'\")", "parent_id": "d5bd284a-45d3-403e-83dd-036350645cae", "metadata": {}, "mutation_prompt": null}
{"id": "d7828ac5-7a81-4dae-9c16-a2bb539214a5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.special import gamma  # Correct import for gamma function\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance adaptiveness by incorporating Levy flights for exploration and dynamic mutation strategies to balance exploration and exploitation, while ensuring correct function calls and imports.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'HybridQODE' object has no attribute 'local_search'\").", "error": "AttributeError(\"'HybridQODE' object has no attribute 'local_search'\")", "parent_id": "d5bd284a-45d3-403e-83dd-036350645cae", "metadata": {}, "mutation_prompt": null}
{"id": "1afaabce-79a0-4d6f-a8c3-a1be3c1d2422", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.special import gamma\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "HybridQODE refines Levy flight calculation by replacing `np.gamma` with `scipy.special.gamma`.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'HybridQODE' object has no attribute 'local_search'\").", "error": "AttributeError(\"'HybridQODE' object has no attribute 'local_search'\")", "parent_id": "d5bd284a-45d3-403e-83dd-036350645cae", "metadata": {}, "mutation_prompt": null}
{"id": "86deb002-6024-4834-9dd6-0c3dc96e020d", "solution": "import numpy as np\nfrom scipy.special import gamma\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Improve solution by correcting numpy gamma function access and refining local search step size.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'HybridQODE' object has no attribute 'local_search'\").", "error": "AttributeError(\"'HybridQODE' object has no attribute 'local_search'\")", "parent_id": "d5bd284a-45d3-403e-83dd-036350645cae", "metadata": {}, "mutation_prompt": null}
{"id": "06396903-0364-45ce-8f65-1996b1f290de", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.special import gamma as gamma_func\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (gamma_func(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (gamma_func((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=list(zip(self.lb, self.ub)), method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n\n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n\n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Adaptive Hybrid QODE using Symmetric Strategies with Chaotic Dynamics for Enhanced Exploration.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'HybridQODE' object has no attribute 'local_search'\").", "error": "AttributeError(\"'HybridQODE' object has no attribute 'local_search'\")", "parent_id": "d5bd284a-45d3-403e-83dd-036350645cae", "metadata": {}, "mutation_prompt": null}
{"id": "67e7c695-823d-4963-b27f-1fc7ab25b1a9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import levy_stable\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):  # Added missing local_search method\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Improve the HybridQODE algorithm by including a basic local search method, fixing the previous exception while maintaining the overall design structure.", "configspace": "", "generation": 11, "fitness": 0.8845942113377508, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.114. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b11e7472-f68d-4a24-bb77-0cf0f346d612", "metadata": {"aucs": [0.9526719515811796, 0.9769226206179344, 0.7241880618141385], "final_y": [0.16485670131798424, 0.16485652506917325, 0.18464993856964962]}, "mutation_prompt": null}
{"id": "7a0139be-6533-4238-8bbd-bbfb99fb4d93", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import levy_stable\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x if result.success else solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Incorporate a simple local search method to enhance fine-tuning of solutions close to promising regions while respecting the modification limit.", "configspace": "", "generation": 11, "fitness": 0.8656568960379302, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.101. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b11e7472-f68d-4a24-bb77-0cf0f346d612", "metadata": {"aucs": [0.9526719515811796, 0.9201106747184726, 0.7241880618141385], "final_y": [0.16485670131798424, 0.16485757522474254, 0.18464993856964962]}, "mutation_prompt": null}
{"id": "b1907515-42bc-48be-87f1-dd43e35f6c88", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import levy_stable\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, method='L-BFGS-B', bounds=np.stack((self.lb, self.ub), axis=1))\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "A hybrid optimization algorithm combining differential evolution and Levy flights with an adaptive local search mechanism to exploit promising regions.", "configspace": "", "generation": 11, "fitness": 0.8658194309128491, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.101. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b11e7472-f68d-4a24-bb77-0cf0f346d612", "metadata": {"aucs": [0.9526719515811796, 0.920598279343229, 0.7241880618141385], "final_y": [0.16485670131798424, 0.16485758057673716, 0.18464993856964962]}, "mutation_prompt": null}
{"id": "b48f7466-18e3-48bd-a819-dc1e0c163119", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import levy_stable\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        res = minimize(func, solution, method='BFGS', bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)])\n        return res.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance adaptiveness by incorporating Levy flights for exploration and dynamic mutation strategies with improved local search using BFGS optimization.", "configspace": "", "generation": 11, "fitness": 0.8277680424829715, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.080. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "b11e7472-f68d-4a24-bb77-0cf0f346d612", "metadata": {"aucs": [0.8390053909163033, 0.9201106747184726, 0.7241880618141385], "final_y": [0.18813128582889427, 0.16485757522474254, 0.18464993856964962]}, "mutation_prompt": null}
{"id": "10111afe-ad72-4412-8ca1-17665a69067f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import levy_stable\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        res = minimize(func, solution, method='BFGS', bounds=[(l, u) for l, u in zip(self.lb, self.ub)])\n        return res.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance adaptiveness by incorporating Levy flights for exploration and dynamic mutation strategies to balance exploration and exploitation, with corrected use of the gamma function, and apply BFGS for local search refinements.", "configspace": "", "generation": 11, "fitness": 0.8277680424829715, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.080. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "b11e7472-f68d-4a24-bb77-0cf0f346d612", "metadata": {"aucs": [0.8390053909163033, 0.9201106747184726, 0.7241880618141385], "final_y": [0.18813128582889427, 0.16485757522474254, 0.18464993856964962]}, "mutation_prompt": null}
{"id": "3496edc9-0388-4bd0-92ae-5a85bd643e03", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import levy_stable\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B', options={'maxiter': 150})\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance local search intensity by increasing iterations when refining solutions.", "configspace": "", "generation": 12, "fitness": 0.952998639460917, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.020. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "67e7c695-823d-4963-b27f-1fc7ab25b1a9", "metadata": {"aucs": [0.9526719515811796, 0.9778299066441565, 0.9284940601574149], "final_y": [0.16485670131798424, 0.16485588447342558, 0.1648566114723854]}, "mutation_prompt": null}
{"id": "2f8c5418-8c08-4cbe-a882-74240e1dbd62", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE by integrating dynamic multi-strategy selection and improved adaptivity for balancing exploration and exploitation.", "configspace": "", "generation": 12, "fitness": 0.9668783792585013, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "67e7c695-823d-4963-b27f-1fc7ab25b1a9", "metadata": {"aucs": [0.9618393035621945, 0.9778286199306891, 0.9609672142826202], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485766939479451]}, "mutation_prompt": null}
{"id": "af7eb5de-0c4a-4c05-91fa-f4d00121328f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution, evals):  # Adjusted line\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step * (1 - evals / self.budget)  # Adjusted line\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i], evals)\n\n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n\n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Slightly increase the exploration capability by dynamically adjusting the Levy flight step size based on the evaluation budget.", "configspace": "", "generation": 12, "fitness": 0.9583347479531765, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.021. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "67e7c695-823d-4963-b27f-1fc7ab25b1a9", "metadata": {"aucs": [0.931365597320623, 0.9826714322562866, 0.9609672142826202], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485766939479451]}, "mutation_prompt": null}
{"id": "402bebdf-8822-4dfa-95ef-6d8e78196ffe", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def adaptive_mutation(self, solution, evals):  # Changed from levy_flight to adaptive_mutation\n        factor = 0.01 + (0.99 * evals / self.budget)\n        return solution + factor * np.random.normal(0, 1, size=self.dim)\n\n    def local_search_with_periodicity(self, solution, func):  # Enhanced local search\n        periodic_solution = np.mean(solution.reshape(-1, 2), axis=1).repeat(2)\n        result = minimize(func, periodic_solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.adaptive_mutation(pop[i], evals)  # Use adaptive_mutation\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search_with_periodicity(pop[i], func)  # Use enhanced local search\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Refine HybridQODE by integrating an adaptive mutation strategy and enhancing the local search with periodicity constraints.", "configspace": "", "generation": 12, "fitness": 0.9517919778247954, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.952 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "67e7c695-823d-4963-b27f-1fc7ab25b1a9", "metadata": {"aucs": [0.9665391859520654, 0.9278695332397005, 0.9609672142826202], "final_y": [0.1648570606567613, 0.1648612599590933, 0.16485766939479451]}, "mutation_prompt": null}
{"id": "3b060463-3c59-44dc-8935-c6f90bd6829f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def adapt_parameters(self, evals):\n        adapt_rate = evals / self.budget\n        self.f = 0.5 + 0.4 * np.sin(2 * np.pi * adapt_rate)\n        self.cr = 0.9 - 0.5 * adapt_rate\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.adapt_parameters(evals)\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < 0.5:\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduce adaptive control of crossover and mutation parameters to improve exploration and exploitation balance in the HybridQODE algorithm.", "configspace": "", "generation": 12, "fitness": 0.9530550574629874, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "67e7c695-823d-4963-b27f-1fc7ab25b1a9", "metadata": {"aucs": [0.9630237505393348, 0.9351742075670071, 0.9609672142826202], "final_y": [0.16485670131798424, 0.16485657887493044, 0.16485766939479451]}, "mutation_prompt": null}
{"id": "5dd0b2aa-6549-41ca-be30-b47e94fa540c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced adaptive mutation rate scaling based on budget usage to improve exploration-exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.9218627724350755, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.035. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "2f8c5418-8c08-4cbe-a882-74240e1dbd62", "metadata": {"aucs": [0.9618424597414492, 0.9265194804122251, 0.8772263771515525], "final_y": [0.16485629840118055, 0.16485757522474254, 0.18188219681393325]}, "mutation_prompt": null}
{"id": "9264559c-6742-4355-b818-7e2343db10e8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='BFGS')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.2 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.4 + 0.6 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.6 + 0.4 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Refined HybridQODE with enhanced adaptive parameter control and improved local search strategy for better convergence.", "configspace": "", "generation": 13, "fitness": 0.8484679332197906, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.078. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "2f8c5418-8c08-4cbe-a882-74240e1dbd62", "metadata": {"aucs": [0.7416579420955944, 0.9265194804122251, 0.8772263771515525], "final_y": [0.1818830840566681, 0.16485757522474254, 0.18188219681393325]}, "mutation_prompt": null}
{"id": "3b82c890-fa61-4892-95af-6bffaafd9e36", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Improved exploration by optimal tuning of the chaotic factor within the mutation strategy.", "configspace": "", "generation": 13, "fitness": 0.970858854906227, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.971 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2f8c5418-8c08-4cbe-a882-74240e1dbd62", "metadata": {"aucs": [0.9618426970274704, 0.9785774320658959, 0.9721564356253148], "final_y": [0.16485592951659345, 0.16485652506917325, 0.1648576631807792]}, "mutation_prompt": null}
{"id": "231e3cf9-262d-4273-932c-7bb02fdfc7c2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def encourage_periodicity(self, solution):\n        half_dim = self.dim // 2\n        return np.tile(solution[:half_dim], 2)\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.6 + 0.4 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n\n                if np.random.rand() < 0.5:\n                    mutant = self.encourage_periodicity(mutant)\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Incorporate adaptive periodicity encouragement and dynamic opposition in crossover to enhance solution exploration and convergence.", "configspace": "", "generation": 13, "fitness": 0.9677355304993301, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2f8c5418-8c08-4cbe-a882-74240e1dbd62", "metadata": {"aucs": [0.9620884680219655, 0.9788050690618287, 0.9623130544141962], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485730168119728]}, "mutation_prompt": null}
{"id": "ae4d795f-242a-48ce-b5f0-4489dc226191", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.005 * step  # Minor adjustment for finer steps\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        if result.success:  # Improve local search by considering success\n            return result.x\n        return solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.4 + 0.6 * evals / self.budget):  # Slightly adjusted for exploration\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.6 + 0.4 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "HybridQODE with enhanced local refinement and adaptive crossover to improve convergence and solution quality.", "configspace": "", "generation": 13, "fitness": 0.9592352358964081, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2f8c5418-8c08-4cbe-a882-74240e1dbd62", "metadata": {"aucs": [0.9365875842131993, 0.9788050690618287, 0.9623130544141962], "final_y": [0.1648563795441571, 0.16485652506917325, 0.16485730168119728]}, "mutation_prompt": null}
{"id": "6d9146d0-1221-42da-a0a4-f4f6a41b1992", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.9 + 0.1 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - 0.5 * evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced mutation strategy by incorporating adaptive scaling factors and dynamic crossover rates to boost convergence.", "configspace": "", "generation": 14, "fitness": 0.9629453309610292, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3b82c890-fa61-4892-95af-6bffaafd9e36", "metadata": {"aucs": [0.961991779390222, 0.9660843147360884, 0.9607598987567774], "final_y": [0.16485629840118055, 0.16485652506917325, 0.1648573483720308]}, "mutation_prompt": null}
{"id": "0ec4028c-367c-4dd9-8e47-002679806df7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced exploration-exploitation balance by modifying dynamic parameters based on cosine function.", "configspace": "", "generation": 14, "fitness": 0.9670869243216415, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3b82c890-fa61-4892-95af-6bffaafd9e36", "metadata": {"aucs": [0.9618424597414492, 0.9786584144666978, 0.9607598987567774], "final_y": [0.16485629840118055, 0.16485682571536198, 0.1648573483720308]}, "mutation_prompt": null}
{"id": "d8be77d1-2fe4-4af1-815e-f5c68cac8ac4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def adaptive_control(self, evals):\n        f_adaptive = self.f + 0.4 * np.sin(2 * np.pi * evals / self.budget)\n        cr_adaptive = self.cr - 0.2 * np.cos(2 * np.pi * evals / self.budget)\n        return f_adaptive, cr_adaptive\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                f_dynamic, cr_dynamic = self.adaptive_control(evals)\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    chaotic_factor = 0.7 + 0.3 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n\n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "The algorithm optimizes a differential evolution strategy by implementing a dynamic adaptive mechanism for controlling mutation and crossover rates, promoting better convergence and stability.", "configspace": "", "generation": 14, "fitness": 0.9670868782902392, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3b82c890-fa61-4892-95af-6bffaafd9e36", "metadata": {"aucs": [0.9618423216472421, 0.9786584144666978, 0.9607598987567774], "final_y": [0.16485635909219398, 0.16485682571536198, 0.1648573483720308]}, "mutation_prompt": null}
{"id": "138ab2e9-eb94-488c-9db4-723577e6fa89", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def adaptive_parameter_control(self, evals):\n        self.f = 0.5 + 0.5 * np.sin(np.pi * evals / self.budget)\n        self.cr = 0.6 + 0.4 * np.cos(np.pi * evals / self.budget)\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.adaptive_parameter_control(evals)\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                indices = np.random.choice(len(pop), 3, replace=False)\n                x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                f_dynamic = self.f\n                chaotic_factor = 0.7 + 0.3 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced HybridQODE with adaptive parameter tuning and symmetry exploitation to improve exploration and solution quality.", "configspace": "", "generation": 14, "fitness": 0.9634675946265016, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3b82c890-fa61-4892-95af-6bffaafd9e36", "metadata": {"aucs": [0.9512799076504015, 0.978362977472326, 0.9607598987567774], "final_y": [0.16485621615967017, 0.16485652506917325, 0.1648573483720308]}, "mutation_prompt": null}
{"id": "a137fbe4-ba8a-4814-a49a-1c9c7555bb73", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution, evals):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))  # Modified line\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.sin(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.sin(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i], evals)\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced exploration by utilizing adaptive Levy flight scaling based on dynamic budget utilization.", "configspace": "", "generation": 14, "fitness": 0.9670679956642417, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3b82c890-fa61-4892-95af-6bffaafd9e36", "metadata": {"aucs": [0.9620811107636218, 0.978362977472326, 0.9607598987567774], "final_y": [0.16485592951659345, 0.16485652506917325, 0.1648573483720308]}, "mutation_prompt": null}
{"id": "0a525b5d-a598-443f-ae56-161b820f45c3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * evals/self.budget * chaotic_factor * (x_2 - x_3), self.lb, self.ub)  # Change here\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhancing exploration by incorporating a dynamic scaling factor in the mutation process.", "configspace": "", "generation": 15, "fitness": 0.9508561898227423, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0ec4028c-367c-4dd9-8e47-002679806df7", "metadata": {"aucs": [0.9623526992106528, 0.9513462273005088, 0.9388696429570654], "final_y": [0.16485620976575133, 0.16485652506917325, 0.1648573987398223]}, "mutation_prompt": null}
{"id": "6db45e11-c6e1-463e-83cd-d5869475d4c7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    adaptive_factor = (best_fitness / (func(pop[i]) + 1e-8))  # New line\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * adaptive_factor * (x_2 - x_3), self.lb, self.ub)  # Modified line\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduced adaptive scaling of mutation factor to improve convergence near promising regions.", "configspace": "", "generation": 15, "fitness": 0.962273455475617, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0ec4028c-367c-4dd9-8e47-002679806df7", "metadata": {"aucs": [0.9597139923662308, 0.972432901905335, 0.9546734721552854], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485730168119728]}, "mutation_prompt": null}
{"id": "0b916508-bc84-405e-8975-f6ae4c372175", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Optimize exploration by dynamically adjusting mutation strategy based on a sinusoidal function.", "configspace": "", "generation": 15, "fitness": 0.9631927351349855, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0ec4028c-367c-4dd9-8e47-002679806df7", "metadata": {"aucs": [0.9624718313443356, 0.972432901905335, 0.9546734721552854], "final_y": [0.1648562211199328, 0.16485652506917325, 0.16485730168119728]}, "mutation_prompt": null}
{"id": "36913d9a-fd68-4824-b265-ccd3b52bb21f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def adaptive_chaotic_factor(self, evals):\n        return 0.5 + 0.5 * np.cos(2 * np.pi * evals / self.budget)\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                    chaotic_factor = self.adaptive_chaotic_factor(evals)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Dynamic parameter adaptation and enhanced exploration through adaptive chaos-enforced diversity mechanisms.", "configspace": "", "generation": 15, "fitness": 0.9629829446006899, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0ec4028c-367c-4dd9-8e47-002679806df7", "metadata": {"aucs": [0.9618424597414492, 0.972432901905335, 0.9546734721552854], "final_y": [0.16485629840118055, 0.16485652506917325, 0.16485730168119728]}, "mutation_prompt": null}
{"id": "44d2019d-6136-4409-b361-c2c8820a643d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.cos(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    perturbation = 0.1 * np.sin(2 * np.pi * np.arange(self.dim) / self.dim)  # New line\n                    mutant = self.levy_flight(pop[i]) + perturbation  # Modified line\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhanced periodicity and constructive interference focus by integrating sinusoidal mutation strategy.", "configspace": "", "generation": 15, "fitness": 0.9630687330293467, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0ec4028c-367c-4dd9-8e47-002679806df7", "metadata": {"aucs": [0.9620998250274196, 0.972432901905335, 0.9546734721552854], "final_y": [0.16485655918651765, 0.16485652506917325, 0.16485730168119728]}, "mutation_prompt": null}
{"id": "902eeaee-e3c1-49e7-b688-e1671aa28b7c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n        self.history = []\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def harmonic_mutation(self, solution, evals):\n        freq = 1.0 + np.sin(2 * np.pi * evals / self.budget) * 0.5\n        return solution + 0.01 * np.random.randn(self.dim) * freq\n\n    def cultural_influence(self, pop):\n        if self.history:\n            best_hist = min(self.history, key=lambda x: x[1])[0]\n            return pop + 0.05 * (best_hist - pop)\n        return pop\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n        \n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):\n                    mutant = self.harmonic_mutation(pop[i], evals)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            new_pop = self.cultural_influence(new_pop)\n            pop = new_pop\n            self.history.append((best_solution, best_fitness))\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "EnhancedHybridQODE", "description": "Employs adaptive periodicity-driven mutation rates and a cultural algorithm to enhance global and fine-tuned solution discovery.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'EnhancedHybridQODE' object has no attribute 'levy_flight'\").", "error": "AttributeError(\"'EnhancedHybridQODE' object has no attribute 'levy_flight'\")", "parent_id": "0b916508-bc84-405e-8975-f6ae4c372175", "metadata": {}, "mutation_prompt": null}
{"id": "27be4ef2-fc3a-4e5e-9470-2e07b43ac4c1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget))  # Adjusted dynamic crossover rate\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance exploration by dynamically adjusting mutation and crossover rates based on a sinusoidal function.", "configspace": "", "generation": 16, "fitness": 0.9658798660016409, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0b916508-bc84-405e-8975-f6ae4c372175", "metadata": {"aucs": [0.9624718313443356, 0.9785774320658959, 0.9565903345946913], "final_y": [0.1648562211199328, 0.16485652506917325, 0.1648573987398223]}, "mutation_prompt": null}
{"id": "7e387ef7-5b90-4e32-b1a4-1ecfff09a652", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.sin(2 * np.pi * evals / self.budget)  # Modified line for chaos\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduce chaos-enhanced mutation dynamics for improved exploration and convergence stability.", "configspace": "", "generation": 16, "fitness": 0.9567471212233393, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.957 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0b916508-bc84-405e-8975-f6ae4c372175", "metadata": {"aucs": [0.9627104115480781, 0.9527854430233231, 0.9547455090986167], "final_y": [0.16485618193535423, 0.16485964280847687, 0.16486350204467226]}, "mutation_prompt": null}
{"id": "648ea648-b589-4aae-aaed-04774145fd88", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget)) * (0.5 + 0.5 * evals / self.budget)  # Adjust mutation scale\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Improve the balance between exploration and exploitation by reducing mutation scale at earlier evaluations.", "configspace": "", "generation": 16, "fitness": 0.9625811882015122, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0b916508-bc84-405e-8975-f6ae4c372175", "metadata": {"aucs": [0.9618424597414492, 0.9536772875772945, 0.9722238172857928], "final_y": [0.16485629840118055, 0.16485692307915534, 0.1648566739995343]}, "mutation_prompt": null}
{"id": "d3d5560a-21b2-48fb-9aa1-3b887851798e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            fitness_variance = np.var([func(ind) for ind in pop])  # Added line\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget) * fitness_variance)  # Modified line\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - evals / self.budget) * (1 + fitness_variance)  # Modified line\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance convergence by introducing adaptive population size scaling with dynamic mutation and crossover based on fitness variance.", "configspace": "", "generation": 16, "fitness": 0.9614615483515339, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0b916508-bc84-405e-8975-f6ae4c372175", "metadata": {"aucs": [0.9591430781285852, 0.9686512323313248, 0.9565903345946913], "final_y": [0.16485630060133527, 0.16485652506917325, 0.1648573987398223]}, "mutation_prompt": null}
{"id": "067076af-d05a-4395-bee1-b51ece1dbb2e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.8 * self.budget))))  # Changed line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget))  # Adjusted dynamic crossover rate\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduce an adaptive population size scaling based on both evaluations and fitness improvements to enhance convergence performance.", "configspace": "", "generation": 17, "fitness": 0.782165951418205, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.132. And the mean value of best solutions found was 0.183 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "27be4ef2-fc3a-4e5e-9470-2e07b43ac4c1", "metadata": {"aucs": [0.9624718313443356, 0.6518151636683102, 0.7322108592419694], "final_y": [0.1648562211199328, 0.20915412196365102, 0.17568777127163848]}, "mutation_prompt": null}
{"id": "e5120f29-9528-46d5-b8f2-6d01331759a3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget))  # Adjusted dynamic crossover rate\n                cross_points = np.random.rand(self.dim) < (cr_dynamic * (0.8 + 0.2 * np.cos(np.pi * evals / self.budget))) \n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduce adaptive scaling for crossover and mutation factors for enhanced exploration-exploitation balance.", "configspace": "", "generation": 17, "fitness": 0.751464093701583, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.751 with standard deviation 0.154. And the mean value of best solutions found was 0.204 (0. is the best) with standard deviation 0.046.", "error": "", "parent_id": "27be4ef2-fc3a-4e5e-9470-2e07b43ac4c1", "metadata": {"aucs": [0.9624718313443356, 0.6011417150894556, 0.6907787346709577], "final_y": [0.1648562211199328, 0.26836516369258967, 0.17849305000662752]}, "mutation_prompt": null}
{"id": "c46cd15c-4872-4bb0-aa90-b914e9dfe63c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func, budget_fraction):\n        search_budget = int(budget_fraction * self.budget)\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B', options={'maxiter': search_budget})\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n\n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget))  # Adjusted dynamic crossover rate\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n\n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func, 0.01)  # Apply with a dynamic budget fraction\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance solution refinement by applying a specific local search based on successful solutions and dynamic adjustment of the local search budget.", "configspace": "", "generation": 17, "fitness": 0.7516783287054142, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.752 with standard deviation 0.155. And the mean value of best solutions found was 0.200 (0. is the best) with standard deviation 0.036.", "error": "", "parent_id": "27be4ef2-fc3a-4e5e-9470-2e07b43ac4c1", "metadata": {"aucs": [0.9624718313443356, 0.5936205899205766, 0.6989425648513304], "final_y": [0.1648562211199328, 0.2484694095673302, 0.1858579190752745]}, "mutation_prompt": null}
{"id": "08196169-0dbd-4290-b6c5-6ca52b1151a0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))  # Adjusted dynamic crossover rate\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Use cosine-based dynamic adjustment for both mutation and crossover rates to enhance convergence stability.", "configspace": "", "generation": 17, "fitness": 0.7127903298706961, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.713 with standard deviation 0.177. And the mean value of best solutions found was 0.194 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "27be4ef2-fc3a-4e5e-9470-2e07b43ac4c1", "metadata": {"aucs": [0.9624718313443356, 0.5674178887085114, 0.6084812695592412], "final_y": [0.1648562211199328, 0.22649959239284856, 0.19111264718139753]}, "mutation_prompt": null}
{"id": "446d14fb-620a-4955-8866-65832846d921", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def chaotic_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        chaotic_map = np.modf((pop * 3.9 * (1 - pop)) % 1)[0]\n        return np.vstack((pop, chaotic_map))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def adaptive_local_search(self, solution, func, evals):\n        if evals / self.budget > 0.7:\n            result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='BFGS')\n            return result.x\n        return solution\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.chaotic_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.5 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget))  # Adjusted dynamic crossover rate\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n\n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.adaptive_local_search(pop[i], func, evals)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance convergence speed and solution quality by integrating chaotic maps and adaptive local search with periodic function encouragement.", "configspace": "", "generation": 17, "fitness": 0.6497900985957051, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.650 with standard deviation 0.038. And the mean value of best solutions found was 0.212 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "27be4ef2-fc3a-4e5e-9470-2e07b43ac4c1", "metadata": {"aucs": [0.6863861530879978, 0.5968091620428071, 0.6661749806563105], "final_y": [0.19982529359151868, 0.21382481380715412, 0.22193934722598274]}, "mutation_prompt": null}
{"id": "3a31ecfc-8d16-4cc7-a4c5-2cb77245aa62", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step_size = 0.01 * (1 - np.sin(np.pi * evals / self.budget))  # Dynamic scaling factor\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + step_size * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.8 * self.budget))))  # Changed line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget))  # Adjusted dynamic crossover rate\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduce a dynamic scaling factor in the Lvy flight step size to enhance exploration during early search stages.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'evals' is not defined\").", "error": "NameError(\"name 'evals' is not defined\")", "parent_id": "067076af-d05a-4395-bee1-b51ece1dbb2e", "metadata": {}, "mutation_prompt": null}
{"id": "0dc063b8-23a8-402a-b0f7-6251e808c41d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.8 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.random.rand())  # Changed line\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget))\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduce chaos-based perturbation to enhance exploration and avoid premature convergence by modifying strategy dynamics.", "configspace": "", "generation": 18, "fitness": 0.9599360784128769, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "067076af-d05a-4395-bee1-b51ece1dbb2e", "metadata": {"aucs": [0.9624916667696775, 0.9416706052861379, 0.975645963182815], "final_y": [0.16485751130789705, 0.16485964280847687, 0.1648566739995343]}, "mutation_prompt": null}
{"id": "c0f5ea52-70de-425b-af1b-08f956bcae52", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.8 * self.budget))))  # Changed line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                    chaotic_factor = 0.8 + 0.1 * np.sin(np.pi * evals / (0.5 * self.budget))  # Changed line\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget))  # Adjusted dynamic crossover rate\n                cross_points = np.random.rand(self.dim) < (cr_dynamic + 0.1)  # Changed line\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance exploration by adjusting the chaotic factor dynamically and improving the crossover mechanism.", "configspace": "", "generation": 18, "fitness": 0.9599309467591074, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "067076af-d05a-4395-bee1-b51ece1dbb2e", "metadata": {"aucs": [0.9624762718083691, 0.9416706052861379, 0.975645963182815], "final_y": [0.16485629840118055, 0.16485964280847687, 0.1648566739995343]}, "mutation_prompt": null}
{"id": "68217bfb-8b5e-4fe1-88b5-a2b2ebcf77d3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution, evals):  # Changed line\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        chaotic_factor = 1.0 + 0.3 * np.sin(np.pi * evals / self.budget)  # Added chaos\n        return solution + 0.01 * chaotic_factor * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.8 * self.budget))))  # Changed line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget))\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i], evals)\n                \n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget))  # Adjusted dynamic crossover rate\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduce chaotic mutations in Levy flight to enhance exploration during early iterations.", "configspace": "", "generation": 18, "fitness": 0.9335750390234021, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.934 with standard deviation 0.050. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "067076af-d05a-4395-bee1-b51ece1dbb2e", "metadata": {"aucs": [0.9624718322394338, 0.8626073216479577, 0.975645963182815], "final_y": [0.1648562211199328, 0.18187895551887445, 0.1648566739995343]}, "mutation_prompt": null}
{"id": "215c0f0e-ef00-4596-8c75-2697f71b39d5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.8 * self.budget))))  # Changed line\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):  # Dynamic strategy selection\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.cos(np.pi * evals / self.budget)) * (1 - best_fitness / 100)\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget))  # Adjusted dynamic crossover rate\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduce a dynamic adjustment to the exploration-exploitation balance by modulating the F parameter based on the current best fitness.", "configspace": "", "generation": 18, "fitness": 0.9592078753075698, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.015. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "067076af-d05a-4395-bee1-b51ece1dbb2e", "metadata": {"aucs": [0.9624709744181213, 0.9395066883217733, 0.975645963182815], "final_y": [0.16485629840118055, 0.16485607789477574, 0.1648566739995343]}, "mutation_prompt": null}
{"id": "6f21d94f-25a9-43e4-88bd-164944674812", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.8 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.random.rand()) \n                    chaotic_factor = 0.7 + 0.3 * np.abs(np.sin(2 * np.pi * evals / self.budget))  # Changed line\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget))\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance population diversity by introducing adaptive chaotic perturbation during mutation.", "configspace": "", "generation": 19, "fitness": 0.9505265912165098, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.029. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0dc063b8-23a8-402a-b0f7-6251e808c41d", "metadata": {"aucs": [0.9617762113148792, 0.9792463065224825, 0.9105572558121677], "final_y": [0.16485751130789705, 0.16485964280847687, 0.16485688012700284]}, "mutation_prompt": null}
{"id": "04e774ef-2ae4-4051-8a15-8643738f0380", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.8 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.random.rand())  # Changed line\n                    chaotic_factor = 0.7 + 0.3 * np.cos(2 * np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - 0.5*np.sin(np.pi * evals / self.budget))\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance diversity by integrating a dynamic crossover probability and refine chaotic perturbation with adaptive scaling.", "configspace": "", "generation": 19, "fitness": 0.9621744208120755, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0dc063b8-23a8-402a-b0f7-6251e808c41d", "metadata": {"aucs": [0.9617761640625879, 0.9660756248696017, 0.9586714735040368], "final_y": [0.16485751130789705, 0.16485652506917325, 0.16485703346450276]}, "mutation_prompt": null}
{"id": "54e986b2-d193-4cec-93cf-a8dc27c122be", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE_Enhanced:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def adaptive_chaotic_mapping(self, evals):\n        return 0.5 + 0.5 * np.cos(np.pi * (evals / self.budget) ** 2)\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.8 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.random.rand())\n                    chaotic_factor = self.adaptive_chaotic_mapping(evals)  # Changed line\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget))\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = np.vstack((new_pop, [best_solution]))  # Include best solution in population\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE_Enhanced", "description": "Integrate adaptive chaotic mapping for enhanced exploration and incorporate elitism to retain the best solutions over iterations.", "configspace": "", "generation": 19, "fitness": 0.9627912436710319, "feedback": "The algorithm HybridQODE_Enhanced got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.012. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0dc063b8-23a8-402a-b0f7-6251e808c41d", "metadata": {"aucs": [0.9625070541811357, 0.9777184270939976, 0.948148249737962], "final_y": [0.16485751130789705, 0.16485964280847687, 0.16485703346450276]}, "mutation_prompt": null}
{"id": "43c87621-cc85-4bff-8f58-ee2088e77b77", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        # This function is no longer used\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.8 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.random.rand())  # Changed line\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = pop[i] + 0.01 * np.random.normal(0, 1, size=self.dim)  # Gaussian perturbation\n                \n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget))\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < func(pop[i]):\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance diversity by replacing Levy flight with Gaussian perturbation for improved local exploration.", "configspace": "", "generation": 19, "fitness": 0.9653918950421402, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0dc063b8-23a8-402a-b0f7-6251e808c41d", "metadata": {"aucs": [0.9621287474268921, 0.9753754641954916, 0.9586714735040368], "final_y": [0.16485629840118055, 0.16485964280847687, 0.16485703346450276]}, "mutation_prompt": null}
{"id": "f0965b9b-3a7a-47b4-8d78-32cd71ca6f30", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.8 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            current_fitness = np.array([func(ind) for ind in pop])\n            fitness_variance = np.var(current_fitness)  # Changed line\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.random.rand())\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget)) * (1 + fitness_variance)  # Changed line\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < current_fitness[i]:  # Changed line\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance exploitation by introducing adaptive tuning of mutation and crossover rates based on fitness variance to refine convergence.", "configspace": "", "generation": 19, "fitness": 0.9657102575060575, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "0dc063b8-23a8-402a-b0f7-6251e808c41d", "metadata": {"aucs": [0.9630838348186446, 0.9753754641954916, 0.9586714735040368], "final_y": [0.16485751130789705, 0.16485964280847687, 0.16485703346450276]}, "mutation_prompt": null}
{"id": "5de44982-346e-4bcb-8c7d-1976f4837860", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.8 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            current_fitness = np.array([func(ind) for ind in pop])\n            fitness_variance = np.var(current_fitness)\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.random.rand())\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget)) * (1 + fitness_variance)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < current_fitness[i]:\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduce adaptive probabilistic weight adjustment in crossover to enhance exploration around promising areas.", "configspace": "", "generation": 20, "fitness": 0.9657102503007224, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f0965b9b-3a7a-47b4-8d78-32cd71ca6f30", "metadata": {"aucs": [0.9630838348186446, 0.975375442579486, 0.9586714735040368], "final_y": [0.16485751130789705, 0.16485964280847687, 0.16485703346450276]}, "mutation_prompt": null}
{"id": "6d1405b4-dec8-4097-bb78-a39a691c49e9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.8 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            current_fitness = np.array([func(ind) for ind in pop])\n            fitness_variance = np.var(current_fitness)\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.random.rand())\n                    chaotic_factor = 0.7 + 0.3 * np.sin(np.pi * evals / self.budget) * np.sin(np.pi * fitness_variance)  # Changed line\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget)) * (1 + fitness_variance)\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < current_fitness[i]:\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Introduce adaptive chaotic factors in the mutation phase to enhance exploration while maintaining convergence efficiency.", "configspace": "", "generation": 20, "fitness": 0.9654717493983966, "feedback": "The algorithm HybridQODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f0965b9b-3a7a-47b4-8d78-32cd71ca6f30", "metadata": {"aucs": [0.9623683321116672, 0.975375442579486, 0.9586714735040368], "final_y": [0.16485751130789705, 0.16485964280847687, 0.16485703346450276]}, "mutation_prompt": null}
{"id": "dab2f97d-78a0-4d61-aaf1-198af638241e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.8 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            current_fitness = np.array([func(ind) for ind in pop])\n            fitness_variance = np.var(current_fitness)\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f + 0.5 * (1 - evals / self.budget)  # Changed line\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget)) * (1 + fitness_variance)  # Changed line\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < current_fitness[i]:  # Changed line\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            elite_indices = np.argsort(current_fitness)[:len(pop)//10]  # Changed line\n            elite_solutions = pop[elite_indices]  # Changed line\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n            \n            pop = np.vstack((pop, elite_solutions))  # Changed line\n            pop = pop[:self.pop_size]  # Changed line\n\n        return best_solution", "name": "HybridQODE", "description": "Introduce adaptive parameter control and elitism to enhance exploration-exploitation balance and maintain diversity.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 63 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 63 is out of bounds for axis 0 with size 50')", "parent_id": "f0965b9b-3a7a-47b4-8d78-32cd71ca6f30", "metadata": {}, "mutation_prompt": null}
{"id": "b0e3e67f-b216-45fa-a162-3c70a1102a9c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution, fitness_variance):  # Changed line\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step * (1 + fitness_variance)  # Changed line\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.8 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            current_fitness = np.array([func(ind) for ind in pop])\n            fitness_variance = np.var(current_fitness)  # Changed line\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (0.5 + 0.5 * np.random.rand())\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i], fitness_variance)  # Changed line\n                \n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget)) * (1 + fitness_variance)  # Changed line\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < current_fitness[i]:  # Changed line\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Enhance exploration by dynamically adapting the levy flight intensity based on the current fitness variance.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 67 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 67 is out of bounds for axis 0 with size 50')", "parent_id": "f0965b9b-3a7a-47b4-8d78-32cd71ca6f30", "metadata": {}, "mutation_prompt": null}
{"id": "2fef2e71-e612-4a11-9943-e9a04f4d7a12", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridQODE:\n    def __init__(self, budget, dim, pop_size=50, f=0.8, cr=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = pop_size\n        self.f = f\n        self.cr = cr\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self):\n        pop = self.lb + (self.ub - self.lb) * np.random.rand(self.pop_size, self.dim)\n        opp_pop = self.lb + self.ub - pop\n        return np.vstack((pop, opp_pop))\n\n    def levy_flight(self, solution):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return solution + 0.01 * step\n\n    def local_search(self, solution, func):\n        result = minimize(func, solution, bounds=[(self.lb[i], self.ub[i]) for i in range(self.dim)], method='L-BFGS-B')\n        return result.x\n\n    def __call__(self, func):\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        evals = 0\n        pop = self.quasi_oppositional_initialization()\n        best_solution = None\n        best_fitness = float('inf')\n\n        while evals < self.budget:\n            self.pop_size = max(5, int(self.pop_size * (1 - evals / (1.8 * self.budget))))\n            new_pop = np.zeros((self.pop_size, self.dim))\n            current_fitness = np.array([func(ind) for ind in pop])\n            fitness_variance = np.var(current_fitness)  # Changed line\n            for i in range(self.pop_size):\n                if np.random.rand() < (0.3 + 0.7 * evals / self.budget):\n                    indices = np.random.choice(len(pop), 3, replace=False)\n                    x_1, x_2, x_3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                    f_dynamic = self.f * (1 / (1 + np.exp(-10 * (evals / self.budget - 0.5))))  # Changed line\n                    chaotic_factor = 0.7 + 0.3 * np.cos(np.pi * evals / self.budget) * np.sin(np.pi * evals / self.budget)\n                    mutant = np.clip(x_1 + f_dynamic * chaotic_factor * (x_2 - x_3), self.lb, self.ub)\n                else:\n                    mutant = self.levy_flight(pop[i])\n                \n                cr_dynamic = self.cr * (1 - np.sin(np.pi * evals / self.budget)) * (1 + fitness_variance)  # Changed line\n                cross_points = np.random.rand(self.dim) < cr_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial_fitness = func(trial)\n                evals += 1\n                if trial_fitness < current_fitness[i]:  # Changed line\n                    new_pop[i] = trial\n                    if trial_fitness < best_fitness:\n                        best_fitness = trial_fitness\n                        best_solution = trial\n                else:\n                    new_pop[i] = pop[i]\n            \n            pop = new_pop\n\n            for i in range(len(pop)):\n                if evals < self.budget:\n                    refined_solution = self.local_search(pop[i], func)\n                    refined_fitness = func(refined_solution)\n                    evals += 1\n                    if refined_fitness < best_fitness:\n                        best_fitness = refined_fitness\n                        best_solution = refined_solution\n\n        return best_solution", "name": "HybridQODE", "description": "Boost exploration by dynamically adjusting the scale factor using a sigmoid function of budget progression to balance exploration and exploitation.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 67 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 67 is out of bounds for axis 0 with size 50')", "parent_id": "f0965b9b-3a7a-47b4-8d78-32cd71ca6f30", "metadata": {}, "mutation_prompt": null}
