{"id": "e54fd89b-3e57-4d54-bcae-7144e64fba0b", "solution": "import numpy as np\n\nclass ACPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.clusters = 5\n        self.positions = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.7   # Inertia weight\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            # Clustering based on performance\n            sorted_indices = np.argsort(self.personal_best_scores)\n            clusters = np.array_split(sorted_indices, self.clusters)\n\n            # Update velocities and positions for each cluster\n            for cluster in clusters:\n                if len(cluster) == 0:\n                    continue\n\n                cluster_leader = self.personal_best_positions[cluster[0]]\n                for i in cluster:\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                    social_velocity = self.c2 * r2 * (cluster_leader - self.positions[i])\n                    self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                    # Update positions\n                    self.positions[i] += self.velocities[i]\n                    self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "ACPSO", "description": "The Adaptive Clustering Particle Swarm Optimization (AC-PSO) algorithm dynamically adjusts swarm clusters based on performance to explore and exploit diverse regions of the search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.660056797745749, "feedback": "The algorithm ACPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.660 with standard deviation 0.000. And the mean value of best solutions found was 0.219 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": null, "metadata": {"aucs": [0.660056797745749, 0.660056797745749, 0.660056797745749], "final_y": [0.21891901516198964, 0.21891901516198964, 0.21891901516198964]}, "mutation_prompt": null}
{"id": "208f9b69-ce57-4f3e-ba5e-c2c203404c85", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        budget_used = population_size\n\n        while budget_used < self.budget:\n            for i in range(population_size):\n                # Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                budget_used += 1\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n                \n                if budget_used >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridMetaheuristicOptimizer", "description": "A hybrid metaheuristic combining differential evolution with a self-adaptive mutation strategy to efficiently explore and exploit the search space for black box optimization within given budget constraints.", "configspace": "", "generation": 0, "fitness": 0.8162751763646882, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.017. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8106835726963175, 0.8399035438577167, 0.7982384125400303], "final_y": [0.13748389817044393, 0.140406246371924, 0.14599208873322533]}, "mutation_prompt": null}
{"id": "6acd838b-0d3e-4fa7-bd5b-e162e056491b", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.inertia_weight = 0.729\n        self.cognitive_weight = 1.49445\n        self.social_weight = 1.49445\n        self.temperature = 100\n        self.temp_decay = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        eval_count = self.num_particles\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.num_particles, self.dim), np.random.rand(self.num_particles, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - particles) +\n                          self.social_weight * r2 * (global_best_position - particles))\n            \n            particles = particles + velocities\n            particles = np.clip(particles, lb, ub)\n\n            # Evaluate particles and update personal best\n            for i in range(self.num_particles):\n                score = func(particles[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n\n                # Simulated Annealing acceptance criterion\n                if score < func(global_best_position) or np.exp((func(global_best_position) - score) / self.temperature) > np.random.rand():\n                    global_best_position = particles[i]\n\n                if eval_count >= self.budget:\n                    break\n\n            # Decay temperature\n            self.temperature *= self.temp_decay\n        \n        return global_best_position", "name": "HybridPSOSA", "description": "A novel hybridized Particle Swarm Optimization (PSO) with Simulated Annealing (SA) to balance exploration and exploitation for efficient black-box optimization.", "configspace": "", "generation": 0, "fitness": 0.8124140044539595, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.041. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7549639098436434, 0.8495979201625421, 0.8326801833556932], "final_y": [0.17091646946852257, 0.12478010293234276, 0.14238737318043126]}, "mutation_prompt": null}
{"id": "4d1f1b87-c85c-4eef-a474-dca6542d5f07", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.9  # cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n\n        return global_best_position", "name": "HybridPSOSA", "description": "A novel hybrid metaheuristic combining Particle Swarm Optimization (PSO) with Simulated Annealing (SA) to exploit global exploration and local exploitation for black-box optimization.", "configspace": "", "generation": 0, "fitness": 0.8491686480279773, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.014. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8524283144810546, 0.8648622483882205, 0.8302153812146573], "final_y": [0.1256608353533094, 0.12257871908623452, 0.14572275907073118]}, "mutation_prompt": null}
{"id": "1cb97f40-025b-4d51-a8b0-e2af7fd918c1", "solution": "import numpy as np\n\nclass QAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Customizable\n        self.inertia_weight = 0.7\n        self.cognition_learning_factor = 1.5\n        self.social_learning_factor = 2.0\n        self.quantum_factor = 0.5  # Controls the spread of the quantum superposition\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        position = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best_position = position.copy()\n        personal_best_score = np.array([func(p) for p in position])\n        global_best_position = personal_best_position[personal_best_score.argmin()]\n        global_best_score = personal_best_score.min()\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r_p = np.random.uniform(0, 1, (self.population_size, self.dim))\n            r_g = np.random.uniform(0, 1, (self.population_size, self.dim))\n\n            # Update velocities with quantum-inspired dynamics\n            velocity = (self.inertia_weight * velocity\n                        + self.cognition_learning_factor * r_p * (personal_best_position - position)\n                        + self.social_learning_factor * r_g * (global_best_position - position)\n                        + self.quantum_factor * np.random.uniform(-1, 1, (self.population_size, self.dim)))\n\n            # Update positions\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(p) for p in position])\n            evaluations += self.population_size\n\n            # Update personal bests\n            improved = scores < personal_best_score\n            personal_best_position[improved] = position[improved]\n            personal_best_score[improved] = scores[improved]\n\n            # Update global best\n            if scores.min() < global_best_score:\n                global_best_score = scores.min()\n                global_best_position = position[scores.argmin()]\n\n        return global_best_position, global_best_score", "name": "QAPSO", "description": "A Quantum-inspired Adaptive Particle Swarm Optimization (QAPSO) leveraging quantum superposition and adaptive velocities for efficient exploration and exploitation in varied dimensional spaces.", "configspace": "", "generation": 0, "fitness": 0.8119495030089149, "feedback": "The algorithm QAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.026. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8132008901715683, 0.8432359553157234, 0.7794116635394531], "final_y": [0.14400906638893107, 0.13662016453711967, 0.15820738828514158]}, "mutation_prompt": null}
{"id": "3b04ba4f-714f-4520-857c-454021beba65", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.inertia_weight = 0.729\n        self.cognitive_weight = 1.49445\n        self.social_weight = 1.49445\n        self.temperature = 100\n        self.temp_decay = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        eval_count = self.num_particles\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.num_particles, self.dim), np.random.rand(self.num_particles, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - particles) +\n                          self.social_weight * r2 * (global_best_position - particles))\n            \n            particles = particles + velocities\n            particles = np.clip(particles, lb, ub)\n\n            # Evaluate particles and update personal best\n            for i in range(self.num_particles):\n                score = func(particles[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n\n                # Simulated Annealing acceptance criterion\n                if score < func(global_best_position) or np.exp((func(global_best_position) - score) / self.temperature) > np.random.rand():\n                    global_best_position = particles[i]\n\n                if eval_count >= self.budget:\n                    break\n\n            # Decay temperature\n            self.temperature *= self.temp_decay\n\n            # Adaptive inertia weight adjustment\n            self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n        \n        return global_best_position", "name": "HybridPSOSA", "description": "A refined Hybrid PSO with Simulated Annealing (SA) using adaptive inertia weight for improved convergence in black-box optimization.", "configspace": "", "generation": 1, "fitness": 0.7857081024379546, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.786 with standard deviation 0.021. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "6acd838b-0d3e-4fa7-bd5b-e162e056491b", "metadata": {"aucs": [0.758925401303683, 0.8102570056681204, 0.7879419003420604], "final_y": [0.16620467158694296, 0.1482136601985622, 0.16139593097456306]}, "mutation_prompt": null}
{"id": "530bae93-0904-4515-bcca-4d57188137f4", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.6 + 0.3 * np.random.random()  # Crossover probability refined\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        budget_used = population_size\n\n        while budget_used < self.budget:\n            for i in range(population_size):\n                # Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                budget_used += 1\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n                \n                if budget_used >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridMetaheuristicOptimizer", "description": "A refined hybrid metaheuristic optimizer with enhanced crossover probability adjustment for improved exploration-exploitation balance in black-box optimization.", "configspace": "", "generation": 1, "fitness": 0.7995386181275866, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.005. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "208f9b69-ce57-4f3e-ba5e-c2c203404c85", "metadata": {"aucs": [0.7931036870591346, 0.8061941452225723, 0.7993180221010531], "final_y": [0.14276329031269885, 0.1448277534036898, 0.14374899555167686]}, "mutation_prompt": null}
{"id": "b38435e3-8f78-4e24-b3cf-e3247a9f7793", "solution": "import numpy as np\n\nclass ACPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.clusters = 5\n        self.positions = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.7   # Inertia weight\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            # Clustering based on performance\n            sorted_indices = np.argsort(self.personal_best_scores)\n            clusters = np.array_split(sorted_indices, self.clusters)\n\n            # Update velocities and positions for each cluster\n            for cluster in clusters:\n                if len(cluster) == 0:\n                    continue\n\n                cluster_leader = self.personal_best_positions[cluster[0]]\n                for i in cluster:\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                    social_velocity = self.c2 * r2 * (cluster_leader - self.positions[i])\n                    self.velocities[i] = self.w * self.velocities[i] + cognitive_velocity + social_velocity\n\n                    # Update positions\n                    self.positions[i] += self.velocities[i]\n                    self.positions[i] = np.clip(self.positions[i], lb, ub)\n            \n            # Adaptive inertia weight adjustment\n            self.w = 0.5 + np.random.rand() * 0.2\n\n        return self.global_best_position, self.global_best_score", "name": "ACPSO", "description": "Enhanced Adaptive Clustering Particle Swarm Optimization (AC-PSO) with an adaptive inertia weight adjustment for improved convergence speed and performance.", "configspace": "", "generation": 1, "fitness": 0.660056797745749, "feedback": "The algorithm ACPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.660 with standard deviation 0.000. And the mean value of best solutions found was 0.219 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e54fd89b-3e57-4d54-bcae-7144e64fba0b", "metadata": {"aucs": [0.660056797745749, 0.660056797745749, 0.660056797745749], "final_y": [0.21891901516198964, 0.21891901516198964, 0.21891901516198964]}, "mutation_prompt": null}
{"id": "23f47294-c975-4771-8d58-c5d00d2d1766", "solution": "import numpy as np\n\nclass ACPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.clusters = 5\n        self.positions = np.random.rand(self.population_size, self.dim)\n        self.velocities = np.random.rand(self.population_size, self.dim) * 0.1\n        self.personal_best_positions = self.positions.copy()\n        self.personal_best_scores = np.full(self.population_size, np.inf)\n        self.global_best_position = None\n        self.global_best_score = np.inf\n        self.c1 = 2.0  # Cognitive coefficient\n        self.c2 = 2.0  # Social coefficient\n        self.w = 0.7   # Inertia weight\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        evaluations = 0\n\n        while evaluations < self.budget:\n            # Evaluate the population\n            for i in range(self.population_size):\n                if evaluations >= self.budget:\n                    break\n\n                score = func(self.positions[i])\n                evaluations += 1\n\n                # Update personal best\n                if score < self.personal_best_scores[i]:\n                    self.personal_best_scores[i] = score\n                    self.personal_best_positions[i] = self.positions[i].copy()\n\n                # Update global best\n                if score < self.global_best_score:\n                    self.global_best_score = score\n                    self.global_best_position = self.positions[i].copy()\n\n            # Clustering based on performance\n            sorted_indices = np.argsort(self.personal_best_scores)\n            clusters = np.array_split(sorted_indices, self.clusters)\n\n            # Update velocities and positions for each cluster\n            for cluster in clusters:\n                if len(cluster) == 0:\n                    continue\n\n                cluster_leader = self.personal_best_positions[cluster[0]]\n                for i in cluster:\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    cognitive_velocity = self.c1 * r1 * (self.personal_best_positions[i] - self.positions[i])\n                    social_velocity = self.c2 * r2 * (cluster_leader - self.positions[i])\n                    self.velocities[i] = (0.7 - (0.3 * evaluations / self.budget)) * self.velocities[i] + cognitive_velocity + social_velocity\n\n                    # Update positions\n                    self.positions[i] += self.velocities[i]\n                    self.positions[i] = np.clip(self.positions[i], lb, ub)\n\n        return self.global_best_position, self.global_best_score", "name": "ACPSO", "description": "Enhanced ACPSO with adaptive inertia weight for improved exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.660056797745749, "feedback": "The algorithm ACPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.660 with standard deviation 0.000. And the mean value of best solutions found was 0.219 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e54fd89b-3e57-4d54-bcae-7144e64fba0b", "metadata": {"aucs": [0.660056797745749, 0.660056797745749, 0.660056797745749], "final_y": [0.21891901516198964, 0.21891901516198964, 0.21891901516198964]}, "mutation_prompt": null}
{"id": "77389bd8-6cc8-4aca-bb1e-2799b712d618", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.inertia_weight = 0.729\n        self.cognitive_weight = 1.49445\n        self.social_weight = 1.49445\n        self.temperature = 100\n        self.temp_decay = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        eval_count = self.num_particles\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight based on evaluations\n            self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.num_particles, self.dim), np.random.rand(self.num_particles, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - particles) +\n                          self.social_weight * r2 * (global_best_position - particles))\n            \n            particles = particles + velocities\n            particles = np.clip(particles, lb, ub)\n\n            # Evaluate particles and update personal best\n            for i in range(self.num_particles):\n                score = func(particles[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n\n                # Simulated Annealing acceptance criterion\n                if score < func(global_best_position) or np.exp((func(global_best_position) - score) / self.temperature) > np.random.rand():\n                    global_best_position = particles[i]\n\n                if eval_count >= self.budget:\n                    break\n\n            # Decay temperature\n            self.temperature *= self.temp_decay\n        \n        return global_best_position", "name": "HybridPSOSA", "description": "A refined hybrid PSO with SA, incorporating adaptive inertia weight to enhance convergence speed and solution quality.", "configspace": "", "generation": 1, "fitness": 0.8063543500909036, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.021. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "6acd838b-0d3e-4fa7-bd5b-e162e056491b", "metadata": {"aucs": [0.7946696528267195, 0.7890296741538928, 0.8353637232920987], "final_y": [0.15667779898756784, 0.15185426722453832, 0.14497370390674913]}, "mutation_prompt": null}
{"id": "a3318c68-fdad-4e4a-b33d-9408608ef4e8", "solution": "import numpy as np\n\nclass QAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Customizable\n        self.inertia_weight = 0.9\n        self.cognition_learning_factor = 1.5\n        self.social_learning_factor = 2.0\n        self.quantum_factor = 0.5  # Controls the spread of the quantum superposition\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        position = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best_position = position.copy()\n        personal_best_score = np.array([func(p) for p in position])\n        global_best_position = personal_best_position[personal_best_score.argmin()]\n        global_best_score = personal_best_score.min()\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r_p = np.random.uniform(0, 1, (self.population_size, self.dim))\n            r_g = np.random.uniform(0, 1, (self.population_size, self.dim))\n\n            # Update inertia weight dynamically\n            self.inertia_weight = 0.4 + 0.5 * ((self.budget - evaluations) / self.budget)\n            \n            # Update velocities with quantum-inspired dynamics\n            velocity = (self.inertia_weight * velocity\n                        + self.cognition_learning_factor * r_p * (personal_best_position - position)\n                        + self.social_learning_factor * r_g * (global_best_position - position)\n                        + self.quantum_factor * np.random.uniform(-1, 1, (self.population_size, self.dim)))\n\n            # Update positions\n            position += velocity\n            position = np.clip(position, lb, ub)\n            \n            # Opposition-based learning\n            opposition_position = lb + ub - position\n            opposition_position = np.clip(opposition_position, lb, ub)\n            opposition_scores = np.array([func(p) for p in opposition_position])\n            \n            # Evaluate new solutions\n            scores = np.array([func(p) for p in position])\n            evaluations += self.population_size\n\n            # Combine scores and positions\n            combined_scores = np.concatenate((scores, opposition_scores))\n            combined_positions = np.vstack((position, opposition_position))\n\n            # Update personal bests\n            improved = combined_scores < personal_best_score\n            personal_best_position[improved[:self.population_size]] = combined_positions[improved][:self.population_size]\n            personal_best_score[improved[:self.population_size]] = combined_scores[improved][:self.population_size]\n\n            # Update global best\n            if combined_scores.min() < global_best_score:\n                global_best_score = combined_scores.min()\n                global_best_position = combined_positions[combined_scores.argmin()]\n\n        return global_best_position, global_best_score", "name": "QAPSO", "description": "Enhanced Quantum-inspired Adaptive PSO by introducing dynamic inertia weight and incorporating opposition-based learning for improved convergence and solution quality.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (60,) (30,) ').", "error": "ValueError('operands could not be broadcast together with shapes (60,) (30,) ')", "parent_id": "1cb97f40-025b-4d51-a8b0-e2af7fd918c1", "metadata": {}, "mutation_prompt": null}
{"id": "495ef403-4490-4f6d-bf40-839d2d0a2c94", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        budget_used = population_size\n\n        while budget_used < self.budget:\n            for i in range(population_size):\n                # Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                \n                # Crossover\n                CR_dynamic = 0.9 - 0.5 * (budget_used / self.budget)  # Dynamic adjustment\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                budget_used += 1\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n                \n                if budget_used >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridMetaheuristicOptimizer", "description": "A refined hybrid metaheuristic optimizer incorporating dynamic adjustment of crossover probability to enhance exploration and exploitation balance within budget constraints.", "configspace": "", "generation": 2, "fitness": 0.8117381991585786, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.005. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "208f9b69-ce57-4f3e-ba5e-c2c203404c85", "metadata": {"aucs": [0.8153934755109641, 0.8045418006218826, 0.815279321342889], "final_y": [0.13749067442950702, 0.14392799843478876, 0.14655299757471085]}, "mutation_prompt": null}
{"id": "362ef943-4fc2-4868-a434-8b8e14ff6469", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.inertia_weight = 0.729\n        self.cognitive_weight = 1.49445\n        self.social_weight = 1.49445\n        self.temperature = 100\n        self.temp_decay = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        eval_count = self.num_particles\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.num_particles, self.dim), np.random.rand(self.num_particles, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - particles) +\n                          self.social_weight * r2 * (global_best_position - particles))\n            \n            # Adaptive Velocity Clamping\n            velocities = np.clip(velocities, -0.5 * (ub - lb), 0.5 * (ub - lb))\n            \n            particles = particles + velocities\n            particles = np.clip(particles, lb, ub)\n\n            # Evaluate particles and update personal best\n            for i in range(self.num_particles):\n                score = func(particles[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n\n                # Simulated Annealing acceptance criterion\n                if score < func(global_best_position) or np.exp((func(global_best_position) - score) / self.temperature) > np.random.rand():\n                    global_best_position = particles[i]\n\n                if eval_count >= self.budget:\n                    break\n\n            # Decay temperature\n            self.temperature *= self.temp_decay\n        \n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced Hybrid PSO-SA with Adaptive Velocity Clamping to improve convergence speed and solution precision.", "configspace": "", "generation": 2, "fitness": 0.7933186686086886, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.009. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6acd838b-0d3e-4fa7-bd5b-e162e056491b", "metadata": {"aucs": [0.7842416827856675, 0.8054364336681852, 0.790277889372213], "final_y": [0.15905825315522448, 0.15218831590470794, 0.16097007402142216]}, "mutation_prompt": null}
{"id": "a2e1a620-2c1f-4392-b648-303048913f6f", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.inertia_weight = 0.729\n        self.cognitive_weight = 1.49445\n        self.social_weight = 1.49445\n        self.temperature = 100\n        self.temp_decay = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n\n        eval_count = self.num_particles\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight based on evaluations\n            self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n            \n            # Dynamic adjustment of cognitive and social weights\n            self.cognitive_weight = 1.49445 + 0.5 * (eval_count / self.budget)\n            self.social_weight = 1.49445 - 0.5 * (eval_count / self.budget)\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.num_particles, self.dim), np.random.rand(self.num_particles, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - particles) +\n                          self.social_weight * r2 * (global_best_position - particles))\n\n            particles = particles + velocities\n            particles = np.clip(particles, lb, ub)\n\n            # Evaluate particles and update personal best\n            for i in range(self.num_particles):\n                score = func(particles[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n\n                # Simulated Annealing acceptance criterion\n                if score < func(global_best_position) or np.exp((func(global_best_position) - score) / self.temperature) > np.random.rand():\n                    global_best_position = particles[i]\n\n                if eval_count >= self.budget:\n                    break\n\n            # Decay temperature\n            self.temperature *= self.temp_decay\n\n        return global_best_position", "name": "HybridPSOSA", "description": "A refined hybrid PSO with SA, enhancing convergence by dynamically adjusting cognitive and social weights based on evaluation progress.", "configspace": "", "generation": 2, "fitness": 0.7920713106401153, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.015. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "77389bd8-6cc8-4aca-bb1e-2799b712d618", "metadata": {"aucs": [0.7702524595724313, 0.8037752174456427, 0.8021862549022715], "final_y": [0.1469149512877309, 0.15504231845816918, 0.15672213832811877]}, "mutation_prompt": null}
{"id": "9b2ef160-fe84-4c5f-a8e1-d3afdf6705b4", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.inertia_weight = 0.729\n        self.cognitive_weight = 1.49445\n        self.social_weight = 1.49445\n        self.temperature = 100\n        self.temp_decay = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        eval_count = self.num_particles\n\n        while eval_count < self.budget:\n            # Adaptive inertia weight based on evaluations\n            self.inertia_weight = 0.9 - (0.5 * (eval_count / self.budget))\n\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.num_particles, self.dim), np.random.rand(self.num_particles, self.dim)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - particles) +\n                          self.social_weight * r2 * (global_best_position - particles))\n            \n            particles = particles + velocities\n            particles = np.clip(particles, lb, ub)\n\n            # Evaluate particles and update personal best\n            for i in range(self.num_particles):\n                score = func(particles[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n\n                # Simulated Annealing acceptance criterion\n                if score < func(global_best_position) or np.exp((func(global_best_position) - score) / self.temperature) > np.random.rand():\n                    global_best_position = particles[i]\n\n                if eval_count >= self.budget:\n                    break\n\n            # Decay temperature\n            self.temperature *= self.temp_decay\n\n            # Apply chaotic map to enhance exploration\n            velocities = velocities * (0.5 + 0.5 * np.sin(np.pi * velocities))\n        \n        return global_best_position", "name": "HybridPSOSA", "description": "Improved particle diversity by introducing chaotic maps to enhance exploration capabilities in Hybrid PSO with SA.", "configspace": "", "generation": 2, "fitness": 0.7944337221844275, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.025. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "77389bd8-6cc8-4aca-bb1e-2799b712d618", "metadata": {"aucs": [0.7931206207599799, 0.8254074199307413, 0.7647731258625614], "final_y": [0.14470214934557002, 0.145153815443402, 0.17075607097703838]}, "mutation_prompt": null}
{"id": "a86d100b-2271-42bc-a4f6-464bfffe3d2a", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        budget_used = population_size\n\n        while budget_used < self.budget:\n            for i in range(population_size):\n                # Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                F_dynamic = 0.5 + 0.3 * (1 - budget_used / self.budget)  # Dynamic F\n                mutant = np.clip(a + F_dynamic * (b - c), bounds.lb, bounds.ub)\n                \n                # Crossover\n                CR_dynamic = 0.9 - 0.5 * (budget_used / self.budget)  # Dynamic adjustment\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                budget_used += 1\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n                \n                if budget_used >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridMetaheuristicOptimizer", "description": "Improved exploration-exploitation balance by dynamically adjusting both differential weight and crossover probability.", "configspace": "", "generation": 3, "fitness": 0.7946635758055672, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.004. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "495ef403-4490-4f6d-bf40-839d2d0a2c94", "metadata": {"aucs": [0.7973305268720371, 0.7972606640138798, 0.7893995365307849], "final_y": [0.14737066532079057, 0.14033923463779407, 0.15200085155860565]}, "mutation_prompt": null}
{"id": "3a501c9c-28fb-44d6-884f-84a1a545f769", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        bounds = func.bounds\n        population_size = 12 * self.dim  # Increased population size for better exploration\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        budget_used = population_size\n\n        while budget_used < self.budget:\n            for i in range(population_size):\n                # Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                budget_used += 1\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n                \n                if budget_used >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridMetaheuristicOptimizer", "description": "A hybrid metaheuristic combining differential evolution with a self-adaptive mutation strategy and increased population size for improved exploration and exploitation efficiency within budget constraints.", "configspace": "", "generation": 3, "fitness": 0.8066805393452356, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.008. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "208f9b69-ce57-4f3e-ba5e-c2c203404c85", "metadata": {"aucs": [0.8102189965945066, 0.7952405541674739, 0.8145820672737266], "final_y": [0.14674964692855696, 0.15086785964361304, 0.14556718981945382]}, "mutation_prompt": null}
{"id": "900f1541-ce73-4440-ab19-0fc64229b5d2", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        budget_used = population_size\n\n        while budget_used < self.budget:\n            for i in range(population_size):\n                # Mutation with adaptive strategy\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                F_dynamic = 0.4 + 0.6 * (1 - (budget_used / self.budget))  # Adaptive F\n                mutant = np.clip(a + F_dynamic * (b - c), bounds.lb, bounds.ub)\n                \n                # Crossover\n                CR_dynamic = 0.9 - 0.5 * (budget_used / self.budget)  # Dynamic adjustment\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                budget_used += 1\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n                else:\n                    # Diversity preservation\n                    if np.random.rand() < 0.1:\n                        population[i] = np.random.uniform(bounds.lb, bounds.ub, self.dim)\n                        fitness[i] = func(population[i])\n                        budget_used += 1\n\n                if budget_used >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridMetaheuristicOptimizer", "description": "An enhanced hybrid metaheuristic optimizer using adaptive mutation strategies and diversity preservation for improved exploration and exploitation.", "configspace": "", "generation": 3, "fitness": 0.8232820169410591, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.023. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "495ef403-4490-4f6d-bf40-839d2d0a2c94", "metadata": {"aucs": [0.833962440786469, 0.8443392101437179, 0.7915443998929902], "final_y": [0.13735440788061115, 0.1368197027481266, 0.14909206092634297]}, "mutation_prompt": null}
{"id": "20a74e4b-8e01-4a0d-b39d-cf9f8cbe30be", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.inertia_weight = 0.9  # Adjusted for dynamic inertia\n        self.cognitive_weight = 1.49445\n        self.social_weight = 1.49445\n        self.temperature = 100\n        self.temp_decay = 0.98  # Slightly faster decay\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        eval_count = self.num_particles\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.num_particles, self.dim), np.random.rand(self.num_particles, self.dim)\n            \n            # Dynamic inertia weight adjustment\n            inertia_weight = 0.9 - 0.5 * (eval_count / self.budget)\n            velocities = (inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - particles) +\n                          self.social_weight * r2 * (global_best_position - particles))\n            \n            particles = particles + velocities\n            particles = np.clip(particles, lb, ub)\n\n            # Evaluate particles and update personal best\n            for i in range(self.num_particles):\n                score = func(particles[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n\n                # Adaptive Simulated Annealing acceptance\n                acceptance_prob = np.exp((func(global_best_position) - score) / (self.temperature / eval_count))\n                if score < func(global_best_position) or acceptance_prob > np.random.rand():\n                    global_best_position = particles[i]\n\n                if eval_count >= self.budget:\n                    break\n\n            # Decay temperature\n            self.temperature *= self.temp_decay\n        \n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA by incorporating dynamic inertia and adaptive Simulated Annealing to improve exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8082644058143885, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.017. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "6acd838b-0d3e-4fa7-bd5b-e162e056491b", "metadata": {"aucs": [0.823199664528458, 0.8164571041937632, 0.7851364487209443], "final_y": [0.13492417340286655, 0.13766393611008632, 0.16297452676646507]}, "mutation_prompt": null}
{"id": "e0b534ca-38a8-45a1-b593-337eb62f38ae", "solution": "import numpy as np\n\nclass QAPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Customizable\n        self.inertia_weight_initial = 0.9  # Increased initial inertia weight\n        self.inertia_weight_final = 0.4   # Added final inertia weight\n        self.cognition_learning_factor = 1.5\n        self.social_learning_factor = 2.0\n        self.quantum_factor = 0.5  # Controls the spread of the quantum superposition\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        velocity = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        position = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best_position = position.copy()\n        personal_best_score = np.array([func(p) for p in position])\n        global_best_position = personal_best_position[personal_best_score.argmin()]\n        global_best_score = personal_best_score.min()\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            r_p = np.random.uniform(0, 1, (self.population_size, self.dim))\n            r_g = np.random.uniform(0, 1, (self.population_size, self.dim))\n            \n            # Dynamic inertia weight adaptation\n            inertia_weight = self.inertia_weight_initial - (self.inertia_weight_initial - self.inertia_weight_final) * (evaluations / self.budget)\n\n            # Update velocities with quantum-inspired dynamics\n            velocity = (inertia_weight * velocity\n                        + self.cognition_learning_factor * r_p * (personal_best_position - position)\n                        + self.social_learning_factor * r_g * (global_best_position - position)\n                        + self.quantum_factor * np.random.uniform(-1, 1, (self.population_size, self.dim)))\n\n            # Update positions\n            position += velocity\n            position = np.clip(position, lb, ub)\n\n            # Evaluate new solutions\n            scores = np.array([func(p) for p in position])\n            evaluations += self.population_size\n\n            # Update personal bests\n            improved = scores < personal_best_score\n            personal_best_position[improved] = position[improved]\n            personal_best_score[improved] = scores[improved]\n\n            # Update global best\n            if scores.min() < global_best_score:\n                global_best_score = scores.min()\n                global_best_position = position[scores.argmin()]\n\n        return global_best_position, global_best_score", "name": "QAPSO", "description": "An enhanced Quantum-inspired Adaptive Particle Swarm Optimization (QAPSO) using dynamic inertia weight adaptation for better convergence. ", "configspace": "", "generation": 3, "fitness": 0.81351403398927, "feedback": "The algorithm QAPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.015. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "1cb97f40-025b-4d51-a8b0-e2af7fd918c1", "metadata": {"aucs": [0.8005827443878691, 0.8341255917067927, 0.8058337658731483], "final_y": [0.15363696668805038, 0.13412603913351906, 0.15125702650001038]}, "mutation_prompt": null}
{"id": "06ee2c70-5aae-481b-8fe0-2ce37c33ecf9", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.7 + 0.2 * np.random.rand()  # Adaptive Crossover probability\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        budget_used = population_size\n\n        while budget_used < self.budget:\n            for i in range(population_size):\n                # Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                budget_used += 1\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n                \n                if budget_used >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridMetaheuristicOptimizer", "description": "An enhanced hybrid metaheuristic with adaptive crossover probability to improve exploration-exploitation balance in black-box optimization.", "configspace": "", "generation": 4, "fitness": 0.8060566429481937, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.016. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "208f9b69-ce57-4f3e-ba5e-c2c203404c85", "metadata": {"aucs": [0.7845701240947234, 0.8219340096850338, 0.8116657950648238], "final_y": [0.15024661748220347, 0.14301037836619157, 0.1376336600285788]}, "mutation_prompt": null}
{"id": "4d4bfa6e-7cd4-4cc0-a57d-4339b7784ac4", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n\n        return global_best_position", "name": "HybridPSOSA", "description": "An enhanced HybridPSOSA algorithm incorporating an adaptive cooling rate for simulated annealing to improve convergence.", "configspace": "", "generation": 4, "fitness": 0.829955939124825, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.029. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "4d1f1b87-c85c-4eef-a474-dca6542d5f07", "metadata": {"aucs": [0.8705850995186183, 0.8017504486627175, 0.8175322691931395], "final_y": [0.11578520111598734, 0.15291195742740815, 0.14004177512290827]}, "mutation_prompt": null}
{"id": "95cee3bd-2497-4c98-85f3-211c09c51ab3", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1_initial = 1.5  # initial cognitive parameter\n        self.c2_initial = 1.5  # initial social parameter\n        self.temperature = 1000\n        self.alpha = 0.9  # cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            # Dynamic update of cognitive and social parameters\n            self.c1 = self.c1_initial * (1 - evaluations / self.budget)\n            self.c2 = self.c2_initial * (evaluations / self.budget)\n            \n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n\n        return global_best_position", "name": "HybridPSOSA", "description": "An improved HybridPSOSA using dynamic social and cognitive parameters for adaptive exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.8138698353825561, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.010. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "4d1f1b87-c85c-4eef-a474-dca6542d5f07", "metadata": {"aucs": [0.8006028253820864, 0.822741461317526, 0.8182652194480557], "final_y": [0.12669852165857864, 0.12580737209036785, 0.13890168833688843]}, "mutation_prompt": null}
{"id": "13593157-b899-4e08-bba0-33368ae08345", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        budget_used = population_size\n\n        while budget_used < self.budget:\n            for i in range(population_size):\n                F = 0.5 + 0.3 * np.sin(budget_used / self.budget * np.pi)  # Dynamic F\n                CR = 0.9 * np.power(0.9, budget_used / self.budget)  # Dynamic CR\n                \n                # Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                budget_used += 1\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n                \n                if budget_used >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced HybridMetaheuristicOptimizer incorporating dynamic adaptation of differential weight and crossover probability for improved exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.7874379729264668, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.787 with standard deviation 0.008. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "208f9b69-ce57-4f3e-ba5e-c2c203404c85", "metadata": {"aucs": [0.78451540915579, 0.7982564620158518, 0.7795420476077589], "final_y": [0.1576070278951628, 0.15209603506892289, 0.1541001800563544]}, "mutation_prompt": null}
{"id": "00cf65d8-576b-4700-9634-c3aa3c06fc43", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = 30\n        self.inertia_weight = 0.729\n        self.cognitive_weight = 1.49445\n        self.social_weight = 1.49445\n        self.temperature = 100\n        self.temp_decay = 0.99\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        particles = np.random.uniform(lb, ub, (self.num_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.num_particles, self.dim))\n        personal_best_positions = np.copy(particles)\n        personal_best_scores = np.array([func(p) for p in particles])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        \n        eval_count = self.num_particles\n\n        while eval_count < self.budget:\n            # Update velocities and positions\n            r1, r2 = np.random.rand(self.num_particles, self.dim), np.random.rand(self.num_particles, self.dim)\n            # Adjust cognitive and social weights over time\n            self.cognitive_weight = 1.49445 - 0.5 * (eval_count / self.budget)\n            self.social_weight = 1.49445 + 0.5 * (eval_count / self.budget)\n            velocities = (self.inertia_weight * velocities +\n                          self.cognitive_weight * r1 * (personal_best_positions - particles) +\n                          self.social_weight * r2 * (global_best_position - particles))\n            \n            particles = particles + velocities\n            particles = np.clip(particles, lb, ub)\n\n            # Evaluate particles and update personal best\n            for i in range(self.num_particles):\n                score = func(particles[i])\n                eval_count += 1\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = particles[i]\n\n                # Simulated Annealing acceptance criterion\n                if score < func(global_best_position) or np.exp((func(global_best_position) - score) / self.temperature) > np.random.rand():\n                    global_best_position = particles[i]\n\n                if eval_count >= self.budget:\n                    break\n\n            # Decay temperature\n            self.temperature *= self.temp_decay\n        \n        return global_best_position", "name": "HybridPSOSA", "description": "An advanced HybridPSOSA algorithm introducing adaptive cognitive and social weights to dynamically balance exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.8223946980241298, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.014. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "6acd838b-0d3e-4fa7-bd5b-e162e056491b", "metadata": {"aucs": [0.8046544377407734, 0.8245600346804808, 0.8379696216511352], "final_y": [0.15298058596865083, 0.12910142398126345, 0.12466072262225525]}, "mutation_prompt": null}
{"id": "94590ba4-3c42-4696-8219-3dcea458b41e", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_swarm_size = 30\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        self.alpha = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        swarm_size = self.initial_swarm_size   # Dynamic swarm size adjustment\n        positions = np.random.uniform(lb, ub, (swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            for i in range(swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            for i in range(swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / (self.temperature * (1 + evaluations/self.budget))):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            self.temperature *= self.alpha\n            if np.random.rand() < 0.5:  # Randomly adjust swarm size\n                swarm_size = min(max(10, swarm_size + np.random.randint(-5, 6)), 50)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "An improved HybridPSOSA algorithm with dynamic swarm size adjustment and a refined simulated annealing acceptance criterion.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_id": "4d4bfa6e-7cd4-4cc0-a57d-4339b7784ac4", "metadata": {}, "mutation_prompt": null}
{"id": "832fedf8-712e-4580-b88d-8767587a87b7", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        budget_used = population_size\n\n        while budget_used < self.budget:\n            CR = 0.9 - 0.4 * (budget_used / self.budget)  # Dynamic crossover probability\n            for i in range(population_size):\n                # Mutation\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                budget_used += 1\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n                \n                if budget_used >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridMetaheuristicOptimizer", "description": "A hybrid metaheuristic combining differential evolution with a self-adaptive mutation strategy and a dynamic crossover probability to efficiently explore and exploit the search space for black box optimization within given budget constraints.", "configspace": "", "generation": 5, "fitness": 0.80105743626051, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.006. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "208f9b69-ce57-4f3e-ba5e-c2c203404c85", "metadata": {"aucs": [0.8097110063297791, 0.7944072502424737, 0.799054052209277], "final_y": [0.1519005299231201, 0.14434883311510305, 0.14562626313243232]}, "mutation_prompt": null}
{"id": "eede3139-60f1-43fd-a882-300ac9b4e01e", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.9  # cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n\n            # Adjust swarm size dynamically\n            self.swarm_size = max(10, int(self.swarm_size * (1 - evaluations/self.budget)))  # Dynamic adjustment\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA with dynamic swarm size adjustment based on convergence to improve exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.8394524223539955, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.018. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "4d1f1b87-c85c-4eef-a474-dca6542d5f07", "metadata": {"aucs": [0.8465400935244226, 0.8564488225471938, 0.8153683509903705], "final_y": [0.12375699622700198, 0.1240013597034868, 0.15015663770212906]}, "mutation_prompt": null}
{"id": "ba171a47-71f8-449a-9ebb-faf36c484ee4", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.9  # inertia weight increased for better exploration (original was 0.5)\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.9  # cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / (self.temperature + 1e-10)): # added a small number to avoid division by zero\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance HybridPSOSA by introducing adaptive inertia weight and adaptive personal best selection to balance exploration and exploitation effectively.", "configspace": "", "generation": 5, "fitness": 0.8228558492991146, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.029. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "4d1f1b87-c85c-4eef-a474-dca6542d5f07", "metadata": {"aucs": [0.8020454346590847, 0.8637514248857517, 0.8027706883525072], "final_y": [0.15245800125947906, 0.11996629467407582, 0.15547832722400845]}, "mutation_prompt": null}
{"id": "54dfd726-3bf8-41e8-9501-7e70996c468e", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Improved convergence by introducing an adaptive swarm size that decreases as the algorithm progresses.", "configspace": "", "generation": 5, "fitness": 0.8557395256120177, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.009. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "4d4bfa6e-7cd4-4cc0-a57d-4339b7784ac4", "metadata": {"aucs": [0.8478068206671054, 0.8516126132744425, 0.8677991428945055], "final_y": [0.12940768547989734, 0.12647817775292036, 0.12931743296401554]}, "mutation_prompt": null}
{"id": "d39b33fa-5198-4da3-8f9e-b8a7447b6d76", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        budget_used = population_size\n\n        while budget_used < self.budget:\n            for i in range(population_size):\n                # Mutation with adaptive strategy\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                F_dynamic = 0.4 + 0.6 * (1 - (budget_used / self.budget))  # Adaptive F\n                mutant = np.clip(a + F_dynamic * (b - c), bounds.lb, bounds.ub)\n                \n                # Crossover\n                CR_dynamic = 0.9 - 0.4 * (budget_used / self.budget)  # Dynamic adjustment\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                budget_used += 1\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n                else:\n                    # Diversity preservation\n                    if np.random.rand() < 0.1:\n                        population[i] = np.random.uniform(bounds.lb, bounds.ub, self.dim)\n                        fitness[i] = func(population[i])\n                        budget_used += 1\n\n                if budget_used >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridMetaheuristicOptimizer", "description": "An enhanced hybrid metaheuristic optimizer integrating adaptive mutation strategies and diversity preservation for improved exploration and exploitation with slightly adjusted dynamic crossover rate to enhance performance.", "configspace": "", "generation": 6, "fitness": 0.7919810441599681, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.007. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "900f1541-ce73-4440-ab19-0fc64229b5d2", "metadata": {"aucs": [0.7938901896843757, 0.7999144412615783, 0.7821385015339503], "final_y": [0.15080817179629058, 0.15290471125902272, 0.16197701918814122]}, "mutation_prompt": null}
{"id": "4372cb1e-8920-4431-8ce3-e2afa255eee6", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        budget_used = population_size\n\n        while budget_used < self.budget:\n            for i in range(population_size):\n                # Mutation with adaptive strategy\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                # Adjust F based on fitness variance\n                F_dynamic = 0.4 + 0.6 * (1 - (np.var(fitness) / np.mean(fitness)))  \n                mutant = np.clip(a + F_dynamic * (b - c), bounds.lb, bounds.ub)\n                \n                # Crossover\n                CR_dynamic = 0.9 - 0.5 * (budget_used / self.budget)  # Dynamic adjustment\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                budget_used += 1\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n                else:\n                    # Diversity preservation\n                    if np.random.rand() < 0.1:\n                        population[i] = np.random.uniform(bounds.lb, bounds.ub, self.dim)\n                        fitness[i] = func(population[i])\n                        budget_used += 1\n\n                if budget_used >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced differential weight adaptation based on fitness variance to improve convergence and exploration balance.", "configspace": "", "generation": 6, "fitness": 0.8011725146462472, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.016. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "900f1541-ce73-4440-ab19-0fc64229b5d2", "metadata": {"aucs": [0.8208487126238164, 0.8021797550504305, 0.7804890762644945], "final_y": [0.14533257375812314, 0.13628780790765016, 0.15514341087653738]}, "mutation_prompt": null}
{"id": "6d754844-d268-4806-8577-fd5933d9fba8", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        budget_used = population_size\n\n        while budget_used < self.budget:\n            for i in range(population_size):\n                # Mutation with adaptive strategy\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                F_dynamic = 0.4 + 0.5 * (1 - (budget_used / self.budget))  # Adaptive F, adjusted to affect mutation more\n                mutant = np.clip(a + F_dynamic * (b - c), bounds.lb, bounds.ub)\n                \n                # Crossover\n                CR_dynamic = 0.9 - 0.5 * (budget_used / self.budget)  # Dynamic adjustment\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                budget_used += 1\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n                else:\n                    # Diversity preservation\n                    if np.random.rand() < 0.1:\n                        population[i] = np.random.uniform(bounds.lb, bounds.ub, self.dim)\n                        fitness[i] = func(population[i])\n                        budget_used += 1\n\n                if budget_used >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridMetaheuristicOptimizer", "description": "Enhanced mutation strategy by dynamically adjusting the differential weight to improve convergence.", "configspace": "", "generation": 6, "fitness": 0.7985450883003615, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.008. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "900f1541-ce73-4440-ab19-0fc64229b5d2", "metadata": {"aucs": [0.807890032830447, 0.7877914635630604, 0.7999537685075772], "final_y": [0.15259432123934114, 0.15933069492453744, 0.15570129816131617]}, "mutation_prompt": null}
{"id": "52ef60f7-f74f-4b7c-85f0-e43ae4c88205", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.9  # Adaptive inertia weight starts high\n        self.w_min = 0.4\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.9  # cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Adaptive inertia weight reduction\n            self.w -= (self.w - self.w_min) * (evaluations / self.budget)\n            \n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n\n            # Adjust swarm size dynamically\n            self.swarm_size = max(10, int(self.swarm_size * (1 - evaluations/self.budget)))  # Dynamic adjustment\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Incorporate adaptive inertia weight and dynamic personal-best exploration to enhance convergence and adaptability.", "configspace": "", "generation": 6, "fitness": 0.7950721675656213, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.017. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "eede3139-60f1-43fd-a882-300ac9b4e01e", "metadata": {"aucs": [0.7770630798893866, 0.7908318597257222, 0.8173215630817552], "final_y": [0.1618230354243273, 0.1613291719904696, 0.15004203439145047]}, "mutation_prompt": null}
{"id": "de5cc3ec-78ab-45ce-b363-4d8fc81d6160", "solution": "import numpy as np\n\nclass HybridMetaheuristicOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        bounds = func.bounds\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n        population = np.random.uniform(bounds.lb, bounds.ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        budget_used = population_size\n\n        while budget_used < self.budget:\n            for i in range(population_size):\n                # Mutation with adaptive strategy\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                F_dynamic = 0.4 + 0.6 * (1 - (budget_used / self.budget))  # Adaptive F\n                mutant = np.clip(a + F_dynamic * (b - c), bounds.lb, bounds.ub)\n                \n                # Crossover\n                CR_dynamic = 0.9 - 0.5 * (budget_used / self.budget)  # Dynamic adjustment\n                cross_points = np.random.rand(self.dim) < CR_dynamic\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Selection\n                trial_fitness = func(trial)\n                budget_used += 1\n                if trial_fitness < fitness[i]:\n                    fitness[i] = trial_fitness\n                    population[i] = trial\n                else:\n                    # Diversity preservation\n                    mutation_prob = 0.1 - 0.05 * (budget_used / self.budget)  # Adaptive mutation probability\n                    if np.random.rand() < mutation_prob:\n                        population[i] = np.random.uniform(bounds.lb, bounds.ub, self.dim)\n                        fitness[i] = func(population[i])\n                        budget_used += 1\n\n                if budget_used >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]", "name": "HybridMetaheuristicOptimizer", "description": "Introduced adaptive mutation probability dynamically decreasing based on budget utilization for improved balance.", "configspace": "", "generation": 6, "fitness": 0.792253224897454, "feedback": "The algorithm HybridMetaheuristicOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.006. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "900f1541-ce73-4440-ab19-0fc64229b5d2", "metadata": {"aucs": [0.7837726081687378, 0.79659083017128, 0.796396236352344], "final_y": [0.15849042279743142, 0.15061380444750427, 0.15372829160851786]}, "mutation_prompt": null}
{"id": "dee6d0e7-694a-4b9c-8220-d882eaf2060b", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.6  # Adjusted inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Slightly adjusted inertia weight to balance exploration and exploitation more effectively.", "configspace": "", "generation": 7, "fitness": 0.8187586044312297, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.819 with standard deviation 0.025. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "4d4bfa6e-7cd4-4cc0-a57d-4339b7784ac4", "metadata": {"aucs": [0.8508292901974297, 0.7898828211700555, 0.8155637019262036], "final_y": [0.12661144139352354, 0.1616825207811453, 0.15017418056251364]}, "mutation_prompt": null}
{"id": "3557526d-6bcf-4cbf-80c0-b50a92e7ff00", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Further optimize convergence by adjusting inertia weight dynamically based on progress.", "configspace": "", "generation": 7, "fitness": 0.8459818510111122, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.013. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "54dfd726-3bf8-41e8-9501-7e70996c468e", "metadata": {"aucs": [0.864700135549587, 0.8341519291997088, 0.8390934882840408], "final_y": [0.11834630300117688, 0.1349338666996427, 0.12868225418243595]}, "mutation_prompt": null}
{"id": "2cd46ebc-d35c-4278-a7aa-7da52f4b4771", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # initial inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.9  # cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n\n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Adaptive inertia weight adjustment\n            self.w = 0.9 - (0.5 * (evaluations / self.budget))\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Incorporates adaptive inertia weight adjustment to improve convergence by balancing exploration and exploitation dynamically.", "configspace": "", "generation": 7, "fitness": 0.7971970329495205, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.016. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "4d1f1b87-c85c-4eef-a474-dca6542d5f07", "metadata": {"aucs": [0.7760597705588994, 0.8140449280560635, 0.8014864002335984], "final_y": [0.16428860105169196, 0.14951678757315656, 0.15712683132833805]}, "mutation_prompt": null}
{"id": "d30f9b0f-df19-41db-8a4e-99d486039e3f", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.9  # initial inertia weight\n        self.w_min = 0.4  # minimum inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.99  # improved cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Adapt inertia weight\n            self.w = self.w_min + (0.9 - self.w_min) * (1 - evaluations / self.budget)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced HybridPSOSA with adaptive inertia weight and improved cooling rate for better exploration-exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.8166835420459543, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.817 with standard deviation 0.015. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "4d1f1b87-c85c-4eef-a474-dca6542d5f07", "metadata": {"aucs": [0.8341866950508862, 0.8183394328990798, 0.797524498187897], "final_y": [0.1365508395434376, 0.14868789839323682, 0.1553854322046121]}, "mutation_prompt": null}
{"id": "667563ac-c6c2-49d3-8dd1-430245f17a66", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.7  # Adjusted inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Slightly adjusted the inertia weight `w` from 0.5 to 0.7 to enhance exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.8346604128671044, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.835 with standard deviation 0.011. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "4d4bfa6e-7cd4-4cc0-a57d-4339b7784ac4", "metadata": {"aucs": [0.8310632596958264, 0.8233002478001131, 0.8496177311053734], "final_y": [0.13814544587505517, 0.14522007892383093, 0.12949765548565617]}, "mutation_prompt": null}
{"id": "424101fd-f41a-45bf-8fa4-8caff54e3858", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.6  # Adjusted cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced convergence by adjusting the cognitive parameter `c1` to improve personal best influence slightly.", "configspace": "", "generation": 8, "fitness": 0.8398835163015312, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.010. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "54dfd726-3bf8-41e8-9501-7e70996c468e", "metadata": {"aucs": [0.8414148354078596, 0.8513953714540765, 0.8268403420426574], "final_y": [0.13178976786971786, 0.12811178637069087, 0.1442442860941232]}, "mutation_prompt": null}
{"id": "4f505fd0-e4b4-4ce4-822a-b49a81c6bb9f", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.7  # Adjusted inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n\n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n\n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n\n            # Adaptive parameter control based on progress\n            self.c1 = 1.5 + 0.5 * (1 - evaluations / self.budget)\n            self.c2 = 1.5 - 0.5 * (1 - evaluations / self.budget)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduced adaptive control for the cognitive and social parameters to enhance convergence by slightly updating `c1` and `c2` during optimization.", "configspace": "", "generation": 8, "fitness": 0.8406534692095172, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.026. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "667563ac-c6c2-49d3-8dd1-430245f17a66", "metadata": {"aucs": [0.8419307514934111, 0.8723145434681183, 0.8077151126670222], "final_y": [0.13270702390840083, 0.11889918665758359, 0.15481832792442984]}, "mutation_prompt": null}
{"id": "eeed778b-3b42-4ac7-ab19-71ae6ba0c62a", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05, self.dim)  # Add random perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce a non-linear temperature cooling schedule and enhance position updating with a random perturbation to improve exploration and convergence.", "configspace": "", "generation": 8, "fitness": 0.8606298564765025, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.025. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "3557526d-6bcf-4cbf-80c0-b50a92e7ff00", "metadata": {"aucs": [0.863707943929694, 0.8291799992744369, 0.8890016262253767], "final_y": [0.1199178380484065, 0.13821413366219926, 0.12065907494762729]}, "mutation_prompt": null}
{"id": "02b2f837-c4dd-4e25-ad13-b0f6abc3a088", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.7  \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.temperature = 1000\n        self.alpha = 0.95  \n        self.beta = 1.5  # Lévy flight parameter\n\n    def levy_flight(self):\n        return np.random.standard_cauchy(self.dim) * 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            w_adjusted = self.w * (1 - evaluations / self.budget)\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w_adjusted * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i] + self.levy_flight()\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            self.temperature *= self.alpha\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduced adaptive parameters and diversified exploration strategy by employing Lévy flight to enhance exploration and exploitation with improved convergence.", "configspace": "", "generation": 8, "fitness": 0.8556781037421052, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.001. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "667563ac-c6c2-49d3-8dd1-430245f17a66", "metadata": {"aucs": [0.8541267100848173, 0.8565195531294935, 0.8563880480120043], "final_y": [0.12770971601646064, 0.12669698702152166, 0.13199568500965309]}, "mutation_prompt": null}
{"id": "02f84b82-ba5a-4c2d-b1ea-4a803cb30e61", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.6  # inertia weight (changed from 0.5 to 0.6)\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.7  # social parameter (changed from 1.5 to 1.7)\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced global exploration by increasing the social parameter `c2` and improved local search by adjusting the inertia weight `w`.", "configspace": "", "generation": 8, "fitness": 0.8519399836033945, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.033. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "54dfd726-3bf8-41e8-9501-7e70996c468e", "metadata": {"aucs": [0.8156584171023311, 0.8453508526543605, 0.8948106810534918], "final_y": [0.14616186518356367, 0.13093811835147828, 0.11513748656288514]}, "mutation_prompt": null}
{"id": "0c1ada55-6e1f-46c2-bd6a-835319a9bb5a", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.9  # cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max * (1 - evaluations / self.budget), v_max * (1 - evaluations / self.budget))\n                self.c1, self.c2 = 1.5 - 0.5 * (evaluations / self.budget), 1.5 + 0.5 * (evaluations / self.budget)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced convergence through adaptive velocity scaling and dynamic social-cognitive parameter balancing.", "configspace": "", "generation": 9, "fitness": 0.8373957820695068, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.019. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "4d1f1b87-c85c-4eef-a474-dca6542d5f07", "metadata": {"aucs": [0.8282446290270569, 0.8644117100671589, 0.8195310071143047], "final_y": [0.13594687401937744, 0.1158865688997961, 0.1484605367807531]}, "mutation_prompt": null}
{"id": "e7a9d827-b288-4b1a-ac90-4d4cb518160c", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhancing the exploration phase by introducing dynamic perturbation scaling based on the remaining budget.", "configspace": "", "generation": 9, "fitness": 0.8616155422495494, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.017. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "eeed778b-3b42-4ac7-ab19-71ae6ba0c62a", "metadata": {"aucs": [0.8839433117430764, 0.8582293943868009, 0.8426739206187709], "final_y": [0.11343623946127723, 0.12831541589155238, 0.13511041517862454]}, "mutation_prompt": null}
{"id": "2438755f-d337-4a96-a67e-6b5d81358761", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.9  # cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = ((0.9 - 0.4 * evaluations / self.budget) * velocities[i] +  # Changed line\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced exploration by adjusting the velocity update with a dynamic inertia weight decreasing linearly over iterations to balance exploration and exploitation.", "configspace": "", "generation": 9, "fitness": 0.8351231673598805, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.835 with standard deviation 0.013. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "4d1f1b87-c85c-4eef-a474-dca6542d5f07", "metadata": {"aucs": [0.8173238936194672, 0.8408549967675103, 0.847190611692664], "final_y": [0.1427464359122229, 0.1339173538077686, 0.13920080436258886]}, "mutation_prompt": null}
{"id": "27a04f18-fa66-4dc2-856c-c331e8058f8f", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.6  # inertia weight (changed from 0.5 to 0.6)\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.7  # social parameter (changed from 1.5 to 1.7)\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                self.w = 0.5 + 0.1 * (1 - evaluations / self.budget)  # Dynamically adjust inertia weight\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / (self.temperature * (1 - evaluations / self.budget))):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced convergence by dynamically adjusting the inertia weight `w` based on the remaining budget, and improving exploration with adaptive temperature scaling.", "configspace": "", "generation": 9, "fitness": 0.8045083243140221, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.013. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "02f84b82-ba5a-4c2d-b1ea-4a803cb30e61", "metadata": {"aucs": [0.8224432705753844, 0.8000020624202875, 0.7910796399463942], "final_y": [0.1436239552976062, 0.1565406649960479, 0.16072096183800777]}, "mutation_prompt": null}
{"id": "4f2596aa-7bde-4827-abe5-f6d09c9ee372", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.9  # cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature\n            self.temperature *= self.alpha * (1 - evaluations / self.budget)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduced adaptive temperature cooling rate based on iteration count to improve convergence efficiency.", "configspace": "", "generation": 9, "fitness": 0.8461210007773237, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.011. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "4d1f1b87-c85c-4eef-a474-dca6542d5f07", "metadata": {"aucs": [0.8577029203470374, 0.8491989752841731, 0.8314611067007603], "final_y": [0.12398935636671049, 0.13043634537470095, 0.1421087272915348]}, "mutation_prompt": null}
{"id": "678a0ca4-31d2-449d-a745-bc7314944dcf", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.7  # increased initial inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.9  # increased social parameter \n        self.temperature = 1000\n        self.alpha = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.2  # increased velocity limit\n        \n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            adaptive_swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))\n            for i in range(adaptive_swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                inertia = self.w * (1 - (evaluations / self.budget))  # dynamic inertia\n                velocities[i] = (inertia * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.05, self.dim)  # reduced noise\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            self.temperature *= self.alpha\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introducing adaptive learning parameters and dynamic velocity updates to enhance exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.8173471863671837, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.817 with standard deviation 0.027. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "02f84b82-ba5a-4c2d-b1ea-4a803cb30e61", "metadata": {"aucs": [0.785830488836385, 0.8511232544511056, 0.8150878158140609], "final_y": [0.1610144570270825, 0.1314361363897536, 0.1502629938431359]}, "mutation_prompt": null}
{"id": "0e8fae84-97d5-4921-995a-4f4a8e3570af", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.7  \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.temperature = 1000\n        self.alpha = 0.95  \n        self.beta = 1.5  # Lévy flight parameter\n\n    def levy_flight(self):\n        return np.random.standard_cauchy(self.dim) * 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            w_adjusted = self.w * (1 - evaluations / self.budget)\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w_adjusted * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i] + self.levy_flight()\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            self.temperature *= self.alpha\n            \n            if evaluations % (self.budget // 10) == 0:  # New addition\n                global_best_position += np.random.normal(0, 0.01, self.dim)  # New addition\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhanced convergence and diversity by applying a small random mutation to global best position periodically.", "configspace": "", "generation": 10, "fitness": 0.8602220566207482, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.024. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "02b2f837-c4dd-4e25-ad13-b0f6abc3a088", "metadata": {"aucs": [0.8572713457324865, 0.8324468692823429, 0.8909479548474151], "final_y": [0.12288616232447158, 0.1368299662437007, 0.12515427928448697]}, "mutation_prompt": null}
{"id": "85068cd1-8dbd-40d3-9336-a72daa873a18", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget)**2)  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance the convergence by introducing a more aggressive decrement in the inertia weight based on the swarm fitness.", "configspace": "", "generation": 10, "fitness": 0.8370958963856584, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.030. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "e7a9d827-b288-4b1a-ac90-4d4cb518160c", "metadata": {"aucs": [0.8653001498149603, 0.850256997331735, 0.7957305420102802], "final_y": [0.12208529830640313, 0.12843077469171338, 0.1568006539389799]}, "mutation_prompt": null}
{"id": "66bd6318-b9bb-4059-ab33-8f482a2a6b86", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.7  \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.temperature = 1000\n        self.alpha = 0.95  \n        self.beta = 1.5  # Lévy flight parameter\n\n    def levy_flight(self):\n        return np.random.standard_cauchy(self.dim) * 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            w_adjusted = self.w * (1 - evaluations / self.budget)\n            c1_dynamic = self.c1 * (0.5 + evaluations / self.budget)\n            c2_dynamic = self.c2 * (1.5 - evaluations / self.budget)\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w_adjusted * velocities[i] +\n                                 c1_dynamic * r1 * (personal_best_positions[i] - positions[i]) +\n                                 c2_dynamic * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i] + self.levy_flight()\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            self.temperature *= self.alpha\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Refine the HybridPSOSA algorithm by incorporating dynamic adjustment of `c1` and `c2` based on the convergence progress to further enhance adaptability and solution quality.", "configspace": "", "generation": 10, "fitness": 0.8419193025629405, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.012. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "02b2f837-c4dd-4e25-ad13-b0f6abc3a088", "metadata": {"aucs": [0.8319901574596154, 0.8342786539112788, 0.8594890963179276], "final_y": [0.13479357336736664, 0.13724732408102858, 0.12674013972345488]}, "mutation_prompt": null}
{"id": "d9ab4fc9-6c63-41fe-a4ea-08fd2345e810", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.07, self.dim)  # Add slightly larger random perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduced a slightly larger random perturbation to positions, enhancing exploration capabilities.", "configspace": "", "generation": 10, "fitness": 0.8767785945745267, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.031. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "eeed778b-3b42-4ac7-ab19-71ae6ba0c62a", "metadata": {"aucs": [0.8689317297321167, 0.8433461838023852, 0.9180578701890777], "final_y": [0.12096319701277858, 0.13399753672016068, 0.11595782902842455]}, "mutation_prompt": null}
{"id": "960f2b60-1896-4fa9-967d-2fb4b0fea1c0", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.08 * (1 - evaluations / self.budget), self.dim)  # Adjusted dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / (self.temperature / 2)):  # Enhanced selection pressure\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Improved exploration by dynamically adjusting perturbation and enhancing selection pressure through a modified acceptance criterion.", "configspace": "", "generation": 11, "fitness": 0.8523806781287111, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.037. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "e7a9d827-b288-4b1a-ac90-4d4cb518160c", "metadata": {"aucs": [0.8496912897260664, 0.8085239134395376, 0.8989268312205291], "final_y": [0.12492908915028877, 0.14017271976307533, 0.1111262011912606]}, "mutation_prompt": null}
{"id": "a220d292-9234-48a0-a98a-5dd8eadc7e98", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n        self.elite_fraction = 0.2  # Fraction of elite particles\n        self.mutation_rate = 0.1  # Initial mutation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        elite_count = int(self.swarm_size * self.elite_fraction)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with elite learning and random perturbation\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                elite_position = personal_best_positions[np.random.choice(elite_indices)]\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (elite_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, self.mutation_rate * (1 - evaluations / self.budget), self.dim)\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive mutation\n            self.mutation_rate = 0.1 + 0.9 * (evaluations / self.budget)\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, self.mutation_rate, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance the HybridPSOSA by incorporating elite learning strategies and adaptive mutation rates to improve exploration and exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.8738835685833491, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.011. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e7a9d827-b288-4b1a-ac90-4d4cb518160c", "metadata": {"aucs": [0.8654781493067286, 0.8664828243071571, 0.8896897321361616], "final_y": [0.11333748017982759, 0.11472243305260388, 0.11247109064395455]}, "mutation_prompt": null}
{"id": "20fc0241-c4cd-4d55-95bd-5f8fc39fd84b", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            self.c1 = 1.5 + 0.5 * (evaluations / self.budget)  # Variable cognitive parameter\n            self.c2 = 1.5 - 0.5 * (evaluations / self.budget)  # Variable social parameter\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduced variable cognitive and social parameters that adapt dynamically based on the budget to enhance convergence.", "configspace": "", "generation": 11, "fitness": 0.8584164587567203, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.002. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "e7a9d827-b288-4b1a-ac90-4d4cb518160c", "metadata": {"aucs": [0.8570309249852985, 0.8608413077805319, 0.8573771435043309], "final_y": [0.12237813534619213, 0.11741586582810748, 0.12227157469677197]}, "mutation_prompt": null}
{"id": "cfff6283-738c-440f-bafa-c56fab394bcd", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i] * 0.99, -v_max, v_max)  # Introduced decay factor\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduced a decay factor to reduce velocity magnitude, improving stability and convergence.", "configspace": "", "generation": 11, "fitness": 0.8280220072829599, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.031. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "e7a9d827-b288-4b1a-ac90-4d4cb518160c", "metadata": {"aucs": [0.8442072598035777, 0.7845364486690946, 0.8553223133762078], "final_y": [0.12866127285839524, 0.1640228208148714, 0.11616652537832384]}, "mutation_prompt": null}
{"id": "bdbc4287-26d9-4977-ba35-46bb2dd9608a", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.7  \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.temperature = 1000\n        self.alpha = 0.95  \n        self.beta = 1.5 \n\n    def levy_flight(self):\n        return np.random.standard_cauchy(self.dim) * 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            w_adjusted = self.w * (1 - evaluations / self.budget) + 0.2  # Change 1\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w_adjusted * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i] + self.levy_flight()\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            if evaluations % (self.budget // 8) == 0:  # Change 2\n                self.temperature *= self.alpha  # Change 3\n                for i in range(self.swarm_size):\n                    candidate = positions[i] + np.random.normal(0, 0.05, self.dim)  # Change 4\n                    candidate = np.clip(candidate, lb, ub)\n                    candidate_score = func(candidate)\n                    evaluations += 1\n\n                    if candidate_score < personal_best_scores[i] or \\\n                       np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                        personal_best_positions[i] = candidate\n                        personal_best_scores[i] = candidate_score\n\n                    if evaluations >= self.budget:\n                        break\n            \n            if evaluations % (self.budget // 15) == 0:  # Change 5\n                global_best_position += np.random.normal(0, 0.005, self.dim)  # Change 6\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introducing adaptive velocity update factors and dynamic mutation strategies to enhance exploration and convergence.", "configspace": "", "generation": 11, "fitness": 0.845589915657802, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.022. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "0e8fae84-97d5-4921-995a-4f4a8e3570af", "metadata": {"aucs": [0.875892083383499, 0.8245216590169052, 0.8363560045730016], "final_y": [0.12052123391797986, 0.12555417562332705, 0.12214386995970072]}, "mutation_prompt": null}
{"id": "7dd2e999-dd10-4fc4-8432-5beea7cc3fb0", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            perturbation_size = 0.05 * (evaluations / self.budget)  # Adaptive perturbation size\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, perturbation_size, self.dim)  # Add adaptive random perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Further enhance exploration by introducing adaptive random perturbation size, synchronized with dynamic swarm size and inertia weight.", "configspace": "", "generation": 12, "fitness": 0.8590240881457408, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.027. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "eeed778b-3b42-4ac7-ab19-71ae6ba0c62a", "metadata": {"aucs": [0.8656358427622677, 0.8233019670655173, 0.8881344546094375], "final_y": [0.12160245083353394, 0.13301455940398643, 0.11251073974022796]}, "mutation_prompt": null}
{"id": "bb621218-8d92-4626-8781-ad588d4137e1", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.7  \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.temperature = 1000\n        self.alpha = 0.95  \n        self.beta = 1.5  # Lévy flight parameter\n\n    def levy_flight(self):\n        return np.random.standard_cauchy(self.dim) * 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            w_adjusted = self.w * (1 - evaluations / self.budget)\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w_adjusted * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i] + self.levy_flight()\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            self.temperature *= self.alpha\n            \n            if evaluations % (self.budget // 20) == 0:  # Changed line\n                global_best_position += np.random.normal(0, 0.01, self.dim)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Improve exploration by perturbing the global best position more frequently with a slightly larger perturbation.", "configspace": "", "generation": 12, "fitness": 0.856780747903619, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.012. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "0e8fae84-97d5-4921-995a-4f4a8e3570af", "metadata": {"aucs": [0.8740465273089774, 0.8483963740441275, 0.8478993423577519], "final_y": [0.11546313268909714, 0.12355479450071116, 0.12544381644781066]}, "mutation_prompt": null}
{"id": "8e177f9b-ccc8-4905-bd50-85f5b53b6efc", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n        self.elite_fraction = 0.2  # Fraction of elite particles\n        self.mutation_rate = 0.1  # Initial mutation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        elite_count = int(self.swarm_size * self.elite_fraction)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with elite learning and random perturbation\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                elite_position = personal_best_positions[np.random.choice(elite_indices)]\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (elite_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, self.mutation_rate * (1 - evaluations / self.budget), self.dim)\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive mutation\n            self.mutation_rate = 0.1 + 0.9 * (evaluations / self.budget)\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, self.mutation_rate, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adjust elite fraction dynamically based on global best improvement\n            if evaluations > self.budget * 0.1:  # after 10% evaluations\n                improvement = (global_best_score / np.min(personal_best_scores)) - 1\n                self.elite_fraction = max(0.05, min(0.5, 0.2 * (1 + improvement)))\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduced a dynamic elite fraction adjusting based on performance to enhance adaptive learning and convergence.", "configspace": "", "generation": 12, "fitness": 0.8726147489947476, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.018. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "a220d292-9234-48a0-a98a-5dd8eadc7e98", "metadata": {"aucs": [0.8491249236146491, 0.8745142866530078, 0.8942050367165858], "final_y": [0.12003508705707155, 0.11320575328397042, 0.11271512649665527]}, "mutation_prompt": null}
{"id": "99390eab-b5b3-4e1c-a151-012f0bad224d", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            elite_positions = np.argsort(personal_best_scores)[:self.swarm_size//2]  # Added elite selection\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in elite_positions:  # Modified to use elite positions\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce an adaptive elite selection mechanism to retain the top solutions dynamically during optimization.", "configspace": "", "generation": 12, "fitness": 0.8770317033289753, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.015. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "e7a9d827-b288-4b1a-ac90-4d4cb518160c", "metadata": {"aucs": [0.89835117469771, 0.8686409206766899, 0.8641030146125261], "final_y": [0.11586607070395472, 0.1172497443708721, 0.12207193946168748]}, "mutation_prompt": null}
{"id": "fa662e8b-7206-4c68-b928-de9d481fb880", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.7  \n        self.c1 = 1.5  \n        self.c2 = 1.5  \n        self.temperature = 1000\n        self.alpha = 0.95  \n        self.beta = 1.5  # Lévy flight parameter\n\n    def levy_flight(self):\n        return np.random.standard_cauchy(self.dim) * 0.01\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            w_adjusted = self.w * (0.5 + np.random.rand() / 2)  # Changed line for adaptive inertia weight\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w_adjusted * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i] + self.levy_flight()\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            self.temperature *= self.alpha\n            \n            if evaluations % (self.budget // 10) == 0:\n                gradient_mutation = np.gradient(global_best_position) * np.random.rand(self.dim) * 0.01  # Added line for gradient-based mutation\n                global_best_position += gradient_mutation  # Changed line for applying the mutation\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce adaptive inertia weight and gradient-based mutation to balance exploration and exploitation.", "configspace": "", "generation": 12, "fitness": 0.8445795931679889, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.029. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "0e8fae84-97d5-4921-995a-4f4a8e3570af", "metadata": {"aucs": [0.8046912486802595, 0.8590994845167554, 0.869948046306952], "final_y": [0.1518392217503094, 0.12175616515766574, 0.11560745499229097]}, "mutation_prompt": null}
{"id": "03efe0d8-2aa8-4408-9b28-e7dd2447a778", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget)) ** 2  # Nonlinear decay of inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Incorporate nonlinear decay in velocity update to enhance convergence towards optimal solutions.", "configspace": "", "generation": 13, "fitness": 0.8342019669052557, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.042. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "e7a9d827-b288-4b1a-ac90-4d4cb518160c", "metadata": {"aucs": [0.8210240934673954, 0.7909286277941734, 0.8906531794541985], "final_y": [0.1385024453101813, 0.14633408995636132, 0.11293947254396963]}, "mutation_prompt": null}
{"id": "47eae291-b056-4767-a97d-0738f3224165", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with adaptive velocity damping\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] *= (1 - evaluations / self.budget)  # Adaptive damping\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                if i == 0:  # Apply elite perturbation\n                    positions[i] += np.random.normal(0, 0.05, self.dim)\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance exploration and exploitation balance by introducing adaptive velocity damping and elite perturbation strategies.", "configspace": "", "generation": 13, "fitness": 0.8553957160765903, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.016. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "d9ab4fc9-6c63-41fe-a4ea-08fd2345e810", "metadata": {"aucs": [0.8406221138632155, 0.8479828934550302, 0.877582140911525], "final_y": [0.13333395303808981, 0.11788404588171908, 0.11105283869776295]}, "mutation_prompt": null}
{"id": "62e499b9-2eb6-4504-b753-20b0c161b1fe", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.7  # cognitive parameter (changed from 1.5)\n        self.c2 = 1.7  # social parameter (changed from 1.5)\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Slightly increase cognitive and social parameters to improve convergence rate.", "configspace": "", "generation": 13, "fitness": 0.8541539479851767, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.011. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "e7a9d827-b288-4b1a-ac90-4d4cb518160c", "metadata": {"aucs": [0.8391246737392252, 0.8601421088376766, 0.8631950613786284], "final_y": [0.12772387283643505, 0.11966457882670867, 0.11346445758537893]}, "mutation_prompt": null}
{"id": "be729fb3-4a74-4b75-8967-cdc5916d7517", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive cooling factor\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / (self.temperature * (1 + evaluations/self.budget))):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down temperature with adaptive rate\n            self.temperature *= (self.alpha ** (1 + evaluations / self.budget))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance exploration and convergence by introducing adaptive cooling factor and elite selection in Simulated Annealing stage.", "configspace": "", "generation": 13, "fitness": 0.8776160304698329, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.015. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "e7a9d827-b288-4b1a-ac90-4d4cb518160c", "metadata": {"aucs": [0.8568693579645048, 0.8939712387520145, 0.8820074946929795], "final_y": [0.12082906958097606, 0.11079932967209172, 0.11704017429199909]}, "mutation_prompt": null}
{"id": "e6004bf1-410d-45fc-a807-84a91ddc85cb", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n        self.elite_fraction = 0.2  # Fraction of elite particles\n        self.mutation_rate = 0.1  # Initial mutation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        elite_count = int(self.swarm_size * self.elite_fraction)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            self.c1 = max(0.5, 1.5 * (1 - (evaluations / self.budget) ** 2))  # Non-linear cognitive parameter reduction\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with elite learning and random perturbation\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                elite_position = personal_best_positions[np.random.choice(elite_indices)]\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (elite_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, self.mutation_rate * (1 - evaluations / self.budget), self.dim)\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive mutation\n            self.mutation_rate = 0.05 + 0.95 * (evaluations / self.budget)  # Adjust mutation rate\n            elite_count = int(self.swarm_size * self.elite_fraction * (1 + evaluations / (2 * self.budget)))  # Dynamic elite fraction\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, self.mutation_rate, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Further refine the exploration-exploitation balance by introducing a non-linear reduction of the cognitive parameter, enhancing adaptive mutation strategies, and utilizing a dynamic elite fraction that adjusts more frequently.", "configspace": "", "generation": 13, "fitness": 0.8799653109139748, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.016. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a220d292-9234-48a0-a98a-5dd8eadc7e98", "metadata": {"aucs": [0.8649121000124897, 0.8733682460715688, 0.9016155866578657], "final_y": [0.11362098727816339, 0.11798668985089045, 0.11213285606938139]}, "mutation_prompt": null}
{"id": "595aa6fe-e26b-4e30-be52-2ff1c34793c2", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.temperature = 1000\n        self.alpha = 0.9  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.03 * (1 - evaluations / self.budget), self.dim)  # Reduced perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Enhanced Simulated Annealing step\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.08, self.dim)  # Adjusted noise\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / (self.temperature * (1 + 2 * evaluations/self.budget))):  # Updated cooling schedule\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic cooling schedule\n            self.temperature *= (self.alpha ** (1 + 2 * evaluations / self.budget))  # More aggressive cooling\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance convergence through dynamic cooling schedule in Simulated Annealing and improved swarm adaptability.", "configspace": "", "generation": 14, "fitness": 0.8488959594703379, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.014. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "be729fb3-4a74-4b75-8967-cdc5916d7517", "metadata": {"aucs": [0.8683878539590149, 0.833838742144553, 0.844461282307446], "final_y": [0.12218701746912775, 0.13365951066755344, 0.13167920558673796]}, "mutation_prompt": null}
{"id": "dcca6b8b-39be-4059-bb91-17abea521b89", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n        self.elite_fraction = 0.2  # Fraction of elite particles\n        self.mutation_rate = 0.1  # Initial mutation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        elite_count = int(self.swarm_size * self.elite_fraction)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with elite learning and random perturbation\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                elite_position = personal_best_positions[np.random.choice(elite_indices)]\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (elite_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, self.mutation_rate * (1 - evaluations / self.budget), self.dim)\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive mutation\n            self.mutation_rate = 0.1 + 0.9 * (evaluations / self.budget)\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, self.mutation_rate, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** (1 + evaluations / self.budget))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Refining the balance between exploration and exploitation by adjusting the cooling rate dynamically based on evaluations.", "configspace": "", "generation": 14, "fitness": 0.8452912454489905, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.022. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "a220d292-9234-48a0-a98a-5dd8eadc7e98", "metadata": {"aucs": [0.8667925927091295, 0.8541376932713682, 0.8149434503664739], "final_y": [0.11252642776817967, 0.12595436146963235, 0.1508475359259841]}, "mutation_prompt": null}
{"id": "9cd4292d-ac9e-448f-b0f8-beead890c5f4", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with adaptive random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                perturbation_scale = 0.07 * (1 - evaluations / self.budget)  # Adaptive perturbation\n                positions[i] += np.random.normal(0, perturbation_scale, self.dim)\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce an adaptive random perturbation based on the iteration count to balance exploration and exploitation.", "configspace": "", "generation": 14, "fitness": 0.8433966010234576, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.843 with standard deviation 0.020. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "d9ab4fc9-6c63-41fe-a4ea-08fd2345e810", "metadata": {"aucs": [0.8699052510056643, 0.8201551121229318, 0.8401294399417769], "final_y": [0.1175428944670256, 0.14380847246137407, 0.14040488000230444]}, "mutation_prompt": null}
{"id": "f5bf1b8f-09b5-4304-b2da-f7585595a560", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                dynamic_c1 = self.c1 * (1 + evaluations/self.budget)\n                dynamic_c2 = self.c2 * (1 - evaluations/self.budget)\n                velocities[i] = (self.w * velocities[i] +\n                                 dynamic_c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 dynamic_c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive cooling factor\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1 * (1 - evaluations/self.budget), self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / (self.temperature * (1 + evaluations/self.budget))):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down temperature with adaptive rate\n            self.temperature *= (self.alpha ** (1 + evaluations / self.budget))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance the algorithm by integrating dynamic learning rates for particle updates and introduce a stochastic perturbation in the Simulated Annealing process to further boost exploration.", "configspace": "", "generation": 14, "fitness": 0.8556413198190028, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.003. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "be729fb3-4a74-4b75-8967-cdc5916d7517", "metadata": {"aucs": [0.8549376579183796, 0.8518018668542107, 0.8601844346844182], "final_y": [0.1257572274077483, 0.12755338822727358, 0.1183173409835947]}, "mutation_prompt": null}
{"id": "c816f589-ce80-47a2-b58a-ebef60693f11", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            self.c1 = max(1.0, 2.5 * (1 - evaluations / self.budget))  # Dynamic cognitive parameter\n            self.c2 = max(1.0, 2.5 * (evaluations / self.budget))  # Dynamic social parameter\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                perturbation = np.random.normal(0, 0.07, self.dim)  # Add slightly larger random perturbation\n                positions[i] += np.clip(perturbation, -0.1, 0.1)  # Clip perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce dynamic cognitive and social parameter adjustments and perform perturbation clipping to improve exploration-exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.8664366317051453, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.012. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "d9ab4fc9-6c63-41fe-a4ea-08fd2345e810", "metadata": {"aucs": [0.8504375498971621, 0.869975535288686, 0.878896809929588], "final_y": [0.12395266703632946, 0.11898109789566358, 0.1186990491738219]}, "mutation_prompt": null}
{"id": "cab3f07b-e8e0-494e-b563-2ecf4a0545e8", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Updated dynamic cognitive-social balance\n                self.c1 = 1.5 * (1 - evaluations / self.budget)\n                self.c2 = 1.5 * (evaluations / self.budget)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive cooling factor\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / (self.temperature * (1 + evaluations/self.budget))):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down temperature with adaptive rate\n            self.temperature *= (self.alpha ** (1 + evaluations / self.budget))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Refined global learning by introducing a dynamic cognitive-social balance to enhance convergence.", "configspace": "", "generation": 15, "fitness": 0.7949965301352405, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.016. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "be729fb3-4a74-4b75-8967-cdc5916d7517", "metadata": {"aucs": [0.7718007502155231, 0.8061409390508643, 0.8070479011393343], "final_y": [0.1551785385697142, 0.14964632211235973, 0.14666981467484919]}, "mutation_prompt": null}
{"id": "0a4d904d-e1d4-47be-b22b-ec11e7e682e1", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n        self.elite_fraction = 0.2  # Fraction of elite particles\n        self.mutation_rate = 0.1  # Initial mutation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        elite_count = int(self.swarm_size * self.elite_fraction)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            self.c1 = max(0.5, 1.5 * (1 - (evaluations / self.budget) ** 2))  # Non-linear cognitive parameter reduction\n            self.c2 = max(0.5, 1.5 * (1 - evaluations / self.budget)**3)  # Non-linear social parameter adjustment\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with elite learning and random perturbation\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                elite_position = personal_best_positions[np.random.choice(elite_indices)]\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (elite_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, self.mutation_rate * (1 - evaluations / self.budget), self.dim)\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive mutation\n            self.mutation_rate = 0.05 + 0.95 * (evaluations / self.budget)  # Adjust mutation rate\n            elite_count = int(self.swarm_size * self.elite_fraction * (1 + evaluations / (2 * self.budget)))  # Dynamic elite fraction\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, self.mutation_rate, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Further refine the exploration-exploitation balance by introducing a nonlinear adjustment to the social parameter for enhanced convergence.", "configspace": "", "generation": 15, "fitness": 0.8486597002313223, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.014. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "e6004bf1-410d-45fc-a807-84a91ddc85cb", "metadata": {"aucs": [0.8645693996974635, 0.8309041204363012, 0.850505580560202], "final_y": [0.12425575416308321, 0.13891798709291425, 0.12702851206698118]}, "mutation_prompt": null}
{"id": "68adf353-48ff-4a96-b13f-6d16e6ca9488", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n        self.elite_fraction = 0.2  # Fraction of elite particles\n        self.mutation_rate = 0.1  # Initial mutation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        elite_count = int(self.swarm_size * self.elite_fraction)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            self.c1 = 1.5 * (1 - evaluations / self.budget)  # Time-varying cognitive parameter\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with elite learning and random perturbation\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            elite_re_eval = np.random.choice(elite_indices, size=elite_count, replace=False)  # Re-evaluate elites\n            for idx in elite_re_eval:\n                score = func(personal_best_positions[idx])\n                evaluations += 1\n                if score < personal_best_scores[idx]:\n                    personal_best_scores[idx] = score\n\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                elite_position = personal_best_positions[np.random.choice(elite_indices)]\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (elite_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, self.mutation_rate * (1 - evaluations / self.budget), self.dim)\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive mutation\n            self.mutation_rate = 0.1 + 0.9 * (evaluations / self.budget)\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, self.mutation_rate, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance HybridPSOSA by adding a time-varying cognitive parameter and improving elite selection with dynamic re-evaluation to boost optimization performance.", "configspace": "", "generation": 15, "fitness": 0.8411333063953315, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.018. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "a220d292-9234-48a0-a98a-5dd8eadc7e98", "metadata": {"aucs": [0.8563875239648572, 0.8154642285783424, 0.8515481666427946], "final_y": [0.1222717024321045, 0.14440751354847325, 0.12560673249105614]}, "mutation_prompt": null}
{"id": "f293cc26-09c7-44f9-8d4c-1f4f05446d05", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1_initial = 2.0  # initial cognitive parameter\n        self.c2_initial = 2.0  # initial social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n        self.elite_fraction = 0.2  # Fraction of elite particles\n        self.mutation_rate = 0.1  # Initial mutation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n\n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n\n        global_best_position = None\n        global_best_score = np.inf\n        elite_count = int(self.swarm_size * self.elite_fraction)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            self.c1 = self.c1_initial * (1 - evaluations / self.budget)  # Dynamic cognitive parameter\n            self.c2 = self.c2_initial * (evaluations / self.budget)  # Dynamic social parameter\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with elite learning and stochastic perturbation\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                elite_position = personal_best_positions[np.random.choice(elite_indices)]\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (elite_position - positions[i]))\n                v_max_dynamic = v_max * (1 - evaluations / self.budget)  # Adaptive velocity clamping\n                velocities[i] = np.clip(velocities[i], -v_max_dynamic, v_max_dynamic)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, self.mutation_rate * (1 - evaluations / self.budget), self.dim)\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive mutation\n            self.mutation_rate = 0.1 + 0.9 * (evaluations / self.budget)\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, self.mutation_rate, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance the HybridPSOSA by incorporating dynamic cognitive and social parameters, adaptive velocity clamping, and stochastic elite mutation to balance exploration and exploitation more effectively.", "configspace": "", "generation": 15, "fitness": 0.7996118352372817, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.022. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "a220d292-9234-48a0-a98a-5dd8eadc7e98", "metadata": {"aucs": [0.7716113836785019, 0.8021723682592565, 0.825051753774087], "final_y": [0.14284476623993414, 0.1519547059832631, 0.13788616306142099]}, "mutation_prompt": null}
{"id": "3ff3f407-2bc6-4be8-88c8-c48b317c685e", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            elite_positions = np.argsort(personal_best_scores)[:self.swarm_size//2]  # Added elite selection\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with non-linear perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity_adjustment = (1 - (evaluations / self.budget)**2)  # Non-linear reduction factor\n                velocities[i] = (self.w * velocities[i] * velocity_adjustment + \n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in elite_positions:  # Modified to use elite positions\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance convergence by introducing a non-linear velocity update factor that dynamically reduces the influence of inertia.", "configspace": "", "generation": 15, "fitness": 0.8378512331901905, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.009. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "99390eab-b5b3-4e1c-a151-012f0bad224d", "metadata": {"aucs": [0.8419620683102096, 0.8252518443005405, 0.8463397869598215], "final_y": [0.13184797028505268, 0.1401980128347654, 0.1294590870179927]}, "mutation_prompt": null}
{"id": "8938a0d8-45b8-4c0a-a7db-81981a18e4d6", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            elite_positions = np.argsort(personal_best_scores)[:self.swarm_size//2]  # Added elite selection\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                dynamic_lr = 0.05 * (1 - evaluations / self.budget)  # Dynamic learning rate\n                positions[i] += np.random.normal(0, dynamic_lr, self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in elite_positions:  # Modified to use elite positions\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance adaptive mutation strategy by introducing a dynamic learning rate that decreases linearly with evaluations to balance exploration and exploitation more effectively.", "configspace": "", "generation": 16, "fitness": 0.8686265388591657, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.010. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "99390eab-b5b3-4e1c-a151-012f0bad224d", "metadata": {"aucs": [0.8547322255215261, 0.8711915053790035, 0.8799558856769678], "final_y": [0.13181062036753277, 0.12447602870164742, 0.12438940942108878]}, "mutation_prompt": null}
{"id": "a8f3b4e2-4c8a-4de1-9e16-e81e682d13f2", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.05, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive cooling factor\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / (self.temperature * (1 + evaluations/self.budget))):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down temperature with adaptive rate\n            self.temperature *= (self.alpha ** (1 + evaluations / self.budget))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce a further reduction in the inertia weight during the final stages to enhance convergence towards optimal solutions.", "configspace": "", "generation": 16, "fitness": 0.8406750498904675, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.012. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "be729fb3-4a74-4b75-8967-cdc5916d7517", "metadata": {"aucs": [0.8558081303587008, 0.8396873204164306, 0.8265296988962714], "final_y": [0.12325480419463919, 0.1316159235171248, 0.14598255394060833]}, "mutation_prompt": null}
{"id": "fa1294ac-9055-40f6-9672-72e26ef0f8f8", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * np.exp(-evaluations / self.budget))  # Non-linear inertia weight reduction\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive cooling factor\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / (self.temperature * (1 + evaluations/self.budget))):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down temperature with adaptive rate\n            self.temperature *= (self.alpha ** (1 + evaluations / self.budget))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce a non-linear inertia weight reduction to improve convergence speed and solution accuracy.", "configspace": "", "generation": 16, "fitness": 0.8728766535334921, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.031. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "be729fb3-4a74-4b75-8967-cdc5916d7517", "metadata": {"aucs": [0.8308122426987816, 0.8850727711648971, 0.9027449467367977], "final_y": [0.13515526560322533, 0.11759221003762776, 0.11292836433061881]}, "mutation_prompt": null}
{"id": "bb65f752-c1ac-447d-8eca-2c628120bd86", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            self.c1 *= 0.99  # Decay cognitive parameter\n            elite_positions = np.argsort(personal_best_scores)[:self.swarm_size//2]  # Added elite selection\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in elite_positions:  # Modified to use elite positions\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce a decay factor for the cognitive parameter to enhance exploitation over time.", "configspace": "", "generation": 16, "fitness": 0.874531650874954, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.025. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "99390eab-b5b3-4e1c-a151-012f0bad224d", "metadata": {"aucs": [0.8796397240808241, 0.9020697127756943, 0.8418855157683436], "final_y": [0.1183716035075082, 0.1134429896144058, 0.14027692668301917]}, "mutation_prompt": null}
{"id": "b1c0b96c-6643-404f-ae8b-4b66d5320a06", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - (evaluations / self.budget)**0.8))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive cooling factor\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / (self.temperature * (1 + evaluations/self.budget))):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down temperature with adaptive rate\n            self.temperature *= (self.alpha ** (1 + evaluations / self.budget))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Adjust the inertia weight to decrease more rapidly initially, enhancing early exploration.", "configspace": "", "generation": 16, "fitness": 0.8435018355145786, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.041. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "be729fb3-4a74-4b75-8967-cdc5916d7517", "metadata": {"aucs": [0.8424441130841959, 0.8941069709405188, 0.7939544225190212], "final_y": [0.1295906923787815, 0.11666785416171932, 0.15984044789247354]}, "mutation_prompt": null}
{"id": "d5245942-7b3c-4cb3-b958-ff1b8271f561", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n        self.success_count = 0\n        self.iteration_count = 0\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            elite_positions = np.argsort(personal_best_scores)[:self.swarm_size//2]  # Added elite selection\n\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n                self.iteration_count += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n                    self.success_count += 1\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n\n                mutation_adapt = 0.05 * (1 - evaluations / self.budget) * (self.iteration_count / (self.success_count + 1))\n                positions[i] += np.random.normal(0, mutation_adapt, self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in elite_positions:  # Modified to use elite positions\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n                    self.success_count += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance convergence by using a dual-phase adaptive strategy adjusting both inertia and mutation based on success rate.", "configspace": "", "generation": 17, "fitness": 0.8521819575978151, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.014. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "99390eab-b5b3-4e1c-a151-012f0bad224d", "metadata": {"aucs": [0.8324482690722598, 0.861122188300841, 0.8629754154203444], "final_y": [0.14040340543738306, 0.12687686200805615, 0.12237869734012463]}, "mutation_prompt": null}
{"id": "463c6e45-a9a3-4c8a-aefb-258ce318dd1b", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n        self.elite_fraction = 0.2  # Fraction of elite particles\n        self.mutation_rate = 0.1  # Initial mutation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        elite_count = int(self.swarm_size * self.elite_fraction)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            self.c1 = max(0.5, 1.5 * (1 - (evaluations / self.budget) ** 2))  # Non-linear cognitive parameter reduction\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with elite learning and random perturbation\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                elite_position = personal_best_positions[np.random.choice(elite_indices)]\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (elite_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, self.mutation_rate * (1 - evaluations / self.budget), self.dim)\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive mutation\n            self.mutation_rate = 0.05 + 0.95 * (evaluations / self.budget)  # Adjust mutation rate\n            elite_count = int(self.swarm_size * self.elite_fraction * (1 + evaluations / (2 * self.budget)))  # Dynamic elite fraction\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, self.mutation_rate, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance adaptive mutation strategy via dynamic adjustment of the mutation rate's lower bound.", "configspace": "", "generation": 17, "fitness": 0.8634099675515546, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.012. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "e6004bf1-410d-45fc-a807-84a91ddc85cb", "metadata": {"aucs": [0.8495106135388341, 0.862065502298095, 0.8786537868177351], "final_y": [0.11914145648771812, 0.12113605860927834, 0.11864571531263302]}, "mutation_prompt": null}
{"id": "cb1c8a4c-fd7f-4e5d-a198-80aaf4691d4e", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            self.c2 = max(0.5, 1.5 * (1 - evaluations / self.budget))  # Dynamic social parameter\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.07, self.dim)  # Add slightly larger random perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce a dynamic social parameter that decreases over time to enhance exploitation capabilities in later stages of optimization.", "configspace": "", "generation": 17, "fitness": 0.816694917297195, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.817 with standard deviation 0.040. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "d9ab4fc9-6c63-41fe-a4ea-08fd2345e810", "metadata": {"aucs": [0.8118311189223283, 0.7705405882790098, 0.8677130446902466], "final_y": [0.14305827869305676, 0.16240581005882926, 0.1175755587284616]}, "mutation_prompt": null}
{"id": "bae8bbb1-e223-401f-8c8b-577adb00e006", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))\n            self.w = 0.9 - 0.8 * (evaluations / self.budget)  # Adaptive inertia weight\n            mutation_factor = 0.1 + 0.2 * (1 - evaluations / self.budget)  # Adaptive mutation factor\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, mutation_factor, self.dim)  # Adaptive perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce adaptive inertia and mutation rates for enhanced exploration and convergence.", "configspace": "", "generation": 17, "fitness": 0.8672316710964144, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.021. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "d9ab4fc9-6c63-41fe-a4ea-08fd2345e810", "metadata": {"aucs": [0.8371460104954598, 0.879460063121179, 0.8850889396726048], "final_y": [0.1369633653858945, 0.11415994250828132, 0.11721885640813412]}, "mutation_prompt": null}
{"id": "5dcc19b9-6f0e-4b29-a8e1-6f1edad0da29", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n        self.elite_fraction = 0.2  # Fraction of elite particles\n        self.mutation_rate = 0.1  # Initial mutation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        elite_count = int(self.swarm_size * self.elite_fraction)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            self.c1 = max(0.5, 1.5 * (1 - (evaluations / self.budget) ** 2))  # Non-linear cognitive parameter reduction\n            self.c2 = max(0.5, 1.5 * (1 - (evaluations / self.budget) ** 2))  # Non-linear social parameter reduction\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with elite learning and random perturbation\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                elite_position = personal_best_positions[np.random.choice(elite_indices)]\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (elite_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, self.mutation_rate * (1 - evaluations / self.budget), self.dim)\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive mutation\n            self.mutation_rate = 0.05 + 0.95 * (evaluations / self.budget)  # Adjust mutation rate\n            elite_count = int(self.swarm_size * self.elite_fraction * (1 + evaluations / (2 * self.budget)))  # Dynamic elite fraction\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, self.mutation_rate, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance convergence by introducing a non-linear reduction in the social parameter to further refine the balance between exploration and exploitation.", "configspace": "", "generation": 17, "fitness": 0.8554793521181027, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.028. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "e6004bf1-410d-45fc-a807-84a91ddc85cb", "metadata": {"aucs": [0.8175648596973426, 0.8662905851648133, 0.8825826114921523], "final_y": [0.1356024573728658, 0.1208068487158559, 0.11882884387993109]}, "mutation_prompt": null}
{"id": "26fde6cd-4c72-4e24-b484-eb9422e5b335", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            self.c1 *= (0.99 - 0.01 * (evaluations / self.budget))  # Quadratic decay cognitive parameter\n            self.c2 = 2.0 - self.c1  # Adjust dynamic social parameter\n            elite_positions = np.argsort(personal_best_scores)[:self.swarm_size//2]  # Added elite selection\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in elite_positions:  # Modified to use elite positions\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce a quadratic decay factor for the cognitive parameter and a dynamic social parameter to balance exploration and exploitation more effectively.", "configspace": "", "generation": 18, "fitness": 0.8356913496244026, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.836 with standard deviation 0.058. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "bb65f752-c1ac-447d-8eca-2c628120bd86", "metadata": {"aucs": [0.8288301262257172, 0.76890311738062, 0.909340805266871], "final_y": [0.13731624439118395, 0.1702433386818767, 0.11072254046631613]}, "mutation_prompt": null}
{"id": "270cdfaf-aab9-4344-b1f6-f1ed22f5348d", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            elite_positions = np.argsort(personal_best_scores)[:self.swarm_size//2]  # Added elite selection\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                dynamic_perturbation = 0.05 * (1 - evaluations / self.budget) * (1 + global_best_score)  # Modified line\n                positions[i] += np.random.normal(0, dynamic_perturbation, self.dim)  # Adjusted perturbation scaling\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in elite_positions:  # Modified to use elite positions\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance adaptive exploration by introducing dynamic perturbation scaling based on current best performance and evaluations.", "configspace": "", "generation": 18, "fitness": 0.8583929912954013, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.025. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "99390eab-b5b3-4e1c-a151-012f0bad224d", "metadata": {"aucs": [0.8308279044893395, 0.8521921256420746, 0.8921589437547895], "final_y": [0.14122263783315747, 0.11895314445975846, 0.1124849929436329]}, "mutation_prompt": null}
{"id": "4f0c1dd4-77b2-4d34-983c-6fddd82b4378", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            elite_positions = np.argsort(personal_best_scores)[:self.swarm_size//2]  # Added elite selection\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with dynamic mutation\n            mutation_rate = 0.1 * (1 - np.std(personal_best_scores) / np.mean(personal_best_scores))  # Dynamic mutation rate\n            for i in elite_positions:  # Modified to use elite positions\n                candidate = positions[i] + np.random.normal(0, mutation_rate * self.temperature / 1000, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance local search by introducing a dynamic mutation strategy based on swarm diversity and adaptive mutation rate in the Simulated Annealing stage to improve convergence speed and solution quality.", "configspace": "", "generation": 18, "fitness": 0.85670212559458, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.035. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "99390eab-b5b3-4e1c-a151-012f0bad224d", "metadata": {"aucs": [0.8355965569630603, 0.8286052307776127, 0.9059045890430673], "final_y": [0.13322250849982153, 0.12821969329612992, 0.11043344103425068]}, "mutation_prompt": null}
{"id": "a7d68d0b-9d19-48c9-bc21-5482775115cd", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            self.c1 *= 0.99  # Decay cognitive parameter\n            elite_positions = np.argsort(personal_best_scores)[:self.swarm_size//2]  # Added elite selection\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                chaotic_factor = 0.5 * np.sin(evaluations)  # Chaotic perturbation\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]) +\n                                 chaotic_factor)\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in elite_positions:  # Modified to use elite positions\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance global search by introducing a chaotic perturbation to velocity, aiding in avoiding local optima.", "configspace": "", "generation": 18, "fitness": 0.8671925518191893, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.023. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "bb65f752-c1ac-447d-8eca-2c628120bd86", "metadata": {"aucs": [0.8859673618307509, 0.8349935452040608, 0.8806167484227564], "final_y": [0.11503804657548866, 0.12067831004828034, 0.11288148800520703]}, "mutation_prompt": null}
{"id": "436ad727-68a8-4d64-84e9-b2d4c3eb68cc", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n        self.elite_fraction = 0.2  # Fraction of elite particles\n        self.mutation_rate = 0.1  # Initial mutation rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n        elite_count = int(self.swarm_size * self.elite_fraction)\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            self.c1 = max(0.5, 1.5 * (1 - (evaluations / self.budget) ** 2))  # Non-linear cognitive parameter reduction\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with elite learning and random perturbation\n            elite_indices = np.argsort(personal_best_scores)[:elite_count]\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                elite_position = personal_best_positions[np.random.choice(elite_indices)]\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (elite_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, self.mutation_rate * (1 - evaluations / self.budget), self.dim)\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive mutation\n            self.mutation_rate = 0.05 + 0.95 * (evaluations / self.budget)  # Adjust mutation rate\n            elite_count = int(self.swarm_size * self.elite_fraction * (1.2 + evaluations / (2 * self.budget)))  # Adjusted dynamic elite fraction\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, self.mutation_rate, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Further enhance the exploration-exploitation balance by adjusting the elite fraction at a more rapid rate.", "configspace": "", "generation": 18, "fitness": 0.8555227205501943, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.007. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "e6004bf1-410d-45fc-a807-84a91ddc85cb", "metadata": {"aucs": [0.8620862532889311, 0.8460937833660942, 0.8583881249955578], "final_y": [0.11533788515861043, 0.12209904732070764, 0.11532093493658058]}, "mutation_prompt": null}
{"id": "98ad5e88-1c8d-4320-9b59-1dcf8f7f53e5", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            self.c1 *= 0.99  # Decay cognitive parameter\n            self.c2 *= 0.98  # Non-linear decay for the social parameter\n            elite_positions = np.argsort(personal_best_scores)[:self.swarm_size//2]  # Added elite selection\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in elite_positions:  # Modified to use elite positions\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Refine the exploration-exploitation balance by introducing a non-linear decay for the social parameter.", "configspace": "", "generation": 19, "fitness": 0.8402603708750661, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.019. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "bb65f752-c1ac-447d-8eca-2c628120bd86", "metadata": {"aucs": [0.8379518200826386, 0.8649014494876079, 0.8179278430549518], "final_y": [0.13788938361051817, 0.12871990475251793, 0.14960591427853298]}, "mutation_prompt": null}
{"id": "60096af8-ec1d-421c-9fdb-7e55a4c463ed", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 35  # Increased swarm size\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive cooling factor\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / (self.temperature * (1 + evaluations/self.budget))):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down temperature with adaptive rate\n            self.temperature *= (self.alpha ** (1 + evaluations / self.budget))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Introduce a slight increase in swarm size to enhance diversity in exploration phase.", "configspace": "", "generation": 19, "fitness": 0.8556928767922504, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.016. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "be729fb3-4a74-4b75-8967-cdc5916d7517", "metadata": {"aucs": [0.8383848127809704, 0.8507993434795251, 0.8778944741162554], "final_y": [0.12994535883998892, 0.13240394587301219, 0.12288986574525695]}, "mutation_prompt": null}
{"id": "601448a5-4559-4387-a306-ac219f0ba849", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            self.c1 *= 0.99 * (1 - evaluations / self.budget)**0.5  # Non-linear decay cognitive parameter\n            elite_positions = np.argsort(personal_best_scores)[:self.swarm_size//2]  # Added elite selection\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget)**2, self.dim)  # Enhanced dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing\n            for i in elite_positions:  # Modified to use elite positions\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / self.temperature):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down the temperature non-linearly\n            self.temperature *= (self.alpha ** 2)\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Implement a non-linear cognitive parameter decay and enhanced dynamic perturbation to improve exploration and exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.8432504305721115, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.843 with standard deviation 0.012. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "bb65f752-c1ac-447d-8eca-2c628120bd86", "metadata": {"aucs": [0.8307618327182361, 0.859855050278778, 0.8391344087193201], "final_y": [0.14108525683100182, 0.1297145237580034, 0.13367372121159926]}, "mutation_prompt": null}
{"id": "b7dfc047-ed7b-47f1-866b-5c5f53c0a7f8", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            self.c1 = 1.5 + 0.5 * (evaluations / self.budget)  # Dynamic cognitive parameter\n            self.c2 = 1.5 - 0.5 * (evaluations / self.budget)  # Dynamic social parameter\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive cooling factor\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / (self.temperature * (1 + evaluations/self.budget))):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Cool down temperature with adaptive rate\n            self.temperature *= (self.alpha ** (1 + evaluations / self.budget))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Refine exploration and exploitation by introducing a dynamic adjustment of cognitive and social parameters based on the evaluation ratio.", "configspace": "", "generation": 19, "fitness": 0.835943334809758, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.836 with standard deviation 0.015. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "be729fb3-4a74-4b75-8967-cdc5916d7517", "metadata": {"aucs": [0.8571651853304312, 0.8293597372882497, 0.8213050818105931], "final_y": [0.12397615393509831, 0.14103416727109797, 0.14989862070637772]}, "mutation_prompt": null}
{"id": "2e720dc3-7b32-46d3-940d-94bbc5a769ca", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_size = 30\n        self.w = 0.5  # inertia weight\n        self.c1 = 1.5  # cognitive parameter\n        self.c2 = 1.5  # social parameter\n        self.temperature = 1000\n        self.alpha = 0.95  # Adjusted cooling rate\n        self.restart_threshold = 0.05  # New parameter for dynamic restart\n        self.neighborhood_factor = 0.2  # New parameter for local search\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        v_max = (ub - lb) * 0.1\n        \n        # Initialize the swarm\n        positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n        velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.full(self.swarm_size, np.inf)\n        \n        global_best_position = None\n        global_best_score = np.inf\n\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            self.swarm_size = max(10, int(30 * (1 - evaluations / self.budget)))  # Adaptive swarm size\n            self.w = max(0.1, 0.5 * (1 - evaluations / self.budget))  # Dynamic inertia weight\n            for i in range(self.swarm_size):\n                score = func(positions[i])\n                evaluations += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = positions[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = positions[i]\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Update velocities and positions with random perturbation\n            for i in range(self.swarm_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.w * velocities[i] +\n                                 self.c1 * r1 * (personal_best_positions[i] - positions[i]) +\n                                 self.c2 * r2 * (global_best_position - positions[i]))\n                velocities[i] = np.clip(velocities[i], -v_max, v_max)\n                positions[i] += velocities[i]\n                positions[i] += np.random.normal(0, 0.05 * (1 - evaluations / self.budget), self.dim)  # Dynamic perturbation\n                positions[i] = np.clip(positions[i], lb, ub)\n\n            # Apply Simulated Annealing with adaptive cooling factor\n            for i in range(self.swarm_size):\n                candidate = positions[i] + np.random.normal(0, self.neighborhood_factor * (ub - lb), self.dim)  # Neighborhood search\n                candidate = np.clip(candidate, lb, ub)\n                candidate_score = func(candidate)\n                evaluations += 1\n\n                if candidate_score < personal_best_scores[i] or \\\n                   np.random.rand() < np.exp(-(candidate_score - personal_best_scores[i]) / (self.temperature * (1 + evaluations/self.budget))):\n                    personal_best_positions[i] = candidate\n                    personal_best_scores[i] = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n            # Strategic restart mechanism\n            if np.min(personal_best_scores) < global_best_score * (1 + self.restart_threshold):\n                positions = np.random.uniform(lb, ub, (self.swarm_size, self.dim))\n                velocities = np.random.uniform(-v_max, v_max, (self.swarm_size, self.dim))\n                \n            # Cool down temperature with adaptive rate\n            self.temperature *= (self.alpha ** (1 + evaluations / self.budget))\n\n        return global_best_position", "name": "HybridPSOSA", "description": "Enhance convergence by introducing a strategic restart mechanism and a dynamic neighborhood search.", "configspace": "", "generation": 19, "fitness": 0.8436321913317798, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.009. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "be729fb3-4a74-4b75-8967-cdc5916d7517", "metadata": {"aucs": [0.8311709798866094, 0.8502576692759378, 0.8494679248327924], "final_y": [0.1326825912424524, 0.12989830150484594, 0.13058951106371486]}, "mutation_prompt": null}
