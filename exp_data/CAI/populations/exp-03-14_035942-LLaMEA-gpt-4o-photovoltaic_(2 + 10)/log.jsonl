{"id": "4849d797-ad83-4a09-89e0-154031e4a3b4", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "A novel metaheuristic algorithm inspired by cooperative swarm intelligence, dynamically balancing exploration and exploitation through adaptive leader-follower interactions with context-based adjustments.", "configspace": "", "generation": 0, "fitness": 0.8522327737080535, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.015. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8506078691939295, 0.8350117172011262, 0.8710787347291048], "final_y": [0.12275689040137594, 0.13323221562301968, 0.11964413430520704]}, "mutation_prompt": null}
{"id": "6c1b9efd-3d31-4e9a-ae86-42bfbb8f4f6b", "solution": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.w = 0.7  # inertia weight\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization (PSO) Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + vel, lb, ub)\n\n            # Differential Evolution (DE) Update\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.mutation_factor * (pop[b] - pop[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HPSO_ADE", "description": "A hybrid Particle Swarm Optimization with Adaptive Differential Evolution (HPSO-ADE) that combines the explorative capabilities of PSO with the exploitative strengths of ADE to efficiently navigate complex search spaces.", "configspace": "", "generation": 0, "fitness": 0.8040539253934189, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.010. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8129925401395626, 0.8095183648725242, 0.78965087116817], "final_y": [0.14550114297461036, 0.15019042800729143, 0.15053901369322342]}, "mutation_prompt": null}
{"id": "053da374-7e9e-4a9e-aad0-4fb71b2b85d7", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n        stagnation_counter = 0\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n\n                if eval_count >= self.budget:\n                    break\n            \n            if stagnation_counter > 50:  # Add a random perturbation if stagnation detected\n                positions = positions + np.random.normal(0, 0.1, positions.shape)\n                stagnation_counter = 0\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhancing diversity by introducing random perturbations in particle positions when stagnation is detected.", "configspace": "", "generation": 1, "fitness": 0.8653643628576431, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.016. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "4849d797-ad83-4a09-89e0-154031e4a3b4", "metadata": {"aucs": [0.8577510686351091, 0.888160318023044, 0.8501817019147759], "final_y": [0.12385248340052946, 0.12169893263461229, 0.1258317489860291]}, "mutation_prompt": null}
{"id": "f816ed24-6a3a-49fb-9f4f-52e9f0967f09", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced Adaptive Swarm Optimizer with improved exploration-exploitation balance through dynamic learning factor adjustments.", "configspace": "", "generation": 1, "fitness": 0.8735811622259032, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.020. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "4849d797-ad83-4a09-89e0-154031e4a3b4", "metadata": {"aucs": [0.8997170027241813, 0.868781471506583, 0.8522450124469454], "final_y": [0.11561669453267653, 0.12183644326726317, 0.12912422468611096]}, "mutation_prompt": null}
{"id": "a15b1251-5198-488f-a135-ba7163cb991a", "solution": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.w = 0.7  # inertia weight\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization (PSO) Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop) + 0.1 * np.sign(global_best - pop)  # Enhanced Velocity Update\n            pop = np.clip(pop + vel, lb, ub)\n\n            # Differential Evolution (DE) Update\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.mutation_factor * (pop[b] - pop[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HPSO_ADE", "description": "HPSO_ADE with Enhanced Velocity Update for Improved Convergence in Complex Search Spaces.", "configspace": "", "generation": 1, "fitness": 0.7914335117238512, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.005. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "6c1b9efd-3d31-4e9a-ae86-42bfbb8f4f6b", "metadata": {"aucs": [0.7954620397853006, 0.7945901820562783, 0.7842483133299748], "final_y": [0.1447213539198131, 0.1601017669387199, 0.1567734684240618]}, "mutation_prompt": null}
{"id": "da46af32-cfe2-43df-854d-7bfae8b26221", "solution": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.w = 0.9  # inertia weight\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            w_dynamic = 0.4 + (0.9 - 0.4) * (eval_count / self.budget)\n            vel = w_dynamic * vel + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n\n            pop = np.clip(pop + vel, lb, ub)\n\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.mutation_factor * (pop[b] - pop[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n            elite_idx = np.argmin(personal_best_scores)\n            pop = np.vstack((pop, personal_best[elite_idx]))\n            pop = pop[np.random.choice(pop.shape[0], self.population_size, replace=False)]\n\n        return global_best", "name": "HPSO_ADE", "description": "A refined version of HPSO-ADE that enhances exploration-exploitation balance by introducing dynamic parameter adaption and an elitism strategy, improving convergence speed and solution quality.", "configspace": "", "generation": 1, "fitness": 0.7765529377987898, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.777 with standard deviation 0.015. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "6c1b9efd-3d31-4e9a-ae86-42bfbb8f4f6b", "metadata": {"aucs": [0.7574375019572549, 0.7945901820562783, 0.777631129382836], "final_y": [0.17142113339121956, 0.1601017669387199, 0.166074932944829]}, "mutation_prompt": null}
{"id": "2f94a708-6cc4-47e6-8c34-b12a43b3c93e", "solution": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.w = 0.7  # inertia weight\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization (PSO) Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.4 + 0.3 * (self.budget - eval_count) / self.budget # Adaptive inertia weight\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + vel, lb, ub)\n\n            # Differential Evolution (DE) Update\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.mutation_factor * (pop[b] - pop[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HPSO_ADE", "description": "Enhanced hybrid PSO and ADE with adaptive inertia weight for improved convergence efficiency.", "configspace": "", "generation": 1, "fitness": 0.7848518348763983, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.014. And the mean value of best solutions found was 0.161 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "6c1b9efd-3d31-4e9a-ae86-42bfbb8f4f6b", "metadata": {"aucs": [0.7949365724071639, 0.7945901820562783, 0.7650287501657527], "final_y": [0.15270361934882548, 0.1601017669387199, 0.16908271329858382]}, "mutation_prompt": null}
{"id": "d2fa32be-8435-41d2-94ab-d5a822aae25e", "solution": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.w = 0.7  # inertia weight\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Adjust inertia weight dynamically\n            self.w = 0.9 - (0.5 * eval_count / self.budget)\n            \n            # Particle Swarm Optimization (PSO) Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + vel, lb, ub)\n\n            # Differential Evolution (DE) Update\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Adjust mutation factor dynamically\n                self.mutation_factor = 0.5 + 0.3 * np.random.rand()\n                mutant = np.clip(pop[a] + self.mutation_factor * (pop[b] - pop[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HPSO_ADE", "description": "Enhanced Particle Swarm Optimization with Adaptive Differential Evolution incorporating dynamic inertia and mutation factor adjustments for improved convergence.  ", "configspace": "", "generation": 1, "fitness": 0.8062840800645515, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.026. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "6c1b9efd-3d31-4e9a-ae86-42bfbb8f4f6b", "metadata": {"aucs": [0.8101124024793629, 0.8354598997068297, 0.773279938007462], "final_y": [0.1384865801998848, 0.1449873248587492, 0.15528795006564022]}, "mutation_prompt": null}
{"id": "eadceb6d-aa91-46d7-8ad2-1b62564c32f2", "solution": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.w = 0.7  # inertia weight\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization (PSO) Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.9 - (0.5 * eval_count / self.budget)  # Dynamic inertia weight\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + vel, lb, ub)\n\n            # Differential Evolution (DE) Update\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.mutation_factor * (pop[b] - pop[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HPSO_ADE", "description": "Improved HPSO-ADE by dynamically adjusting the inertia weight for enhanced convergence speed and solution diversity.", "configspace": "", "generation": 1, "fitness": 0.7833810510383717, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.009. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "6c1b9efd-3d31-4e9a-ae86-42bfbb8f4f6b", "metadata": {"aucs": [0.7827634551555983, 0.7950893334145877, 0.7722903645449293], "final_y": [0.15189944555721002, 0.1599038150112625, 0.1441692933468608]}, "mutation_prompt": null}
{"id": "a105db9a-2554-48e4-bf35-3eeb2778df50", "solution": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.w = 0.7  # inertia weight\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization (PSO) Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.9 - (0.5 * eval_count / self.budget)  # Dynamic inertia\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + vel, lb, ub)\n\n            # Differential Evolution (DE) Update\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.mutation_factor * (pop[b] - pop[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HPSO_ADE", "description": "Enhanced hybrid PSO and ADE with dynamic inertia weight adjustment to better balance exploration and exploitation.", "configspace": "", "generation": 1, "fitness": 0.7817465331786148, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.014. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "6c1b9efd-3d31-4e9a-ae86-42bfbb8f4f6b", "metadata": {"aucs": [0.7891340666646429, 0.7945901820562783, 0.7615153508149228], "final_y": [0.15013760029562362, 0.1601017669387199, 0.1599527315930036]}, "mutation_prompt": null}
{"id": "7901e75c-9b1f-466a-ac87-d0fb47dfc011", "solution": "import numpy as np\n\nclass HPSO_ADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 50\n        self.c1 = 2.0  # cognitive coefficient\n        self.c2 = 2.0  # social coefficient\n        self.w = 0.7  # inertia weight\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        vel = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best = pop.copy()\n        personal_best_scores = np.array([func(ind) for ind in personal_best])\n        global_best = personal_best[np.argmin(personal_best_scores)]\n        global_best_score = min(personal_best_scores)\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            # Particle Swarm Optimization (PSO) Update\n            r1, r2 = np.random.rand(self.population_size, self.dim), np.random.rand(self.population_size, self.dim)\n            self.w = 0.9  # dynamically updated inertia weight for improved exploration\n            vel = self.w * vel + self.c1 * r1 * (personal_best - pop) + self.c2 * r2 * (global_best - pop)\n            pop = np.clip(pop + vel, lb, ub)\n\n            # Differential Evolution (DE) Update\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(pop[a] + self.mutation_factor * (pop[b] - pop[c]), lb, ub)\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                trial = np.where(cross_points, mutant, pop[i])\n                trial_score = func(trial)\n                eval_count += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best[i] = trial\n                    personal_best_scores[i] = trial_score\n\n                    if trial_score < global_best_score:\n                        global_best = trial\n                        global_best_score = trial_score\n\n        return global_best", "name": "HPSO_ADE", "description": "Enhance the exploration capabilities by increasing the inertia weight dynamically to improve convergence.", "configspace": "", "generation": 1, "fitness": 0.8019322858938219, "feedback": "The algorithm HPSO_ADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.007. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "6c1b9efd-3d31-4e9a-ae86-42bfbb8f4f6b", "metadata": {"aucs": [0.8005863625043044, 0.7945901820562783, 0.8106203131208829], "final_y": [0.146342663358359, 0.1601017669387199, 0.15299892339833754]}, "mutation_prompt": null}
{"id": "b9b052c8-b150-437a-98e5-0c61ade60bd2", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.4 + 0.1 * np.random.rand()  # Enhanced adaptive inertia weight\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced Adaptive Inertia Weight Mechanism in AdaptiveSwarmOptimizer for improved convergence in dynamic search spaces.", "configspace": "", "generation": 1, "fitness": 0.8335766282909555, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.031. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "4849d797-ad83-4a09-89e0-154031e4a3b4", "metadata": {"aucs": [0.7908772401173254, 0.8655146694245649, 0.8443379753309761], "final_y": [0.15026745057426238, 0.12352009416760013, 0.13531430725352322]}, "mutation_prompt": null}
{"id": "64801db2-504d-44ac-be69-e222a603222f", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n            num_particles = min(100, num_particles + 1)  # Increment particle count\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a dynamic particle count by adaptively adjusting the number of particles based on convergence speed.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "f816ed24-6a3a-49fb-9f4f-52e9f0967f09", "metadata": {}, "mutation_prompt": null}
{"id": "09368f22-8bd3-44e0-a355-854e193feebb", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n        stagnation_counter = 0\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n\n                if eval_count >= self.budget:\n                    break\n            \n            if stagnation_counter > 50:  # Add a random perturbation if stagnation detected\n                velocities *= 1.5  # Boost velocity magnitude\n                stagnation_counter = 0\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introducing periodic boosting by amplifying velocity magnitude when exploration stagnates to enhance exploration.", "configspace": "", "generation": 2, "fitness": 0.8667488107431846, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.024. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "053da374-7e9e-4a9e-aad0-4fb71b2b85d7", "metadata": {"aucs": [0.8809741935107657, 0.8329873285296263, 0.8862849101891617], "final_y": [0.11639296321851145, 0.13969430180025022, 0.11789882864025292]}, "mutation_prompt": null}
{"id": "6b2f5db1-7d18-4a85-a237-338c7a8bc905", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2\n            c1, c2 = np.random.uniform(0.5, 2.5, 2)  # Time-varying acceleration coefficients\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introducing a time-varying acceleration coefficient to enhance convergence speed and solution quality.", "configspace": "", "generation": 2, "fitness": 0.8619171248652137, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.024. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "f816ed24-6a3a-49fb-9f4f-52e9f0967f09", "metadata": {"aucs": [0.8439954645040548, 0.8454067760422208, 0.8963491340493651], "final_y": [0.12664255312685158, 0.13162379645523248, 0.10984097590745712]}, "mutation_prompt": null}
{"id": "0a7df8ac-f634-43df-943a-9f528a4620b8", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.4 + np.random.rand() / 2  # Slightly adjusted inertia weight\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.4 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.4, 2.1, 2)  # Modified learning factors range\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced exploration-exploitation balance by modifying dynamic learning factor range and slightly adjusting inertia weight.", "configspace": "", "generation": 2, "fitness": 0.849987892541365, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.015. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "f816ed24-6a3a-49fb-9f4f-52e9f0967f09", "metadata": {"aucs": [0.853662115928123, 0.8306014360077679, 0.8657001256882043], "final_y": [0.11752053857517486, 0.13788145519361905, 0.12089510029754658]}, "mutation_prompt": null}
{"id": "72581de6-1fd8-4276-8651-bd6962f539b5", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            if np.random.rand() < 0.05:  # Add mutation mechanism\n                positions[np.random.randint(0, num_particles)] = np.random.uniform(lb, ub, self.dim)\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Incorporate a mutation mechanism by randomly resetting some particle positions to enhance exploration.", "configspace": "", "generation": 2, "fitness": 0.8692037432751016, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.029. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "f816ed24-6a3a-49fb-9f4f-52e9f0967f09", "metadata": {"aucs": [0.8769244237828243, 0.8309200413041264, 0.8997667647383538], "final_y": [0.12040133979125056, 0.13367949624574016, 0.1107107599544821]}, "mutation_prompt": null}
{"id": "885add02-efd1-4d52-beed-83c5881af9ae", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n        stagnation_counter = 0\n        \n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] *= 0.9  # Adaptive velocity scaling factor\n                velocities[i] += c1 * r1 * (personal_best[i] - positions[i])\n                velocities[i] += c2 * r2 * (global_best - positions[i])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n\n                if eval_count >= self.budget:\n                    break\n            \n            if stagnation_counter > 50:\n                perturbation_intensity = np.random.uniform(0.05, 0.2)\n                positions += np.random.normal(0, perturbation_intensity, positions.shape)\n                stagnation_counter = 0\n            \n            w = 0.5 + np.random.rand() / 2\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Integrating adaptive velocity scaling and dynamic perturbation intensity to enhance swarm diversity while maintaining convergence speed.", "configspace": "", "generation": 2, "fitness": 0.8653182343111054, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.016. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "053da374-7e9e-4a9e-aad0-4fb71b2b85d7", "metadata": {"aucs": [0.8673448230741401, 0.8446984220146405, 0.8839114578445357], "final_y": [0.12489009421063146, 0.13132614958051725, 0.11210783995934126]}, "mutation_prompt": null}
{"id": "441b6785-55de-4545-84c1-b48289ecebfd", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = np.random.uniform(lb, ub, (num_particles, self.dim))  # Change 1\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Change 2: Add a dynamic velocity scaling factor\n                velocity_scale = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n                velocities[i] = velocity_scale * (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced Adaptive Swarm with stochastic personal-best initialization and dynamic velocity scaling for improved exploration.", "configspace": "", "generation": 2, "fitness": 0.8786925609009444, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.010. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f816ed24-6a3a-49fb-9f4f-52e9f0967f09", "metadata": {"aucs": [0.8718880840442905, 0.8712464673310734, 0.8929431313274692], "final_y": [0.11933675316264802, 0.12390811155338821, 0.11631875651355639]}, "mutation_prompt": null}
{"id": "a1409176-615a-4a26-943c-8d3eba6c8a68", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n        decay = 0.99  # Inertia weight decay factor\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = (0.5 + np.random.rand() / 2) * decay  # Apply decay to adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Optimized the velocity update equation by introducing a decay factor to inertia weight for enhancing convergence speed.", "configspace": "", "generation": 2, "fitness": 0.8611995674029848, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.012. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f816ed24-6a3a-49fb-9f4f-52e9f0967f09", "metadata": {"aucs": [0.864326986625391, 0.8453163370475644, 0.873955378535999], "final_y": [0.12618554213478173, 0.13081553742876495, 0.12025487764146703]}, "mutation_prompt": null}
{"id": "d40944dd-77d8-4795-bea4-1d60e7cee5e4", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n        stagnation_counter = 0\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n\n                if eval_count >= self.budget:\n                    break\n            \n            if stagnation_counter > 50:  # Add a dynamic perturbation if stagnation detected\n                perturbation_scale = 0.1 * (1 - (eval_count / self.budget) ** 2)\n                positions = positions + np.random.normal(0, perturbation_scale, positions.shape)\n                stagnation_counter = 0\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introducing a dynamic perturbation mechanism based on a quadratic cooling schedule to enhance exploration and convergence in the swarm optimizer.", "configspace": "", "generation": 2, "fitness": 0.8596250842381715, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.011. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "053da374-7e9e-4a9e-aad0-4fb71b2b85d7", "metadata": {"aucs": [0.8511210061998292, 0.8526346552289218, 0.8751195912857637], "final_y": [0.12296565962833417, 0.12714603506723854, 0.11097659087407108]}, "mutation_prompt": null}
{"id": "bb25d459-b1e6-4419-a618-439f37a638e6", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 30 + np.random.randint(20)  # Dynamic particle count\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i] + np.random.normal(0, 0.01, self.dim), lb, ub)  # Adaptive perturbation\n\n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a dynamic particle count and adaptive perturbation to enhance exploration and exploitation balance in the swarm.", "configspace": "", "generation": 2, "fitness": 0.8570214430328057, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.017. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "f816ed24-6a3a-49fb-9f4f-52e9f0967f09", "metadata": {"aucs": [0.8757276191112257, 0.8346507228282455, 0.8606859871589462], "final_y": [0.12019012798847029, 0.13969316262067277, 0.1258532767020698]}, "mutation_prompt": null}
{"id": "8964e35b-bfef-4aad-8225-76414ec88ac9", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def levy_flight(self, dim):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, dim)\n        v = np.random.normal(0, 1, dim)\n        step = u / abs(v)**(1 / beta)\n        return 0.01 * step\n\n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                if np.random.rand() < 0.1:\n                    positions[i] += self.levy_flight(self.dim)\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.4 + np.random.rand() / 3  # Refined adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.1, 2)  # Slightly adjusted dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Hybrid Swarm Optimizer with Levy flights for intensified global exploration and adaptive convergence control.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "f816ed24-6a3a-49fb-9f4f-52e9f0967f09", "metadata": {}, "mutation_prompt": null}
{"id": "43d11a96-9b10-4e5a-861c-3c012b94dedb", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = np.random.uniform(lb, ub, (num_particles, self.dim))  \n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.9  # Initialize inertia weight\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                neighborhood_best = personal_best[np.random.choice(num_particles)]  # Use neighborhood best\n                velocity_scale = 0.5 + np.random.rand() * 0.5\n                velocities[i] = velocity_scale * (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (neighborhood_best - positions[i]))  # Use neighborhood best\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = max(0.4, w * 0.99)  # Decay inertia weight over time\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)\n\n        return global_best", "name": "EnhancedAdaptiveSwarmOptimizer", "description": "Enhanced Adaptive Swarm with stochastic neighborhood influence and inertia decay for improved convergence precision.", "configspace": "", "generation": 3, "fitness": 0.8267752027295053, "feedback": "The algorithm EnhancedAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.018. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "441b6785-55de-4545-84c1-b48289ecebfd", "metadata": {"aucs": [0.813464318071828, 0.8144742140706447, 0.8523870760460436], "final_y": [0.12627644106907765, 0.13685364461189153, 0.13380191274648667]}, "mutation_prompt": null}
{"id": "d2782f48-e378-4d65-ac0d-995b5ac499f2", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = np.random.uniform(lb, ub, (num_particles, self.dim))  # Change 1\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Change 2: Add a dynamic velocity scaling factor\n                velocity_scale = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n                velocities[i] = velocity_scale * (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            if eval_count % (self.budget // 5) == 0:  # Periodic positional reshuffling\n                positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced Adaptive Swarm with stochastic diversification through periodic positional reshuffling for improved exploration.", "configspace": "", "generation": 3, "fitness": 0.8799995165524478, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.023. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "441b6785-55de-4545-84c1-b48289ecebfd", "metadata": {"aucs": [0.8473783655175021, 0.8914053341064812, 0.90121485003336], "final_y": [0.12957115457158574, 0.11726056108227889, 0.10980308215899293]}, "mutation_prompt": null}
{"id": "5fc0b0cd-9f8c-4162-abb9-1174e6705d27", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n\n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            elite_index = np.argmin(personal_best_values)  # Elite learning\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                if i == elite_index:\n                    velocities[i] *= 1.1  # Boost elite particle\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n            if eval_count % (self.budget // 10) == 0:  # Adaptive population size\n                num_particles = max(10, num_particles - 1)\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced Adaptive Swarm Optimizer with improved convergence through adaptive population size and elite learning mechanisms.", "configspace": "", "generation": 3, "fitness": 0.8670510932440326, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.034. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "f816ed24-6a3a-49fb-9f4f-52e9f0967f09", "metadata": {"aucs": [0.8200919476134833, 0.8980357121819947, 0.8830256199366202], "final_y": [0.13583191870928857, 0.11309501371829322, 0.11694278856842755]}, "mutation_prompt": null}
{"id": "2261031d-dabf-4714-9cfd-4700ecc9ff20", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n            # Re-evaluate personal best diversity\n            if np.std(personal_best_values) < 0.01:\n                personal_best_values = np.array([func(pos) for pos in personal_best])\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Adaptive Swarm Optimizer with enhanced exploitation through personal-best diversity re-evaluation.", "configspace": "", "generation": 3, "fitness": 0.8756443423670183, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.028. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "f816ed24-6a3a-49fb-9f4f-52e9f0967f09", "metadata": {"aucs": [0.8386815248003386, 0.8820070033296337, 0.9062444989710828], "final_y": [0.12767672319697965, 0.11726677946591801, 0.10984542204330294]}, "mutation_prompt": null}
{"id": "3e98f05b-a764-4770-b83d-ce8d6077b12a", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n\n        w_max, w_min = 0.9, 0.4\n        c1, c2 = 2.0, 2.0\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            w = w_max - ((w_max - w_min) * (eval_count / self.budget))  # Nonlinear inertia weight\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]) +\n                                 np.random.randn(self.dim) * 0.05)  # Added noise for exploration\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n\n            c1, c2 = np.random.uniform(1.5, 2.5, 2)  # Adjusted dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced Adaptive Swarm Optimizer with a nonlinear dynamic adaptive velocity control and neighborhood-based local search for improved convergence.", "configspace": "", "generation": 3, "fitness": 0.8798803583314333, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.040. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "f816ed24-6a3a-49fb-9f4f-52e9f0967f09", "metadata": {"aucs": [0.8228147203039704, 0.9046598956076771, 0.9121664590826523], "final_y": [0.1302198416959267, 0.10979382235711477, 0.11006003100927475]}, "mutation_prompt": null}
{"id": "f2ba7752-7fd2-4f04-a7b1-9e0839f3c115", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = np.random.uniform(lb, ub, (num_particles, self.dim))\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n        velocity_limit = (ub - lb) * 0.1  # Change 1: Adaptive velocity limit\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocity_scale = 0.5 + np.random.rand() * 0.5\n                velocities[i] = np.clip(velocity_scale * (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i])),\n                                 -velocity_limit, velocity_limit)  # Change 2: Apply velocity limit\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n                \n                # Change 3: Introduce elitism by preserving the best position found\n                positions[np.argmax(personal_best_values)] = global_best.copy()\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Incorporating adaptive velocity limits and elitism to further enhance exploration and convergence capabilities.", "configspace": "", "generation": 3, "fitness": 0.8856763988672971, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.005. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "441b6785-55de-4545-84c1-b48289ecebfd", "metadata": {"aucs": [0.8787347073252278, 0.8888866093734084, 0.889407879903255], "final_y": [0.11731257799900363, 0.11796662194014196, 0.11690706331365275]}, "mutation_prompt": null}
{"id": "0fe5d9be-9e46-43bb-9be1-218773a0a40a", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = np.random.uniform(lb, ub, (num_particles, self.dim))  # Change 1\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Change 2: Add a dynamic velocity scaling factor\n                velocity_scale = 0.5 + np.random.rand() * 0.5  # Dynamic scaling factor\n                velocities[i] = velocity_scale * (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n                \n                # Single line Change: Dynamically update the global best based on neighborhood\n                neighborhood_best_index = np.argmin(personal_best_values[max(0, i-2):min(num_particles, i+3)])\n                global_best = personal_best[max(0, i-2) + neighborhood_best_index] \n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced Adaptive Swarm with stochastic personal-best initialization, dynamic velocity scaling, and dynamic neighborhood-based global best selection for improved exploration.", "configspace": "", "generation": 3, "fitness": 0.8766594582968305, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.029. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "441b6785-55de-4545-84c1-b48289ecebfd", "metadata": {"aucs": [0.838240931456827, 0.8848637811341789, 0.9068736622994854], "final_y": [0.12068445434643815, 0.11796700886667377, 0.11006746705242287]}, "mutation_prompt": null}
{"id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce dynamic neighborhood-based local search to particles for enhanced local optimization without exceeding the 2.0% change limit.", "configspace": "", "generation": 3, "fitness": 0.8922906917804229, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.005. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "f816ed24-6a3a-49fb-9f4f-52e9f0967f09", "metadata": {"aucs": [0.8878622467129569, 0.9000268921998749, 0.8889829364284371], "final_y": [0.1212216569117941, 0.10991069795439046, 0.1171231279248709]}, "mutation_prompt": null}
{"id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduced adaptive dynamic population size adjustment for improved adaptability and convergence in the swarm optimization process.", "configspace": "", "generation": 3, "fitness": 0.9005665971857351, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.015. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "f816ed24-6a3a-49fb-9f4f-52e9f0967f09", "metadata": {"aucs": [0.8798319807966626, 0.9136321514837128, 0.9082356592768301], "final_y": [0.11835153652204633, 0.10977332945741936, 0.10967486178626906]}, "mutation_prompt": null}
{"id": "924cdff2-4dd2-4b81-a4a7-74ad6219f65a", "solution": "import numpy as np\nimport math\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = lb + (ub - lb) * np.array([math.sin(i) for i in range(num_particles * self.dim)]).reshape((num_particles, self.dim))\n        velocities = lb + (ub - lb) * np.array([math.cos(i) for i in range(num_particles * self.dim)]).reshape((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  \n            c1, c2 = np.random.uniform(1.3, 2.0, 2)\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced exploration by introducing chaotic maps to initialize positions and velocities for diverse solutions.", "configspace": "", "generation": 4, "fitness": 0.8592144433146368, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.032. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8157832543245745, 0.87169299129636, 0.8901670843229761], "final_y": [0.12520427418911273, 0.1221741635930722, 0.11755765133596996]}, "mutation_prompt": null}
{"id": "aa516599-9548-42ea-8ddf-09c937394ac1", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Change: Adaptive velocity scaling\n                velocities[i] *= 0.5 + 0.5 * (global_best_value - personal_best_values[i]) / (global_best_value + 1e-9)\n                velocities[i] += (c1 * r1 * (personal_best[i] - positions[i]) +\n                                  c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Implemented an adaptive velocity scaling mechanism based on convergence progress to enhance exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.8526565217189326, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.028. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8913430150678882, 0.8250830035017639, 0.8415435465871459], "final_y": [0.11489023337457593, 0.14552096475156973, 0.13287189080105932]}, "mutation_prompt": null}
{"id": "63c35193-5c34-49b2-88f6-ff7055a83117", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.4 + np.random.rand() / 2  # Slight adjustment in adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Incorporated a strategic exploration-exploitation balance by slightly adjusting the adaptive inertia weight calculation to enhance convergence precision.", "configspace": "", "generation": 4, "fitness": 0.8388046094230663, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.009. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8384461085302435, 0.8277898046903347, 0.8501779150486211], "final_y": [0.11855101384523636, 0.14068690323210276, 0.12924465040947453]}, "mutation_prompt": null}
{"id": "39275196-e327-4711-a5b4-8552edf1130d", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.9  # Adaptive inertia weight decay\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index] + np.random.randn(self.dim) * 0.01)  # Stochastic local search\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w *= 0.99  # Inertia weight decay\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhance convergence by introducing an inertia weight decay and a stochastic local search step.", "configspace": "", "generation": 4, "fitness": 0.8522351311563235, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.013. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8463338771180419, 0.840257697784963, 0.8701138185659661], "final_y": [0.1306434189420015, 0.12672851892312875, 0.12451687997579852]}, "mutation_prompt": null}
{"id": "5f39119f-8c41-4096-bc42-68e96edd9bc4", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n            # Enhanced global best update (code change)\n            if personal_best_values[global_best_index] > np.min(personal_best_values):\n                global_best_index = np.argmin(personal_best_values)\n                global_best = personal_best[global_best_index].copy()\n                global_best_value = personal_best_values[global_best_index]\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced global best update logic to refine convergence precision by considering a secondary criterion for improved local exploitation.", "configspace": "", "generation": 4, "fitness": 0.8664642521755402, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.007. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8700976326820367, 0.8573334680191007, 0.8719616558254837], "final_y": [0.11887439884883633, 0.13147742942724838, 0.12449754163052063]}, "mutation_prompt": null}
{"id": "c3830308-b3c2-4c34-9c73-ae19af18dfc7", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w_start, w_end = 0.9, 0.4  # Change: Introduce linearly decreasing inertia weight\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w_start - (w_start - w_end) * (eval_count / self.budget)) * velocities[i] + \\\n                                 c1 * r1 * (personal_best[i] - positions[i]) + \\\n                                 c2 * r2 * (global_best - positions[i])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a linearly decreasing inertia weight strategy for enhanced exploration-exploitation balance in the swarm optimization process.", "configspace": "", "generation": 4, "fitness": 0.8643656820621516, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.011. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8768453380452462, 0.8493032145248423, 0.8669484936163662], "final_y": [0.10991785677686083, 0.12803827043833982, 0.1237366472884468]}, "mutation_prompt": null}
{"id": "7d058d10-4eea-4ba1-ab9a-caff4d51d6ce", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        mutation_rate = 0.1\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.uniform(-1, 1, self.dim)\n                    positions[i] += mutation_vector * (ub - lb) * 0.05\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced swarm optimization by integrating mutation-based exploration to avoid local minima and improve convergence speed.", "configspace": "", "generation": 4, "fitness": 0.8383169967233032, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.003. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8362906071771787, 0.8362526761861724, 0.8424077068065585], "final_y": [0.12505891729147534, 0.13951202654293693, 0.12711804990452957]}, "mutation_prompt": null}
{"id": "4103446d-f346-4352-ba2f-33cdba2c2723", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]) +\n                                 0.01 * np.random.randn(self.dim))  # Small random perturbation\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Strengthen global exploration by adding a small random perturbation to particle velocities.", "configspace": "", "generation": 4, "fitness": 0.8700629608190521, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.002. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8729620845872629, 0.8680604946556505, 0.8691663032142432], "final_y": [0.12421923305436633, 0.1226217436145709, 0.12328975422427824]}, "mutation_prompt": null}
{"id": "db65963c-bcbb-4c96-b9f8-4a57fa9584db", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                # Introduce periodic random perturbation\n                if eval_count % 10 == 0:\n                    positions[i] += np.random.uniform(-0.01, 0.01, self.dim)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a periodic random perturbation to enhance particle exploration and prevent premature convergence.", "configspace": "", "generation": 4, "fitness": 0.8519206368855204, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.006. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8481478284072941, 0.8598410325156159, 0.8477730497336511], "final_y": [0.1322796741859631, 0.13231585469678608, 0.1358007909399911]}, "mutation_prompt": null}
{"id": "b99b123e-9f23-4a52-b328-dc78db7d6973", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = np.clip((w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i])), -0.1, 0.1)  # Velocity clamping\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduced adaptive velocity clamping for stability in particle movement and convergence.", "configspace": "", "generation": 4, "fitness": 0.8005576338636384, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.083. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.040.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.683385206340875, 0.8535877064103503, 0.86469998883969], "final_y": [0.2068230255827298, 0.13079911241718056, 0.11533348588030867]}, "mutation_prompt": null}
{"id": "f7432928-8b46-44d4-892c-270845f574f7", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub) * 0.99  # Reduce velocities over time\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive velocity damping for better convergence by reducing velocities over time.", "configspace": "", "generation": 5, "fitness": 0.8626080741271688, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.018. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8565434886896522, 0.8436279818938215, 0.887652751798033], "final_y": [0.1195815310244509, 0.1328223445438398, 0.12119571468770474]}, "mutation_prompt": null}
{"id": "5c44e08e-0981-4544-8bb4-d7ceffb1ae72", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index] + \n                                          np.random.normal(0, 0.1, self.dim))  # Perturbation factor\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Incorporate a perturbation factor to particle positions after neighborhood-based local search for enhanced exploration.", "configspace": "", "generation": 5, "fitness": 0.8612764781597421, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.010. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8510673772138249, 0.8743480879167442, 0.8584139693486569], "final_y": [0.12753226989478184, 0.12143138685697363, 0.12884430514464107]}, "mutation_prompt": null}
{"id": "4b673c30-be88-4748-8940-3d479a8d75b2", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                # Apply differential mutation strategy\n                random_indices = np.random.choice(num_particles, 3, replace=False)\n                mutant_vector = positions[random_indices[0]] + 0.8 * (positions[random_indices[1]] - positions[random_indices[2]])\n                positions[i] = np.clip(mutant_vector, lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Incorporated differential mutation strategy to enhance global exploration in swarm optimization.", "configspace": "", "generation": 5, "fitness": 0.8366271895230891, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.837 with standard deviation 0.045. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.7725544174437694, 0.8647504292214211, 0.8725767219040769], "final_y": [0.1590784425896019, 0.12714634110862144, 0.12027349734238435]}, "mutation_prompt": null}
{"id": "9610cade-51fa-4c18-8561-b7a3ddfa23e6", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        def levy_flight(Lambda):\n            sigma = (np.math.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2) /\n                     (np.math.gamma((1 + Lambda) / 2) * Lambda * \n                      2 ** ((Lambda - 1) / 2))) ** (1 / Lambda)\n            u = np.random.randn(self.dim) * sigma\n            v = np.random.randn(self.dim)\n            step = u / abs(v) ** (1 / Lambda)\n            return 0.01 * step\n\n        while eval_count < self.budget:\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i] + levy_flight(1.5), lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Incorporated Levy flights for stochastic exploration to enhance global search capabilities in swarm optimization.", "configspace": "", "generation": 5, "fitness": 0.8655225608686988, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.010. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8781083019817281, 0.8633982419198809, 0.8550611387044873], "final_y": [0.1185454354313894, 0.1282971682319155, 0.12233897555016693]}, "mutation_prompt": null}
{"id": "2bb38215-d897-4de6-b024-8a5595bc281c", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i])) * np.tanh(1 + np.random.rand(self.dim))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce non-linear velocity adjustment for enhanced exploration and exploitation balance in swarm optimization.", "configspace": "", "generation": 5, "fitness": 0.8563528658132552, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.004. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8608451571817791, 0.8518301683556494, 0.8563832719023373], "final_y": [0.12402587999632597, 0.12515061120507365, 0.12260129169508638]}, "mutation_prompt": null}
{"id": "bdefc529-991b-4880-842a-a9fdfe29f3f4", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n        neighborhood_memory = np.inf * np.ones((num_particles, self.dim))  # Memory for neighborhood solutions\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + neighborhood_memory[neighbor_index])  # Use memory\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                neighborhood_memory[i] = positions[i].copy()  # Update memory\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Implement a memory-based strategy to enhance convergence by considering the best neighborhood solutions from recent iterations.", "configspace": "", "generation": 5, "fitness": 0.8518472125865989, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.017. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8695942955502511, 0.8564608079870447, 0.8294865342225013], "final_y": [0.11864002827444797, 0.1231596390344547, 0.12825532767806702]}, "mutation_prompt": null}
{"id": "6775cfc2-c15f-4c7f-828c-2068858b5221", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Change: Adaptive velocity clamping\n                velocities[i] = np.clip(velocities[i], -0.1 * (ub - lb), 0.1 * (ub - lb))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduced adaptive velocity clamping to maintain stable exploration and exploitation balance in swarm optimization.", "configspace": "", "generation": 5, "fitness": 0.8642544174899797, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.014. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.883822579045856, 0.8588871216321284, 0.8500535517919541], "final_y": [0.11291658797906623, 0.12494822097858549, 0.13162828698628037]}, "mutation_prompt": null}
{"id": "47b2bb77-27ba-4143-abf8-0da60676175b", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                dist_to_global = np.linalg.norm(global_best - positions[i])\n                velocity_scale = np.exp(-dist_to_global)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i])) * velocity_scale\n                \n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive velocity scaling based on the proximity to global best to enhance convergence.", "configspace": "", "generation": 5, "fitness": 0.8160605649378251, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.051. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.7472738718166954, 0.8710294368958873, 0.8298783861008925], "final_y": [0.17528544058110074, 0.12268751557055202, 0.13354676692497824]}, "mutation_prompt": null}
{"id": "6c143df6-3e48-4487-b76c-32a35e9a4c0b", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n\n                # Periodic random perturbation for exploration\n                if eval_count % 10 == 0:\n                    positions[i] += np.random.uniform(-0.1, 0.1, self.dim)\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce periodic random perturbation to enhance global exploration capabilities of particles.", "configspace": "", "generation": 5, "fitness": 0.8811660751257114, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.016. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8803438648869071, 0.9010339988023471, 0.86212036168788], "final_y": [0.12116489883021908, 0.11228781764121021, 0.12528894358355314]}, "mutation_prompt": null}
{"id": "f6b3c76e-62cd-4959-b728-d581ebb09ba6", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                rand_factor = np.random.uniform(0.9, 1.1)  # New randomness factor\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i])) * rand_factor\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduced variability in velocity update by incorporating a randomness factor to enhance exploration capabilities in particle dynamics.", "configspace": "", "generation": 5, "fitness": 0.863426536649277, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.019. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8815660493054431, 0.8379278607469436, 0.8707856998954444], "final_y": [0.11996281959893684, 0.13955011301424547, 0.11689834548084344]}, "mutation_prompt": null}
{"id": "f4748168-f4c5-4c2b-864d-18cb18e5144a", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        # Change: Chaotic initialization\n        positions = lb + (ub - lb) * np.random.rand(num_particles, self.dim) ** 2\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.9  # Change: Initial inertia weight set to 0.9\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Change: Nonlinear decreasing inertia weight\n            w = 0.9 - 0.4 * (eval_count / self.budget) ** 2\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced AdaptiveSwarmOptimizer by introducing chaotic initialization and nonlinear decreasing inertia weight for improved exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.849050074878608, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.029. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8893850748068988, 0.8373785641046716, 0.8203865857242537], "final_y": [0.11898432587989238, 0.1335255366845306, 0.1321809186605939]}, "mutation_prompt": null}
{"id": "df697b6b-8a20-4bb0-8ba1-d4ffa5afa5d2", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                random_perturbation = np.random.uniform(-0.1, 0.1, self.dim)  # Added perturbation\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]) +\n                                 random_perturbation)  # Applied perturbation\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduced a random velocity perturbation to enhance exploration in particle movement.", "configspace": "", "generation": 6, "fitness": 0.8217760823263598, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.011. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8268535287201976, 0.8326146963629142, 0.8058600218959675], "final_y": [0.12687148551043215, 0.1365575232744498, 0.15446293515684173]}, "mutation_prompt": null}
{"id": "155421e6-c929-484d-aa4c-a2ca676a953e", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n        momentum = 0.9  # Momentum factor for velocity update\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (momentum * velocities[i] +  # Modified velocity update with momentum\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.2, 2)  # Adaptive learning factors for enhanced exploration\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Incorporate momentum-inspired velocity update and adaptive learning rates for enhanced exploration and convergence.  ", "configspace": "", "generation": 6, "fitness": 0.8201303783814726, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.031. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8574102684477828, 0.8223163562365529, 0.780664510460082], "final_y": [0.1283966344141262, 0.13859654361463303, 0.15949358165847216]}, "mutation_prompt": null}
{"id": "09992da8-a0ca-4fb0-a494-93d2affe3087", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.1, 2)  # Dynamic learning factors (slightly increased upper bound)\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduced a dynamic social influence factor to enhance exploration and exploitation balance in swarm optimization.", "configspace": "", "generation": 6, "fitness": 0.824857273746848, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.023. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8466716289985567, 0.8345321216881005, 0.7933680705538868], "final_y": [0.1275451966443758, 0.13635245173742505, 0.14274294129084286]}, "mutation_prompt": null}
{"id": "11ae3251-bdef-4dcf-90f8-dd7041a35b45", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = 0.1 * (w * velocities[i] +  # Velocity scaling factor added here\n                                       c1 * r1 * (personal_best[i] - positions[i]) +\n                                       c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a velocity scaling factor to limit excessive velocity increases, enhancing stability and convergence.", "configspace": "", "generation": 6, "fitness": 0.812820733175894, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.037. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.7650112647966787, 0.8540704046448483, 0.819380530086155], "final_y": [0.1529591072503378, 0.1291049720368862, 0.1362480751237488]}, "mutation_prompt": null}
{"id": "32918591-3c1a-4a4d-b0f5-24dbc4e1cb16", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n\n                # Velocity clamping based on global best\n                velocities[i] = np.clip(velocities[i], -abs(global_best - positions[i]), abs(global_best - positions[i]))\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduced velocity clamping based on global best to enhance convergence stability.", "configspace": "", "generation": 6, "fitness": 0.8339866238233947, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.015. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8539933801089382, 0.830030717070249, 0.8179357742909972], "final_y": [0.13571056606173615, 0.13849084931546796, 0.14540945073797684]}, "mutation_prompt": null}
{"id": "2bda0e46-dfc8-478f-b926-a4cea03daa46", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n\n                # Probabilistic global-best perturbation\n                if np.random.rand() < 0.05:\n                    positions[i] = positions[i] + np.random.normal(0, 0.1, self.dim)\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a probabilistic global-best perturbation mechanism to enhance exploration while maintaining the dynamic neighborhood-based local search.", "configspace": "", "generation": 6, "fitness": 0.829954781990589, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.022. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8602575317707948, 0.8120524165692374, 0.8175543976317351], "final_y": [0.12655541414631843, 0.14810784494648144, 0.13818524656129216]}, "mutation_prompt": null}
{"id": "37aa66ac-485f-4931-bb61-13210851409b", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n        decay_factor = 0.99  # New line for decay factor\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2) * decay_factor  # Modified line with decay factor\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Implemented a decay factor for dynamic learning factors to enhance convergence precision in later stages.", "configspace": "", "generation": 6, "fitness": 0.8299626464886853, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.016. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8483196072301491, 0.8313101224249676, 0.8102582098109394], "final_y": [0.1238718476233227, 0.13669160657193913, 0.14799978683781978]}, "mutation_prompt": null}
{"id": "9d525c90-2bd3-436e-9a10-b386308488f7", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i])) * np.random.rand()\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduced adaptive velocity update strategy to improve convergence rate in the swarm optimization process.", "configspace": "", "generation": 6, "fitness": 0.8423270691261798, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.037. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8936019060366925, 0.8224830051390888, 0.8108962962027582], "final_y": [0.11740453365903403, 0.14312264087716253, 0.14758208664164696]}, "mutation_prompt": null}
{"id": "150a1215-0286-415a-88c3-237666964fb1", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n        initial_local_search_prob = 0.1\n        decay_rate = 0.99\n\n        while eval_count < self.budget:\n            local_search_prob = initial_local_search_prob * (decay_rate ** (eval_count / num_particles))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < local_search_prob:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Implement a decay factor for local search probability to balance exploration and exploitation over time.", "configspace": "", "generation": 6, "fitness": 0.8259756370794905, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.016. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8468241853568683, 0.8094709930862223, 0.8216317327953808], "final_y": [0.13309198735947592, 0.14863614969283556, 0.13659914779685434]}, "mutation_prompt": null}
{"id": "341944e6-0dce-4ff7-8c27-f8501ed8cb24", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2) + np.random.rand(2) * 0.1  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Improve convergence by introducing a stochastic component to the learning factors in the swarm optimization process.", "configspace": "", "generation": 7, "fitness": 0.8573693695332844, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.013. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8485618545887859, 0.8760820337375427, 0.8474642202735247], "final_y": [0.1266019688054456, 0.11853582928403461, 0.12445200450072469]}, "mutation_prompt": null}
{"id": "61b1d167-f2d1-4326-8091-94a4ccf35a18", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            convergence_rate = np.exp(-eval_count / self.budget)\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Convergence-based dynamic neighborhood\n                if np.random.rand() < 0.1 * convergence_rate:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a convergence-based dynamic neighborhood selection mechanism for particles to enhance exploitation without exceeding the 1.9% change limit.", "configspace": "", "generation": 7, "fitness": 0.8563401615358064, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.007. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8531915434903949, 0.8494455040863598, 0.8663834370306644], "final_y": [0.12233858536005182, 0.12953155857469356, 0.12036541109075538]}, "mutation_prompt": null}
{"id": "89ea40bd-9c75-462c-acb8-73377098b4ef", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search with stochastic selection\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, np.random.randint(2, num_particles))) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce stochastic selection of neighborhood size for improved exploration during local search.", "configspace": "", "generation": 7, "fitness": 0.842578382811655, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.843 with standard deviation 0.012. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8286188738273105, 0.8578925135978605, 0.8412237610097941], "final_y": [0.13622800604618523, 0.12306817009831739, 0.13141367023717643]}, "mutation_prompt": null}
{"id": "d30699c8-2fd0-4664-875a-f2c0e405be05", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 * (1 + np.cos(np.pi * eval_count / self.budget))  # Cosine annealing for inertia\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce dynamic inertia adjustment using cosine annealing for smoother convergence.", "configspace": "", "generation": 7, "fitness": 0.8505982465145095, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.010. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.846218003319266, 0.8410576879182531, 0.8645190483060096], "final_y": [0.1153508525360546, 0.13360003199670134, 0.12477239861115219]}, "mutation_prompt": null}
{"id": "f279eb78-c1e2-4fb8-8448-87ab66ed8e03", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (0.9 * velocities[i] +  # Introduced velocity damping\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce velocity damping to enhance convergence stability while maintaining the 1.9% code change limit.", "configspace": "", "generation": 7, "fitness": 0.8629733567068198, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.023. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8311910483684486, 0.8772299562521949, 0.8804990654998159], "final_y": [0.13345731442360287, 0.12809773186547446, 0.12175929082085712]}, "mutation_prompt": null}
{"id": "2ea36ff9-91ad-4a9a-8c04-5ec8a4ee641e", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = (0.7 * positions[i] + 0.3 * positions[neighbor_index])  # Weighted averaging\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhance dynamic neighborhood-based local search by using weighted averaging for improved exploitation.", "configspace": "", "generation": 7, "fitness": 0.8770532909179325, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.027. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.843688809946387, 0.8787132337903536, 0.908757829017057], "final_y": [0.1376548560270492, 0.11825411616147197, 0.11334779091629033]}, "mutation_prompt": null}
{"id": "d2165599-4780-4b1d-b0a7-94fefda2788a", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n        v_factor = 0.9  # Adaptive velocity factor\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (v_factor * (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i])))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce an adaptive velocity factor to improve convergence by controlling particle movement speed. ", "configspace": "", "generation": 7, "fitness": 0.8716881320363049, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.012. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8831625337453074, 0.8544723851153346, 0.8774294772482727], "final_y": [0.12043939799003389, 0.12902669878661654, 0.11805069402144064]}, "mutation_prompt": null}
{"id": "16c450e9-733c-450a-b4a7-3a340162b7c6", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            # Change: Nonlinear dynamic adjustment factor for velocities\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i])) * (1 - eval_count/self.budget)\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduced nonlinear dynamic adjustment factor for velocities to enhance convergence speed and robustness in the optimization process.", "configspace": "", "generation": 7, "fitness": 0.8746080638261295, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.006. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8822328047759987, 0.8665081864578859, 0.8750832002445039], "final_y": [0.12120190083566873, 0.12250923317835194, 0.11999262800459032]}, "mutation_prompt": null}
{"id": "74327ba3-f423-4193-bf91-bbd64991aa66", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    # Change: Introduce mutation step for personal best positions\n                    if np.random.rand() < 0.1:\n                        personal_best[i] += np.random.uniform(-0.1, 0.1, self.dim)\n                        personal_best[i] = np.clip(personal_best[i], lb, ub)\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhance the swarm's adaptability by introducing a mutation step to the personal best positions.", "configspace": "", "generation": 7, "fitness": 0.8504751241081415, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.013. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8687012925921013, 0.8451398970364256, 0.8375841826958977], "final_y": [0.12012722125248543, 0.1304146373170446, 0.1365935460754094]}, "mutation_prompt": null}
{"id": "0ffb9af6-12df-4aa9-a379-4e11806a7c01", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.random.uniform(-0.1, 0.1, (num_particles, self.dim))  # Adaptive velocity initialization\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Adaptive velocity clamping\n                velocities[i] = np.clip(velocities[i], -0.1, 0.1)\n                \n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value and np.random.rand() < 0.7:  # Probabilistic global best update\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive velocity clamping and probabilistic global best update to enhance swarm exploration and convergence stability.", "configspace": "", "generation": 7, "fitness": 0.806623566434801, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.082. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.691512737849495, 0.8783946459758701, 0.8499633154790385], "final_y": [0.1895635995015521, 0.11393182818417324, 0.1297615681365244]}, "mutation_prompt": null}
{"id": "ce3ac29b-dbae-401c-8a73-32a40894a5e1", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n        \n        iteration = 0  # Track the number of iterations\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n\n            # Introduce diversity every 5 iterations\n            if iteration % 5 == 0:\n                new_particles = np.random.uniform(lb, ub, (5, self.dim))\n                for new_particle in new_particles:\n                    if eval_count < self.budget:\n                        value = func(new_particle)\n                        eval_count += 1\n                        if value < global_best_value:\n                            global_best = new_particle.copy()\n                            global_best_value = value\n\n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n            iteration += 1\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Integrate a diversity enhancement scheme by periodically introducing new random particles to maintain exploration and prevent premature convergence.", "configspace": "", "generation": 8, "fitness": 0.8599374217478278, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.005. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.867325855240352, 0.8555227278259326, 0.856963682177199], "final_y": [0.12560310664640173, 0.12612150720205362, 0.13134832054012047]}, "mutation_prompt": null}
{"id": "23f21601-06de-4746-ae6c-9c8454629919", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n\n                velocities[i] *= (0.5 + np.random.rand() / 2)  # Adaptive velocity damping\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Incorporate adaptive velocity damping to fine-tune exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8447002394637635, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.024. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8580230083515796, 0.8650706162572954, 0.8110070937824155], "final_y": [0.126954944133704, 0.13179039850614405, 0.14295074984842093]}, "mutation_prompt": null}
{"id": "f28ea8d5-15fb-4fc7-9e74-f1c0b35df283", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1 = 1.5 + 1.5 * (self.budget - eval_count) / self.budget  # Time-varying acceleration coefficient\n            c2 = np.random.uniform(1.3, 2.0)  \n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Incorporating a time-varying acceleration coefficient to enhance exploration and exploitation balance in the swarm optimization process.", "configspace": "", "generation": 8, "fitness": 0.8568732959724729, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.009. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8680747119837676, 0.8561887706512957, 0.8463564052823551], "final_y": [0.11819803017449082, 0.13040306638033794, 0.12992562162891919]}, "mutation_prompt": null}
{"id": "f68554db-c2ee-4029-b8b2-389ffedcb872", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                max_velocity = 0.1 * (ub - lb)  # Adaptive velocity clamping\n                velocities[i] = np.clip(velocities[i], -max_velocity, max_velocity)\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive velocity clamping to improve convergence control and enhance exploration-exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8681454667893513, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.013. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8861283457243085, 0.8624084540762424, 0.8558996005675032], "final_y": [0.11238567210219108, 0.12567361938119914, 0.12640368800130997]}, "mutation_prompt": null}
{"id": "e0ff5248-bb5e-4306-a3a6-f186ec165255", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                mutation_factor = 0.1 + 0.4 * (self.budget - eval_count) / self.budget\n                mutation = mutation_factor * np.random.uniform(-1, 1, self.dim)\n                positions[i] += mutation\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  \n            c1, c2 = np.random.uniform(1.3, 2.0, 2)\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive mutation strategy to enhance exploration and balance between global and local search.", "configspace": "", "generation": 8, "fitness": 0.8549784646402371, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.024. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8231654198427054, 0.8601146258331765, 0.8816553482448294], "final_y": [0.13765498155090983, 0.12702598073537508, 0.11889201190732457]}, "mutation_prompt": null}
{"id": "de6f81b5-3990-4b93-a10f-b8a158d3d77b", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.7 + np.random.rand() / 2  # Changed line\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best + np.random.rand(self.dim) - positions[i]))  # Changed line\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced velocity update rule by introducing nonlinear inertia weight adaptation and leader-influenced velocity adjustment.", "configspace": "", "generation": 8, "fitness": 0.8436261485673132, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.015. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8271320494984975, 0.864186647485577, 0.839559748717865], "final_y": [0.13970744045048367, 0.12411217001591979, 0.1315421082133421]}, "mutation_prompt": null}
{"id": "eb676379-2dc7-4817-bd79-b6c804286d57", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = min(50, self.budget // 10)  # Adaptive particle count based on budget\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive particle count adjustment to enhance exploration and convergence in the swarm optimization process.", "configspace": "", "generation": 8, "fitness": 0.8572191425691429, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.014. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8758129877135092, 0.8543744215040171, 0.8414700184899024], "final_y": [0.12079445461057237, 0.13082950357178402, 0.13385308405832663]}, "mutation_prompt": null}
{"id": "3056f9d9-cd8a-4596-9daa-51d9fb36eca0", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                neighborhood_avg = np.mean(positions, axis=0)  # New line\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]) +\n                                 0.2 * (neighborhood_avg - positions[i]))  # New line\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhance the velocity update equation by adding a term for average neighborhood position to improve convergence speed and precision.", "configspace": "", "generation": 8, "fitness": 0.8666340959735527, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.020. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8792264621777713, 0.8390753386329582, 0.8816004871099283], "final_y": [0.12433019053847572, 0.1340417138984158, 0.116925140063182]}, "mutation_prompt": null}
{"id": "45568f4e-6870-44b5-b736-3b1f076c391b", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search with perturbation\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                    positions[i] += np.random.uniform(-0.01, 0.01, self.dim)  # Perturbation\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a perturbation operator to explore more varied local minima while introducing a gradient-based step size adaptation to the velocity update.", "configspace": "", "generation": 8, "fitness": 0.8750245635179527, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.013. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8626776604937295, 0.8698757329910322, 0.8925202970690966], "final_y": [0.1242365530176982, 0.12202176465376757, 0.11797753475731543]}, "mutation_prompt": null}
{"id": "f9b5975c-0a66-43d3-a820-debc74ece927", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Enhanced neighbor-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.6 * positions[i] + 0.4 * positions[neighbor_index]\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhance particle position update using a weighted average of neighboring particles for improved convergence.", "configspace": "", "generation": 8, "fitness": 0.8532216055660603, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.026. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8307591392191825, 0.8388923931411889, 0.8900132843378095], "final_y": [0.12977732741285342, 0.13758364231145293, 0.120150071980071]}, "mutation_prompt": null}
{"id": "3afb7ca6-9271-4cca-8799-8b09a9a0f26f", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        velocity_scaling_factor = 0.1 + np.random.rand()  # New scaling factor\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                velocities[i] *= velocity_scaling_factor  # Apply the scaling factor\n\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Refine swarm dynamics by incorporating self-adaptive velocity scaling to enhance exploration and exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.8595831265036354, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.024. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8441865566493978, 0.8928561584645311, 0.8417066643969776], "final_y": [0.1334966307646348, 0.12124788013790011, 0.13091717105512024]}, "mutation_prompt": null}
{"id": "35a7c1b1-5c14-4389-8c6b-722e87102326", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Adaptive velocity update using local and global contexts\n                velocities[i] += 0.1 * (np.mean(positions, axis=0) - positions[i])\n                \n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive velocity update using local and global contextual information for enhanced convergence.", "configspace": "", "generation": 9, "fitness": 0.867843727469432, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.028. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8835587867136849, 0.8918796327514438, 0.8280927629431674], "final_y": [0.12044813087612083, 0.11818808402454617, 0.1392430107048801]}, "mutation_prompt": null}
{"id": "f6f8872e-672b-45e3-9d3a-2593457b72c5", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Adaptive mutation strategy\n                mutation_probability = 0.2 - 0.15 * (eval_count / self.budget)\n                if np.random.rand() < mutation_probability:\n                    mutation_strength = np.random.rand(self.dim) * 0.1\n                    mutation_vector = (np.random.rand(self.dim) - 0.5) * mutation_strength\n                    positions[i] += mutation_vector\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive mutation strategies for particles to enhance exploration and exploitation balance in swarm optimization.", "configspace": "", "generation": 9, "fitness": 0.8806784796031888, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.017. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8594425609041866, 0.8814203274967393, 0.9011725504086407], "final_y": [0.1286390522287072, 0.12036991289254229, 0.11692077693937786]}, "mutation_prompt": null}
{"id": "386f5482-3b1a-47b7-a27d-a0582c79db41", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Change: Convergence-based adaptive velocity update\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]) +\n                                 0.1 * (global_best_value - personal_best_values[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduced a convergence-based adaptive velocity update mechanism to enhance exploration and exploitation balance in swarm optimization.", "configspace": "", "generation": 9, "fitness": 0.899717265671048, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.003. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.896139843964082, 0.9031052709587581, 0.8999066820903041], "final_y": [0.11544037815578811, 0.11719329080258412, 0.1123565693407611]}, "mutation_prompt": null}
{"id": "1d85d346-b7f6-4699-9d41-32bf29ee0516", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.7 * positions[i] + 0.3 * positions[neighbor_index]  # Change made here\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced local search by introducing a weighted average in the dynamic neighborhood-based local search step.", "configspace": "", "generation": 9, "fitness": 0.8742177787926616, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.026. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.840489044275238, 0.9050220355723599, 0.8771422565303866], "final_y": [0.13201053970996213, 0.11798217081519213, 0.11773820974765381]}, "mutation_prompt": null}
{"id": "dfb46d7e-f111-48b3-8a17-5855a2003981", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0 - (eval_count/self.budget), 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a dynamic adjustment for cognitive and social coefficients based on the remaining budget to enhance convergence.", "configspace": "", "generation": 9, "fitness": 0.8758441980158777, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.029. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8467218080008543, 0.8655038343633534, 0.9153069516834252], "final_y": [0.12298576575085929, 0.12786330993281103, 0.11233836755913218]}, "mutation_prompt": null}
{"id": "70536d5a-c6e8-4f3e-b422-6f853614ca1d", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Weighted neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    weight = np.random.uniform(0.4, 0.6)\n                    positions[i] = weight * positions[i] + (1 - weight) * positions[neighbor_index]\n\n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive local search enhancement using weighted neighbor influence for improved convergence in particle swarm optimization.", "configspace": "", "generation": 9, "fitness": 0.8737516290205684, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.018. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8520647596509838, 0.8732658100992735, 0.8959243173114476], "final_y": [0.12753613565171362, 0.1270268715549605, 0.11800251778084547]}, "mutation_prompt": null}
{"id": "e7dc5130-f52a-4468-92e1-a798e729a037", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * ((global_best + 0.01 * np.random.randn(self.dim)) - positions[i]))  # Add perturbation\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced global exploration by introducing a slight mutation to the global best position when updating particle positions.", "configspace": "", "generation": 9, "fitness": 0.8742995206354708, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.033. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8282134776368268, 0.8927134730428996, 0.9019716112266859], "final_y": [0.14026545014953284, 0.11732092799778748, 0.1143798009609055]}, "mutation_prompt": null}
{"id": "c4ab8ff7-7ccf-40b3-ad30-594b609d2aaf", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        velocity_clamp = (ub - lb) * 0.1  # Adaptive velocity clamping\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)  # Apply clamping\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduced adaptive velocity clamping for enhanced exploration-exploitation balance in the swarm optimization process.", "configspace": "", "generation": 9, "fitness": 0.8842717160909319, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.015. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8923500881784369, 0.8967196391937237, 0.8637454209006353], "final_y": [0.1104160717756425, 0.11715338105221551, 0.12837984572946115]}, "mutation_prompt": null}
{"id": "a455ee82-be7e-46af-99cd-7ce4d7847b77", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                # Dynamic neighborhood-based local search\n                if np.random.rand() < 0.1:\n                    neighbor_index = (i + np.random.randint(1, num_particles)) % num_particles\n                    positions[i] = 0.5 * (positions[i] + positions[neighbor_index])\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w *= 0.99  # Non-linear inertia weight decay\n            c1, c2 = np.random.uniform(1.3, 2.0) + 0.1 * np.random.rand(2)  # Stochastic convergence factor\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a non-linear inertia weight decay and a stochastic convergence factor to enhance the balance between exploration and exploitation in the particle swarm optimization process.", "configspace": "", "generation": 9, "fitness": 0.8708676925189623, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.027. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "0cc29f20-71a5-42bd-89f7-73c4d89b8a60", "metadata": {"aucs": [0.8388766833582031, 0.8682684038915265, 0.9054579903071575], "final_y": [0.13597199426264328, 0.12730141443967025, 0.11495111884594711]}, "mutation_prompt": null}
{"id": "d61bbf93-f411-4adf-bce9-0afa7f7fa4e2", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Change: Nonlinear time-varying inertia weight and adaptive learning factors\n            w = 0.4 + 0.5 * np.exp(-0.01 * eval_count)  \n            c1, c2 = np.random.uniform(1.5, 2.5, 2) \n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduced a nonlinear time-varying inertia weight and adaptive learning rates to enhance convergence precision in swarm optimization.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"cannot access local variable 'w' where it is not associated with a value\").", "error": "UnboundLocalError(\"cannot access local variable 'w' where it is not associated with a value\")", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {}, "mutation_prompt": null}
{"id": "5d322e1a-0557-4f91-99c3-79f8ceaf128a", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2 * (1 - eval_count / self.budget)  # Nonlinear decrement in inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduced a nonlinear decrement in inertia weight to better control exploration and exploitation phases dynamically.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {}, "mutation_prompt": null}
{"id": "3cbcf020-9f11-4a34-8731-bf12670c014e", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]) * (1 - eval_count / self.budget)) # Changed social influence\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Improved global information sharing by incorporating a dynamic social influence factor in velocity updates.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {}, "mutation_prompt": null}
{"id": "f67ab1f2-dc54-4b7b-8151-f31e1a8a73c9", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]) +\n                                 0.1 * (global_best_value - personal_best_values[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)\n            \n            # New: Incorporate mean personal best into global best selection\n            mean_personal_best = np.mean(personal_best, axis=0)\n            if np.mean([func(mean_personal_best), global_best_value]) < global_best_value:\n                global_best = mean_personal_best\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced leader selection by combining global and mean personal best for improved convergence and exploration balance.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 50 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 50 is out of bounds for axis 0 with size 50')", "parent_id": "386f5482-3b1a-47b7-a27d-a0582c79db41", "metadata": {}, "mutation_prompt": null}
{"id": "1f984768-4a62-416e-9a6b-8c00d0e2305e", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n        prev_best_value = global_best_value\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size with convergence speed factor\n            convergence_factor = (prev_best_value - global_best_value) / abs(prev_best_value) if prev_best_value != 0 else 1\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget * (1 + convergence_factor)))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        prev_best_value = global_best_value\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced convergence by adapting the dynamic population size based on both remaining budget and current convergence speed.", "configspace": "", "generation": 10, "fitness": 0.8571429576106301, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.004. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8631161878689678, 0.8552780732240619, 0.8530346117388607], "final_y": [0.11588123871863709, 0.1252459623027411, 0.12581085507078826]}, "mutation_prompt": null}
{"id": "e849aa47-bb86-4c93-96d1-086dcad4c30a", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.4 + np.random.rand() / 2  # Modified inertia weight\n            c1, c2 = np.random.normal(1.5, 0.1, 2)  # Dynamic learning factors with Gaussian variation\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduced a hybrid inertia weight and dynamic acceleration coefficients strategy for improved convergence and exploration.", "configspace": "", "generation": 10, "fitness": 0.8504359612469434, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.010. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8360264993727066, 0.8588559485670111, 0.8564254358011127], "final_y": [0.1375854765666511, 0.12280798886812827, 0.1320933280916342]}, "mutation_prompt": null}
{"id": "6180f60a-4578-439e-9b06-75f4d67fd365", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            # Change: Adaptive population size\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = np.clip((w * velocities[i] +\n                                         c1 * r1 * (personal_best[i] - positions[i]) +\n                                         c2 * r2 * (global_best - positions[i])), -0.1, 0.1)  # Adaptive velocity bounds\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced by introducing adaptive velocity bound adjustments to improve convergence speed and solution accuracy.", "configspace": "", "generation": 10, "fitness": 0.8074642605860634, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.088. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.041.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.6833680186721853, 0.8775726842701693, 0.8614520788158356], "final_y": [0.20689493749038657, 0.12121487777696727, 0.1194141418776018]}, "mutation_prompt": null}
{"id": "f1ee3274-23fa-4fe9-8dad-706a46202a80", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (0.5 + (0.5 * (1 - eval_count / self.budget)) * velocities[i] +  # Adaptive inertia weight\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]) +\n                                 0.1 * (global_best_value - personal_best_values[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            c1, c2 = np.random.uniform(1.3, 2.0, 2)\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduced adaptive inertia weight scaling based on the iteration ratio to enhance convergence speed.", "configspace": "", "generation": 10, "fitness": 0.8669724194104337, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.011. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "386f5482-3b1a-47b7-a27d-a0582c79db41", "metadata": {"aucs": [0.8804531148555554, 0.8540008817146197, 0.8664632616611263], "final_y": [0.1188161426923986, 0.12166915492057384, 0.11657913580191215]}, "mutation_prompt": null}
{"id": "255f921b-ba09-407d-b89e-308794d11980", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]) +\n                                 0.1 * (global_best_value - personal_best_values[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = (positions[i] + np.random.uniform(lb, ub) * 0.01).copy()  # Perturbation mechanism\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Introduced a perturbation mechanism in the global best update process to enhance exploration and prevent premature convergence.", "configspace": "", "generation": 10, "fitness": 0.8621261575363287, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.021. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "386f5482-3b1a-47b7-a27d-a0582c79db41", "metadata": {"aucs": [0.8419859461266322, 0.8913814335934611, 0.8530110928888924], "final_y": [0.12597697369858418, 0.1164512461635574, 0.12274692453338931]}, "mutation_prompt": null}
{"id": "bbf79b46-c783-4b60-8680-76e7cb3dd3f8", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = np.array(func.bounds.lb), np.array(func.bounds.ub)\n        num_particles = 50\n        positions = np.random.uniform(lb, ub, (num_particles, self.dim))\n        velocities = np.zeros((num_particles, self.dim))\n        personal_best = positions.copy()\n        personal_best_values = np.array([func(pos) for pos in personal_best])\n        global_best_index = np.argmin(personal_best_values)\n        global_best = personal_best[global_best_index].copy()\n        global_best_value = personal_best_values[global_best_index]\n        \n        w = 0.5 + np.random.rand() / 2\n        c1, c2 = 1.5, 1.5\n        eval_count = num_particles\n\n        while eval_count < self.budget:\n            num_particles = max(10, int(50 * (self.budget - eval_count) / self.budget))\n            for i in range(num_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (w * velocities[i] +\n                                 c1 * r1 * (personal_best[i] - positions[i]) +\n                                 c2 * r2 * (global_best - positions[i]))\n                \n                positions[i] = np.clip(positions[i] + velocities[i], lb, ub)\n                \n                # New: Adaptive mutation strategy\n                mutation_prob = 0.1  # Mutation probability\n                if np.random.rand() < mutation_prob:\n                    mutation_vector = np.random.uniform(-0.1, 0.1, self.dim)\n                    positions[i] = np.clip(positions[i] + mutation_vector, lb, ub)\n                \n                value = func(positions[i])\n                eval_count += 1\n                \n                if value < personal_best_values[i]:\n                    personal_best[i] = positions[i].copy()\n                    personal_best_values[i] = value\n                    \n                    if value < global_best_value:\n                        global_best = positions[i].copy()\n                        global_best_value = value\n\n                if eval_count >= self.budget:\n                    break\n            \n            w = 0.5 + np.random.rand() / 2  # Adaptive inertia weight\n            c1, c2 = np.random.uniform(1.3, 2.0, 2)  # Dynamic learning factors\n\n        return global_best", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced diversity and convergence through adaptive mutation strategy applied to positions.", "configspace": "", "generation": 10, "fitness": 0.8541902549300104, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.014. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "28c1b608-77fc-4978-82b6-f8742a4713bf", "metadata": {"aucs": [0.8682011705125167, 0.8584676411364709, 0.8359019531410437], "final_y": [0.12032930029484179, 0.12152141323275445, 0.1331470309840047]}, "mutation_prompt": null}
