{"id": "6a419159-fc5c-40b4-a803-9d60b1caf635", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim, periodic_weight=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.periodic_weight = periodic_weight\n        self.population_size = 15 * dim  # Recommended for DE\n        self.pop = None\n        self.fitness = None\n        self.bounds = None\n        \n    def periodic_cost(self, solution, period):\n        \"\"\"Encourage periodicity in the solution.\"\"\"\n        repeated = np.tile(solution[:period], self.dim // period)\n        return np.sum((solution - repeated) ** 2)\n\n    def initialize_population(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        self.pop = np.random.rand(self.population_size, self.dim)\n        self.pop = self.bounds[0] + self.pop * (self.bounds[1] - self.bounds[0])\n        self.fitness = np.array([func(ind) for ind in self.pop])\n    \n    def differential_evolution(self, func):\n        F = 0.8  # Mutation factor\n        CR = 0.9  # Crossover probability\n        for generation in range(self.budget // self.population_size):\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = self.pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), self.bounds[0], self.bounds[1])\n                cross_points = np.random.rand(self.dim) < CR\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial_fitness = func(trial) + self.periodic_weight * self.periodic_cost(trial, 2)\n                \n                if trial_fitness < self.fitness[i]:\n                    self.fitness[i] = trial_fitness\n                    self.pop[i] = trial\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_sol = self.pop[best_idx]\n\n        def wrapped_func(x):\n            return func(x) + self.periodic_weight * self.periodic_cost(x, 2)\n\n        res = minimize(wrapped_func, best_sol, method='L-BFGS-B', bounds=[(self.bounds[0], self.bounds[1])] * self.dim)\n        if res.fun < self.fitness[best_idx]:\n            self.pop[best_idx] = res.x\n            self.fitness[best_idx] = res.fun\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        self.differential_evolution(func)\n        self.local_search(func)\n        best_idx = np.argmin(self.fitness)\n        return self.pop[best_idx]", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic algorithm that combines Differential Evolution with a periodicity-enforcing cost function to explore and exploit the search space, fine-tuned with BFGS for optimizing multilayer photonic structures.", "configspace": "", "generation": 0, "fitness": 0.6247946229880704, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.625 with standard deviation 0.022. And the mean value of best solutions found was 0.301 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": null, "metadata": {"aucs": [0.5946502532340878, 0.635668069328305, 0.6440655464018185], "final_y": [0.3091003679220313, 0.2918768553273967, 0.30075233198543416]}, "mutation_prompt": null}
{"id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic algorithm combining Differential Evolution with periodicity-encouraging constraints and local optimization for enhanced exploration and exploitation in black box problems.", "configspace": "", "generation": 0, "fitness": 0.6945250013606833, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.695 with standard deviation 0.173. And the mean value of best solutions found was 0.268 (0. is the best) with standard deviation 0.085.", "error": "", "parent_id": null, "metadata": {"aucs": [0.9265757037193236, 0.5104008658698695, 0.6465984344928566], "final_y": [0.16485603832335616, 0.3733108348139642, 0.26649697762261937]}, "mutation_prompt": null}
{"id": "710e5bd9-59a8-4caa-9570-528be5833f81", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Improved periodicity enforcement\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = 0.5 * (individual[i] + individual[i % period])\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic algorithm combining Differential Evolution with a periodicity-encouraging constraints and local optimization for enhanced exploration and exploitation in black box problems, now with an improved periodicity enforcement strategy to ensure better constructive interference.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {}, "mutation_prompt": null}
{"id": "aee4e82c-fdfa-4dd8-82b5-93a034502d22", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim, periodic_weight=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.periodic_weight = periodic_weight\n        self.population_size = 15 * dim\n        self.pop = None\n        self.fitness = None\n        self.bounds = None\n        \n    def adaptive_periodic_cost(self, solution):\n        \"\"\"Adaptively encourage periodicity in the solution.\"\"\"\n        min_period = 2\n        max_period = min(10, self.dim // 2)\n        cost = np.inf\n        for period in range(min_period, max_period + 1):\n            repeated = np.tile(solution[:period], self.dim // period)\n            current_cost = np.sum((solution - repeated) ** 2)\n            cost = min(cost, current_cost)\n        return cost\n\n    def chaotically_initialize_population(self, func):\n        \"\"\"Use chaotic initialization to diversify the population.\"\"\"\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        self.pop = np.random.rand(self.population_size, self.dim)\n        self.pop = np.sin(self.pop * np.pi) * (self.bounds[1] - self.bounds[0]) + self.bounds[0]\n        self.fitness = np.array([func(ind) for ind in self.pop])\n    \n    def differential_evolution(self, func):\n        F = 0.8\n        CR = 0.9\n        for generation in range(self.budget // self.population_size):\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = self.pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), self.bounds[0], self.bounds[1])\n                cross_points = np.random.rand(self.dim) < CR\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial_fitness = func(trial) + self.periodic_weight * self.adaptive_periodic_cost(trial)\n                \n                if trial_fitness < self.fitness[i]:\n                    self.fitness[i] = trial_fitness\n                    self.pop[i] = trial\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_sol = self.pop[best_idx]\n\n        def wrapped_func(x):\n            return func(x) + self.periodic_weight * self.adaptive_periodic_cost(x)\n\n        res = minimize(wrapped_func, best_sol, method='L-BFGS-B', bounds=[(self.bounds[0], self.bounds[1])] * self.dim)\n        if res.fun < self.fitness[best_idx]:\n            self.pop[best_idx] = res.x\n            self.fitness[best_idx] = res.fun\n\n    def __call__(self, func):\n        self.chaotically_initialize_population(func)\n        self.differential_evolution(func)\n        self.local_search(func)\n        best_idx = np.argmin(self.fitness)\n        return self.pop[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic incorporating adaptive periodicity and chaotic initialization strategies for optimizing multilayer photonic structures.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (10,) (9,) ').", "error": "ValueError('operands could not be broadcast together with shapes (10,) (9,) ')", "parent_id": "6a419159-fc5c-40b4-a803-9d60b1caf635", "metadata": {}, "mutation_prompt": null}
{"id": "cb30c9d0-7ff4-4a98-b078-c23d5bc21285", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim, periodic_weight=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.periodic_weight = periodic_weight\n        self.population_size = 15 * dim  # Recommended for DE\n        self.pop = None\n        self.fitness = None\n        self.bounds = None\n\n    def periodic_cost(self, solution, period):\n        \"\"\"Encourage periodicity in the solution.\"\"\"\n        repeated = np.tile(solution[:period], self.dim // period)\n        return np.sum((solution - repeated) ** 2)\n\n    def initialize_population(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        self.pop = np.random.rand(self.population_size, self.dim)\n        self.pop = self.bounds[0] + self.pop * (self.bounds[1] - self.bounds[0])\n        self.fitness = np.array([func(ind) for ind in self.pop])\n    \n    def differential_evolution(self, func):\n        F = 0.8  # Mutation factor\n        CR = 0.9  # Crossover probability\n        for generation in range(self.budget // self.population_size):\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = self.pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), self.bounds[0], self.bounds[1])\n                cross_points = np.random.rand(self.dim) < CR\n                trial = np.where(cross_points, mutant, self.pop[i])\n                if generation > 0.5 * (self.budget // self.population_size):\n                    self.periodic_weight *= 0.9  # Adaptive periodic weight adjustment\n                trial_fitness = func(trial) + self.periodic_weight * self.periodic_cost(trial, 2)\n                \n                if trial_fitness < self.fitness[i]:\n                    self.fitness[i] = trial_fitness\n                    self.pop[i] = trial\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_sol = self.pop[best_idx]\n\n        def wrapped_func(x):\n            return func(x) + self.periodic_weight * self.periodic_cost(x, 2)\n\n        if np.random.rand() < 0.5:  # Selective local search\n            res = minimize(wrapped_func, best_sol, method='L-BFGS-B', bounds=[(self.bounds[0], self.bounds[1])] * self.dim)\n            if res.fun < self.fitness[best_idx]:\n                self.pop[best_idx] = res.x\n                self.fitness[best_idx] = res.fun\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        self.differential_evolution(func)\n        self.local_search(func)\n        best_idx = np.argmin(self.fitness)\n        return self.pop[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive periodic weight and selective local search to optimize multilayer photonic structures more effectively.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (10,) (9,) ').", "error": "ValueError('operands could not be broadcast together with shapes (10,) (9,) ')", "parent_id": "6a419159-fc5c-40b4-a803-9d60b1caf635", "metadata": {}, "mutation_prompt": null}
{"id": "c2f702bd-ed8c-48ea-adc9-2dbe62f99559", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim, periodic_weight=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.periodic_weight = periodic_weight\n        self.population_size = 15 * dim  # Recommended for DE\n        self.pop = None\n        self.fitness = None\n        self.bounds = None\n        \n    def periodic_cost(self, solution, period):\n        \"\"\"Encourage periodicity in the solution.\"\"\"\n        repeated = np.tile(solution[:period], self.dim // period)\n        return np.sum((solution - repeated) ** 2)\n\n    def initialize_population(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        self.pop = np.random.rand(self.population_size, self.dim)\n        self.pop = self.bounds[0] + self.pop * (self.bounds[1] - self.bounds[0])\n        self.fitness = np.array([func(ind) for ind in self.pop])\n    \n    def differential_evolution(self, func):\n        F = 0.8  # Mutation factor\n        CR = 0.9  # Crossover probability\n        for generation in range(self.budget // self.population_size):\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = self.pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), self.bounds[0], self.bounds[1])\n                cross_points = np.random.rand(self.dim) < CR\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial_fitness = func(trial) + self.periodic_weight * self.periodic_cost(trial, 2)\n                \n                if trial_fitness < self.fitness[i]:\n                    self.fitness[i] = trial_fitness\n                    self.pop[i] = trial\n            self.periodic_weight *= 0.99  # Adaptive weight reduction\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_sol = self.pop[best_idx]\n\n        def wrapped_func(x):\n            return func(x) + self.periodic_weight * self.periodic_cost(x, 2)\n\n        res = minimize(wrapped_func, best_sol, method='L-BFGS-B', bounds=[(self.bounds[0], self.bounds[1])] * self.dim)\n        if res.fun < self.fitness[best_idx]:\n            self.pop[best_idx] = res.x\n            self.fitness[best_idx] = res.fun\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        self.differential_evolution(func)\n        self.local_search(func)\n        best_idx = np.argmin(self.fitness)\n        return self.pop[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic algorithm using adaptive periodicity weight for improved convergence in multilayer photonic structure optimization.", "configspace": "", "generation": 1, "fitness": 0.6271621088147888, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.627 with standard deviation 0.040. And the mean value of best solutions found was 0.283 (0. is the best) with standard deviation 0.037.", "error": "", "parent_id": "6a419159-fc5c-40b4-a803-9d60b1caf635", "metadata": {"aucs": [0.5959718922078874, 0.683156363486253, 0.6023580707502261], "final_y": [0.3179878245451184, 0.2319726180331032, 0.29988378627542767]}, "mutation_prompt": null}
{"id": "fea2124d-60d8-4861-a7f9-b35993e0448b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        # Adjust crossover rate dynamically\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tight bounds\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic algorithm that combines Differential Evolution with a dynamic crossover strategy, periodicity-encouraging initialization, and improved local optimization for superior exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 1, "fitness": 0.7495752738319079, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.750 with standard deviation 0.141. And the mean value of best solutions found was 0.237 (0. is the best) with standard deviation 0.059.", "error": "", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {"aucs": [0.9308001572753836, 0.7312152095749691, 0.5867104546453711], "final_y": [0.16485603832335616, 0.23631663908548373, 0.30906290979558226]}, "mutation_prompt": null}
{"id": "f87c9384-ac47-4a6a-819e-0eb297c426b0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim, periodic_weight=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.periodic_weight = periodic_weight\n        self.population_size = 15 * dim  # Recommended for DE\n        self.pop = None\n        self.fitness = None\n        self.bounds = None\n        \n    def periodic_cost(self, solution, period):\n        \"\"\"Encourage periodicity in the solution.\"\"\"\n        repeated = np.tile(solution[:period], self.dim // period)\n        return np.sum((solution - repeated) ** 2)\n\n    def initialize_population(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        self.pop = np.random.rand(self.population_size, self.dim)\n        self.pop = self.bounds[0] + self.pop * (self.bounds[1] - self.bounds[0])\n        self.fitness = np.array([func(ind) for ind in self.pop])\n    \n    def differential_evolution(self, func):\n        F = 0.8  # Mutation factor\n        CR = 0.9  # Crossover probability\n        for generation in range(self.budget // self.population_size):\n            self.periodic_weight *= 0.95  # Adaptive reduction of periodic weight\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = self.pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), self.bounds[0], self.bounds[1])\n                cross_points = np.random.rand(self.dim) < CR\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial_fitness = func(trial) + self.periodic_weight * self.periodic_cost(trial, 2)\n                \n                if trial_fitness < self.fitness[i]:\n                    self.fitness[i] = trial_fitness\n                    self.pop[i] = trial\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_sol = self.pop[best_idx]\n\n        def wrapped_func(x):\n            return func(x) + self.periodic_weight * self.periodic_cost(x, 2)\n\n        res = minimize(wrapped_func, best_sol, method='L-BFGS-B', bounds=[(self.bounds[0], self.bounds[1])] * self.dim)\n        if res.fun < self.fitness[best_idx]:\n            self.pop[best_idx] = res.x\n            self.fitness[best_idx] = res.fun\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        self.differential_evolution(func)\n        self.local_search(func)\n        best_idx = np.argmin(self.fitness)\n        return self.pop[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic algorithm incorporating adaptive periodic weighting to dynamically adjust search strategy based on convergence progress.", "configspace": "", "generation": 1, "fitness": 0.6024501247247045, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.602 with standard deviation 0.043. And the mean value of best solutions found was 0.306 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "6a419159-fc5c-40b4-a803-9d60b1caf635", "metadata": {"aucs": [0.5746603481600181, 0.5695235053925307, 0.6631665206215646], "final_y": [0.30433906164205204, 0.32857650181042597, 0.28626162494085206]}, "mutation_prompt": null}
{"id": "d917b5f1-8e41-4b23-a5a6-b529f1b4df47", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim, periodic_weight=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.periodic_weight = periodic_weight\n        self.population_size = 15 * dim  # Recommended for DE\n        self.pop = None\n        self.fitness = None\n        self.bounds = None\n\n    def periodic_cost(self, solution, period):\n        \"\"\"Encourage periodicity in the solution.\"\"\"\n        repeated = np.tile(solution[:period], self.dim // period)\n        return np.sum((solution - repeated) ** 2)\n\n    def initialize_population(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        self.pop = np.random.rand(self.population_size, self.dim)\n        self.pop = self.bounds[0] + self.pop * (self.bounds[1] - self.bounds[0])\n        self.fitness = np.array([func(ind) for ind in self.pop])\n\n    def differential_evolution(self, func):\n        F_base = 0.5  # Mutation factor base\n        CR_base = 0.9  # Crossover probability base\n        for generation in range(self.budget // self.population_size):\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = self.pop[np.random.choice(indices, 3, replace=False)]\n                F = F_base + 0.3 * np.random.rand()  # Adaptive Mutation factor\n                mutant = np.clip(a + F * (b - c), self.bounds[0], self.bounds[1])\n                CR = CR_base - 0.1 * (generation / (self.budget // self.population_size))\n                cross_points = np.random.rand(self.dim) < CR\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial_fitness = func(trial) + self.periodic_weight * self.periodic_cost(trial, 2)\n\n                if trial_fitness < self.fitness[i]:\n                    self.fitness[i] = trial_fitness\n                    self.pop[i] = trial\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_sol = self.pop[best_idx]\n\n        def wrapped_func(x):\n            return func(x) + self.periodic_weight * self.periodic_cost(x, 2)\n\n        res = minimize(wrapped_func, best_sol, method='L-BFGS-B', bounds=[(self.bounds[0], self.bounds[1])] * self.dim, options={'maxiter': 100})\n        if res.fun < self.fitness[best_idx]:\n            self.pop[best_idx] = res.x\n            self.fitness[best_idx] = res.fun\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        self.differential_evolution(func)\n        self.local_search(func)\n        best_idx = np.argmin(self.fitness)\n        return self.pop[best_idx]", "name": "HybridMetaheuristic", "description": "An improved hybrid metaheuristic leveraging adaptive parameters in Differential Evolution and enhanced local search to optimize multilayer photonic structures.", "configspace": "", "generation": 1, "fitness": 0.6286119305940777, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.629 with standard deviation 0.024. And the mean value of best solutions found was 0.307 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "6a419159-fc5c-40b4-a803-9d60b1caf635", "metadata": {"aucs": [0.6330291726242385, 0.6551731636347897, 0.5976334555232049], "final_y": [0.31002804717457566, 0.29616985853886957, 0.31463017209813116]}, "mutation_prompt": null}
{"id": "e1af883d-2b27-4707-93f6-9e6dcd52c10e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim, periodic_weight=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.periodic_weight = periodic_weight\n        self.population_size = 15 * dim  # Recommended for DE\n        self.pop = None\n        self.fitness = None\n        self.bounds = None\n        \n    def periodic_cost(self, solution, period):\n        \"\"\"Encourage periodicity in the solution.\"\"\"\n        repeated = np.tile(solution[:period], self.dim // period)\n        return np.sum((solution - repeated) ** 2)\n\n    def initialize_population(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        self.pop = np.random.rand(self.population_size, self.dim)\n        self.pop = self.bounds[0] + self.pop * (self.bounds[1] - self.bounds[0])\n        self.fitness = np.array([func(ind) for ind in self.pop])\n    \n    def differential_evolution(self, func):\n        F = 0.8  # Mutation factor\n        CR = 0.9  # Crossover probability\n        for generation in range(self.budget // self.population_size):\n            if generation % 10 == 0:  # Adjust periodic weight dynamically\n                self.periodic_weight *= 0.95\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = self.pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), self.bounds[0], self.bounds[1])\n                cross_points = np.random.rand(self.dim) < CR\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial_fitness = func(trial) + self.periodic_weight * self.periodic_cost(trial, 2)\n                \n                if trial_fitness < self.fitness[i]:\n                    self.fitness[i] = trial_fitness\n                    self.pop[i] = trial\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_sol = self.pop[best_idx]\n\n        def wrapped_func(x):\n            return func(x) + self.periodic_weight * self.periodic_cost(x, 2)\n\n        res = minimize(wrapped_func, best_sol, method='L-BFGS-B', bounds=[(self.bounds[0], self.bounds[1])] * self.dim)\n        if res.fun < self.fitness[best_idx]:\n            self.pop[best_idx] = res.x\n            self.fitness[best_idx] = res.fun\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        self.differential_evolution(func)\n        self.local_search(func)\n        best_idx = np.argmin(self.fitness)\n        return self.pop[best_idx]", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic algorithm incorporating a dynamic periodic weight adjustment and adaptive mutation strategy in Differential Evolution for optimizing multilayer photonic structures.", "configspace": "", "generation": 1, "fitness": 0.6164956391427943, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.616 with standard deviation 0.030. And the mean value of best solutions found was 0.294 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "6a419159-fc5c-40b4-a803-9d60b1caf635", "metadata": {"aucs": [0.5884495444329731, 0.6036822900657905, 0.657355082929619], "final_y": [0.29341199290695974, 0.32948674919932885, 0.25874947006641913]}, "mutation_prompt": null}
{"id": "ddfe4af4-2412-422e-80a5-de5e3a6782b2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim, periodic_weight=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.periodic_weight = periodic_weight\n        self.population_size = 15 * dim  # Recommended for DE\n        self.pop = None\n        self.fitness = None\n        self.bounds = None\n        \n    def periodic_cost(self, solution, period):\n        \"\"\"Encourage periodicity in the solution.\"\"\"\n        repeated = np.tile(solution[:period], self.dim // period)\n        return np.sum((solution - repeated) ** 2)\n\n    def initialize_population(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        self.pop = np.random.rand(self.population_size, self.dim)\n        self.pop = self.bounds[0] + self.pop * (self.bounds[1] - self.bounds[0])\n        self.fitness = np.array([func(ind) for ind in self.pop])\n    \n    def differential_evolution(self, func):\n        F = 0.8  # Mutation factor\n        CR = 0.9  # Crossover probability\n        for generation in range(self.budget // self.population_size):\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = self.pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), self.bounds[0], self.bounds[1])\n                cross_points = np.random.rand(self.dim) < CR\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial_fitness = func(trial) + self.periodic_weight * self.periodic_cost(trial, 2)\n                \n                if trial_fitness < self.fitness[i]:\n                    self.fitness[i] = trial_fitness\n                    self.pop[i] = trial\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_sol = self.pop[best_idx]\n\n        def wrapped_func(x):\n            return func(x) + self.periodic_weight * self.periodic_cost(x, 2)\n\n        res = minimize(wrapped_func, best_sol, method='L-BFGS-B', bounds=[(self.bounds[0], self.bounds[1])] * self.dim, options={\"ftol\": 1e-9})\n        if res.fun < self.fitness[best_idx]:\n            self.pop[best_idx] = res.x\n            self.fitness[best_idx] = res.fun\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        self.differential_evolution(func)\n        self.local_search(func)\n        best_idx = np.argmin(self.fitness)\n        return self.pop[best_idx]", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm using Differential Evolution and a periodicity-enforcing cost function, coupled with enhanced local search using BFGS, optimized for multilayer photonic structures.", "configspace": "", "generation": 1, "fitness": 0.5831218883599333, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.583 with standard deviation 0.029. And the mean value of best solutions found was 0.325 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "6a419159-fc5c-40b4-a803-9d60b1caf635", "metadata": {"aucs": [0.5463143178467329, 0.6163060352482408, 0.586745311984826], "final_y": [0.3343196429850792, 0.31479809110168966, 0.32447655065714187]}, "mutation_prompt": null}
{"id": "9d4d9855-0ddb-4b3a-a471-a189e2c015ae", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim, periodic_weight=1.0):\n        self.budget = budget\n        self.dim = dim\n        self.periodic_weight = periodic_weight\n        self.population_size = max(15 * dim, 20)  # Ensure minimum population for robustness\n        self.pop = None\n        self.fitness = None\n        self.bounds = None\n        \n    def periodic_cost(self, solution, period):\n        \"\"\"Encourage periodicity in the solution.\"\"\"\n        repeated = np.tile(solution[:period], self.dim // period)\n        return np.sum((solution - repeated) ** 2)\n\n    def initialize_population(self, func):\n        self.bounds = (func.bounds.lb, func.bounds.ub)\n        self.pop = np.random.rand(self.population_size, self.dim)\n        self.pop = self.bounds[0] + self.pop * (self.bounds[1] - self.bounds[0])\n        self.fitness = np.array([func(ind) for ind in self.pop])\n    \n    def differential_evolution(self, func):\n        F = 0.8  # Mutation factor\n        CR = 0.9  # Crossover probability\n        for generation in range(self.budget // self.population_size):\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = self.pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), self.bounds[0], self.bounds[1])\n                cross_points = np.random.rand(self.dim) < CR\n                trial = np.where(cross_points, mutant, self.pop[i])\n                trial_fitness = func(trial) + self.periodic_weight * self.periodic_cost(trial, 2)\n                \n                if trial_fitness < self.fitness[i]:\n                    self.fitness[i] = trial_fitness\n                    self.pop[i] = trial\n\n    def local_search(self, func):\n        best_idx = np.argmin(self.fitness)\n        best_sol = self.pop[best_idx]\n\n        def wrapped_func(x):\n            return func(x) + self.periodic_weight * self.periodic_cost(x, 2)\n\n        res = minimize(wrapped_func, best_sol, method='L-BFGS-B', bounds=[(self.bounds[0], self.bounds[1])] * self.dim)\n        if res.fun < self.fitness[best_idx]:\n            self.pop[best_idx] = res.x\n            self.fitness[best_idx] = res.fun\n\n    def __call__(self, func):\n        self.initialize_population(func)\n        self.differential_evolution(func)\n        self.local_search(func)\n        best_idx = np.argmin(self.fitness)\n        return self.pop[best_idx]", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic algorithm that combines Differential Evolution with a periodicity-enforcing cost function to explore and exploit the search space, fine-tuned with BFGS for optimizing multilayer photonic structures, with enhanced exploration through dynamic population adjustment based on the dimension size.", "configspace": "", "generation": 1, "fitness": 0.5847683779391524, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.585 with standard deviation 0.038. And the mean value of best solutions found was 0.328 (0. is the best) with standard deviation 0.027.", "error": "", "parent_id": "6a419159-fc5c-40b4-a803-9d60b1caf635", "metadata": {"aucs": [0.5518565635329518, 0.6374268132380498, 0.5650217570464556], "final_y": [0.36146470565247335, 0.29556201671892945, 0.3278237856371701]}, "mutation_prompt": null}
{"id": "b2c7bf8c-5a95-4f31-ba5f-33eb6333c3c4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            adaptive_mutation_factor = 0.5 + 0.5 * np.random.rand()  # Change 1\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)  # Change 2\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = (individual[i] + individual[i % period]) / 2  # Change 3\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An improved hybrid metaheuristic algorithm incorporating adaptive mutation factor and enhanced periodicity constraint enforcement for superior optimization performance.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {}, "mutation_prompt": null}
{"id": "d08b8608-4c6b-4ec7-aa90-65454fadb35a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub.ub\n        new_population = np.copy(self.population)\n        # Adjust crossover rate dynamically\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            # Introduce adaptive mutation factor\n            adaptive_mutation_factor = self.mutation_factor * (0.5 + 0.5 * np.cos(np.pi * self.func_evals / self.budget))\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tight bounds\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals with enhanced strategy\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period] * (0.9 + 0.1 * np.cos(2 * np.pi * i / self.dim))\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved HybridMetaheuristic with adaptive mutation factor and enhanced periodic constraint for better exploration and convergence.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "fea2124d-60d8-4861-a7f9-b35993e0448b", "metadata": {}, "mutation_prompt": null}
{"id": "44975a7c-2637-4408-9696-2afbdbefb8c1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            adaptive_mutation = self.mutation_factor * (0.5 + np.random.rand() * 0.5)  # Changed line\n            mutant = np.clip(a + adaptive_mutation * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic with adaptive mutation factor to enhance convergence and exploration balance.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {}, "mutation_prompt": null}
{"id": "ad255e31-953a-4cf7-b9db-5532e6204ba9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            # Adaptive mutation factor based on iteration\n            iter_factor = 1 - (self.func_evals / self.budget)\n            mutant = np.clip(a + (self.mutation_factor * iter_factor) * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An improved hybrid metaheuristic algorithm that enhances exploration via adaptive mutation in Differential Evolution for better performance in black box problems.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {}, "mutation_prompt": null}
{"id": "50bcddbb-8918-4392-9922-9aff6469e4e6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Adaptive mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic algorithm with adaptive mutation factor for improved exploration and convergence in black box optimization.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {}, "mutation_prompt": null}
{"id": "7608b999-3185-4d0a-9564-333b073f9c3e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n                trial = self.local_optimization(trial, bounds)  # Added local optimization here\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic algorithm that refines the Differential Evolution step to improve convergence and solution quality.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {}, "mutation_prompt": null}
{"id": "92add2d5-9769-4932-916b-a14bcb49ae7d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            # Adaptive mutation factor update\n            self.mutation_factor = 0.5 + 0.3 * np.sin(0.5 * np.pi * (self.func_evals / self.budget))\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic algorithm combining Differential Evolution with periodicity-encouraging constraints, local optimization, and adaptive mutation factor for enhanced exploration and exploitation in black box problems.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {}, "mutation_prompt": null}
{"id": "3b407b6d-87dc-48a4-a113-69ec2c2def99", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.85  # Adjusted mutation factor\n        self.crossover_rate = 0.85  # Adjusted crossover rate\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm with enhanced dynamic crossover and a diversity-promoting strategy to improve exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "fea2124d-60d8-4861-a7f9-b35993e0448b", "metadata": {}, "mutation_prompt": null}
{"id": "a1df2b80-2b21-43ba-ad22-6f73cb4ef2c7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            # Adaptive mutation factor\n            adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic algorithm that combines Differential Evolution with a dynamic crossover strategy, periodicity-encouraging initialization, and improved local optimization for superior exploration and exploitation in black box optimization problems, now featuring adaptive mutation factor adjustment to enhance convergence.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "fea2124d-60d8-4861-a7f9-b35993e0448b", "metadata": {}, "mutation_prompt": null}
{"id": "5c8a5182-6222-48a7-b020-ff0f320cefd6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        symmetry_indices = np.arange(0, self.dim // 2)\n        self.population[:, self.dim // 2:] = self.population[:, symmetry_indices]\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        adaptive_period = max(1, self.dim // (self.func_evals // (self.budget // 5) + 1))\n        for i in range(adaptive_period, self.dim):\n            individual[i] = individual[i % adaptive_period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm incorporating adaptive mutation and crossover rates, symmetry-based initialization, and a dynamic periodicity constraint for enhanced global and local exploration in black box optimization.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {}, "mutation_prompt": null}
{"id": "ae5a5dd3-49c1-4f7a-af58-38b06ca0473c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            # Adaptive mutation factor based on current evaluations\n            adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            # Adaptive crossover rate based on current evaluations\n            adaptive_crossover_rate = self.crossover_rate * (1 - self.func_evals / self.budget)\n            crossover_mask = np.random.rand(self.dim) < adaptive_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic algorithm that includes adaptive mutation and crossover strategies alongside periodic constraints and local optimization for improved exploration and exploitation.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {}, "mutation_prompt": null}
{"id": "989ff046-b10e-4b0c-a42b-d6c67b372781", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            self.mutation_factor = 0.5 + (np.random.rand() / 2)  # Adaptive mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm enhances Differential Evolution with periodicity-encouraging constraints, improved local optimization, and adaptive mutation factors for better exploration and exploitation in black box problems.  ", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {}, "mutation_prompt": null}
{"id": "2d955fdb-4a12-4a69-a673-e7a4e2128445", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        options = {'maxiter': min(100, self.budget - self.func_evals)}  # Adjust max iterations dynamically\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B', options=options)\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved local optimization step by adapting the maximum number of iterations based on the remaining budget for more efficient exploitation.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {}, "mutation_prompt": null}
{"id": "96c1d1db-d9ed-4ff2-bddb-94d1cadcb943", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.9  # Adjusted mutation factor for better diversity\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic with adaptive mutation factor for enhanced convergence in challenging optimization problems.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {}, "mutation_prompt": null}
{"id": "4263acc2-0fe5-4360-b45e-69ad28c1017f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        # Adjust mutation factor dynamically\n        dynamic_mutation_factor = self.mutation_factor - 0.4 * (self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + dynamic_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tight bounds\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An advanced hybrid metaheuristic that adjusts mutation dynamics and refines periodic initialization for better exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "fea2124d-60d8-4861-a7f9-b35993e0448b", "metadata": {}, "mutation_prompt": null}
{"id": "e889cb56-28f5-4a10-9ac3-2227398be828", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            # Dynamic mutation strategy\n            adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic algorithm incorporating a dynamic mutation strategy for improved exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {}, "mutation_prompt": null}
{"id": "ee68e055-a09f-4a36-a592-3f77b1615514", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            # Adaptive mutation factor\n            adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic algorithm integrating Differential Evolution with an adaptive mutation factor, periodicity constraints, and local optimization for improved exploration and exploitation in black box problems.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {}, "mutation_prompt": null}
{"id": "e2691482-53af-4bca-94eb-dca2c4eb5bb1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        # Adjust crossover and mutation rate dynamically\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        self.mutation_factor = 0.8 + 0.2 * (self.func_evals / self.budget)  # Changed line\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tight bounds\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm further enhances dynamic crossover strategies by adjusting mutation strategies based on the evaluation budget, aiming for superior performance in black-box optimization problems.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "fea2124d-60d8-4861-a7f9-b35993e0448b", "metadata": {}, "mutation_prompt": null}
{"id": "b347d4e8-d82c-4238-8722-1c4e45cb50f4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            adaptive_mutation = self.mutation_factor * (b - c) * (1 - self.func_evals / self.budget)  # Adaptive mutation\n            mutant = np.clip(a + adaptive_mutation, lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An improved hybrid metaheuristic algorithm combining Differential Evolution with tailored periodicity constraints and adaptive mutation strategy for superior performance in black box optimization problems.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {}, "mutation_prompt": null}
{"id": "de979135-4fb6-4257-b782-7f6afbbe8434", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        adaptive_mutation_factor = self.mutation_factor * (1 - 0.5 * (self.func_evals / self.budget))\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An improved hybrid metaheuristic algorithm with adaptive mutation factor and a strategic local optimization update for enhanced convergence in black box optimization tasks.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "fea2124d-60d8-4861-a7f9-b35993e0448b", "metadata": {}, "mutation_prompt": null}
{"id": "272afc9a-9d07-493a-84e7-57bf2934b429", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Adjusting mutation factor dynamically\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic with Adaptive Mutation Factor for Improved Exploration-Exploitation Balance.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {}, "mutation_prompt": null}
{"id": "adc12abf-1abb-45a1-b28e-23774bc7444d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5 * dim, 50)  # Dynamic population size adjustment\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic with dynamic population size adjustment for improved exploration.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {}, "mutation_prompt": null}
{"id": "b7d0067b-895a-48a8-b1e6-c6d553f42de8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub = bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            adaptive_factor = np.random.uniform(0.5, 1.0)  # Adaptive mutation factor\n            mutant = np.clip(a + adaptive_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            if i % 2 == 0:  # Enhanced periodicity constraint\n                individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm that integrates adaptive mutation factors and enhanced periodicity constraints for better exploration and exploitation in black box problems.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('too many values to unpack (expected 2)').", "error": "ValueError('too many values to unpack (expected 2)')", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {}, "mutation_prompt": null}
{"id": "215ad048-0bfa-49e8-af18-06b5feaec278", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic algorithm with improved local search initialization for better exploration and exploitation in black box problems.", "configspace": "", "generation": 4, "fitness": 0.9422903865526454, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.942 with standard deviation 0.015. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {"aucs": [0.9265757037193236, 0.9376832041482804, 0.9626122517903323], "final_y": [0.16485603832335616, 0.16485621164867614, 0.1648562534258209]}, "mutation_prompt": null}
{"id": "1bdbaba6-139b-40a5-a116-c3e6b24b0a3f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8  # Original fixed mutation factor\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        diversity = np.std(self.population)  # Estimate population diversity\n        self.mutation_factor = 0.5 + 0.5 * (diversity / np.mean(np.abs(self.population)))  # Dynamic mutation factor\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved HybridMetaheuristic by adjusting the mutation factor dynamically based on population diversity to better balance exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.9412045230930524, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.016. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {"aucs": [0.9233181133405446, 0.9376832041482804, 0.9626122517903323], "final_y": [0.16485603832335616, 0.16485621164867614, 0.1648562534258209]}, "mutation_prompt": null}
{"id": "dc4efb0e-02f1-44ab-a892-5b5d07d166ae", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        # Adaptive mutation factor\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tight bounds\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Improved periodic constraint for better symmetry\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic algorithm integrating adaptive mutation and improved periodic constraints for optimized exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 4, "fitness": 0.9599576292212504, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.016. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fea2124d-60d8-4861-a7f9-b35993e0448b", "metadata": {"aucs": [0.977721971775278, 0.9395386640981411, 0.9626122517903323], "final_y": [0.16485621120421234, 0.16485621164867614, 0.1648562534258209]}, "mutation_prompt": null}
{"id": "580180ad-d316-408b-a3c5-3cc1eaa92cda", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            # Change made: Adaptive mutation factor based on current progress\n            self.mutation_factor = 0.5 + 0.3 * (1 - self.func_evals / self.budget)\n            mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An improved hybrid metaheuristic algorithm that combines Differential Evolution with periodicity-encouraging constraints, adaptive mutation factor, and local optimization for enhanced exploration and exploitation in black box problems.", "configspace": "", "generation": 4, "fitness": 0.9422723605299225, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.942 with standard deviation 0.015. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {"aucs": [0.9265216256511549, 0.9376832041482804, 0.9626122517903323], "final_y": [0.16485603832335616, 0.16485621164867614, 0.1648562534258209]}, "mutation_prompt": null}
{"id": "663a6081-56b0-4f6f-b246-3411a4ad46b8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.85  # Adjusted mutation factor for improved performance\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic algorithm with a refined DE mutation factor for better exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.940332359343488, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.940 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "706f912e-2268-4fb5-b31a-b63727ef13a9", "metadata": {"aucs": [0.9207016220918516, 0.9376832041482804, 0.9626122517903323], "final_y": [0.16485603832335616, 0.16485621164867614, 0.1648562534258209]}, "mutation_prompt": null}
{"id": "2a29955c-b8e2-4c2a-a8c4-1d84ab6d974f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        # Self-adaptive mutation and crossover rates\n        self.mutation_factor = 0.5 + 0.5 * np.sin(np.pi * self.func_evals / self.budget)\n        self.crossover_rate = 0.5 + 0.5 * np.cos(np.pi * self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + self.mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm integrating self-adaptive mutation and crossover rates to enhance exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 4, "fitness": 0.9468064031086696, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fea2124d-60d8-4861-a7f9-b35993e0448b", "metadata": {"aucs": [0.9401237533873961, 0.9376832041482804, 0.9626122517903323], "final_y": [0.16485603832335616, 0.16485621164867614, 0.1648562534258209]}, "mutation_prompt": null}
{"id": "224332de-7dd8-4384-96de-9859a16a7bd5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        # Adjust crossover rate dynamically\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        dynamic_mutation_factor = self.mutation_factor + 0.4 * (self.func_evals / self.budget)  # Changed line\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + dynamic_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tight bounds\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm that combines Differential Evolution with a dynamically adaptive mutation factor, periodicity-encouraging initialization, and improved local optimization for superior exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 4, "fitness": 0.9517214091114643, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.952 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fea2124d-60d8-4861-a7f9-b35993e0448b", "metadata": {"aucs": [0.9548687713957801, 0.9376832041482804, 0.9626122517903323], "final_y": [0.16485603832335616, 0.16485621164867614, 0.1648562534258209]}, "mutation_prompt": null}
{"id": "61ef93ee-e6ff-45b0-9daf-a6f46376f59b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        # Adjust crossover rate dynamically\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        dynamic_mutation_factor = self.mutation_factor + 0.5 * (self.func_evals / self.budget)  # Changed line\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + dynamic_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tight bounds\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm that combines Differential Evolution with a dynamically adaptive mutation factor, periodicity-encouraging initialization, improved local optimization, and slightly boosted mutation for enhanced exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "224332de-7dd8-4384-96de-9859a16a7bd5", "metadata": {}, "mutation_prompt": null}
{"id": "5b179c38-eb3c-47ac-848f-5d59993e97f8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        # Adjust crossover rate dynamically\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)  # Changed line\n        dynamic_mutation_factor = self.mutation_factor + 0.6 * (self.func_evals / self.budget)  # Changed line\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + dynamic_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tight bounds\n        result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='L-BFGS-B')  # Changed line\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = 0.5 * (individual[i % period] + individual[(i + 1) % period])  # Changed line\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic algorithm enhancing periodicity constraints and dynamic parameter adaptation for optimized exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "224332de-7dd8-4384-96de-9859a16a7bd5", "metadata": {}, "mutation_prompt": null}
{"id": "4defe9ae-02e7-456e-bc4d-800a37c1710b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = int(8 * dim * (1 + np.log(1 + dim)))  # Dynamically adjusted population size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget) * (1 + 0.1 * np.random.randn())  # Refined adaptive mutation\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n        \n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "An optimized hybrid metaheuristic algorithm introducing more refined adaptive mutation and a dynamic population size for improved search efficiency in black box optimization problems.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "dc4efb0e-02f1-44ab-a892-5b5d07d166ae", "metadata": {}, "mutation_prompt": null}
{"id": "c95465bc-9635-4ec4-aecc-c88f098d6a96", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        # Adaptive mutation factor\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tight bounds\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Adaptive periodic constraint for enhanced symmetry\n        period = self.dim // 3\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period] * (1 + 0.01 * np.sin(2 * np.pi * i / period))\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic with adaptive periodic constraints and improved selection mechanism for better convergence.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "dc4efb0e-02f1-44ab-a892-5b5d07d166ae", "metadata": {}, "mutation_prompt": null}
{"id": "d7c8a376-119a-433a-aa9e-d172f89bf793", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        # Adjust crossover rate dynamically\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        dynamic_mutation_factor = self.mutation_factor + 0.4 * (self.func_evals / self.budget)  # Changed line\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + dynamic_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization strategy\n        result = minimize(self.func, x0, bounds=np.array([0.8 * lb + 0.2 * x0, 0.8 * ub + 0.2 * x0]).T, method='L-BFGS-B')  # Changed line\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An incrementally enhanced hybrid metaheuristic algorithm with a dynamically adjusted local optimization strategy for fine-tuning near-optimal solutions in black box optimization problems.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "224332de-7dd8-4384-96de-9859a16a7bd5", "metadata": {}, "mutation_prompt": null}
{"id": "0bf1e819-310e-46f8-b307-1949b9f417dd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * np.sqrt(1 - self.func_evals / self.budget)  # Improved scale\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n        # Dynamic population size adjustment\n        if self.func_evals < self.budget / 2:\n            self.population_size = max(5, int(0.8 * self.population_size))\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic algorithm with improved adaptive mutation factor scaling and dynamic population size adjustment for optimized exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "dc4efb0e-02f1-44ab-a892-5b5d07d166ae", "metadata": {}, "mutation_prompt": null}
{"id": "526e0771-cc0e-45af-8cac-f2937269649a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        # Adjust crossover rate dynamically\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        dynamic_mutation_factor = self.mutation_factor + 0.4 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + dynamic_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with adaptive weights\n        alpha = 0.7  # Alpha can be tuned further\n        result = minimize(self.func, x0, bounds=np.array([alpha * lb + (1-alpha) * x0, alpha * ub + (1-alpha) * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic algorithm integrating adaptive weights in local optimization to enhance solution fine-tuning.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "224332de-7dd8-4384-96de-9859a16a7bd5", "metadata": {}, "mutation_prompt": null}
{"id": "f9bb6232-2a0f-42ef-927c-564b9b1ff210", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        dynamic_mutation_factor = self.mutation_factor + 0.4 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + dynamic_mutation_factor * (b - c) + np.random.normal(0, 0.1, size=self.dim), lb, ub)  # Added diversity\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def adaptive_population_resize(self):\n        factor = 1 + (0.5 * (self.func_evals / self.budget))  # Adaptive resizing\n        self.population_size = int(self.population_size * factor)\n        self.population_size = max(4, min(self.population_size, 20 * self.dim))  # Maintain reasonable limits\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            self.adaptive_population_resize()  # Call to resize population\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic algorithm that introduces diversity boosting strategies and adaptive population resizing for improved convergence in black box optimization problems.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "224332de-7dd8-4384-96de-9859a16a7bd5", "metadata": {}, "mutation_prompt": null}
{"id": "1136ce3a-77e0-455d-8bf0-855943da0cba", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        # Adjust crossover rate dynamically\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        dynamic_mutation_factor = self.mutation_factor + 0.4 * (self.func_evals / self.budget)  # Changed line\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + dynamic_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tighter bounds\n        result = minimize(self.func, x0, bounds=np.array([0.8 * lb + 0.2 * x0, 0.8 * ub + 0.2 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "The algorithm introduces a refined local optimization strategy by slightly increasing the influence of the current solution in the optimization bounds for more effective exploitation.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "224332de-7dd8-4384-96de-9859a16a7bd5", "metadata": {}, "mutation_prompt": null}
{"id": "4af128b2-0b01-41c0-98be-862583baa306", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        dynamic_mutation_factor = self.mutation_factor + 0.4 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + dynamic_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        scale_factor = 0.8 + 0.2 * (self.func_evals / self.budget)  # Added line\n        result = minimize(self.func, x0, bounds=np.array([scale_factor * lb + (1 - scale_factor) * x0, scale_factor * ub + (1 - scale_factor) * x0]).T, method='L-BFGS-B')  # Modified line\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved HybridMetaheuristic with enhanced local optimization through dynamic scaling to maintain optimal exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "224332de-7dd8-4384-96de-9859a16a7bd5", "metadata": {}, "mutation_prompt": null}
{"id": "191927be-99fd-4759-8d34-96f9b654f9b7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        # Adaptive mutation factor\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        # Modified dynamic crossover rate\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tight bounds\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Enhanced periodic constraint for improved symmetry\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = 0.5 * (individual[i] + individual[i % period])\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic algorithm integrating adaptive crossover rate and improved periodic constraints for optimized exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "dc4efb0e-02f1-44ab-a892-5b5d07d166ae", "metadata": {}, "mutation_prompt": null}
{"id": "4ad8b6c4-b362-42a0-9f07-58f80ba8c22a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        dynamic_mutation_factor = self.mutation_factor + 0.4 * (self.func_evals / self.budget)\n        self.population_size = max(4, int(self.population_size * (1 - 0.1 * (self.func_evals / self.budget))))  # Changed line\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + dynamic_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm that introduces adaptive population size reduction in Differential Evolution, dynamically adjusting exploration and exploitation throughout the optimization process.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "224332de-7dd8-4384-96de-9859a16a7bd5", "metadata": {}, "mutation_prompt": null}
{"id": "4c7e78b2-1590-4955-8766-1c2b4e199bc6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        # Adjust crossover rate dynamically\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        dynamic_mutation_factor = self.mutation_factor + 0.4 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + dynamic_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tighter bounds\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An advanced hybrid metaheuristic algorithm that optimizes exploration and exploitation through adaptive mutation and crossover, improving local search leveraging deep periodicity insights in multilayer structures.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "224332de-7dd8-4384-96de-9859a16a7bd5", "metadata": {}, "mutation_prompt": null}
{"id": "68e86665-e76d-4656-8011-f8a86fff7281", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.85  # Changed line\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        dynamic_mutation_factor = self.mutation_factor + 0.35 * (self.func_evals / self.budget)  # Changed line\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + dynamic_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm with enhanced local exploration using a hybrid crossover and mutation strategy, improving exploration-exploitation balance in black box optimization problems.", "configspace": "", "generation": 6, "fitness": 0.9403059504754605, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.940 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "224332de-7dd8-4384-96de-9859a16a7bd5", "metadata": {"aucs": [0.9273865964085195, 0.9433859217186814, 0.9501453332991805], "final_y": [0.16485603832335616, 0.164856454672896, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "31bb24ca-ac48-47a9-b58f-bb43019e15e5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        # Adaptive mutation factor\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with dynamic boundary adjustment\n        dyn_lb = np.maximum(lb, x0 - 0.1 * (ub - lb))\n        dyn_ub = np.minimum(ub, x0 + 0.1 * (ub - lb))\n        result = minimize(self.func, x0, bounds=np.array([dyn_lb, dyn_ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Improved periodic constraint for better symmetry\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm with enhanced local exploitation through dynamic boundary adjustment in local optimization for improved convergence in black box optimization problems.", "configspace": "", "generation": 6, "fitness": 0.9568968077644319, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.957 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dc4efb0e-02f1-44ab-a892-5b5d07d166ae", "metadata": {"aucs": [0.9707127314819518, 0.943385805410935, 0.9565918864004089], "final_y": [0.1648585498936932, 0.164856454672896, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "566175bb-021d-4e96-8fa8-cc2556b4e3d5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        # Adjust crossover rate dynamically\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        dynamic_mutation_factor = self.mutation_factor + 0.4 * (self.func_evals / self.budget)  # Changed line\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + dynamic_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tighter bounds\n        result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm with an enhanced local optimization strategy using tighter bounds for better exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 6, "fitness": 0.9408171402308977, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "224332de-7dd8-4384-96de-9859a16a7bd5", "metadata": {"aucs": [0.922473728881349, 0.943385805410935, 0.9565918864004089], "final_y": [0.16485603832335616, 0.164856454672896, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "fc0a250b-49e3-4e2a-820b-8333ef6373d1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        # Adjust crossover rate dynamically\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        dynamic_mutation_factor = self.mutation_factor + 0.4 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + dynamic_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tight bounds\n        adaptive_bounds = np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T\n        result = minimize(self.func, x0, bounds=adaptive_bounds, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced local optimization strategy with adaptive bounds to improve solution refinement in high-performance regions.", "configspace": "", "generation": 6, "fitness": 0.9408171402308977, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "224332de-7dd8-4384-96de-9859a16a7bd5", "metadata": {"aucs": [0.922473728881349, 0.943385805410935, 0.9565918864004089], "final_y": [0.16485603832335616, 0.164856454672896, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "ff1f3352-5ddc-4ec9-b4b7-73342d8851b2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        # Adjust crossover rate dynamically\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        dynamic_mutation_factor = self.mutation_factor + 0.4 * (self.func_evals / self.budget)  # Changed line\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + dynamic_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tight bounds\n        result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='L-BFGS-B')  # Changed line\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced local optimization by refining the search area bounds, improving convergence speed for better solutions.", "configspace": "", "generation": 6, "fitness": 0.9408171402308977, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "224332de-7dd8-4384-96de-9859a16a7bd5", "metadata": {"aucs": [0.922473728881349, 0.943385805410935, 0.9565918864004089], "final_y": [0.16485603832335616, 0.164856454672896, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "169da925-4b57-464a-95d4-bcabe344425f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        # Adjust crossover rate dynamically\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        dynamic_mutation_factor = self.mutation_factor + 0.6 * (self.func_evals / self.budget)  # Changed line\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + dynamic_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tighter bounds\n        result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='L-BFGS-B')  # Changed line\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Encouraging periodic signals\n        period = self.dim // 2\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm that dynamically adjusts mutation and crossover parameters and integrates improved local optimization strategies to enhance exploration and exploitation efficiency in black box optimization problems.", "configspace": "", "generation": 6, "fitness": 0.9420633625679377, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.942 with standard deviation 0.012. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "224332de-7dd8-4384-96de-9859a16a7bd5", "metadata": {"aucs": [0.9262123958924691, 0.943385805410935, 0.9565918864004089], "final_y": [0.16485603832335616, 0.164856454672896, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "8ebde92e-9927-4081-9a72-03256ec33cf5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        # Adaptive mutation factor\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)  # Changed from 0.5 to 0.3\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tight bounds\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Improved periodic constraint for better symmetry\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm with a dynamically adaptive crossover rate and enhanced periodicity enforcement for improved exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 6, "fitness": 0.9592332211955407, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dc4efb0e-02f1-44ab-a892-5b5d07d166ae", "metadata": {"aucs": [0.977721971775278, 0.943385805410935, 0.9565918864004089], "final_y": [0.16485621120421234, 0.164856454672896, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "90258bcc-6cc6-4999-b89a-9aaedbca6f23", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        # Adaptive mutation factor\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.5 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tight bounds\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Diversified periodic constraint for enhanced exploration\n        period = self.dim // 5\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n            # Elitism strategy integration for better convergence\n            self.population[np.argmax([self.evaluate(ind) for ind in self.population])] = best_solution\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic algorithm with diversified periodic constraints and improved convergence through elitism strategy integration.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "dc4efb0e-02f1-44ab-a892-5b5d07d166ae", "metadata": {}, "mutation_prompt": null}
{"id": "076373e4-97c0-4476-ac44-93f86b183bc0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        # Adaptive mutation factor\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)  # Changed from 0.5 to 0.3\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tighter bounds\n        result = minimize(self.func, x0, bounds=np.array([0.8 * lb + 0.2 * x0, 0.8 * ub + 0.2 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm with a dynamically adaptive crossover rate and enhanced periodicity enforcement for improved exploration and exploitation in black box optimization problems, now with a more aggressive local optimization step.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "8ebde92e-9927-4081-9a72-03256ec33cf5", "metadata": {}, "mutation_prompt": null}
{"id": "936a1359-a9b7-43ed-8289-56dc6f052756", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        # Adaptive mutation factor\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)  # Changed from 0.5 to 0.3\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tight bounds\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Improved periodic constraint for better symmetry, with a smaller period\n        period = self.dim // 5\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm with adaptive mutation factor and custom periodicity enforcement for enhanced exploration and exploitation in black box optimization problems.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "8ebde92e-9927-4081-9a72-03256ec33cf5", "metadata": {}, "mutation_prompt": null}
{"id": "90bbc307-6d0f-45d0-8c27-4a82e0f738d2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        # Adaptive mutation factor\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)  # Changed from 0.5 to 0.3\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Improved periodic constraint for better symmetry\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = 0.5 * (individual[i] + individual[i % period])  # Modified for better adaptation\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An optimized hybrid metaheuristic algorithm with improved periodic adaptation and dynamic mutation for enhanced search and exploitation in black box optimization problems.", "configspace": "", "generation": 7, "fitness": 0.9806071463619759, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.981 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8ebde92e-9927-4081-9a72-03256ec33cf5", "metadata": {"aucs": [0.9697553266012099, 0.9881159643692903, 0.9839501481154274], "final_y": [0.1648561624523186, 0.16485635309376245, 0.1648562964871383]}, "mutation_prompt": null}
{"id": "a0bde664-ae93-4b7e-8484-b38f991520dd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - 0.5 * self.func_evals / self.budget)  # Adjusted\n        dynamic_crossover_rate = self.crossover_rate - 0.25 * (self.func_evals / self.budget)  # Adjusted\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='L-BFGS-B')  # Adjusted\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 2  # Adjusted\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "This refined hybrid metaheuristic algorithm introduces an adaptive mutation strategy and enhanced periodicity constraints to optimize exploration and exploitation in black box optimization problems more effectively.", "configspace": "", "generation": 7, "fitness": 0.9648465934056768, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.030. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dc4efb0e-02f1-44ab-a892-5b5d07d166ae", "metadata": {"aucs": [0.922473728881349, 0.9881159032202541, 0.9839501481154274], "final_y": [0.16485603832335616, 0.16485635309376245, 0.1648562964871383]}, "mutation_prompt": null}
{"id": "3f7ed15a-f5f4-4d67-83ed-fbc486b1420c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - 0.5 * np.sin(self.func_evals * (np.pi / self.budget)))  # Change here\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Enhanced local optimization with dynamic bounds adjustment\n        factor = 0.9 + 0.1 * np.cos(self.func_evals * (np.pi / self.budget))  # Change here\n        result = minimize(self.func, x0, bounds=np.array([factor * lb + (1 - factor) * x0, factor * ub + (1 - factor) * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm with dynamically adaptive mutation and enhanced local search for improved convergence in black box optimization problems.", "configspace": "", "generation": 7, "fitness": 0.9819552029895148, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.982 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8ebde92e-9927-4081-9a72-03256ec33cf5", "metadata": {"aucs": [0.9737994964838269, 0.9881159643692903, 0.9839501481154274], "final_y": [0.16485613963366308, 0.16485635309376245, 0.1648562964871383]}, "mutation_prompt": null}
{"id": "6200d9c9-6ea2-46e9-8f5d-c9e712ab651b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        # Adaptive mutation factor\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)  # Changed from 0.5 to 0.3\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Improved local optimization with tight bounds\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        # Improved periodic constraint for better symmetry\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic algorithm integrating adaptive strategy adjustment and periodicity reinforcement for improved solution quality in black box optimization problems.", "configspace": "", "generation": 7, "fitness": 0.9704014568445339, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.015. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8ebde92e-9927-4081-9a72-03256ec33cf5", "metadata": {"aucs": [0.977721971775278, 0.9495322506428964, 0.9839501481154274], "final_y": [0.16485621120421234, 0.16485630379449578, 0.1648562964871383]}, "mutation_prompt": null}
{"id": "199ce9a6-6172-4607-ac62-86778d895742", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)  # Adjusted crossover rate change\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 3  # Improved periodic constraint for better symmetry\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with improved adaptive crossover rate and periodic initialization for optimized exploration and exploitation.", "configspace": "", "generation": 7, "fitness": 0.9817288751901486, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.982 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "dc4efb0e-02f1-44ab-a892-5b5d07d166ae", "metadata": {"aucs": [0.9731205130857281, 0.9881159643692903, 0.9839501481154274], "final_y": [0.1648559456794625, 0.16485635309376245, 0.1648562964871383]}, "mutation_prompt": null}
{"id": "5082e51d-1a99-47de-9dfa-0f08e40fed6e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')  # Enhanced local search\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An advanced hybrid metaheuristic algorithm integrating adaptive population sizing and enhanced local search techniques for improved efficiency and accuracy in solving black box optimization tasks.", "configspace": "", "generation": 7, "fitness": 0.982179126076622, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.982 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8ebde92e-9927-4081-9a72-03256ec33cf5", "metadata": {"aucs": [0.9744712657451483, 0.9881159643692903, 0.9839501481154274], "final_y": [0.16485621120421234, 0.16485635309376245, 0.1648562964871383]}, "mutation_prompt": null}
{"id": "6c170155-7ae8-403a-8a94-b1bcd10c6ce1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='L-BFGS-B')  # Adjusted tighter bounds\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 3  # Adjusted period for better symmetry\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An improved hybrid metaheuristic with adaptive learning rate and enhanced local exploration for better convergence in black box optimization.", "configspace": "", "generation": 7, "fitness": 0.9761972324473179, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.976 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8ebde92e-9927-4081-9a72-03256ec33cf5", "metadata": {"aucs": [0.9565255848572364, 0.9881159643692903, 0.9839501481154274], "final_y": [0.16485631692539815, 0.16485635309376245, 0.1648562964871383]}, "mutation_prompt": null}
{"id": "5e41c455-f360-4c9c-ad38-5a59174a1174", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 + 0.2 * np.cos(self.func_evals * (np.pi / self.budget)))  # Change here\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Enhanced local optimization with dynamic bounds adjustment\n        factor = 0.9 + 0.1 * np.cos(self.func_evals * (np.pi / self.budget))\n        result = minimize(self.func, x0, bounds=np.array([factor * lb + (1 - factor) * x0, factor * ub + (1 - factor) * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm with adaptive mutation using cosine-based modulation for improved convergence in black box optimization problems.", "configspace": "", "generation": 8, "fitness": 0.9719149104410102, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.972 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3f7ed15a-f5f4-4d67-83ed-fbc486b1420c", "metadata": {"aucs": [0.9740242589669025, 0.9721403675907371, 0.9695801047653912], "final_y": [0.16485613963366308, 0.16485624815985456, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "1c68e6c9-727e-4a2c-a1f3-9c3c3aa32395", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.9  # Adjusted mutation factor\n        self.crossover_rate = 0.85  # Adjusted crossover rate\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic algorithm using adaptive mutation and crossover strategies with periodic constraints for optimal convergence in black box optimization tasks.", "configspace": "", "generation": 8, "fitness": 0.9699422488131129, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5082e51d-1a99-47de-9dfa-0f08e40fed6e", "metadata": {"aucs": [0.9681062740832103, 0.9721403675907371, 0.9695801047653912], "final_y": [0.16485603318465036, 0.16485624815985456, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "48a7dbd5-8632-4aaa-8081-7af39783f506", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.9  # Changed from 0.8\n        self.crossover_rate = 0.85  # Changed from 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - 0.5 * np.sin(self.func_evals * (np.pi / self.budget)))\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        factor = 0.9 + 0.1 * np.cos(self.func_evals * (np.pi / self.budget))\n        result = minimize(self.func, x0, bounds=np.array([factor * lb + (1 - factor) * x0, factor * ub + (1 - factor) * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = (individual[i] + individual[i % period]) / 2  # Refined periodic constraint\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic incorporating adaptive learning for population diversity and refined periodic constraints to boost convergence in black box optimization problems.", "configspace": "", "generation": 8, "fitness": 0.9702759620922817, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3f7ed15a-f5f4-4d67-83ed-fbc486b1420c", "metadata": {"aucs": [0.9691074139207166, 0.9721403675907371, 0.9695801047653912], "final_y": [0.16485626992055968, 0.16485624815985456, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "2d153a17-162d-4e79-959b-8a6736ab1cd7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - 0.5 * np.sin(self.func_evals * (np.pi / self.budget)))\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        factor = 0.9 + 0.1 * np.cos(self.func_evals * (np.pi / self.budget))\n        result = minimize(self.func, x0, bounds=np.array([factor * lb + (1 - factor) * x0, factor * ub + (1 - factor) * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 2 + self.func_evals % 2  # Change here\n        for i in range(period, self.dim):  # Change here\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm with enhanced adaptive strategies and periodicity constraints for improved convergence in black box optimization problems.", "configspace": "", "generation": 8, "fitness": 0.9588923305361369, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3f7ed15a-f5f4-4d67-83ed-fbc486b1420c", "metadata": {"aucs": [0.9418249143796488, 0.9721403675907371, 0.9627117096380249], "final_y": [0.16485638094671184, 0.16485624815985456, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "d65eb77b-f138-4102-b4b0-4a2b5fff32ba", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - 0.5 * np.sin(self.func_evals * (np.pi / self.budget)))  # Change here\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Enhanced local optimization with dynamic bounds adjustment\n        factor = 0.9 + 0.1 * np.cos(self.func_evals * (np.pi / self.budget))  # Change here\n        result = minimize(self.func, x0, bounds=np.array([factor * lb + (1 - factor) * x0, factor * ub + (1 - factor) * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period] * (1 + 0.1 * np.sin(i))  # Adjusted periodic constraint\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm with dynamically adaptive mutation, enhanced local search, and improved periodic constraints for better convergence in black box optimization problems.", "configspace": "", "generation": 8, "fitness": 0.9717430814777049, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.972 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3f7ed15a-f5f4-4d67-83ed-fbc486b1420c", "metadata": {"aucs": [0.9735087720769864, 0.9721403675907371, 0.9695801047653912], "final_y": [0.16485612997891574, 0.16485624815985456, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "27c7835f-4d20-4cfd-a672-a39dc7bf6c59", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        diversity_factor = np.std(self.population, axis=0).mean()  # Calculate population diversity\n        dynamic_crossover_rate = self.crossover_rate * (0.5 + diversity_factor)  # Adapt crossover rate\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')  # Enhanced local search\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced diversity through adaptive crossover rates based on population diversity.", "configspace": "", "generation": 8, "fitness": 0.9821195033711018, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.982 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5082e51d-1a99-47de-9dfa-0f08e40fed6e", "metadata": {"aucs": [0.9885381976647724, 0.9721403675907371, 0.9856799448577959], "final_y": [0.16485621120421234, 0.16485624815985456, 0.16485592396169546]}, "mutation_prompt": null}
{"id": "faa4cdee-a949-4110-917a-d8a4b06f31c9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')  # Enhanced local search\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = max(self.dim // 4, 2)  # Ensure minimum period\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic algorithm incorporating adaptive periodicity scaling and refined local search for improved convergence efficiency. ", "configspace": "", "generation": 8, "fitness": 0.9731474813771355, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5082e51d-1a99-47de-9dfa-0f08e40fed6e", "metadata": {"aucs": [0.977721971775278, 0.9721403675907371, 0.9695801047653912], "final_y": [0.16485621120421234, 0.16485624815985456, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "0f151fc5-65a3-4a67-901f-f6f580ebda30", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - 0.5 * np.sin(self.func_evals * (np.pi / self.budget)))\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        factor = 0.95 + 0.05 * np.cos(self.func_evals * (np.pi / self.budget))  # Change 1: Adjusted factor\n        result = minimize(self.func, x0, bounds=np.array([factor * lb + (1 - factor) * x0, factor * ub + (1 - factor) * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        if np.random.rand() < 0.1:  # Change 2: Periodicity mutation chance\n            individual = np.roll(individual, np.random.randint(1, period))  # Change 3: Random roll\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Refined hybrid metaheuristic with enhanced adaptive periodicity and local search balance for improved reflectivity optimization.", "configspace": "", "generation": 8, "fitness": 0.9728534061257896, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3f7ed15a-f5f4-4d67-83ed-fbc486b1420c", "metadata": {"aucs": [0.9768397460212407, 0.9721403675907371, 0.9695801047653912], "final_y": [0.1648560883046991, 0.16485624815985456, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "9a46951e-90da-49b9-b537-0987e8d1dbd0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        # Periodicity-encouraging initialization\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - 0.5 * np.sin(self.func_evals * (np.pi / self.budget)))  # Change here\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            oscillation_factor = np.cos(self.func_evals * (2 * np.pi / self.budget))  # Added line\n            mutant = np.clip(a + oscillation_factor * adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        # Enhanced local optimization with dynamic bounds adjustment\n        factor = 0.9 + 0.1 * np.cos(self.func_evals * (np.pi / self.budget))  # Change here\n        result = minimize(self.func, x0, bounds=np.array([factor * lb + (1 - factor) * x0, factor * ub + (1 - factor) * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced the mutation strategy by introducing time-varying adaptive oscillations to explore the search space more effectively.", "configspace": "", "generation": 8, "fitness": 0.9725921107181907, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3f7ed15a-f5f4-4d67-83ed-fbc486b1420c", "metadata": {"aucs": [0.976055859798444, 0.9721403675907371, 0.9695801047653912], "final_y": [0.16485613963366308, 0.16485624815985456, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "b5957ae8-a9e5-4dbf-9279-98ba48dfe1df", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.mutation_factor = 0.9  # Changed from 0.8 to 0.9\n        self.crossover_rate = 0.85  # Changed from 0.9 to 0.85\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - 0.3 * np.sin(self.func_evals * (np.pi / self.budget)))  # Change here\n        dynamic_crossover_rate = self.crossover_rate - 0.25 * (self.func_evals / self.budget)  # Change here\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        factor = 0.9 + 0.15 * np.cos(self.func_evals * (np.pi / self.budget))  # Change here\n        result = minimize(self.func, x0, bounds=np.array([factor * lb + (1 - factor) * x0, factor * ub + (1 - factor) * x0]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic with adaptive differential evolution and improved local search utilizing periodicity to solve complex black box optimization problems.", "configspace": "", "generation": 8, "fitness": 0.9749239809356465, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3f7ed15a-f5f4-4d67-83ed-fbc486b1420c", "metadata": {"aucs": [0.9830514704508112, 0.9721403675907371, 0.9695801047653912], "final_y": [0.16485613963366308, 0.16485624815985456, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "3ba71da0-96a8-4a99-bac3-ae9a24187222", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        adaptive_mutation_factor += 0.2 * np.sin(self.func_evals / self.budget * np.pi)  # Dynamic modulation\n        diversity_factor = np.std(self.population, axis=0).mean()  # Calculate population diversity\n        dynamic_crossover_rate = self.crossover_rate * (0.5 + diversity_factor)  # Adapt crossover rate\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')  # Enhanced local search\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic algorithm leveraging adaptive exploration-exploitation balance through dynamic mutation factor modulation.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "27c7835f-4d20-4cfd-a672-a39dc7bf6c59", "metadata": {}, "mutation_prompt": null}
{"id": "7610dd22-d597-4f7a-b59d-ea3ff74958d7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')  # Enhanced local search\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 6  # Adjusted for more diverse periodicity\n        for i in range(period, self.dim):\n            individual[i] = 0.5 * (individual[i] + individual[i % period])  # Symbiotic evolution\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced symbiotic evolution and enhanced periodic constraints to improve exploration and convergence in multilayer optimization.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "5082e51d-1a99-47de-9dfa-0f08e40fed6e", "metadata": {}, "mutation_prompt": null}
{"id": "23251c51-5e1b-498e-bc00-30dcece243be", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        if np.random.rand() < 0.5:  # Adaptive local search frequency\n            return x0\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')  # Enhanced local search\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            if np.random.rand() < 0.8:  # Selective relaxation in periodic constraints\n                individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Introducing adaptive local search frequency and selective relaxation in periodic constraints for enhanced solution exploration.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "5082e51d-1a99-47de-9dfa-0f08e40fed6e", "metadata": {}, "mutation_prompt": null}
{"id": "81dddaa3-be0a-45d9-960c-5980c0ffe226", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        diversity_factor = np.std(self.population, axis=0).mean()  # Calculate population diversity\n        dynamic_crossover_rate = self.crossover_rate * (0.5 + diversity_factor)  # Adapt crossover rate\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        if np.linalg.norm(self.func(x0)) > 1e-6:  # Gradient check to avoid unnecessary calls\n            result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n            if not result.success:\n                result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')  # Enhanced local search\n            return result.x if result.success else x0\n        return x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved local search efficiency by introducing a gradient check during local optimization to prevent unnecessary calls to minimize.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "27c7835f-4d20-4cfd-a672-a39dc7bf6c59", "metadata": {}, "mutation_prompt": null}
{"id": "282dbb2c-5cde-4aab-88b2-91bfbec4e743", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / (2 * self.budget))  # Change 1\n        diversity_factor = np.std(self.population, axis=0).mean()\n        dynamic_crossover_rate = self.crossover_rate * (0.5 + diversity_factor)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c + np.random.rand(self.dim)), lb, ub)  # Change 2\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // (4 + int(2 * np.sin(np.pi * self.func_evals / self.budget)))  # Change 3\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhances diversity and periodicity through dynamic mutation strategies and adaptive periodic constraints for improved black-box optimization.", "configspace": "", "generation": 9, "fitness": 0.964427315257291, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.021. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "27c7835f-4d20-4cfd-a672-a39dc7bf6c59", "metadata": {"aucs": [0.9847141743167307, 0.9361717109349446, 0.9723960605201976], "final_y": [0.16485619318133227, 0.16485621164867614, 0.1648562534258209]}, "mutation_prompt": null}
{"id": "3d4684fd-af66-494f-9f69-0a7b951766ed", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n        self.archive = []  # Archive to store elite solutions\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        diversity_factor = np.std(self.population, axis=0).mean()  # Calculate population diversity\n        dynamic_crossover_rate = self.crossover_rate * (0.5 + diversity_factor)  # Adapt crossover rate\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n        self.dynamic_resize_population()  # Adjust the population size dynamically\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        value = self.func(individual)\n        self.archive.append((value, individual))  # Maintain an archive of evaluated solutions\n        return value\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')  # Enhanced local search\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def dynamic_resize_population(self):  # New function to dynamically resize population\n        if self.func_evals < self.budget / 2:\n            self.population_size = int(self.initial_population_size * (1 + 0.1 * np.sin(2 * np.pi * self.func_evals / self.budget)))\n        elif self.func_evals > 3 * self.budget / 4:\n            self.population_size = max(5, int(self.population_size * 0.9))\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        self.archive.sort()  # Sort archive based on function values\n        elite_solution = self.archive[0][1]  # Extract the best from archive\n        return elite_solution", "name": "HybridMetaheuristic", "description": "Incorporating dynamic population resizing and strategic archive-based elitism to enhance exploration and exploitation balance in optimization.", "configspace": "", "generation": 9, "fitness": 0.9662120434147413, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.021. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "27c7835f-4d20-4cfd-a672-a39dc7bf6c59", "metadata": {"aucs": [0.9885381976647724, 0.9377018720592539, 0.9723960605201976], "final_y": [0.16485621120421234, 0.16485621164867614, 0.1648562534258209]}, "mutation_prompt": null}
{"id": "1aa65a2c-5583-4e2f-a77e-a93354cf8c74", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget) * (self.evaluate(a) / self.evaluate(b))\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')  # Enhanced local search\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved diversity through adaptive mutation factors based on individual performance.", "configspace": "", "generation": 9, "fitness": 0.9658462728934883, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.022. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5082e51d-1a99-47de-9dfa-0f08e40fed6e", "metadata": {"aucs": [0.988971047225323, 0.9361717109349446, 0.9723960605201976], "final_y": [0.16485589480274299, 0.16485621164867614, 0.1648562534258209]}, "mutation_prompt": null}
{"id": "66c05c35-27eb-4104-ba43-133d56069ae7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        diversity_factor = np.std(self.population, axis=0).mean()  # Calculate population diversity\n        dynamic_crossover_rate = self.crossover_rate * (0.5 + diversity_factor)  # Adapt crossover rate\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')  # Enhanced local search\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n            if self.func_evals < 0.8 * self.budget:  # New line: Enhance local search based on periodicity\n                self.population = np.apply_along_axis(self.periodic_constraint, 1, self.population)\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved search efficiency by introducing periodicity-based local search enhancement in the optimization loop.", "configspace": "", "generation": 9, "fitness": 0.9712431199762349, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.971 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "27c7835f-4d20-4cfd-a672-a39dc7bf6c59", "metadata": {"aucs": [0.9729528673817474, 0.9683804320267596, 0.9723960605201976], "final_y": [0.16485621120421234, 0.16485584491238314, 0.1648562534258209]}, "mutation_prompt": null}
{"id": "db00ea80-41f9-45b8-b736-86f3ff0c1c00", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget) * 0.9  # Change 1\n        diversity_factor = np.std(self.population, axis=0).mean()\n        dynamic_crossover_rate = self.crossover_rate * (0.5 + diversity_factor * 0.8)  # Change 2\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved global-local balance by adjusting parameters dynamically based on the search progress.", "configspace": "", "generation": 9, "fitness": 0.9603512042830991, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "27c7835f-4d20-4cfd-a672-a39dc7bf6c59", "metadata": {"aucs": [0.9724858413941551, 0.9361717109349446, 0.9723960605201976], "final_y": [0.16485621120421234, 0.16485621164867614, 0.1648562534258209]}, "mutation_prompt": null}
{"id": "d5049909-9729-47b1-a676-a326a028d09f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        diversity_factor = np.std(self.population, axis=0).mean()  # Calculate population diversity\n        dynamic_crossover_rate = self.crossover_rate * (0.5 + diversity_factor)  # Adapt crossover rate\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')  # Enhanced local search\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 2  # Refined periodic constraint for better structural harmony\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced diversity through adaptive crossover rates based on population diversity with refined periodic constraint for better structural harmony.", "configspace": "", "generation": 9, "fitness": 0.9577840725873715, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.016. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "27c7835f-4d20-4cfd-a672-a39dc7bf6c59", "metadata": {"aucs": [0.9647844463069725, 0.9361717109349446, 0.9723960605201976], "final_y": [0.16485603832335616, 0.16485621164867614, 0.1648562534258209]}, "mutation_prompt": null}
{"id": "9b4c5dc4-1cb9-4962-8260-9e4e85c61a79", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        diversity_factor = np.std(self.population, axis=0).mean()  # Calculate population diversity\n        dynamic_crossover_rate = self.crossover_rate * (0.5 + diversity_factor)  # Adapt crossover rate\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')  # Enhanced local search\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        best_period = max(1, int(self.func_evals / (self.budget / self.dim)))  # Dynamic period size\n        for i in range(best_period, self.dim):\n            individual[i] = individual[i % best_period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced periodic constraint strategy by optimizing periodic size dynamically based on the population's best solutions.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "27c7835f-4d20-4cfd-a672-a39dc7bf6c59", "metadata": {}, "mutation_prompt": null}
{"id": "49fca394-9a38-42f5-b23d-f402a79e5edd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        diversity_factor = np.std(self.population, axis=0).mean()  # Calculate population diversity\n        dynamic_crossover_rate = self.crossover_rate * (0.5 + diversity_factor)  # Adapt crossover rate\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population[np.argmin([self.evaluate(ind) for ind in self.population])] = new_population[np.argmin([self.evaluate(ind) for ind in new_population])]  # Maintain best solution\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')  # Enhanced local search\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced diversity-maintaining elitism and mutation-based exploration strategies for enhanced convergence.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "27c7835f-4d20-4cfd-a672-a39dc7bf6c59", "metadata": {}, "mutation_prompt": null}
{"id": "aa148579-a092-4a95-84fc-2f6d24cb82ab", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        diversity_factor = np.std(self.population, axis=0).mean()  # Calculate population diversity\n        dynamic_crossover_rate = self.crossover_rate * (0.5 + diversity_factor)  # Adapt crossover rate\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B', options={'maxiter': 50})\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')  # Enhanced local search\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Optimized local search leveraging early termination for improved efficiency in solution refinement.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "27c7835f-4d20-4cfd-a672-a39dc7bf6c59", "metadata": {}, "mutation_prompt": null}
{"id": "224b0e9d-e739-4267-8598-dc06faf0a588", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            if i % 2 == 0:\n                self.population[i] = self.periodic_constraint(self.population[i])\n            else:\n                self.population[i] = self.structured_initialization(lb, ub)\n\n    def structured_initialization(self, lb, ub):\n        period = self.dim // 4\n        layers = np.random.uniform(lb, ub, period)\n        return np.tile(layers, self.dim // period)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        diversity_factor = np.std(self.population, axis=0).mean()\n        dynamic_crossover_rate = self.crossover_rate * (0.5 + diversity_factor)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=[(lb[i], ub[i]) for i in range(self.dim)], method='Powell')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced adaptive hybrid metaheuristic with structured periodic initialization and improved local search integration for robust black box optimization.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (2,) and arg 1 with shape (10,).').", "error": "ValueError('shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (2,) and arg 1 with shape (10,).')", "parent_id": "27c7835f-4d20-4cfd-a672-a39dc7bf6c59", "metadata": {}, "mutation_prompt": null}
{"id": "0cae8041-84c7-4393-a76c-b9345a93986e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.adapt_population_size()\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def adapt_population_size(self):\n        # Adaptive population resizing based on function evaluations\n        self.population_size = min(self.initial_population_size, int(self.budget * 0.1 * (1 - self.func_evals / self.budget)) + 1)\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic algorithm with adaptive population size scaling based on search progress for enhanced convergence in black box optimization.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'ub' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'ub' referenced before assignment\")", "parent_id": "5082e51d-1a99-47de-9dfa-0f08e40fed6e", "metadata": {}, "mutation_prompt": null}
{"id": "850f6299-3745-4705-9c1f-5c240edb296d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')  # Enhanced local search\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period] * np.sin(np.pi * i / period)  # Adjusted periodic constraint with modulation\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced search diversity by incorporating adaptive mutation scale adjustment and periodicity constraints.", "configspace": "", "generation": 10, "fitness": 0.8191427984483256, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.819 with standard deviation 0.227. And the mean value of best solutions found was 0.240 (0. is the best) with standard deviation 0.106.", "error": "", "parent_id": "5082e51d-1a99-47de-9dfa-0f08e40fed6e", "metadata": {"aucs": [0.49865080143983365, 0.9666999491825349, 0.9920776447226082], "final_y": [0.3900956803078762, 0.1648562947036254, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "7314804c-59d3-4179-8dfc-7e481b40bc1a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        diversity_factor = np.std(self.population, axis=0).mean()\n        dynamic_crossover_rate = self.crossover_rate * (0.5 + diversity_factor)\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            population_diversity = np.std(self.population, axis=0).mean()  # Added line\n            dynamic_local_search_trigger = population_diversity > 0.05  # Added line\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                if dynamic_local_search_trigger:  # Added line\n                    constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved exploration and local refinement in differential evolution through dynamic mutation scaling and diversity-driven local search triggers.", "configspace": "", "generation": 10, "fitness": 0.9824385971899718, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.982 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "27c7835f-4d20-4cfd-a672-a39dc7bf6c59", "metadata": {"aucs": [0.9885381976647724, 0.9666999491825349, 0.9920776447226082], "final_y": [0.16485621120421234, 0.1648562947036254, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "ff12e1af-6fa4-4465-8f1e-38c75d280136", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        diversity_factor = np.std(self.population, axis=0).mean()  # Calculate population diversity\n        dynamic_crossover_rate = self.crossover_rate * (0.5 + diversity_factor)  # Adapt crossover rate\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')  # Enhanced local search\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4 + (self.dim % 4 > 2)  # Adaptive periodic constraint\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced adaptive periodic constraint to enhance solution modularity and leverage periodic solutions.", "configspace": "", "generation": 10, "fitness": 0.9757722918708854, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.976 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "27c7835f-4d20-4cfd-a672-a39dc7bf6c59", "metadata": {"aucs": [0.9885381976647724, 0.9666999491825349, 0.9720787287653492], "final_y": [0.16485621120421234, 0.1648562947036254, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "97cb8d86-bc75-47f4-a6e3-cc8e51e3142e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        diversity = np.std(self.population, axis=0).mean()  # Calculate diversity\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget) * (1 + diversity)  # Line 1\n        dynamic_crossover_rate = self.crossover_rate - 0.3 * (self.func_evals / self.budget) * diversity  # Line 2\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')  # Enhanced local search\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced adaptive mutation and crossover strategies based on diversity and periodicity to enhance solution quality.", "configspace": "", "generation": 10, "fitness": 0.9618346997382753, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5082e51d-1a99-47de-9dfa-0f08e40fed6e", "metadata": {"aucs": [0.9655098759830004, 0.967390964512725, 0.9526032587191002], "final_y": [0.16485621120421234, 0.1648562947036254, 0.16485625496256795]}, "mutation_prompt": null}
{"id": "306229e5-f811-4519-a0d3-fff465454860", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.population = None\n        self.func_evals = 0\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = min(self.initial_population_size, self.budget // 2)  # Adaptive population sizing\n        self.population = lb + (ub - lb) * np.random.rand(self.population_size, self.dim)\n        for i in range(self.population_size):\n            self.population[i] = self.periodic_constraint(self.population[i])\n\n    def differential_evolution_step(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        new_population = np.copy(self.population)\n        adaptive_mutation_factor = self.mutation_factor * (1 - self.func_evals / self.budget)\n        diversity_factor = np.std(self.population, axis=0).mean()  # Calculate population diversity\n        dynamic_crossover_rate = self.crossover_rate * (0.5 + diversity_factor)  # Adapt crossover rate\n        for i in range(self.population_size):\n            indices = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = self.population[indices]\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), lb, ub)\n            crossover_mask = np.random.rand(self.dim) < dynamic_crossover_rate\n            trial = np.where(crossover_mask, mutant, self.population[i])\n            trial = np.clip(trial, lb, ub)\n            if self.evaluate(trial) < self.evaluate(self.population[i]):\n                new_population[i] = trial\n        self.population = new_population\n\n    def evaluate(self, individual):\n        if self.func_evals >= self.budget:\n            return float('inf')\n        self.func_evals += 1\n        return self.func(individual)\n\n    def local_optimization(self, x0, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        result = minimize(self.func, x0, bounds=np.array([0.9 * lb + 0.1 * x0, 0.9 * ub + 0.1 * x0]).T, method='L-BFGS-B')\n        if not result.success:\n            result = minimize(self.func, x0, bounds=np.array([0.95 * lb + 0.05 * x0, 0.95 * ub + 0.05 * x0]).T, method='TNC')  # Enhanced local search\n        if not result.success and self.func_evals < self.budget - 10:  # Additional multi-start to improve local search\n            result = minimize(self.func, x0, bounds=np.array([lb, ub]).T, method='L-BFGS-B')\n        return result.x if result.success else x0\n\n    def periodic_constraint(self, individual):\n        period = self.dim // 4 if self.func_evals < self.budget // 2 else self.dim // 2  # Adaptive periodicity enforcement\n        for i in range(period, self.dim):\n            individual[i] = individual[i % period]\n        return individual\n\n    def __call__(self, func):\n        self.func = func\n        bounds = func.bounds\n        self.initialize_population(bounds)\n        best_solution = None\n        best_value = float('inf')\n\n        while self.func_evals < self.budget:\n            self.differential_evolution_step(bounds)\n            for i in range(self.population_size):\n                constrained_individual = self.periodic_constraint(self.population[i])\n                constrained_individual = self.local_optimization(constrained_individual, bounds)\n                self.population[i] = constrained_individual\n                current_value = self.evaluate(constrained_individual)\n                if current_value < best_value:\n                    best_value = current_value\n                    best_solution = constrained_individual\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced adaptive periodicity enforcement and enhanced local search using multi-start L-BFGS-B.", "configspace": "", "generation": 10, "fitness": 0.9761145653395604, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.976 with standard deviation 0.020. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "27c7835f-4d20-4cfd-a672-a39dc7bf6c59", "metadata": {"aucs": [0.9885381976647724, 0.9477278536313009, 0.9920776447226082], "final_y": [0.16485621120421234, 0.1648562947036254, 0.16485625496256795]}, "mutation_prompt": null}
