{"id": "4bce3922-68ea-4dca-ab84-c802068928da", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "A hybrid Multi-Population Differential Evolution algorithm combined with Quasi-Oppositional Learning and Local Search to efficiently navigate complex optimization landscapes while exploiting periodicity.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 194, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 288, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 149, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 69, in __call__\n  File \"<string>\", line 33, in local_search\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 670, in minimize\n    bounds = standardize_bounds(bounds, x0, 'new')\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 1058, in standardize_bounds\n    lb, ub = old_bound_to_new(bounds)\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_constraints.py\", line 433, in old_bound_to_new\n    lb, ub = zip(*bounds)\nTypeError: zip() argument after * must be an iterable, not ioh.iohcpp.RealBounds\n.", "error": "TypeError('zip() argument after * must be an iterable, not ioh.iohcpp.RealBounds')Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 194, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 288, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 149, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 69, in __call__\n  File \"<string>\", line 33, in local_search\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 670, in minimize\n    bounds = standardize_bounds(bounds, x0, 'new')\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 1058, in standardize_bounds\n    lb, ub = old_bound_to_new(bounds)\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_constraints.py\", line 433, in old_bound_to_new\n    lb, ub = zip(*bounds)\nTypeError: zip() argument after * must be an iterable, not ioh.iohcpp.RealBounds\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "d4c0955c-188b-4978-8e75-c9987cf29df7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.eval_count = 0\n\n    def _initialize_population(self, pop_size, lb, ub):\n        population = np.random.uniform(lb, ub, (pop_size, self.dim))\n        opposition_population = lb + ub - population\n        combined_population = np.vstack((population, opposition_population))\n        return combined_population\n\n    def _evaluate_population(self, population, func):\n        fitness = np.apply_along_axis(func, 1, population)\n        self.eval_count += len(population)\n        return fitness\n\n    def _differential_evolution(self, func, pop_size, lb, ub):\n        F = 0.8  # Mutation factor\n        CR = 0.9  # Crossover probability\n        population = self._initialize_population(pop_size, lb, ub)\n        fitness = self._evaluate_population(population, func)\n\n        while self.eval_count < self.budget:\n            for i in range(pop_size):\n                indices = np.arange(len(population))\n                indices = indices[indices != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            if self.eval_count >= self.budget:\n                break\n\n            # Local search on the best individual found so far\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n            local_result = minimize(func, best_solution, bounds=list(zip(lb, ub)), method='L-BFGS-B')\n\n            if local_result.fun < fitness[best_idx]:\n                population[best_idx] = local_result.x\n                fitness[best_idx] = local_result.fun\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 10 * self.dim  # Population size\n        best_solution, best_fitness = self._differential_evolution(func, pop_size, lb, ub)\n        return best_solution", "name": "HybridMetaheuristic", "description": "A novel hybrid metaheuristic algorithm combining Differential Evolution with Quasi-Oppositional Initialization and Local Search to optimize multilayered photonic structures by encouraging periodicity and constructive interference.", "configspace": "", "generation": 0, "fitness": 0.9346416437749072, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.935 with standard deviation 0.025. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": null, "metadata": {"aucs": [0.9201127946726424, 0.9136036779741027, 0.9702084586779766], "final_y": [0.1818851863939165, 0.18187968905672636, 0.1648568487921228]}, "mutation_prompt": null}
{"id": "f733d357-05c7-40f7-b4e9-94e42bfeec6c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.ub - (population - bounds.lb)  # Improved initialization\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "The algorithm is enhanced by utilizing a more robust method for initializing the opposite population, improving initial exploration coverage.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('zip() argument after * must be an iterable, not ioh.iohcpp.RealBounds').", "error": "TypeError('zip() argument after * must be an iterable, not ioh.iohcpp.RealBounds')", "parent_id": "4bce3922-68ea-4dca-ab84-c802068928da", "metadata": {}, "mutation_prompt": null}
{"id": "3e28225f-b77f-4747-8b2a-db73e1dd9878", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        if self.dim % periodicity == 0:  # Ensure equal division\n            partition_size = self.dim // periodicity  \n            for i in range(1, periodicity):  # Adjust loop to start from 1\n                candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhanced Hybrid Differential Evolution with refined periodicity enforcement for efficient optimization of photonic structures.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('zip() argument after * must be an iterable, not ioh.iohcpp.RealBounds').", "error": "TypeError('zip() argument after * must be an iterable, not ioh.iohcpp.RealBounds')", "parent_id": "4bce3922-68ea-4dca-ab84-c802068928da", "metadata": {}, "mutation_prompt": null}
{"id": "c0ba4928-f6df-4153-8f44-7dd763598e35", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        result = minimize(func, candidate, method=self.local_search_method, bounds=list(zip(bounds.lb, bounds.ub)))\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "A refined Hybrid Multi-Population Differential Evolution with enhanced exception handling for bounds compatibility.", "configspace": "", "generation": 1, "fitness": 0.9793005818928675, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.979 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4bce3922-68ea-4dca-ab84-c802068928da", "metadata": {"aucs": [0.969280548261394, 0.9876318060875457, 0.9809893913296629], "final_y": [0.1648564832285403, 0.16486033806597644, 0.1648565606598239]}, "mutation_prompt": null}
{"id": "99132186-b5a0-41f0-9276-36c1237efc16", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        scipy_bounds = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]  # Correct bounds\n        result = minimize(func, candidate, method=self.local_search_method, bounds=scipy_bounds)  # Use scipy_bounds\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "A refined hybrid Multi-Population Differential Evolution algorithm with corrected bounds handling for local search to enhance compatibility with the optimization framework.", "configspace": "", "generation": 1, "fitness": 0.9740314461081048, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4bce3922-68ea-4dca-ab84-c802068928da", "metadata": {"aucs": [0.9700732575044978, 0.9771602368364372, 0.9748608439833792], "final_y": [0.1648563909546933, 0.16485704773080057, 0.16485741507686458]}, "mutation_prompt": null}
{"id": "f0a7a48d-803b-4ce7-83da-d7edc9497a8e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        scipy_bounds = [(lb, ub) for lb, ub in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=scipy_bounds)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "An enhanced Hybrid Differential Evolution with a corrected boundary handling in local search to optimize multilayered photonic structures by exploiting periodicity and constructive interference.", "configspace": "", "generation": 1, "fitness": 0.9709367822425713, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.971 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4bce3922-68ea-4dca-ab84-c802068928da", "metadata": {"aucs": [0.9472192700910538, 0.9867446216259596, 0.9788464550107006], "final_y": [0.16485911237450512, 0.16485778989745914, 0.16485705814327878]}, "mutation_prompt": null}
{"id": "26d5c733-43ca-47ff-8fa8-afc6390edf9e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Refines the hybrid Differential Evolution algorithm by correcting the bounds handling in local search and refining population update for consistency.", "configspace": "", "generation": 1, "fitness": 0.9772787833596643, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.977 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "4bce3922-68ea-4dca-ab84-c802068928da", "metadata": {"aucs": [0.9731184773044548, 0.9806156647695814, 0.9781022080049566], "final_y": [0.16485630111085237, 0.16486667672559774, 0.16486047144673688]}, "mutation_prompt": null}
{"id": "5cf80950-1ed7-4071-b460-e4eac9a340a4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.eval_count = 0\n\n    def _initialize_population(self, pop_size, lb, ub):\n        population = np.random.uniform(lb, ub, (pop_size, self.dim))\n        opposition_population = lb + ub - population\n        combined_population = np.vstack((population, opposition_population))\n        return combined_population\n\n    def _evaluate_population(self, population, func):\n        fitness = np.apply_along_axis(func, 1, population)\n        self.eval_count += len(population)\n        return fitness\n\n    def _differential_evolution(self, func, pop_size, lb, ub):\n        CR = 0.9  # Crossover probability\n        population = self._initialize_population(pop_size, lb, ub)\n        fitness = self._evaluate_population(population, func)\n\n        while self.eval_count < self.budget:\n            F = 0.8 * (1 - self.eval_count / self.budget)  # Dynamic mutation factor\n            for i in range(pop_size):\n                indices = np.arange(len(population))\n                indices = indices[indices != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            if self.eval_count >= self.budget:\n                break\n\n            # Local search on the best individual found so far\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n            local_result = minimize(func, best_solution, bounds=list(zip(lb, ub)), method='L-BFGS-B')\n\n            if local_result.fun < fitness[best_idx]:\n                population[best_idx] = local_result.x\n                fitness[best_idx] = local_result.fun\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 10 * self.dim  # Population size\n        best_solution, best_fitness = self._differential_evolution(func, pop_size, lb, ub)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhance exploration by varying the scale factor in Differential Evolution dynamically based on the current evaluation count.", "configspace": "", "generation": 1, "fitness": 0.8942432287959289, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.028. And the mean value of best solutions found was 0.185 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "d4c0955c-188b-4978-8e75-c9987cf29df7", "metadata": {"aucs": [0.9206339351746288, 0.8554454047284992, 0.9066503464846585], "final_y": [0.1727331165636805, 0.20044536196415497, 0.18187907917806245]}, "mutation_prompt": null}
{"id": "5f1c9ba1-38ec-4311-afab-03930420e7a6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.eval_count = 0\n\n    def _initialize_population(self, pop_size, lb, ub):\n        population = np.random.uniform(lb, ub, (pop_size, self.dim))\n        opposition_population = lb + ub - population\n        combined_population = np.vstack((population, opposition_population))\n        return combined_population\n\n    def _evaluate_population(self, population, func):\n        fitness = np.apply_along_axis(func, 1, population)\n        self.eval_count += len(population)\n        return fitness\n\n    def _differential_evolution(self, func, pop_size, lb, ub):\n        F = 0.8  # Mutation factor\n        CR = 0.9  # Crossover probability\n        population = self._initialize_population(pop_size, lb, ub)\n        fitness = self._evaluate_population(population, func)\n\n        while self.eval_count < self.budget:\n            for i in range(pop_size):\n                indices = np.arange(len(population))\n                indices = indices[indices != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                # Modified crossover condition\n                cross_points = np.random.rand(self.dim) < (CR + (fitness[i] - np.min(fitness)) / (np.max(fitness) - np.min(fitness) + 1e-9))\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            if self.eval_count >= self.budget:\n                break\n\n            # Local search on the best individual found so far\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n            local_result = minimize(func, best_solution, bounds=list(zip(lb, ub)), method='L-BFGS-B')\n\n            if local_result.fun < fitness[best_idx]:\n                population[best_idx] = local_result.x\n                fitness[best_idx] = local_result.fun\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 10 * self.dim  # Population size\n        best_solution, best_fitness = self._differential_evolution(func, pop_size, lb, ub)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced the crossover process by modifying the crossover condition to improve solution diversity and exploration.", "configspace": "", "generation": 1, "fitness": 0.8808083370671023, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.030. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "d4c0955c-188b-4978-8e75-c9987cf29df7", "metadata": {"aucs": [0.9201127946726424, 0.8747236501452356, 0.8475885663834289], "final_y": [0.1818851863939165, 0.1648599379258897, 0.20044533993101543]}, "mutation_prompt": null}
{"id": "1ff9e0fe-fded-41a6-9635-87d1d65e3c62", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.eval_count = 0\n\n    def _initialize_population(self, pop_size, lb, ub):\n        population = np.random.uniform(lb, ub, (pop_size, self.dim))\n        opposition_population = lb + ub - population\n        combined_population = np.vstack((population, opposition_population))\n        return combined_population\n\n    def _evaluate_population(self, population, func):\n        fitness = np.apply_along_axis(func, 1, population)\n        self.eval_count += len(population)\n        return fitness\n\n    def _differential_evolution(self, func, pop_size, lb, ub):\n        F = 0.8  # Mutation factor\n        CR = 0.95  # Crossover probability (changed from 0.9 to 0.95)\n        population = self._initialize_population(pop_size, lb, ub)\n        fitness = self._evaluate_population(population, func)\n\n        while self.eval_count < self.budget:\n            for i in range(pop_size):\n                indices = np.arange(len(population))\n                indices = indices[indices != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            if self.eval_count >= self.budget:\n                break\n\n            # Local search on the best individual found so far\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n            local_result = minimize(func, best_solution, bounds=list(zip(lb, ub)), method='L-BFGS-B')\n\n            if local_result.fun < fitness[best_idx]:\n                population[best_idx] = local_result.x\n                fitness[best_idx] = local_result.fun\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 10 * self.dim  # Population size\n        best_solution, best_fitness = self._differential_evolution(func, pop_size, lb, ub)\n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic using Differential Evolution with Quasi-Oppositional Initialization and enhanced Local Search, focusing on periodicity and constructive interference.", "configspace": "", "generation": 1, "fitness": 0.9231491942407218, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.005. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "d4c0955c-188b-4978-8e75-c9987cf29df7", "metadata": {"aucs": [0.9201127946726424, 0.9306608554916103, 0.9186739325579129], "final_y": [0.1818851863939165, 0.16485884346663093, 0.1648559542130399]}, "mutation_prompt": null}
{"id": "1d85f5fd-f292-4f04-a1ed-1847fa66a25d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.eval_count = 0\n\n    def _initialize_population(self, pop_size, lb, ub):\n        population = np.random.uniform(lb, ub, (pop_size, self.dim))\n        opposition_population = lb + ub - population\n        combined_population = np.vstack((population, opposition_population))\n        return combined_population\n\n    def _evaluate_population(self, population, func):\n        fitness = np.apply_along_axis(func, 1, population)\n        self.eval_count += len(population)\n        return fitness\n\n    def _differential_evolution(self, func, pop_size, lb, ub):\n        F = 0.5 + 0.3 * np.random.rand()  # Adjusted mutation factor\n        CR = 0.9  # Crossover probability\n        population = self._initialize_population(pop_size, lb, ub)\n        fitness = self._evaluate_population(population, func)\n\n        while self.eval_count < self.budget:\n            for i in range(pop_size):\n                indices = np.arange(len(population))\n                indices = indices[indices != i]\n                a, b, c = population[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n                cross_points = np.random.rand(self.dim) < CR\n                trial = np.where(cross_points, mutant, population[i])\n                trial_fitness = func(trial)\n                self.eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n            if self.eval_count >= self.budget:\n                break\n\n            if np.random.rand() < 0.3:  # Adaptive local search frequency\n                best_idx = np.argmin(fitness)\n                best_solution = population[best_idx]\n                local_result = minimize(func, best_solution, bounds=list(zip(lb, ub)), method='L-BFGS-B')\n\n                if local_result.fun < fitness[best_idx]:\n                    population[best_idx] = local_result.x\n                    fitness[best_idx] = local_result.fun\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx], fitness[best_idx]\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        pop_size = 10 * self.dim  # Population size\n        best_solution, best_fitness = self._differential_evolution(func, pop_size, lb, ub)\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic algorithm with dynamic mutation factor adjustment and adaptive local search frequency for optimizing multilayered photonic structures.", "configspace": "", "generation": 1, "fitness": 0.9449604497513536, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.945 with standard deviation 0.023. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "d4c0955c-188b-4978-8e75-c9987cf29df7", "metadata": {"aucs": [0.9633432580307217, 0.9596867990418534, 0.9118512921814859], "final_y": [0.16485622748550455, 0.16485651620159458, 0.1818811722836544]}, "mutation_prompt": null}
{"id": "081e4fd7-0034-4f47-a5b9-1d41481389ea", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Adaptive mutation factor, changed from 0.7\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        result = minimize(func, candidate, method=self.local_search_method, bounds=list(zip(bounds.lb, bounds.ub)))\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate, periodicity=2)  # Added periodicity constraint\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhanced algorithm by integrating adaptive mutation factor and periodicity constraint to improve exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.9748529487961978, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c0ba4928-f6df-4153-8f44-7dd763598e35", "metadata": {"aucs": [0.97364256467377, 0.9779867297782228, 0.9729295519366006], "final_y": [0.16485604340413507, 0.1648607744313565, 0.16485623529615467]}, "mutation_prompt": null}
{"id": "24dae180-5d20-4213-a507-ee5dec3833d6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < np.random.uniform(0.5, 1.0)  # Adaptive CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Introduces adaptive crossover probability in the Differential Evolution step to enhance exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.940784026011699, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.052. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "26d5c733-43ca-47ff-8fa8-afc6390edf9e", "metadata": {"aucs": [0.9785986106211862, 0.9762316058312598, 0.8675218615826509], "final_y": [0.16486816652199776, 0.16486023586366083, 0.20044634337677902]}, "mutation_prompt": null}
{"id": "87d4f9fa-5741-493f-865e-e5bbebecaf1b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n        self.mutation_rate_decay = 0.95  # New: Adaptive mutation rate decay\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            F_adaptive = self.F * (1 - (i / population.shape[0]) * (1 - self.mutation_rate_decay))  # New: Adaptive F\n            mutant_vector = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        result = minimize(func, candidate, method=self.local_search_method, bounds=list(zip(bounds.lb, bounds.ub)))\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhanced Hybrid Differential Evolution with Adaptive Mutation to Improve Convergence.", "configspace": "", "generation": 2, "fitness": 0.955748758356603, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.956 with standard deviation 0.026. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c0ba4928-f6df-4153-8f44-7dd763598e35", "metadata": {"aucs": [0.9189842055368684, 0.9729044940593847, 0.9753575754735557], "final_y": [0.16486249031646616, 0.1648563579835296, 0.16485852356325548]}, "mutation_prompt": null}
{"id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Refines the hybrid Differential Evolution algorithm by adjusting the mutation factor for enhanced exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.9843055492416298, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.984 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "26d5c733-43ca-47ff-8fa8-afc6390edf9e", "metadata": {"aucs": [0.9912468219486418, 0.981870193372802, 0.9797996324034454], "final_y": [0.16485644578529102, 0.1648562866066311, 0.16485605001347592]}, "mutation_prompt": null}
{"id": "ab58420b-483e-4e1d-a9c4-39fbab741ede", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def adaptive_strategy(self, score, best_score):\n        if score < best_score:\n            self.F = min(0.9, self.F + 0.1)\n            self.CR = min(0.95, self.CR + 0.05)\n        else:\n            self.F = max(0.5, self.F - 0.1)\n            self.CR = max(0.8, self.CR - 0.05)\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    self.adaptive_strategy(score, best_score)  # Adaptive mutation and crossover\n\n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhanced exploration with adaptive mutation and crossover rates for improved convergence.", "configspace": "", "generation": 2, "fitness": 0.9700622260118225, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "26d5c733-43ca-47ff-8fa8-afc6390edf9e", "metadata": {"aucs": [0.9508910216459877, 0.9770919912738869, 0.9822036651155925], "final_y": [0.16486069794736846, 0.16485626770346462, 0.16485997944057607]}, "mutation_prompt": null}
{"id": "5f28fdc8-603e-44a5-ba32-30e912d628df", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < (self.CR * (1 - i/population.shape[0]))  # Adaptive CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Introduce adaptive crossover probability to enhance exploration and exploitation balance in the evolutionary process.", "configspace": "", "generation": 2, "fitness": 0.9792413881678357, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.979 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "26d5c733-43ca-47ff-8fa8-afc6390edf9e", "metadata": {"aucs": [0.98069919785538, 0.9748558492815905, 0.9821691173665367], "final_y": [0.164856214269396, 0.16485888362338796, 0.16485811444178666]}, "mutation_prompt": null}
{"id": "f71044f6-0db1-4939-b54e-62f3a773cdcf", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n            # Randomly reset a portion of the population to enhance diversity\n            reset_indices = np.random.choice(self.population_size, size=self.population_size // 10, replace=False)\n            for idx in reset_indices:\n                populations[np.random.randint(0, self.num_populations)][idx] = np.random.uniform(bounds.lb, bounds.ub, self.dim)\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhanced diversity by integrating random resetting during stagnation to refine solution quality.", "configspace": "", "generation": 2, "fitness": 0.9696364544908368, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "26d5c733-43ca-47ff-8fa8-afc6390edf9e", "metadata": {"aucs": [0.9716542803586922, 0.9585511754418135, 0.9787039076720043], "final_y": [0.16485627578211626, 0.16485586605699876, 0.16486182499091495]}, "mutation_prompt": null}
{"id": "4dc71e87-5051-4849-9f9f-60ee1aebc176", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability adjusted adaptively\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size] * (0.5 + 0.5 * np.cos(2 * np.pi * np.arange(partition_size) / partition_size))\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Introduced adaptive crossover probability (CR) and enhanced periodicity enforcement to improve convergence and solution quality.", "configspace": "", "generation": 2, "fitness": 0.8235427840013504, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.220. And the mean value of best solutions found was 0.240 (0. is the best) with standard deviation 0.106.", "error": "", "parent_id": "26d5c733-43ca-47ff-8fa8-afc6390edf9e", "metadata": {"aucs": [0.5126059043379048, 0.9814354227696198, 0.9765870248965265], "final_y": [0.39009608674217533, 0.164863062840102, 0.16486580225232372]}, "mutation_prompt": null}
{"id": "df7c7dde-6ddf-431d-94f9-87d42051cad1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            dynamic_CR = self.CR * (1 - ((i + 1) / population.shape[0]))  # Adaptive CR\n            cross_points = np.random.rand(self.dim) < dynamic_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        result = minimize(func, candidate, method=self.local_search_method, bounds=list(zip(bounds.lb, bounds.ub)))\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        base_pattern = candidate[:partition_size]\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = base_pattern  # Refined periodicity\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "An enhanced variation of Hybrid Differential Evolution with refined periodicity enforcement and adaptive crossover probability.", "configspace": "", "generation": 2, "fitness": 0.9814759671042054, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.981 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "c0ba4928-f6df-4153-8f44-7dd763598e35", "metadata": {"aucs": [0.9793692669686328, 0.9843977565737365, 0.980660877770247], "final_y": [0.16485988444488997, 0.16485945479760888, 0.16485674458869726]}, "mutation_prompt": null}
{"id": "980195d6-7db2-490f-91b7-9241033a9530", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            F_dynamic = np.random.rand() * self.F  # Dynamic adjustment\n            mutant_vector = np.clip(a + F_dynamic * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        result = minimize(func, candidate, method=self.local_search_method, bounds=list(zip(bounds.lb, bounds.ub)))\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def simulated_annealing(self, candidate, func):\n        temperature = 1.0\n        cooling_rate = 0.9\n        current_score = func(candidate)\n        while temperature > 0.1:\n            new_candidate = candidate + np.random.normal(0, 0.1, self.dim)\n            new_score = func(new_candidate)\n            if new_score < current_score or np.exp((current_score - new_score) / temperature) > np.random.rand():\n                candidate = new_candidate\n                current_score = new_score\n            temperature *= cooling_rate\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.simulated_annealing(best_candidate, func)  # Integrated Simulated Annealing\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Improved population diversity and hybrid search by dynamically adjusting mutation factor and integrating Simulated Annealing for local refinement.", "configspace": "", "generation": 2, "fitness": 0.9027352919540611, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.114. And the mean value of best solutions found was 0.189 (0. is the best) with standard deviation 0.035.", "error": "", "parent_id": "c0ba4928-f6df-4153-8f44-7dd763598e35", "metadata": {"aucs": [0.7418220622450997, 0.9841225057872518, 0.9822613078298316], "final_y": [0.2386820357697903, 0.1648617581081364, 0.164856727664218]}, "mutation_prompt": null}
{"id": "9b8d8607-b8c9-423d-93af-fde586f45235", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        population_diversity = np.std(population, axis=0).mean()\n        self.F = 0.5 + 0.5 * (1 - population_diversity / (bounds.ub - bounds.lb).mean())\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Improved Hybrid Differential Evolution by dynamically adjusting the mutation factor based on population diversity to enhance exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.9796785116157226, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.980 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.9733325919443747, 0.9846632234399477, 0.9810397194628455], "final_y": [0.16485842784515725, 0.1648560557316595, 0.16485738958627216]}, "mutation_prompt": null}
{"id": "0e88bec8-82da-4838-a617-92ef906e4eb6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n\n                # Starting line change\n                self.CR = 0.9 - 0.5 * (evaluations / self.budget)  # Dynamic crossover probability\n                # Ending line change\n\n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Introduces a dynamic update mechanism for adaptive crossover probability to bolster exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.9779837105175232, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.978 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.973121715941223, 0.9773354939720252, 0.9834939216393215], "final_y": [0.16485845870333837, 0.16485925665388257, 0.16485598364621246]}, "mutation_prompt": null}
{"id": "4639db59-adb3-4d65-91a0-e33ae60cfcad", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds, iteration, max_iterations):\n        new_population = np.empty_like(population)\n        dynamic_CR = self.CR * (1 - (iteration / max_iterations))  # Dynamic crossover adjustment\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < dynamic_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        max_iterations = self.budget // (self.population_size * self.num_populations)\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds, evaluations // (self.population_size * self.num_populations), max_iterations)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Introduces dynamic crossover probability adjustment based on iteration progress to enhance exploration and convergence.", "configspace": "", "generation": 3, "fitness": 0.9795086053281356, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.980 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.9738677996224818, 0.9871996788184625, 0.9774583375434621], "final_y": [0.16485593680064747, 0.1648644117445487, 0.16486403539030425]}, "mutation_prompt": null}
{"id": "91a32b75-7d01-402c-b145-edfa48b5d54c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5 + np.random.rand() * 0.5  # Dynamic mutation factor\n        self.CR = 0.9\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            dynamic_CR = self.CR * (1 - ((i + 1) / population.shape[0]))  # Adaptive CR\n            cross_points = np.random.rand(self.dim) < dynamic_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        result = minimize(func, candidate, method=self.local_search_method, bounds=list(zip(bounds.lb, bounds.ub)))\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        base_pattern = candidate[:partition_size]\n        candidate[:partition_size*periodicity] = np.tile(base_pattern, periodicity)  # Enhanced periodicity enforcement\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Improved Hybrid Differential Evolution with dynamic mutation factor and enhanced periodicity alignment.", "configspace": "", "generation": 3, "fitness": 0.9417578204628517, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.942 with standard deviation 0.051. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "df7c7dde-6ddf-431d-94f9-87d42051cad1", "metadata": {"aucs": [0.9790670308260134, 0.9759209556423136, 0.8702854749202282], "final_y": [0.16485940442355596, 0.16485629733279905, 0.20044555335404557]}, "mutation_prompt": null}
{"id": "0ddc09b5-b18b-4356-9885-a900d557f9b8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds, best_score):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            dynamic_F = self.F * (1 + (best_score / (best_score + 0.01)))  # Dynamic mutation factor adaptation\n            mutant_vector = np.clip(a + dynamic_F * (b - c), bounds.lb, bounds.ub)\n            dynamic_CR = self.CR * (1 - ((i + 1) / population.shape[0]))  # Adaptive CR\n            cross_points = np.random.rand(self.dim) < dynamic_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        result = minimize(func, candidate, method=self.local_search_method, bounds=list(zip(bounds.lb, bounds.ub)))\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        base_pattern = candidate[:partition_size]\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = base_pattern  # Refined periodicity\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds, best_score)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Introduces dynamic mutation factor adaptation based on fitness improvement to enhance exploration-exploitation balance in the Hybrid Differential Evolution algorithm.", "configspace": "", "generation": 3, "fitness": 0.9655966393518886, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.018. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "df7c7dde-6ddf-431d-94f9-87d42051cad1", "metadata": {"aucs": [0.9404343950644192, 0.9780424229763033, 0.9783131000149434], "final_y": [0.16485762741451593, 0.1648580762699251, 0.16485654110685644]}, "mutation_prompt": null}
{"id": "845514e8-1432-41bf-afdb-5e11b9244ee6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Initial mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.5 + 0.3 * np.random.rand()  # Dynamic mutation factor\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(0, self.dim, partition_size):  # Adjust periodicity enforcement\n            candidate[i:i + partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances the algorithm by dynamically adjusting the mutation factor and improving the periodicity enforcement to better maintain constructive interference.", "configspace": "", "generation": 3, "fitness": 0.9653579164004817, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.015. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.9449039303667538, 0.9775482113119158, 0.9736216075227755], "final_y": [0.16485931903632978, 0.16485767637994408, 0.16485684427988767]}, "mutation_prompt": null}
{"id": "d6c20f23-b603-470c-8ca6-4239050aab18", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor (initial)\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            self.F = 0.8 if evaluations < self.budget / 2 else 0.6  # Dynamic mutation factor adjustment\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhance the Hybrid Differential Evolution by tuning the mutation factor dynamically based on the budget consumption to improve exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.9497532103213598, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.950 with standard deviation 0.041. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.891996200609527, 0.9757137829548473, 0.9815496473997053], "final_y": [0.16486272699783, 0.16485707997892196, 0.16485833280238726]}, "mutation_prompt": null}
{"id": "371eaea6-d81e-4a59-9215-8da673d2a61d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.5 + 0.3 * np.random.rand()  # Dynamic mutation factor\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Implements a dynamic mutation factor for enhanced adaptive exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.9645721367933181, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.9555402284745068, 0.9548685784667977, 0.9833076034386501], "final_y": [0.16485669308638917, 0.16485712555144405, 0.16485627878173847]}, "mutation_prompt": null}
{"id": "32abf143-ef98-49c8-a7bf-5aebbfe3396f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            dynamic_CR = self.CR * (1 - ((i + 1) / population.shape[0]))  # Adaptive CR\n            cross_points = np.random.rand(self.dim) < dynamic_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        result = minimize(func, candidate, method=self.local_search_method, bounds=list(zip(bounds.lb, bounds.ub)))\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=None):\n        if periodicity is None: \n            periodicity = max(1, self.dim // 5)  # Dynamic periodicity based on dimension\n        partition_size = self.dim // periodicity\n        base_pattern = candidate[:partition_size]\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = base_pattern  # Refined periodicity\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhanced periodicity enforcement by adjusting periodicity dynamically based on the dimension.", "configspace": "", "generation": 3, "fitness": 0.9773593210629095, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.977 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "df7c7dde-6ddf-431d-94f9-87d42051cad1", "metadata": {"aucs": [0.9836282998056155, 0.9826520055378816, 0.9657976578452312], "final_y": [0.16486139174634318, 0.1648560685571987, 0.16485895632154846]}, "mutation_prompt": null}
{"id": "215f1a9c-222f-497c-b279-51aab9fb1c86", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            dynamic_F = self.F + (0.3 * (0.5 - np.random.rand()))  # Dynamic F adjustment\n            mutant_vector = np.clip(a + dynamic_F * (b - c), bounds.lb, bounds.ub)\n            dynamic_CR = self.CR * (1 - ((i + 1) / population.shape[0]))  # Adaptive CR\n            cross_points = np.random.rand(self.dim) < dynamic_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        result = minimize(func, candidate, method=self.local_search_method, bounds=list(zip(bounds.lb, bounds.ub)))\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        base_pattern = candidate[:partition_size]\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = base_pattern  # Refined periodicity\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Introduced dynamic mutation factor adjustment to enhance exploration capabilities of the algorithm.", "configspace": "", "generation": 3, "fitness": 0.9832616563499244, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.983 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "df7c7dde-6ddf-431d-94f9-87d42051cad1", "metadata": {"aucs": [0.9831160655382848, 0.9768996269837362, 0.9897692765277523], "final_y": [0.16485709539927162, 0.16485642715582793, 0.16485933632152117]}, "mutation_prompt": null}
{"id": "d83f256e-50b8-471a-9120-8d5f0ea2a29e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < (self.CR + 0.1 * (1 - evaluations/self.budget))\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances hybrid Differential Evolution by dynamically adjusting both mutation factor and crossover probability based on evaluation progress.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {}, "mutation_prompt": null}
{"id": "4bca5ca4-f024-4f5e-b1c2-113ee5f3c243", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Adjusted mutation factor\n        self.CR = 0.7  # Adjusted crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n        self.adaptive_F = True  # New attribute for adaptive control\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            dynamic_F = self.F + (0.3 * (0.5 - np.random.rand())) if self.adaptive_F else self.F  # Adaptive F control\n            mutant_vector = np.clip(a + dynamic_F * (b - c), bounds.lb, bounds.ub)\n            dynamic_CR = self.CR * (1 - ((i + 1) / population.shape[0]))  # Adaptive CR\n            cross_points = np.random.rand(self.dim) < dynamic_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        result = minimize(func, candidate, method=self.local_search_method, bounds=list(zip(bounds.lb, bounds.ub)))\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        base_pattern = candidate[:partition_size]\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = base_pattern  # Refined periodicity\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhanced the hybrid Differential Evolution algorithm by incorporating adaptive control parameters and a diversity preservation mechanism.", "configspace": "", "generation": 4, "fitness": 0.9816637545175254, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.982 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "215f1a9c-222f-497c-b279-51aab9fb1c86", "metadata": {"aucs": [0.9860663149695004, 0.9767880216210197, 0.9821369269620562], "final_y": [0.16485633827248303, 0.16485606530281816, 0.16485694253368066]}, "mutation_prompt": null}
{"id": "05f8c8d9-134a-47b1-b4ea-e6ab7c9af242", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                # Adapt mutation factor based on progress\n                self.F = 0.5 + 0.3 * (1 - evaluations / self.budget)\n                \n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhance exploration by adapting the mutation factor based on convergence to bolster search dynamics.", "configspace": "", "generation": 4, "fitness": 0.9463909979007946, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.946 with standard deviation 0.053. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.9837927632479504, 0.9844396727900121, 0.8709405576644214], "final_y": [0.1648593283747536, 0.1648567625749905, 0.20044664641708465]}, "mutation_prompt": null}
{"id": "989783c1-9cdc-40b4-b28b-de7de63fd8ff", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            dynamic_F = self.F + (0.3 * (0.5 - np.random.rand()))  # Dynamic F adjustment\n            mutant_vector = np.clip(a + dynamic_F * (b - c), bounds.lb, bounds.ub)\n            dynamic_CR = self.CR * (1 - ((i + 1) / (population.shape[0] + 10)))  # Adaptive CR fine-tuning\n            cross_points = np.random.rand(self.dim) < dynamic_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        result = minimize(func, candidate, method=self.local_search_method, bounds=list(zip(bounds.lb, bounds.ub)))\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        base_pattern = candidate[:partition_size]\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = base_pattern  # Refined periodicity\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhanced exploration and convergence balance by refining crossover strategy with dynamic adjustment.", "configspace": "", "generation": 4, "fitness": 0.9839187704258577, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.984 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "215f1a9c-222f-497c-b279-51aab9fb1c86", "metadata": {"aucs": [0.9924791141309928, 0.9758602602219106, 0.9834169369246698], "final_y": [0.1648580393086403, 0.16485619014273267, 0.16485708432935375]}, "mutation_prompt": null}
{"id": "951ddfb9-0c90-4ffd-899e-010f000d8b9a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                diversity = np.mean(np.std(population, axis=0))  # Calculate diversity\n                self.CR = max(0.1, min(1.0, diversity))  # Adaptive CR based on diversity\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Introduces adaptive crossover probability adjustment based on population diversity to enhance solution quality.", "configspace": "", "generation": 4, "fitness": 0.9667572963008344, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.019. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.9399682224495337, 0.9827084549716988, 0.9775952114812707], "final_y": [0.16486189531060902, 0.16485739282101686, 0.16485637264462294]}, "mutation_prompt": null}
{"id": "7e5f1db1-7373-463f-9414-396e59c238d7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds, evaluations, max_evaluations):\n        new_population = np.empty_like(population)\n        dynamic_F = self.F * (1 - evaluations / max_evaluations)  # Dynamic mutation factor\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + dynamic_F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds, evaluations, self.budget)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhanced exploration-exploitation by introducing variable mutation factor based on evaluation progress.", "configspace": "", "generation": 4, "fitness": 0.9757215771624917, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.976 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.973306615530049, 0.9777628917004172, 0.9760952242570092], "final_y": [0.1648561945668494, 0.16485629400508384, 0.16485607773222632]}, "mutation_prompt": null}
{"id": "6636761f-15cf-4dde-af25-640867910b9f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            dynamic_F = self.F + (0.3 * (0.5 - np.random.rand()))  # Dynamic F adjustment\n            mutant_vector = np.clip(a + dynamic_F * (b - c), bounds.lb, bounds.ub)\n            dynamic_CR = self.CR * (1 - ((i + 1) / population.shape[0]))  # Adaptive CR\n            cross_points = np.random.rand(self.dim) < dynamic_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        search_bounds = [(max(lb, c - 0.1 * np.abs(c - lb)), min(ub, c + 0.1 * np.abs(ub - c))) for c, lb, ub in zip(candidate, bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=search_bounds)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        base_pattern = candidate[:partition_size]\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = base_pattern  # Refined periodicity\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhanced local search by dynamically adjusting search intervals based on convergence trends.", "configspace": "", "generation": 4, "fitness": 0.9658631386155058, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.030. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "215f1a9c-222f-497c-b279-51aab9fb1c86", "metadata": {"aucs": [0.9235447060246306, 0.9829956347274952, 0.9910490750943914], "final_y": [0.164858477716896, 0.1648656009320194, 0.1648648898895333]}, "mutation_prompt": null}
{"id": "da2af7ae-016c-47a4-a709-f024e55780ab", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            diversity = np.std(population, axis=0)  # Added line to calculate diversity\n            adaptive_F = self.F * (1 + 0.1 * np.mean(diversity)) # Adjust F based on diversity\n            mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Incorporate adaptive mutation factor control based on population diversity to improve convergence dynamics.", "configspace": "", "generation": 4, "fitness": 0.8623342363286944, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.164. And the mean value of best solutions found was 0.213 (0. is the best) with standard deviation 0.068.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.6305546706485785, 0.983443588324681, 0.9730044500128234], "final_y": [0.30958365976333757, 0.1648577212327077, 0.1648624110629483]}, "mutation_prompt": null}
{"id": "fc7dad61-723e-4e2d-b837-017b7aa56e2d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.population_size = self.initial_population_size\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            dynamic_F = self.F + (0.3 * (0.5 - np.random.rand()))  # Dynamic F adjustment\n            mutant_vector = np.clip(a + dynamic_F * (b - c), bounds.lb, bounds.ub)\n            dynamic_CR = self.CR * (1 - ((i + 1) / population.shape[0]))  # Adaptive CR\n            cross_points = np.random.rand(self.dim) < dynamic_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        result = minimize(func, candidate, method=self.local_search_method, bounds=list(zip(bounds.lb, bounds.ub)))\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        base_pattern = candidate[:partition_size]\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = base_pattern  # Refined periodicity\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                        # Adjust population size dynamically based on progress\n                        self.population_size = min(self.initial_population_size, self.population_size + 1)\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhanced exploration by introducing dynamic adaptation of population size and mutation factor based on convergence feedback.", "configspace": "", "generation": 4, "fitness": 0.9690503651466691, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "215f1a9c-222f-497c-b279-51aab9fb1c86", "metadata": {"aucs": [0.9546220643245824, 0.9747155191137169, 0.9778135120017081], "final_y": [0.16485954716894202, 0.16486026564787126, 0.16485771773286473]}, "mutation_prompt": null}
{"id": "cd17caab-d14e-429c-b20a-526a462feded", "solution": "import numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import levy\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            dynamic_F = self.F + (0.4 * (0.5 - np.random.rand()))  # Modified dynamic F adjustment\n            mutant_vector = np.clip(a + dynamic_F * (b - c), bounds.lb, bounds.ub)\n            dynamic_CR = self.CR * (1 - ((i + 1) / population.shape[0]))  # Adaptive CR\n            cross_points = np.random.rand(self.dim) < dynamic_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = self.levy_perturbation(trial_vector, bounds)  # Levy flight perturbation\n        return new_population\n    \n    def levy_perturbation(self, candidate, bounds):\n        perturbation = levy.rvs(size=self.dim) * 0.01  # Levy flight with a small step size\n        candidate = candidate + perturbation\n        return np.clip(candidate, bounds.lb, bounds.ub)\n\n    def local_search(self, candidate, func, bounds):\n        result = minimize(func, candidate, method=self.local_search_method, bounds=list(zip(bounds.lb, bounds.ub)))\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        base_pattern = candidate[:partition_size]\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = base_pattern  # Refined periodicity\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhance exploration and exploitation by adding a Levy flight perturbation step and improved dynamic mutation factor adjustment.", "configspace": "", "generation": 4, "fitness": 0.9788433879682886, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.979 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "215f1a9c-222f-497c-b279-51aab9fb1c86", "metadata": {"aucs": [0.9707648263806932, 0.9747162624297815, 0.9910490750943914], "final_y": [0.16485656684854966, 0.1648595707460614, 0.1648648898895333]}, "mutation_prompt": null}
{"id": "8c153bc0-4a6a-4271-bc4a-ef233298698a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            dynamic_F = self.F + (0.3 * (0.5 - np.random.rand()))  # Dynamic F adjustment\n            mutant_vector = np.clip(a + dynamic_F * (b - c), bounds.lb, bounds.ub)\n            dynamic_CR = self.CR * (1 - ((i + 1) / (population.shape[0] + 10)))  # Adaptive CR fine-tuning\n            cross_points = np.random.rand(self.dim) < dynamic_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        # Adaptive local search: alter method based on function evaluations\n        if self.budget - evaluations > self.budget * 0.1:\n            method = 'L-BFGS-B'\n        else:\n            method = 'Powell'\n        result = minimize(func, candidate, method=method, bounds=list(zip(bounds.lb, bounds.ub)))\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        base_pattern = candidate[:partition_size]\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = base_pattern\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Introduces synergy across populations by employing periodic crossover and applying adaptive local search for improved convergence.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_id": "989783c1-9cdc-40b4-b28b-de7de63fd8ff", "metadata": {}, "mutation_prompt": null}
{"id": "517fd687-5dfe-4050-8ebb-9e7d8f252b2a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Refines periodicity enforcement by adjusting partition size for improved constructive interference.", "configspace": "", "generation": 5, "fitness": 0.9904818058668415, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.990 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.9975211158564036, 0.9888740095482941, 0.985050292195827], "final_y": [0.16485692136063568, 0.16485931180515778, 0.16485855437819918]}, "mutation_prompt": null}
{"id": "d09610c3-2dcf-47dd-addd-66eda373ad8d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F_min = 0.5  # Minimum mutation factor\n        self.F_max = 0.9  # Maximum mutation factor\n        self.CR_min = 0.7  # Minimum crossover probability\n        self.CR_max = 0.95  # Maximum crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        F = np.random.uniform(self.F_min, self.F_max)  # Adaptive mutation factor\n        CR = np.random.uniform(self.CR_min, self.CR_max)  # Adaptive crossover probability\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances exploration by introducing adaptive mutation and crossover rates in the Differential Evolution process.", "configspace": "", "generation": 5, "fitness": 0.9807464764609044, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.981 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.9767382072445738, 0.9832438863046297, 0.9822573358335094], "final_y": [0.164858515005064, 0.1648604050328193, 0.1648593747714302]}, "mutation_prompt": null}
{"id": "f7d1b79e-32fc-4537-a6b3-ed8f9d7cc4d7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - 1.2 * population  # Enhanced diversity\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Refines the hybrid Differential Evolution algorithm by enhancing initial population diversity through scaling quasi-oppositional initialization.", "configspace": "", "generation": 5, "fitness": 0.9712630535293751, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.971 with standard deviation 0.019. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.9445961470250368, 0.9895655668932921, 0.9796274466697966], "final_y": [0.16486032574618525, 0.16485947782085097, 0.16485906118141658]}, "mutation_prompt": null}
{"id": "c4f5b64c-5219-46dd-a298-09db50f921c4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            adaptive_F = np.random.uniform(0.5, 0.9)  # Adaptive mutation factor\n            mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        candidate[:partition_size] = np.mean(candidate[:partition_size])  # Enforces periodicity adjustment\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Introduces adaptive mutation factor and periodicity enforcement to enhance exploration and convergence.", "configspace": "", "generation": 5, "fitness": 0.9780141712263086, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.978 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.9743445173914165, 0.9769452602228561, 0.9827527360646531], "final_y": [0.16485644647472164, 0.16485664675180012, 0.16485865937809197]}, "mutation_prompt": null}
{"id": "bbab330b-297b-48cd-9015-79da647f5d08", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            dynamic_F = self.F + (0.5 * (0.5 - np.random.rand()))  # Increased dynamic F adjustment\n            mutant_vector = np.clip(a + dynamic_F * (b - c), bounds.lb, bounds.ub)\n            if i % 2 == 0:  # Periodic crossover strategy\n                dynamic_CR = self.CR * (1 - ((i + 1) / (population.shape[0] + 5)))  # Adjusted adaptive CR fine-tuning\n            else:\n                dynamic_CR = self.CR * (1 - ((i + 1) / (population.shape[0] + 10)))\n            cross_points = np.random.rand(self.dim) < dynamic_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        result = minimize(func, candidate, method=self.local_search_method, bounds=list(zip(bounds.lb, bounds.ub)))\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        base_pattern = candidate[:partition_size]\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = base_pattern  # Refined periodicity\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhanced DE by introducing periodic crossover strategy and adaptive mutation factor to improve solution diversity and convergence.", "configspace": "", "generation": 5, "fitness": 0.9802240990356671, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.980 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "989783c1-9cdc-40b4-b28b-de7de63fd8ff", "metadata": {"aucs": [0.9755978719369314, 0.9887422357564241, 0.9763321894136459], "final_y": [0.16485678999078335, 0.16486477807370337, 0.16485923179658457]}, "mutation_prompt": null}
{"id": "b4862852-6d25-4f13-83c0-25f65dbfba41", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n        self.niche_radius = 0.1 * (dim ** 0.5)\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            dynamic_F = self.F + (0.3 * (0.5 - np.random.rand()))\n            mutant_vector = np.clip(a + dynamic_F * (b - c), bounds.lb, bounds.ub)\n            dynamic_CR = self.CR * (1 - ((i + 1) / (population.shape[0] + 10)))\n            cross_points = np.random.rand(self.dim) < dynamic_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            if np.linalg.norm(trial_vector - population[i]) < self.niche_radius:\n                new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        result = minimize(func, candidate, method=self.local_search_method, bounds=list(zip(bounds.lb, bounds.ub)))\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=3):\n        partition_size = self.dim // periodicity\n        base_pattern = candidate[:partition_size]\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = base_pattern\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                population = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Improves modularity and adaptiveness by integrating niche-based selection and dynamic periodicity adjustments in Differential Evolution.", "configspace": "", "generation": 5, "fitness": 0.9832413457308982, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.983 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "989783c1-9cdc-40b4-b28b-de7de63fd8ff", "metadata": {"aucs": [0.9905557240101628, 0.9856116057149674, 0.9735567074675643], "final_y": [0.16485607187642604, 0.1648560403285999, 0.16486101261705066]}, "mutation_prompt": null}
{"id": "35b20d6c-66c2-4d98-b3eb-7dd0f8934350", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            # Dynamically adjust F based on population diversity\n            diversity = np.std(population, axis=0).mean()\n            adaptive_F = self.F * (1 + 0.5 * diversity)\n            mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Improved convergence by adapting the mutation factor dynamically based on population diversity.", "configspace": "", "generation": 5, "fitness": 0.9577945996403714, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.026. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.9215454133015683, 0.976640504200854, 0.975197881418692], "final_y": [0.16485684188469918, 0.164856446308687, 0.16485675588721427]}, "mutation_prompt": null}
{"id": "920d7fce-b2ab-435c-a7ea-765cca05dc5c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8\n        self.CR = 0.9\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n        \n    def chaotic_init(self, bounds):\n        population = np.empty((self.population_size, self.dim))\n        for i in range(self.population_size):\n            x = np.random.rand(self.dim)\n            x = 4 * x * (1 - x)  # Logistic map for chaos\n            population[i] = bounds.lb + (bounds.ub - bounds.lb) * x\n        return population\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            F_adaptive = self.F * (1.1 if np.random.rand() > 0.5 else 0.9)\n            mutant_vector = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=3):\n        if self.dim % periodicity == 0:\n            partition_size = self.dim // periodicity\n            for i in range(periodicity):\n                candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.chaotic_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Adaptive hybrid Differential Evolution with chaotic initialization and periodicity reinforcement for enhanced global optimization.", "configspace": "", "generation": 5, "fitness": 0.9223664290509568, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.082. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.8068373968127638, 0.9806281707772209, 0.9796337195628856], "final_y": [0.2280475098825846, 0.16485956008290403, 0.1648575464001285]}, "mutation_prompt": null}
{"id": "b4851d47-4ca2-42f2-856f-62c26d028666", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            adaptive_F = self.F * np.random.uniform(0.9, 1.1)  # Dynamic adjustment\n            mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        candidate = np.roll(candidate, np.random.randint(self.dim))  # Random roll for diversity\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhanced periodicity enforcement and dynamic mutation strategy for improved convergence.", "configspace": "", "generation": 5, "fitness": 0.9472036882722249, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.044. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.8858736642138295, 0.9714621231634322, 0.9842752774394131], "final_y": [0.16486285004313894, 0.1648578683362869, 0.16486010056078804]}, "mutation_prompt": null}
{"id": "d7bab0a0-ccbc-45ff-a586-51a6820c38ae", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.92  # Crossover probability, slightly increased\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Refines periodicity enforcement by slightly increasing crossover probability for better exploration-exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.9887321997268176, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.989 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "517fd687-5dfe-4050-8ebb-9e7d8f252b2a", "metadata": {"aucs": [0.9976804675084566, 0.9912051585222179, 0.9773109731497782], "final_y": [0.16485692136063568, 0.16485702935221258, 0.16486187290343868]}, "mutation_prompt": null}
{"id": "4a291260-c36e-4806-889d-907d887d1ec1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.85  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances periodicity enforcement by adjusting the mutation factor for optimized constructive interference.", "configspace": "", "generation": 6, "fitness": 0.9870985122402377, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.987 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "517fd687-5dfe-4050-8ebb-9e7d8f252b2a", "metadata": {"aucs": [0.9973122696891163, 0.9918639170113287, 0.9721193500202682], "final_y": [0.16485709969493056, 0.16485770328473848, 0.16485830652031053]}, "mutation_prompt": null}
{"id": "8f3b5ab0-7c82-426c-a685-8376ab7c1ee2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Mutation factor, adjusted for exploration\n        self.CR = 0.85  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n        self.min_periodicity = 3\n        self.max_periodicity = 7\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, population_variance):\n        # Adaptive periodicity based on population variance\n        periodicity = int(self.min_periodicity + (self.max_periodicity - self.min_periodicity) * (1 - population_variance))\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n\n                population_scores = np.array([func(ind) for ind in population])\n                population_variance = np.var(population_scores)\n\n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate, population_variance)\n                    score = func(candidate)\n                    evaluations += 1\n\n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances periodicity and exploration-exploitation balance by varying partition size adaptively based on fitness variance.", "configspace": "", "generation": 6, "fitness": 0.9136883766417645, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.019. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "517fd687-5dfe-4050-8ebb-9e7d8f252b2a", "metadata": {"aucs": [0.9181733826002869, 0.9345389668736692, 0.8883527804513371], "final_y": [0.18187989144612915, 0.1648577283675945, 0.18187965570661202]}, "mutation_prompt": null}
{"id": "f06269e9-065f-469c-9145-c10a2cf1f807", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.initial_F = 0.8  # Initial mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n        self.F_reduction_rate = 0.9  # Reduction rate for mutation factor\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds, current_F):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + current_F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n        current_F = self.initial_F\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds, current_F)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                current_F *= self.F_reduction_rate  # Dynamically adjust mutation factor\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Refines periodicity enforcement by integrating an adaptive mutation factor for dynamic exploration-exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.8996329197340677, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.090. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "517fd687-5dfe-4050-8ebb-9e7d8f252b2a", "metadata": {"aucs": [0.9963693838559053, 0.9226212149895268, 0.779908160356771], "final_y": [0.16485685245532244, 0.1648608753274805, 0.1648598151924301]}, "mutation_prompt": null}
{"id": "aecb23b1-a5a3-4e9f-acf0-167868530dcd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        self.F = np.var(population) / 10  # Dynamic mutation factor based on population diversity\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances periodicity enforcement by dynamically adjusting the mutation factor based on population diversity.", "configspace": "", "generation": 6, "fitness": 0.8693179089159687, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.111. And the mean value of best solutions found was 0.202 (0. is the best) with standard deviation 0.052.", "error": "", "parent_id": "517fd687-5dfe-4050-8ebb-9e7d8f252b2a", "metadata": {"aucs": [0.7149508247516163, 0.9737787364471139, 0.9192241655491761], "final_y": [0.2749583064887554, 0.16485666971075386, 0.16485897878513378]}, "mutation_prompt": null}
{"id": "df1a0ee0-74bf-4209-8448-b4a957cc9f04", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds, iteration):\n        new_population = np.empty_like(population)\n        dynamic_CR = 0.5 + 0.4 * np.cos(2 * np.pi * (iteration / self.budget))  # Dynamic CR\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < dynamic_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        iteration = 0\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds, iteration)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n            iteration += 1\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "The algorithm enhances diversity and convergence by updating the crossover probability dynamically based on iteration count in the hybrid Differential Evolution approach.", "configspace": "", "generation": 6, "fitness": 0.9322865362316253, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.932 with standard deviation 0.060. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.973121715941223, 0.9762736969231071, 0.8474641958305458], "final_y": [0.16485845870333837, 0.1648573489115488, 0.2072557737065851]}, "mutation_prompt": null}
{"id": "eae9d933-54a9-496a-b056-54a4c12327e5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.85  # Slightly decreased crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Refines the hybrid Differential Evolution algorithm by slightly increasing the population size and modifying the crossover probability for improved diversity and convergence.", "configspace": "", "generation": 6, "fitness": 0.8477496593764379, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.149. And the mean value of best solutions found was 0.213 (0. is the best) with standard deviation 0.068.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.970389660212684, 0.9340745990890607, 0.6387847188275693], "final_y": [0.16485939828095886, 0.1648568322088222, 0.30958420076802984]}, "mutation_prompt": null}
{"id": "da5ae602-3fe8-476b-933a-ff451e4592e7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.5 + 0.3 * np.sin(i * np.pi / population.shape[0])  # Adaptive mutation factor\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=2):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances mutation factor adaptively based on evaluation count to further improve exploration-exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.9641339388032213, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.024. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "f9caadfa-bf5d-4d4c-9eb4-1d096ddd8dbf", "metadata": {"aucs": [0.9851230600437119, 0.9299677832161739, 0.9773109731497782], "final_y": [0.16485833990929255, 0.16485855787299397, 0.16486187290343868]}, "mutation_prompt": null}
{"id": "bfbdd9f9-6338-4466-9f30-15b1fee13da2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, fitness, max_fitness, periodicity=5):\n        adaptive_periodicity = max(2, int(periodicity * (fitness / max_fitness)))\n        partition_size = self.dim // adaptive_periodicity\n        for i in range(adaptive_periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    fitness = func(candidate)\n                    evaluations += 1\n                    candidate = self.enforce_periodicity(candidate, fitness, best_score)\n                    \n                    if fitness < best_score:\n                        best_score = fitness\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances periodicity enforcement by adaptively tuning partition size based on individual fitness to improve constructive interference.", "configspace": "", "generation": 6, "fitness": 0.8524612917357356, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.111. And the mean value of best solutions found was 0.202 (0. is the best) with standard deviation 0.052.", "error": "", "parent_id": "517fd687-5dfe-4050-8ebb-9e7d8f252b2a", "metadata": {"aucs": [0.9353773115280305, 0.6954509135856455, 0.9265556500935308], "final_y": [0.16485608819551223, 0.2749572014189431, 0.16485721622572258]}, "mutation_prompt": null}
{"id": "75140f6a-6638-454f-a1af-eaa6a4107797", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n        self.partition_min = 3\n        self.partition_max = 10\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            dynamic_F = self.F + np.random.uniform(-0.2, 0.2)\n            mutant_vector = np.clip(a + dynamic_F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate):\n        periodicity = np.random.randint(self.partition_min, self.partition_max)\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances periodicity enforcement and exploration with dynamic partitioning and adaptive mutation strategies.", "configspace": "", "generation": 6, "fitness": 0.9358943198340551, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.936 with standard deviation 0.040. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "517fd687-5dfe-4050-8ebb-9e7d8f252b2a", "metadata": {"aucs": [0.9922029637556491, 0.9052762148907676, 0.9102037808557488], "final_y": [0.16485688912806662, 0.18187990315391478, 0.18187945262635852]}, "mutation_prompt": null}
{"id": "f49fcea4-3893-46ef-9b48-0d8118fd1f68", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = (self.dim // periodicity) + 1  # Dynamic adjustment based on evaluation\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Refines periodicity enforcement by dynamically adjusting the partition size based on the current evaluation position to enhance constructive interference.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('could not broadcast input array from shape (3,) into shape (1,)').", "error": "ValueError('could not broadcast input array from shape (3,) into shape (1,)')", "parent_id": "517fd687-5dfe-4050-8ebb-9e7d8f252b2a", "metadata": {}, "mutation_prompt": null}
{"id": "bd00431f-eedc-47e1-8207-2a83c3b336e3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.85  # Mutation factor, slightly increased\n        self.CR = 0.92  # Crossover probability, slightly increased\n        self.num_populations = 3\n        self.local_search_method = 'Powell'  # Changed local search method\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Tweaks mutation factor and local search strategy to enhance solution refinement.", "configspace": "", "generation": 7, "fitness": 0.9925856294998686, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.993 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d7bab0a0-ccbc-45ff-a586-51a6820c38ae", "metadata": {"aucs": [0.9970539556157615, 0.9851948700527603, 0.9955080628310838], "final_y": [0.16485577218021996, 0.16485687740789168, 0.16486089832327866]}, "mutation_prompt": null}
{"id": "df8f5ac8-2f25-4c2f-8d98-c01571ecfb4a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.75  # Mutation factor adjusted from 0.8 to 0.75\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Fine-tunes exploration-exploitation balance by slightly reducing mutation factor for enhanced convergence.", "configspace": "", "generation": 7, "fitness": 0.9928273812887882, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.993 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "517fd687-5dfe-4050-8ebb-9e7d8f252b2a", "metadata": {"aucs": [0.9973622853288796, 0.9849097406094981, 0.996210117927987], "final_y": [0.16485785545978537, 0.16486115809223856, 0.16485803262802912]}, "mutation_prompt": null}
{"id": "7f3c21da-855d-4589-a8ae-f89ec5c88814", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, phase_budget):\n        periodicity = max(3, 5 - phase_budget // (self.budget // 5))  # Dynamic periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    phase_budget = evaluations // (self.budget // 5)\n                    candidate = self.enforce_periodicity(candidate, phase_budget)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances convergence by dynamically adjusting periodicity based on current optimization phase.", "configspace": "", "generation": 7, "fitness": 0.9901010205817418, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.990 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "517fd687-5dfe-4050-8ebb-9e7d8f252b2a", "metadata": {"aucs": [0.9968047113714624, 0.9901370213731931, 0.9833613290005697], "final_y": [0.16485622638166908, 0.1648577870353819, 0.16485590227090385]}, "mutation_prompt": null}
{"id": "ab8a424f-865d-461b-802f-d1ea09504c8d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor (changed from 0.8)\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 4  # Increased number of populations for better diversity\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Adjusts mutation factor and increases population diversity for enhanced exploration and convergence.", "configspace": "", "generation": 7, "fitness": 0.9931066849953959, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.993 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "517fd687-5dfe-4050-8ebb-9e7d8f252b2a", "metadata": {"aucs": [0.9920511095908041, 0.9900441705795581, 0.9972247748158254], "final_y": [0.1648577466862423, 0.16485762639655932, 0.1648569687686937]}, "mutation_prompt": null}
{"id": "786ec689-0ad2-4fab-b9e5-b722e4ad010d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=4):  # Increased periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Refines periodicity enforcement by increasing periodicity factor for enhanced structural uniformity.", "configspace": "", "generation": 7, "fitness": 0.9891729495818998, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.989 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "517fd687-5dfe-4050-8ebb-9e7d8f252b2a", "metadata": {"aucs": [0.9858609495689274, 0.99057800152564, 0.9910798976511319], "final_y": [0.1648569550813681, 0.1648565280766816, 0.16485964235319306]}, "mutation_prompt": null}
{"id": "2de5737a-93e7-461f-8ac1-fb466b1eb4fd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.92  # Crossover probability, slightly increased\n        self.num_populations = 5  # Increased number of populations\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Improves exploration by increasing the number of populations, allowing for broader parameter space coverage.", "configspace": "", "generation": 7, "fitness": 0.996704631378854, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.997 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d7bab0a0-ccbc-45ff-a586-51a6820c38ae", "metadata": {"aucs": [0.9938094024894825, 0.9990086075393438, 0.9972958841077356], "final_y": [0.16485966343738734, 0.16486019323424161, 0.1648561965589006]}, "mutation_prompt": null}
{"id": "aba30633-7f57-4a8d-9a5b-9603b4c46b40", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhance exploration by increasing the population size for broader search space coverage.", "configspace": "", "generation": 7, "fitness": 0.9927717732619342, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.993 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "517fd687-5dfe-4050-8ebb-9e7d8f252b2a", "metadata": {"aucs": [0.9935288588846835, 0.9930087085172591, 0.99177775238386], "final_y": [0.16485658772337164, 0.16485954877447484, 0.16486294960636283]}, "mutation_prompt": null}
{"id": "9934a1ed-caa9-4e25-96ba-785f5a046a85", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 * dim  # Increased population size\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances search efficiency by increasing the population size for broader exploration.", "configspace": "", "generation": 7, "fitness": 0.992777360192668, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.993 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "517fd687-5dfe-4050-8ebb-9e7d8f252b2a", "metadata": {"aucs": [0.989413969307893, 0.9929210091513947, 0.9959971021187167], "final_y": [0.16485859034667327, 0.16485904577734167, 0.16485723981815958]}, "mutation_prompt": null}
{"id": "c9abb8b4-1e42-49e2-b8df-c194095b3c83", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.92  # Crossover probability, slightly increased\n        self.num_populations = 3\n        self.local_search_method = 'L-BFGS-B'\n    \n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate):\n        periods = np.random.choice(range(3, 7))  # Dynamic selection from 3 to 6\n        partition_size = self.dim // periods\n        for i in range(periods):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n\n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n\n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n\n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n\n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Refines periodicity enforcement by using dynamic partition size for adaptive constructive interference.", "configspace": "", "generation": 7, "fitness": 0.9929435427271942, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.993 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "d7bab0a0-ccbc-45ff-a586-51a6820c38ae", "metadata": {"aucs": [0.9961616163445289, 0.9877322156911552, 0.9949367961458988], "final_y": [0.16485685245532244, 0.16485963018644878, 0.16485979340806978]}, "mutation_prompt": null}
{"id": "8be03097-fbb0-4117-b909-e8aa8fc5d536", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor (changed from 0.8)\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 4  # Increased number of populations for better diversity\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations % (self.budget // 20) == 0:  # Increased local search frequency\n                    local_best = self.local_search(best_candidate, func, bounds)\n                    if func(local_best) < best_score:\n                        best_score = func(local_best)\n                        best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhance local search frequency for improved fine-tuning of candidate solutions.", "configspace": "", "generation": 8, "fitness": 0.9904209136933145, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.990 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ab8a424f-865d-461b-802f-d1ea09504c8d", "metadata": {"aucs": [0.9887404463425556, 0.9880203688264114, 0.9945019259109762], "final_y": [0.1648570166408998, 0.16485758103086023, 0.16485598088153675]}, "mutation_prompt": null}
{"id": "637ac1b0-3750-4474-aaa7-54393fe77ecc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.85  # Mutation factor, slightly increased\n        self.CR = 0.92  # Crossover probability, slightly increased\n        self.num_populations = 5  # Increased number of populations\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Augment the mutation factor in the differential evolution step to enhance convergence speed.", "configspace": "", "generation": 8, "fitness": 0.9929850794005538, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.993 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2de5737a-93e7-461f-8ac1-fb466b1eb4fd", "metadata": {"aucs": [0.9963902485903395, 0.9953596473031716, 0.9872053423081504], "final_y": [0.1648601922028078, 0.16485918916195286, 0.16485728374008546]}, "mutation_prompt": null}
{"id": "eba630f7-626a-4816-afaf-46c32326c2a6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.92  # Crossover probability, slightly increased\n        self.num_populations = 5  # Increased number of populations\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.5 + 0.3 * np.random.rand()  # Dynamic mutation factor\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Introduces a dynamic mutation factor to improve exploration and convergence by adapting to the current state of the search.", "configspace": "", "generation": 8, "fitness": 0.9942441354966394, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.994 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2de5737a-93e7-461f-8ac1-fb466b1eb4fd", "metadata": {"aucs": [0.9952058303624295, 0.993978124812182, 0.9935484513153067], "final_y": [0.16485616618446408, 0.164859044873517, 0.16486319089392243]}, "mutation_prompt": null}
{"id": "a67828ae-2d42-41d7-bbdf-74f1aee0bbee", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 15 * dim  # Increased population size\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 4\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            self.CR = 0.8 - 0.2 * (i / population.shape[0])  # Adaptive crossover probability\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Introduce adaptive crossover probability and increase population size to enhance exploration and convergence.", "configspace": "", "generation": 8, "fitness": 0.9945222813006765, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.995 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ab8a424f-865d-461b-802f-d1ea09504c8d", "metadata": {"aucs": [0.9958115150078183, 0.997016478421399, 0.9907388504728127], "final_y": [0.16487112758162492, 0.16485607509616662, 0.16485688529778497]}, "mutation_prompt": null}
{"id": "f01dc793-8571-49a4-a43c-005752ef8989", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor (changed from 0.8)\n        self.CR = 0.85  # Crossover probability (adjusted from 0.9)\n        self.num_populations = 4  # Increased number of populations for better diversity\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=4):  # Adjusted periodicity (from 5 to 4)\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Fine-tunes the crossover probability and enhances periodicity enforcement for better convergence.", "configspace": "", "generation": 8, "fitness": 0.991060039268646, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.991 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ab8a424f-865d-461b-802f-d1ea09504c8d", "metadata": {"aucs": [0.9842728121272586, 0.9923535021349308, 0.9965538035437486], "final_y": [0.16486232908148024, 0.1648578265310784, 0.16485656575278795]}, "mutation_prompt": null}
{"id": "840b0976-1a5e-4a46-b97d-29db5ed6770b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.75  # Mutation factor (updated from 0.7)\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 4  # Increased number of populations for better diversity\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Slightly adjusted mutation factor to refine exploration and convergence balance.", "configspace": "", "generation": 8, "fitness": 0.9924881072758227, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.992 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ab8a424f-865d-461b-802f-d1ea09504c8d", "metadata": {"aucs": [0.9850199859911106, 0.9970840503485131, 0.9953602854878443], "final_y": [0.1648608041720876, 0.1648586091742582, 0.16485730924656927]}, "mutation_prompt": null}
{"id": "d1b67ed2-9e5b-4208-9098-7f7aa3223dee", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor (changed from 0.8)\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 4  # Increased number of populations for better diversity\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        base_pattern = candidate[:partition_size].copy()  # Ensure uniformity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = base_pattern\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances periodicity enforcement by adjusting candidate cloning to ensure uniformity across all partitions.", "configspace": "", "generation": 8, "fitness": 0.9900582079075789, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.990 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ab8a424f-865d-461b-802f-d1ea09504c8d", "metadata": {"aucs": [0.9887404463425556, 0.9871753280166166, 0.9942588493635642], "final_y": [0.1648570166408998, 0.16485713807186142, 0.1648562712687357]}, "mutation_prompt": null}
{"id": "8f6e534e-356d-40d4-bda1-f19b69da7156", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.num_populations = 4\n        self.local_search_method = 'L-BFGS-B'\n        self.mutation_adapt_rate = 0.1  # Added adaptive mutation rate\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n            new_population[i] += np.random.normal(0, self.mutation_adapt_rate, self.dim)  # Added random walk\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if evaluations % 50 == 0:  # Added dynamic adjustment of mutation factor\n                    self.F = np.random.uniform(0.5, 1.0)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances exploration and convergence by using adaptive mutation factors and incorporating diversity through random walks.", "configspace": "", "generation": 8, "fitness": 0.9949447882341738, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.995 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ab8a424f-865d-461b-802f-d1ea09504c8d", "metadata": {"aucs": [0.9959266814645502, 0.9922013300117135, 0.9967063532262577], "final_y": [0.1648593117315037, 0.16486472081302117, 0.16485910287318173]}, "mutation_prompt": null}
{"id": "ee3d9024-4171-4154-8c61-390f941567b1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.85  # Mutation factor, slightly increased\n        self.CR = 0.92  # Crossover probability, slightly increased\n        self.num_populations = 5  # Increased number of populations\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances the mutation process by slightly increasing the mutation factor to improve solution diversity.", "configspace": "", "generation": 8, "fitness": 0.9921435917259007, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.992 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2de5737a-93e7-461f-8ac1-fb466b1eb4fd", "metadata": {"aucs": [0.9944984002559067, 0.9934209063929073, 0.9885114685288879], "final_y": [0.16485782254207337, 0.16486087722517795, 0.16485684595686]}, "mutation_prompt": null}
{"id": "80ac74b9-ba01-48de-8679-43cb80307b77", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n        self.num_populations = 4  # Increased number of populations for better diversity\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            diversity = np.mean(np.std(population, axis=0))\n            adaptive_F = self.F + 0.1 * diversity  # Adjusting mutation based on diversity\n            adaptive_CR = max(0.5, self.CR - 0.1 * diversity)  # Adjusting crossover based on diversity\n            mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < adaptive_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances convergence by incorporating adaptive mutation and crossover rates based on population diversity.", "configspace": "", "generation": 8, "fitness": 0.9938958855326554, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.994 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ab8a424f-865d-461b-802f-d1ea09504c8d", "metadata": {"aucs": [0.9919112702718277, 0.9955297897922338, 0.9942465965339048], "final_y": [0.1648583269627244, 0.16486236481738026, 0.1648560521788186]}, "mutation_prompt": null}
{"id": "5bbe2b25-f7f5-4a12-84ad-ede8d11ce7ca", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.95  # Crossover probability, slightly increased\n        self.num_populations = 5  # Increased number of populations\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances local optimization effectiveness by adjusting crossover probability to improve convergence in promising regions.", "configspace": "", "generation": 9, "fitness": 0.9925450249822384, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.993 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2de5737a-93e7-461f-8ac1-fb466b1eb4fd", "metadata": {"aucs": [0.9967848018128742, 0.99414005500323, 0.9867102181306111], "final_y": [0.16485745146717568, 0.16485792062579363, 0.16485619226828963]}, "mutation_prompt": null}
{"id": "93f6725a-9886-4fe7-b1e1-a848878ef684", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.9  # Mutation factor, increased for better exploration\n        self.CR = 0.92  # Crossover probability, slightly increased\n        self.num_populations = 5  # Increased number of populations\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances differential evolution by increasing mutation factor for improved exploration.", "configspace": "", "generation": 9, "fitness": 0.995582479121714, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.996 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2de5737a-93e7-461f-8ac1-fb466b1eb4fd", "metadata": {"aucs": [0.9956024044071992, 0.9936965914129611, 0.9974484415449817], "final_y": [0.16485977361203463, 0.16485774982820545, 0.16485793229241452]}, "mutation_prompt": null}
{"id": "041e3c1d-50a2-4a97-86ec-cbdc4c5aeaa9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.95  # Crossover probability, slightly increased\n        self.num_populations = 5\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=None):  # Adaptive periodicity\n        if periodicity is None:\n            periodicity = max(5, self.dim // 4)  # Adjusted periodicity calculation\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances exploration and periodicity enforcement by using adaptive periodicity and increased crossover probability.", "configspace": "", "generation": 9, "fitness": 0.9932895938918432, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.993 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2de5737a-93e7-461f-8ac1-fb466b1eb4fd", "metadata": {"aucs": [0.9967848018128742, 0.9944182833691472, 0.9886656964935083], "final_y": [0.16485745146717568, 0.1648578922753019, 0.1648583494670559]}, "mutation_prompt": null}
{"id": "9c25ff28-fd60-43a1-8813-e33d59091371", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.92  # Crossover probability, slightly increased\n        self.num_populations = 5  # Increased number of populations\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=4):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances local search efficiency by adjusting the periodicity parameter for better adaptability to problem complexity.", "configspace": "", "generation": 9, "fitness": 0.9936831895859376, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.994 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2de5737a-93e7-461f-8ac1-fb466b1eb4fd", "metadata": {"aucs": [0.9957508481081909, 0.9966023238019027, 0.9886963968477193], "final_y": [0.1648568068349875, 0.16485729465809373, 0.16485955777279582]}, "mutation_prompt": null}
{"id": "c31f92ee-b9a6-40e6-bc71-c31ad1d3101c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.num_populations = 4\n        self.local_search_method = 'L-BFGS-B'\n        self.mutation_adapt_rate = 0.1  # Added adaptive mutation rate\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n            new_population[i] += np.random.normal(0, self.mutation_adapt_rate, self.dim)  # Added random walk\n            new_population[i] = self.enforce_periodicity(new_population[i])  # Enforce periodicity during mutation\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if evaluations % 50 == 0:  # Added dynamic adjustment of mutation factor\n                    self.F = np.random.uniform(0.5, 1.0)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Adds periodicity enforcement during mutation to emphasize constructive interference.", "configspace": "", "generation": 9, "fitness": 0.9955733328210181, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.996 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8f6e534e-356d-40d4-bda1-f19b69da7156", "metadata": {"aucs": [0.9966062089080195, 0.9950282017894904, 0.9950855877655442], "final_y": [0.1648580283746398, 0.16486024732669535, 0.16485766630243393]}, "mutation_prompt": null}
{"id": "98e83b01-d21b-4296-b76f-d838abc04f96", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.num_populations = 4\n        self.local_search_method = 'L-BFGS-B'\n        self.mutation_adapt_rate = 0.1  # Added adaptive mutation rate\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n            new_population[i] += np.random.normal(0, self.mutation_adapt_rate, self.dim)  # Added random walk\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                self.CR = np.var(population) / (np.mean(population) + 1e-10)  # Dynamically update CR\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if evaluations % 50 == 0:  # Added dynamic adjustment of mutation factor\n                    self.F = np.random.uniform(0.5, 1.0)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances exploration by dynamically adjusting the crossover rate based on population diversity.", "configspace": "", "generation": 9, "fitness": 0.9916721944530552, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.992 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8f6e534e-356d-40d4-bda1-f19b69da7156", "metadata": {"aucs": [0.9871864054674403, 0.9917884314696952, 0.9960417464220301], "final_y": [0.1648567042585769, 0.1648585441155347, 0.1648579440745891]}, "mutation_prompt": null}
{"id": "e72b4830-8fa8-49f2-adf4-9d809db48493", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.92  # Crossover probability, slightly increased\n        self.num_populations = 5  # Increased number of populations\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size] * (i % 2 + 1)\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances periodicity enforcement by adjusting candidate segments for improved constructive interference.", "configspace": "", "generation": 9, "fitness": 0.9556411649550638, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.956 with standard deviation 0.054. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "2de5737a-93e7-461f-8ac1-fb466b1eb4fd", "metadata": {"aucs": [0.8790775583441428, 0.9959266416959835, 0.9919192948250648], "final_y": [0.20044617522060348, 0.16485635810711363, 0.16485782626158307]}, "mutation_prompt": null}
{"id": "0cbc0442-5384-439c-bd67-97faf2a23d41", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim  # Changed variable name for clarity\n        self.F = 0.7\n        self.CR = 0.9\n        self.num_populations = 4\n        self.local_search_method = 'L-BFGS-B'\n        self.mutation_adapt_rate = 0.1\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.initial_population_size, self.dim))  # Renamed variable\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n            new_population[i] += np.random.normal(0, self.mutation_adapt_rate, self.dim)\n            reinit_prob = np.cos(np.pi * i / population.shape[0])  # Added cosine reinitialization\n            if np.random.rand() < reinit_prob:\n                new_population[i] = np.random.uniform(bounds.lb, bounds.ub, self.dim)\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                if evaluations % 200 == 0:  # Adjusted to dynamically resize population\n                    population = np.vstack((population, self.quasi_oppositional_init(bounds)))\n                \n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if evaluations % 50 == 0:\n                    self.F = np.random.uniform(0.5, 1.0)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Introduces modified mutation strategy using cosine reinitialization and dynamic population resizing for enhanced exploration.", "configspace": "", "generation": 9, "fitness": 0.9922987559984845, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.992 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8f6e534e-356d-40d4-bda1-f19b69da7156", "metadata": {"aucs": [0.9924182172227041, 0.9878214536459269, 0.9966565971268226], "final_y": [0.16485843660901522, 0.16486380384394927, 0.1648579381960259]}, "mutation_prompt": null}
{"id": "fe1f876d-ea55-4ddc-9b82-c35e1678e369", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.num_populations = 4\n        self.local_search_method = 'L-BFGS-B'\n        self.mutation_adapt_rate = 0.1\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n            new_population[i] += np.random.normal(0, self.mutation_adapt_rate, self.dim)\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=None):\n        if periodicity is None:\n            periodicity = np.random.randint(3, 8)  # Dynamic periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if evaluations % 50 == 0:\n                    self.F = np.random.uniform(0.5, 1.0)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "An enhanced hybrid differential evolution algorithm using adaptive periodicity enforcement and dynamic population sizes to refine solutions more effectively.", "configspace": "", "generation": 9, "fitness": 0.9937201462294638, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.994 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8f6e534e-356d-40d4-bda1-f19b69da7156", "metadata": {"aucs": [0.9921253366917505, 0.9937171113752559, 0.9953179906213847], "final_y": [0.16486314780143463, 0.16485692679127673, 0.1648588330091355]}, "mutation_prompt": null}
{"id": "db56ff1c-25d9-4d96-8d74-8a5aa4fafd0c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.num_populations = 4\n        self.local_search_method = 'L-BFGS-B'\n        self.mutation_adapt_rate = 0.1\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n            new_population[i] += np.random.normal(0, self.mutation_adapt_rate, self.dim)\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate, periodicity=np.random.choice([5, 10]))  # Changed\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if evaluations % 50 == 0:\n                    self.F = np.random.uniform(0.5, 1.0)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        elite_preserved = self.local_search(best_candidate, func, bounds)  # Added\n        return elite_preserved  # Changed", "name": "HybridDifferentialEvolution", "description": "Enhances convergence by integrating a strategic elite solution preservation mechanism and dynamic periodicity enforcement.", "configspace": "", "generation": 9, "fitness": 0.9970780358898619, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.997 with standard deviation 0.000. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "8f6e534e-356d-40d4-bda1-f19b69da7156", "metadata": {"aucs": [0.9967673839451704, 0.9971233180014456, 0.99734340572297], "final_y": [0.16486096022287888, 0.16485780908598213, 0.16485956682834169]}, "mutation_prompt": null}
{"id": "01c4c127-90c1-4c6a-ad02-5ff398fc95f8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.num_populations = 4\n        self.local_search_method = 'L-BFGS-B'\n        self.mutation_adapt_rate = 0.1\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            self.CR = np.random.uniform(0.8, 1.0)  # Changed: Adjust crossover probability dynamically\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n            new_population[i] += np.random.normal(0, self.mutation_adapt_rate, self.dim)\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):\n        partition_size = self.dim // np.random.choice([5, 8, 10])  # Changed: Varied partition sizes for periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate, periodicity=np.random.choice([5, 10]))\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if evaluations % 50 == 0:\n                    self.F = np.random.uniform(0.5, 1.0)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        elite_preserved = self.local_search(best_candidate, func, bounds)\n        return elite_preserved", "name": "HybridDifferentialEvolution", "description": "Enhances convergence by adjusting crossover probability dynamically and applying periodicity enforcement with varied partition sizes.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('could not broadcast input array from shape (2,) into shape (0,)').", "error": "ValueError('could not broadcast input array from shape (2,) into shape (0,)')", "parent_id": "db56ff1c-25d9-4d96-8d74-8a5aa4fafd0c", "metadata": {}, "mutation_prompt": null}
{"id": "6ab6867d-dc6c-4a08-97c1-a0a8f808e99f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.num_populations = 4\n        self.local_search_method = 'L-BFGS-B'\n        self.mutation_adapt_rate = 0.1\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n            new_population[i] += np.random.normal(0, self.mutation_adapt_rate, self.dim)\n            self.mutation_adapt_rate = 0.05 if evaluations % 100 == 0 else self.mutation_adapt_rate  # Changed\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate, periodicity=np.random.choice([5, 10]))\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if evaluations % 50 == 0:\n                    self.F = np.random.uniform(0.5, 1.0)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        elite_preserved = self.local_search(best_candidate, func, bounds)\n        return elite_preserved", "name": "HybridDifferentialEvolution", "description": "Enhances periodicity adaptation by dynamically adjusting mutation rates based on recent performance trends.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'evaluations' is not defined\").", "error": "NameError(\"name 'evaluations' is not defined\")", "parent_id": "db56ff1c-25d9-4d96-8d74-8a5aa4fafd0c", "metadata": {}, "mutation_prompt": null}
{"id": "52a59df5-6d4e-408d-ac71-54a5b271b72e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.92  # Crossover probability, slightly increased\n        self.num_populations = 5  # Increased number of populations\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search selectively to periodic candidates\n                if evaluations % 10 == 0:  # Every 10 evaluations, consider local search\n                    local_best = self.local_search(best_candidate, func, bounds)\n                    if func(local_best) < best_score:\n                        best_score = func(local_best)\n                        best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances local refinement by selectively applying local search to periodic candidates, improving convergence on periodic landscapes.", "configspace": "", "generation": 10, "fitness": 0.7757106940871977, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.776 with standard deviation 0.201. And the mean value of best solutions found was 0.252 (0. is the best) with standard deviation 0.099.", "error": "", "parent_id": "2de5737a-93e7-461f-8ac1-fb466b1eb4fd", "metadata": {"aucs": [0.9967848018128742, 0.5107009020128599, 0.8196463784358591], "final_y": [0.16485745146717568, 0.39009581454229814, 0.2004466190496046]}, "mutation_prompt": null}
{"id": "3143eb0d-8a99-4cce-a458-2bc18b29d2aa", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.92  # Crossover probability, slightly increased\n        self.num_populations = 5  # Increased number of populations\n        self.local_search_method = 'L-BFGS-B'\n        self.adaptive_periodicity = max(1, dim // 5)  # New adaptive periodicity\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            adaptive_F = self.F * (0.5 + 0.5 * np.random.rand())  # Adaptive mutation factor\n            mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate):\n        partition_size = self.dim // self.adaptive_periodicity\n        for i in range(self.adaptive_periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Incorporates adaptive periodicity and adaptive mutation factors in Hybrid DE for enhanced convergence and solution quality.", "configspace": "", "generation": 10, "fitness": 0.7048487387870557, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.705 with standard deviation 0.185. And the mean value of best solutions found was 0.282 (0. is the best) with standard deviation 0.092.", "error": "", "parent_id": "2de5737a-93e7-461f-8ac1-fb466b1eb4fd", "metadata": {"aucs": [0.9528155263534495, 0.6541547975471744, 0.5075758924605429], "final_y": [0.16485855525649906, 0.2918281549462406, 0.39009654827744933]}, "mutation_prompt": null}
{"id": "4a72c39c-211d-42a4-a4ee-43845af20f71", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.92  # Crossover probability\n        self.num_populations = 5\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds, dynamic_F):  # Updated to include dynamic_F\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + dynamic_F * (b - c), bounds.lb, bounds.ub)  # Changed F to dynamic_F\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity):  # Adjusted to use dynamic periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                diversity = np.mean(np.std(population, axis=0))  # Compute diversity\n                dynamic_F = 0.5 + 0.3 * diversity  # Dynamic mutation factor\n                periodicity = max(2, int(self.dim * (1 - diversity)))  # Adaptive periodicity\n\n                new_population = self.differential_evolution_step(population, bounds, dynamic_F)\n\n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate, periodicity)  # Use adaptive periodicity\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances adaptability by introducing a dynamic mutation factor and adaptive periodicity based on population diversity.", "configspace": "", "generation": 10, "fitness": 0.7485255517034419, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.749 with standard deviation 0.025. And the mean value of best solutions found was 0.245 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "2de5737a-93e7-461f-8ac1-fb466b1eb4fd", "metadata": {"aucs": [0.7247459153051935, 0.7838095107560727, 0.7370212290490596], "final_y": [0.2578113552748631, 0.22804995427350527, 0.25059046115334005]}, "mutation_prompt": null}
{"id": "7006448d-b4bd-45dd-b75a-35b4e10c0c9e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.85  # Crossover probability, slightly decreased\n        self.num_populations = 5  # Increased number of populations\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances exploration by adjusting the crossover probability, improving diversity in candidate solutions.", "configspace": "", "generation": 10, "fitness": 0.7258822684529499, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.726 with standard deviation 0.217. And the mean value of best solutions found was 0.282 (0. is the best) with standard deviation 0.107.", "error": "", "parent_id": "2de5737a-93e7-461f-8ac1-fb466b1eb4fd", "metadata": {"aucs": [0.9944190615610538, 0.46315274766757353, 0.7200749961302223], "final_y": [0.16485745146717568, 0.4239552623997461, 0.2578118347439421]}, "mutation_prompt": null}
{"id": "3ec77418-482a-4dea-b149-0d9d5d5e8461", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = 10 * dim\n        self.F = 0.8\n        self.CR = 0.92\n        self.num_populations = 5\n        self.local_search_method = 'L-BFGS-B'\n        self.adaptive_factor = 0.9  # Added adaptive factor\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.base_population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            adaptive_F = self.F * self.adaptive_factor  # Adaptive mutation factor\n            adaptive_CR = self.CR * self.adaptive_factor  # Adaptive crossover probability\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + adaptive_F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < adaptive_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=4):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        base_pattern = candidate[:partition_size]\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = base_pattern\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                # Dynamic population size adjustment\n                if evaluations > self.budget / 2:\n                    population = population[:self.base_population_size // 2]\n\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Introduces adaptive mutation and crossover rates, dynamic population size, and improved periodicity enforcement for enhanced exploration and convergence. ", "configspace": "", "generation": 10, "fitness": 0.7841901969975943, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.784 with standard deviation 0.150. And the mean value of best solutions found was 0.241 (0. is the best) with standard deviation 0.054.", "error": "", "parent_id": "2de5737a-93e7-461f-8ac1-fb466b1eb4fd", "metadata": {"aucs": [0.9961992920153786, 0.6725063734933204, 0.6838649254840836], "final_y": [0.16485860612244008, 0.2827476394559669, 0.274957833824204]}, "mutation_prompt": null}
{"id": "7f74b66d-5a1f-4ef1-ae79-c6951c27ebd6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.95  # Crossover probability, slightly increased\n        self.num_populations = 5  # Increased number of populations\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhancing the algorithm by increasing the crossover probability (CR) to improve diversity and exploration capabilities.", "configspace": "", "generation": 10, "fitness": 0.6996697953542307, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.700 with standard deviation 0.285. And the mean value of best solutions found was 0.318 (0. is the best) with standard deviation 0.174.", "error": "", "parent_id": "2de5737a-93e7-461f-8ac1-fb466b1eb4fd", "metadata": {"aucs": [0.9967848018128742, 0.7860767864584955, 0.3161477977913224], "final_y": [0.16485745146717568, 0.22804687680324476, 0.5616396274538082]}, "mutation_prompt": null}
{"id": "bd3a6c39-e1b3-4c5f-b5f2-4616b5de6d9c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.7\n        self.CR = 0.9\n        self.num_populations = 4\n        self.local_search_method = 'L-BFGS-B'\n        self.mutation_adapt_rate = 0.1\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n            new_population[i] += np.random.normal(0, self.mutation_adapt_rate, self.dim)\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=5):\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n\n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n\n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate, periodicity=max(5, self.dim // 10))  # Changed\n                    score = func(candidate)\n                    evaluations += 1\n\n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n\n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population\n\n                local_best = self.local_search(best_candidate, func, bounds)\n                if evaluations % 50 == 0:\n                    self.F = np.random.uniform(0.5, 1.0)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        elite_preserved = self.local_search(best_candidate, func, bounds)  \n        return elite_preserved", "name": "HybridDifferentialEvolution", "description": "Enhances convergence by refining periodicity enforcement to adapt dynamically based on evaluation metrics.", "configspace": "", "generation": 10, "fitness": 0.7266221104941267, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.727 with standard deviation 0.220. And the mean value of best solutions found was 0.282 (0. is the best) with standard deviation 0.107.", "error": "", "parent_id": "db56ff1c-25d9-4d96-8d74-8a5aa4fafd0c", "metadata": {"aucs": [0.9965242920622596, 0.4579430555484937, 0.725398983871627], "final_y": [0.1648560656493384, 0.42395259821473874, 0.2578124657642814]}, "mutation_prompt": null}
{"id": "ca524113-d299-4676-b59e-c9185fdceadc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Mutation factor\n        self.CR = 0.92  # Crossover probability, slightly increased\n        self.num_populations = 5  # Increased number of populations\n        self.local_search_method = 'L-BFGS-B'\n\n    def quasi_oppositional_init(self, bounds):\n        population = np.random.uniform(bounds.lb, bounds.ub, (self.population_size, self.dim))\n        opposite_population = bounds.lb + bounds.ub - population\n        return np.vstack((population, opposite_population))\n\n    def differential_evolution_step(self, population, bounds):\n        new_population = np.empty_like(population)\n        for i in range(population.shape[0]):\n            idxs = [idx for idx in range(population.shape[0]) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant_vector = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial_vector = np.where(cross_points, mutant_vector, population[i])\n            new_population[i] = trial_vector\n        return new_population\n\n    def local_search(self, candidate, func, bounds):\n        bounds_list = [(low, high) for low, high in zip(bounds.lb, bounds.ub)]\n        result = minimize(func, candidate, method=self.local_search_method, bounds=bounds_list)\n        return result.x if result.success else candidate\n\n    def enforce_periodicity(self, candidate, periodicity=4):  # Adjusted periodicity\n        partition_size = self.dim // periodicity\n        for i in range(periodicity):\n            candidate[i * partition_size:(i + 1) * partition_size] = candidate[:partition_size]\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        populations = [self.quasi_oppositional_init(bounds) for _ in range(self.num_populations)]\n        evaluations = 0\n        \n        best_candidate = None\n        best_score = float('inf')\n\n        while evaluations < self.budget:\n            for pop_idx, population in enumerate(populations):\n                new_population = self.differential_evolution_step(population, bounds)\n                \n                for candidate in new_population:\n                    candidate = self.enforce_periodicity(candidate)\n                    score = func(candidate)\n                    evaluations += 1\n                    \n                    if score < best_score:\n                        best_score = score\n                        best_candidate = candidate\n                    \n                    if evaluations >= self.budget:\n                        break\n\n                populations[pop_idx] = new_population  # Update population\n\n                # Apply local search to the best candidate of each population\n                local_best = self.local_search(best_candidate, func, bounds)\n                if func(local_best) < best_score:\n                    best_score = func(local_best)\n                    best_candidate = local_best\n\n                if evaluations >= self.budget:\n                    break\n\n        return best_candidate", "name": "HybridDifferentialEvolution", "description": "Enhances convergence by fine-tuning the periodicity for the specific problem domain, improving the balance between exploration and exploitation.", "configspace": "", "generation": 10, "fitness": 0.7972905116677769, "feedback": "The algorithm HybridDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.158. And the mean value of best solutions found was 0.237 (0. is the best) with standard deviation 0.063.", "error": "", "parent_id": "2de5737a-93e7-461f-8ac1-fb466b1eb4fd", "metadata": {"aucs": [0.9957508481081909, 0.7860767864584955, 0.6100439004366438], "final_y": [0.1648568068349875, 0.22804687680324476, 0.31933092591664936]}, "mutation_prompt": null}
