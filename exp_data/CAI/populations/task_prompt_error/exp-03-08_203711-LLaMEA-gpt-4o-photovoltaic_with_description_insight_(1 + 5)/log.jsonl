{"id": "4dcf5886-0d51-44bc-803d-d021328ce066", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic combining Differential Evolution (DE) for global exploration and a local search optimizer, with adaptive layer growth and robustness-driven cost adjustments for optimizing multilayered structures.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 52, in __call__\n  File \"<string>\", line 29, in _local_search\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 738, in minimize\n    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 386, in _minimize_lbfgsb\n    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 291, in _prepare_scalar_function\n    sf = ScalarFunction(fun, x0, args, grad, hess,\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 223, in __init__\n    self._update_fun()\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 295, in _update_fun\n    fx = self._wrapped_fun(self.x)\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 21, in wrapped\n    fx = fun(np.copy(x), *args)\n  File \"<string>\", line 27, in wrapped_func\nNameError: name 'func' is not defined\n.", "error": "NameError(\"name 'func' is not defined\")Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 52, in __call__\n  File \"<string>\", line 29, in _local_search\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 738, in minimize\n    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 386, in _minimize_lbfgsb\n    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 291, in _prepare_scalar_function\n    sf = ScalarFunction(fun, x0, args, grad, hess,\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 223, in __init__\n    self._update_fun()\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 295, in _update_fun\n    fx = self._wrapped_fun(self.x)\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 21, in wrapped\n    fx = fun(np.copy(x), *args)\n  File \"<string>\", line 27, in wrapped_func\nNameError: name 'func' is not defined\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "2cbd654d-4bf8-472d-b6bb-5eec78fce88b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop, bounds):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n        return mutant\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop, bounds)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhance the HybridMetaheuristic by properly scoping the `func` variable in the local search function and improving mutation bounds handling.", "configspace": "", "generation": 1, "fitness": 0.847967903016408, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.051. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "4dcf5886-0d51-44bc-803d-d021328ce066", "metadata": {"aucs": [0.7764203599947412, 0.8858884904073446, 0.8815948586471379], "final_y": [0.13165843032376423, 0.12198100740057771, 0.11148579853123786]}, "mutation_prompt": null}
{"id": "91d61162-b4b8-43ef-a787-7ea22fb6791d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func as parameter to fix NameError\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Updated to pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic with DE for global exploration and local search, corrected for proper function reference and improved memory handling.", "configspace": "", "generation": 1, "fitness": 0.8539102851168586, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.025. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "4dcf5886-0d51-44bc-803d-d021328ce066", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8262283049574385], "final_y": [0.11874804534293504, 0.12198100740057771, 0.11874675418757141]}, "mutation_prompt": null}
{"id": "ae986847-dc6b-497b-b4a7-b7d613e115a7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic using Differential Evolution (DE) for global exploration and integrating a local search optimizer with fixed dimension local search and robustness-driven cost adjustments for optimizing multilayered structures.", "configspace": "", "generation": 1, "fitness": 0.8626610732702257, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.016. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "4dcf5886-0d51-44bc-803d-d021328ce066", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8524806694175395], "final_y": [0.11874804534293504, 0.12198100740057771, 0.11874046818009976]}, "mutation_prompt": null}
{"id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic using DE for global exploration and local search refinement, fixing bug in function reference.", "configspace": "", "generation": 1, "fitness": 0.863214343435212, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "4dcf5886-0d51-44bc-803d-d021328ce066", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8541404799124982], "final_y": [0.11874804534293504, 0.12198100740057771, 0.1114884579974087]}, "mutation_prompt": null}
{"id": "282f442d-2d15-4779-9e77-60b0f63a3ba0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func as a parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Use func parameter\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved function reference in local search to prevent NameError, ensuring optimized performance of a hybrid metaheuristic for multilayered photonic structures.", "configspace": "", "generation": 1, "fitness": 0.8169742504588607, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.817 with standard deviation 0.052. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "4dcf5886-0d51-44bc-803d-d021328ce066", "metadata": {"aucs": [0.8054325663467226, 0.8858884904073446, 0.7596016946225149], "final_y": [0.12428051531774664, 0.12198100740057771, 0.12214275989147505]}, "mutation_prompt": null}
{"id": "8660969d-60e2-42a7-b14f-f56104372846", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1) * np.std(pop)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved DE strategy by adjusting the scale factor dynamically based on population diversity for enhanced exploration.", "configspace": "", "generation": 2, "fitness": 0.8381467340482193, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.040. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.8799876646202376, 0.7843068621978617, 0.8501456753265585], "final_y": [0.12607186217935074, 0.11875336010085202, 0.1170826433129104]}, "mutation_prompt": null}
{"id": "a624c306-556e-4928-9758-efbea99c5fc2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size\n        self.f = 0.9  # Adjusted DE scale factor\n        self.cr = 0.95  # Adjusted DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 3, self.dim)  # Increment layer growth\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid algorithm integrating Differential Evolution with dynamic layer adjustments and robustness checks.", "configspace": "", "generation": 2, "fitness": 0.8224376580064815, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.042. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.8652116144099673, 0.7648715385654372, 0.83722982104404], "final_y": [0.118739310799161, 0.11874057244286862, 0.11765045752757741]}, "mutation_prompt": null}
{"id": "efb1b812-7c4d-4a76-ae5c-9ea56e826742", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n        self.layer_roles = np.random.randint(0, 2, size=self.dim)  # Added modular role detection\n        self.robustness_weight = 0.05  # Added robustness metric weight\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n\n    def _robustness_penalty(self, x):  # Added robustness penalty calculation\n        perturbation = np.random.uniform(-0.01, 0.01, size=x.shape)  \n        return self.robustness_weight * np.linalg.norm(perturbation)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  \n        \n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + self._robustness_penalty(trial)  # Included robustness\n                f_target = func(target) + self._robustness_penalty(target)  # Included robustness\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + self._robustness_penalty(individual)  # Included robustness\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic using DE for global exploration and local search refinement, with modular structure detection and robustness metrics.", "configspace": "", "generation": 2, "fitness": 0.8086202172603133, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.061. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.8518776912535455, 0.7227051067067112, 0.8512778538206833], "final_y": [0.12477075748621902, 0.17709519919659122, 0.11874285735259216]}, "mutation_prompt": null}
{"id": "2ac4c16a-d7c3-4cdd-a6d0-966d51632c18", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adaptive_f = self.f * (1 - (len(self.history) / self.budget))  # Adapt mutation scale\n        return np.clip(a + adaptive_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE crossover with adaptive mutation scale for improved convergence in hybrid metaheuristic.", "configspace": "", "generation": 2, "fitness": 0.8140953653331927, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.037. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.849614059985793, 0.8293987590285454, 0.7632732769852398], "final_y": [0.11874804534293504, 0.11874910257627325, 0.16884397986018473]}, "mutation_prompt": null}
{"id": "78365459-1321-44e6-a05d-365c78980295", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim + 1)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "An enhanced hybrid algorithm that combines Differential Evolution and local search with adaptive population growth to efficiently explore high-dimensional spaces.", "configspace": "", "generation": 2, "fitness": 0.8304022107858305, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.021. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.849614059985793, 0.8015030710305189, 0.8400895013411802], "final_y": [0.11874804534293504, 0.12990623909007915, 0.12331070989832238]}, "mutation_prompt": null}
{"id": "d4ec02b9-46a4-49e4-8c8e-bbaac9ca4d17", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n            self.cr = 0.7 + 0.3 * (1 - evaluations / self.budget)  # Adaptive crossover probability\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic using DE for global exploration and local search refinement with adaptive crossover probability.", "configspace": "", "generation": 3, "fitness": 0.809002044121748, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.067. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.7301953483802466, 0.8029963170382293, 0.8938144669467684], "final_y": [0.18500990431892295, 0.11873941039392266, 0.11012082087147657]}, "mutation_prompt": null}
{"id": "1a23b96d-f9d5-4591-a1fb-b779c8f62d80", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved DE tournament selection to enhance exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8503806475002286, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.035. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.849614059985793, 0.8077134155681246, 0.8938144669467684], "final_y": [0.11874804534293504, 0.11906053971928432, 0.11012082087147657]}, "mutation_prompt": null}
{"id": "97cb9ab1-aeeb-4d7a-a9d3-0b35dd4576a2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant, evaluations):  # Added evaluations\n        dynamic_cr = self.cr * (1 - evaluations / self.budget)  # Dynamic crossover probability\n        cross_points = np.random.rand(self.dim) < dynamic_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant, evaluations)  # Pass evaluations\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Refined DE crossover to improve diversity by using a dynamic crossover probability based on evaluations.", "configspace": "", "generation": 3, "fitness": 0.854003992277784, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.031. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.849614059985793, 0.8185834499007907, 0.8938144669467684], "final_y": [0.11874804534293504, 0.1187407172701751, 0.11012082087147657]}, "mutation_prompt": null}
{"id": "30e62ab4-1143-4d68-a166-79a00fa41af3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        d = pop[np.random.randint(self.population_size)]  # New: additional vector for mutation\n        return np.clip(a + self.f * (b - c) + self.f * (d - a), 0, 1)  # Modified mutation\n\n    def _de_crossover(self, target, mutant):\n        self.cr = 0.5 + (0.4 * np.random.rand())  # New: dynamic crossover probability\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhance DE mutation strategy and introduce dynamic crossover probability for better exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8333342348622307, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.045. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.8204692463083103, 0.7857189913316132, 0.8938144669467684], "final_y": [0.11874370858125605, 0.11969535191079239, 0.11012082087147657]}, "mutation_prompt": null}
{"id": "5d799fc9-a846-4bd8-9712-880e78d60b54", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 2, replace=False)\n        b, c = pop[idxs]\n        population_mean = np.mean(pop, axis=0)  # Added line\n        return np.clip(population_mean + self.f * (b - c), 0, 1)  # Modified line\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced mutation strategy by using the average of the whole population to guide differential evolution.", "configspace": "", "generation": 3, "fitness": 0.8359698971633662, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.836 with standard deviation 0.054. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.849614059985793, 0.7644811645575376, 0.8938144669467684], "final_y": [0.11874804534293504, 0.1303073213283087, 0.11012082087147657]}, "mutation_prompt": null}
{"id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with adaptive scaling for improved exploration and convergence.", "configspace": "", "generation": 4, "fitness": 0.8723658030134253, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8815948586471379], "final_y": [0.11874804534293504, 0.12198100740057771, 0.11148579853123786]}, "mutation_prompt": null}
{"id": "2e118b41-5445-4bf4-b7b1-2c0517416643", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                self.f = 0.5 + (0.9 - 0.5) * (evaluations / self.budget)  # Adaptive DE scale factor\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved HybridMetaheuristic with adaptive DE parameters for dynamic exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.8539102851168586, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.025. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8262283049574385], "final_y": [0.11874804534293504, 0.12198100740057771, 0.11874675418757141]}, "mutation_prompt": null}
{"id": "8ed3ec32-5f1b-46fa-b79b-ff70b6054799", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n            self.population_size = min(50, int(self.population_size * 1.1))  # Dynamic adjustment\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic combining DE and local search with adaptive layer growth and dynamic population size for enhanced exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.8317014150052175, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.053. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.7596016946225149], "final_y": [0.11874804534293504, 0.12198100740057771, 0.12214275989147505]}, "mutation_prompt": null}
{"id": "292e7db7-700c-41d5-9751-757b14b4f047", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                    self.f = min(1.0, self.f + 0.1)  # Adjust DE scale factor\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved global exploration by adjusting DE scale factor dynamically based on performance.", "configspace": "", "generation": 4, "fitness": 0.8626610732702257, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.016. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8524806694175395], "final_y": [0.11874804534293504, 0.12198100740057771, 0.11874046818009976]}, "mutation_prompt": null}
{"id": "70cf28f0-a641-4b93-987f-0e50f5aca7e5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Changed population size\n        self.f = 0.9  # Adjusted DE scale factor\n        self.cr = 0.85  # Adjusted DE crossover probability\n        self.history = []\n        self.epsilon = 0.01  # Perturbation step size for robustness\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        # Apply perturbation for robustness\n        for _ in range(5):\n            perturbed_x = result.x + np.random.uniform(-self.epsilon, self.epsilon, size=result.x.shape)\n            perturbed_x = np.clip(perturbed_x, bounds[:, 0], bounds[:, 1])\n            perturbed_value = func(perturbed_x)\n            if perturbed_value < func(result.x):\n                result.x = perturbed_x\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 3, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic combining DE, adaptive layer growth, and perturbation-based local search for robust photonic structure optimization.", "configspace": "", "generation": 4, "fitness": 0.8501418050775333, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.031. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.8103964449127572, 0.8858884904073446, 0.8541404799124982], "final_y": [0.12341039885374938, 0.12198100740057771, 0.1114884579974087]}, "mutation_prompt": null}
{"id": "6a76f7cf-bfdc-4483-b71d-b1de3bc04c86", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        init_guess = best_solution if best_solution is not None else x  # Changed line\n        result = minimize(wrapped_func, init_guess, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved local search initialization by using the best solution found so far for enhanced convergence.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_solution' is not defined\").", "error": "NameError(\"name 'best_solution' is not defined\")", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {}, "mutation_prompt": null}
{"id": "4bcc8dc6-e6a1-491b-b3a9-bf391eb7c833", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                if evaluations % 50 == 0:  # Intensify local search periodically\n                    trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with adaptive scaling and periodic local search intensification for improved exploration and convergence.", "configspace": "", "generation": 5, "fitness": 0.7778807395301065, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.778 with standard deviation 0.054. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.7655085432502247, 0.7185196153543019], "final_y": [0.11874804534293504, 0.1702433386818767, 0.19103396660959382]}, "mutation_prompt": null}
{"id": "1afa9f9a-0094-49d0-b986-e27e439c388f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        # Changed crossover rate to be adaptive\n        self.cr = 0.9 * (0.5 + 0.5 * np.random.rand())  \n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved DE mutation strategy with a dynamic crossover rate for enhanced diversification and convergence.", "configspace": "", "generation": 5, "fitness": 0.7886207229733165, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.042. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.8479175208624656, 0.7655605235629769, 0.7523841244945068], "final_y": [0.13049656078779093, 0.1702433386818767, 0.16606019353260815]}, "mutation_prompt": null}
{"id": "aeea1e76-1480-4fe3-b55b-62b6af691ad8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _robust_neighborhood_search(self, x, bounds, func):\n        noise_amplitude = 0.05 * (bounds[:, 1] - bounds[:, 0])\n        for _ in range(5):  # Conduct multiple local perturbations\n            perturb = np.random.uniform(-noise_amplitude, noise_amplitude)\n            candidate = np.clip(x + perturb, bounds[:, 0], bounds[:, 1])\n            candidate_value = func(candidate)\n            if candidate_value < func(x):\n                x = candidate\n        return x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._robust_neighborhood_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            if evaluations % (self.budget // 5) == 0:  # Dynamically adjust population size\n                self.population_size = max(10, int(self.population_size * 0.9))\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Integrate robust neighborhood search and dynamic population size adjustment for enhanced exploitation and exploration.", "configspace": "", "generation": 5, "fitness": 0.7476913047442609, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.748 with standard deviation 0.028. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.7082694273152014, 0.7645532161774838, 0.7702512707400977], "final_y": [0.18724094295371618, 0.1702433386818767, 0.14985575073548707]}, "mutation_prompt": null}
{"id": "99ee943b-41f2-4a4a-8d4b-a539fd721466", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant, iteration):\n        adapt_cr = self.cr * (0.5 + 0.5 * np.cos(np.pi * iteration / self.budget))  # Dynamic crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def _adaptive_population_size(self, evaluations):\n        return max(10, int(self.population_size * (1 - (evaluations / self.budget))))  # Adaptive population\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n            self.population_size = self._adaptive_population_size(evaluations)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant, evaluations)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhances HybridMetaheuristic with adaptive population size and dynamic crossover probability for improved convergence.", "configspace": "", "generation": 5, "fitness": 0.7788112214606174, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.779 with standard deviation 0.053. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.7653772545435434, 0.721442349852516], "final_y": [0.11874804534293504, 0.1702433386818767, 0.18951544282499466]}, "mutation_prompt": null}
{"id": "5816799c-9a3d-4959-995a-26f713055d59", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n            self.population_size = max(10, int(self.population_size * 0.95))  # Adaptive population size\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "An improved hybrid strategy with adaptive population size to enhance exploitation while maintaining exploration.", "configspace": "", "generation": 6, "fitness": 0.8723658030134253, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8815948586471379], "final_y": [0.11874804534293504, 0.12198100740057771, 0.11148579853123786]}, "mutation_prompt": null}
{"id": "c405f18b-61ac-470b-84da-eb20edc82152", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n            pop += np.random.normal(0, 0.01, pop.shape)  # Added line for diversity preservation\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation with adaptive scaling and diversity preservation for improved exploration and convergence.", "configspace": "", "generation": 6, "fitness": 0.8539102851168586, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.025. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8262283049574385], "final_y": [0.11874804534293504, 0.12198100740057771, 0.11874675418757141]}, "mutation_prompt": null}
{"id": "8da4bd39-b41e-4845-9c9b-7fc480004e9e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = self.cr * (1 - (len(self.history) / (2 * self.budget)))  # Dynamic crossover probability\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduce dynamic crossover probability in DE to enhance the exploration-exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.863214343435212, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8541404799124982], "final_y": [0.11874804534293504, 0.12198100740057771, 0.1114884579974087]}, "mutation_prompt": null}
{"id": "c175d09e-3e79-4690-8ce6-8b2bf7cd8242", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < (self.cr * (1 - len(self.history) / self.budget))  # Adaptive crossover\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B', options={'maxiter': 20})  # Limited iterations\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid algorithm with adaptive crossover probability and enhanced local search for better convergence.", "configspace": "", "generation": 6, "fitness": 0.8272841033726883, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.052. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.8363621250882054, 0.8858884904073446, 0.7596016946225149], "final_y": [0.12816976325694884, 0.12198100740057771, 0.12214275989147505]}, "mutation_prompt": null}
{"id": "515a90fa-c9ee-4848-bfec-fcf805b9f409", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.92  # DE crossover probability (adjusted from 0.9)\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with fine-tuned crossover probability for improved exploration and convergence.", "configspace": "", "generation": 6, "fitness": 0.8469394138541563, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.034. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.8024490817375847, 0.8858884904073446, 0.8524806694175395], "final_y": [0.1331152301709333, 0.12198100740057771, 0.11874046818009976]}, "mutation_prompt": null}
{"id": "02a37573-b649-418c-9b14-a7e3fd31f715", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B', options={'ftol': 1e-9})  # Improved precision\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with adaptive scaling and improved local search precision for better convergence.", "configspace": "", "generation": 7, "fitness": 0.860566093396088, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.018. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8461957297951265], "final_y": [0.11874804534293504, 0.12198100740057771, 0.1187392685060592]}, "mutation_prompt": null}
{"id": "70d3bbd8-dec8-4489-b3cc-bf338b8dd3a7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in) + np.random.normal(0, 0.01)  # Adding noise tolerance\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 3, self.dim)  # Faster layer growth\n\n    def _select_best(self, pop, func):\n        best_index = np.argmin([func(ind) for ind in pop])\n        return pop[best_index]\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristicV2", "description": "HybridMetaheuristicV2 integrates adaptive layer growth with noise-tolerant evaluation to enhance solution robustness and convergence.", "configspace": "", "generation": 7, "fitness": 0.6876478821418153, "feedback": "The algorithm HybridMetaheuristicV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.688 with standard deviation 0.027. And the mean value of best solutions found was 0.192 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.6490725243287543, 0.7084287159384777, 0.7054424061582137], "final_y": [0.2156209653416159, 0.1702433386818767, 0.19103396660959382]}, "mutation_prompt": null}
{"id": "71c1e0aa-d9c8-4c43-9543-b5bf9d2aa010", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * np.exp(-len(self.history) / (self.budget * 0.5))  # Improved adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in) + np.random.normal(0, 0.01)  # Added noise handling\n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 1, self.dim)  # Slower layer growth\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved adaptive scaling and layer growth strategy with noise-handling for enhanced convergence in high-dimensional, noisy optimization problems.", "configspace": "", "generation": 7, "fitness": 0.7989358239952397, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.096. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.037.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.6652752466506491, 0.8858884904073446, 0.845643734927725], "final_y": [0.2014367685750209, 0.12198100740057771, 0.12198436351802955]}, "mutation_prompt": null}
{"id": "f1dda743-f892-4f81-bf3d-28a313c229c7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = self.cr * (1 - (len(self.history) / self.budget))  # Adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced adaptive crossover probability to enhance exploration and convergence further.", "configspace": "", "generation": 7, "fitness": 0.8295427125043847, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.058. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8877516019619975, 0.7512624755653635], "final_y": [0.11874804534293504, 0.11873934456403512, 0.12312761998472632]}, "mutation_prompt": null}
{"id": "cff72750-1cd8-43f1-b654-be58dd98888c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            self.population_size = max(10, int(self.population_size * 0.99))  # Dynamically adjust population size\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with adaptive scaling and dynamic population size for improved exploration and convergence.", "configspace": "", "generation": 7, "fitness": 0.863169027065345, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.017. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8870954590442979, 0.8527975621659444], "final_y": [0.11874804534293504, 0.11874001514710464, 0.1187525200831584]}, "mutation_prompt": null}
{"id": "afa19028-be01-4aac-98f8-089509ec5e69", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B', options={'maxiter': 10})\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "HybridMetaheuristic with adaptive scaling and dynamic local search budget for enhanced convergence.", "configspace": "", "generation": 8, "fitness": 0.8336495143590814, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.028. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.8119158816439502, 0.8730445167661944, 0.8159881446670995], "final_y": [0.1379286870328884, 0.12658795976969384, 0.13107043255648376]}, "mutation_prompt": null}
{"id": "5d339c53-ad59-45d3-9f01-984c3358f889", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.mutation_rate = 0.2  # New mutation rate for diversity\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))\n        return np.clip(a + adapt_f * (b - c) + self.mutation_rate * (np.random.rand(*a.shape) - 0.5), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        init_guess = x + self.mutation_rate * (np.random.rand(*x.shape) - 0.5)  # Enhanced initialization\n        result = minimize(wrapped_func, init_guess, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved exploration and convergence by integrating a diversity mechanism and enhanced local search initialization.", "configspace": "", "generation": 8, "fitness": 0.8318725943896101, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.074. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.8943624280208065, 0.8730445167661944, 0.7282108383818298], "final_y": [0.11874402765231418, 0.12658795976969384, 0.18500984808461274]}, "mutation_prompt": null}
{"id": "42850106-9520-4a40-a14b-bcb40cfe47de", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr * (1 - (len(self.history) / self.budget))  # Dynamic CR adjustment\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic with dynamic crossover probability adjustment for improved exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8530858174651067, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.015. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8730445167661944, 0.8365988756433322], "final_y": [0.11874804534293504, 0.12658795976969384, 0.12188405789988066]}, "mutation_prompt": null}
{"id": "a4f5d80e-ec5d-404d-acc4-9ee4ac7ba9ca", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n        self.diversity_threshold = 1e-3  # Diversity threshold\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def _preserve_diversity(self, pop):\n        diversity = np.std(pop, axis=0).mean()\n        if diversity < self.diversity_threshold:\n            noise = np.random.normal(0, 0.01, pop.shape)\n            pop += noise\n        return pop\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            pop = self._preserve_diversity(pop)\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic with a diversity preservation mechanism for improved robustness and exploration.", "configspace": "", "generation": 8, "fitness": 0.8545252958216665, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.014. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8730445167661944, 0.8409173107130117], "final_y": [0.11874804534293504, 0.12658795976969384, 0.12836083883875438]}, "mutation_prompt": null}
{"id": "b6d2b675-b762-4e6e-822b-9fb1c2b4ca05", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def _dynamic_population_size(self, evaluations, best_value):\n        if len(self.history) > 1:\n            recent_improvement = abs((self.history[-1][1] - best_value) / best_value)\n            if recent_improvement < 0.001:\n                self.population_size = min(self.population_size + 5, 50)\n            else:\n                self.population_size = max(self.initial_population_size, self.population_size - 2)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            self._dynamic_population_size(evaluations, best_value)  # Adjust population size\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduce a dynamic population size based on convergence rate to improve exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8565410717547789, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.012. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8730445167661944, 0.8469646385123492], "final_y": [0.11874804534293504, 0.12658795976969384, 0.12316522592182444]}, "mutation_prompt": null}
{"id": "2a2c6422-e3a3-4da9-bb75-f3474bb91ae4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='TNC')  # Changed method to 'TNC'\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with adaptive scaling and improved local search for better convergence.", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('`x0` violates bound constraints.').", "error": "ValueError('`x0` violates bound constraints.')", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {}, "mutation_prompt": null}
{"id": "b6a550f3-36ca-409f-9a46-070e7c8451c5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                self.f = 0.6 + 0.4 * np.random.rand()  # Dynamic DE scaling factor\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced local search by dynamically adjusting DE parameters based on layer-specific performance.", "configspace": "", "generation": 9, "fitness": 0.8597046092955356, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.021. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8883352480756346, 0.8411645198251793], "final_y": [0.11874804534293504, 0.11874721856277104, 0.1187392339127501]}, "mutation_prompt": null}
{"id": "68bdc6d8-7265-4379-bc33-44fc5c5cc048", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            self.population_size = max(10, int(self.population_size * 0.95))  # Dynamic population size\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with adaptive scaling and dynamic population size for improved exploration and convergence.", "configspace": "", "generation": 9, "fitness": 0.8723658030134253, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8815948586471379], "final_y": [0.11874804534293504, 0.12198100740057771, 0.11148579853123786]}, "mutation_prompt": null}
{"id": "e215afdd-7997-4e13-aa31-591bd4013d79", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget)**2)  # Adaptive scaling with non-linear decay\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved adaptive scaling factor by introducing a non-linear decay for enhanced convergence speed.", "configspace": "", "generation": 9, "fitness": 0.8627390332578241, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.017. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8869072809941064, 0.8516957587935732], "final_y": [0.11874804534293504, 0.12101795761709144, 0.11644988411540558]}, "mutation_prompt": null}
{"id": "dee85201-0ed6-436d-9800-323234266359", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = self.cr * (1 - (len(self.history) / self.budget))  # Dynamic crossover probability\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced a dynamic adjustment of crossover probability in DE based on evaluation progress for enhanced exploration.", "configspace": "", "generation": 9, "fitness": 0.8538474092068921, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.025. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8858905750556428, 0.8260375925792407], "final_y": [0.11874804534293504, 0.12191205612792932, 0.11873940236535785]}, "mutation_prompt": null}
{"id": "0e7b49d8-dd1f-4562-93b8-103714b08179", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):  # Added noise reduction\n            self.history.append(x_in)\n            noise_samples = [func(x_in) for _ in range(3)]\n            return np.mean(noise_samples)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def _dynamic_population(self):  # New method for dynamic population\n        self.population_size = max(10, int(0.8 * self.population_size))\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n            self._dynamic_population()  # Call dynamic population\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced differential evolution with dynamic population size and noise reduction for robust exploration and convergence.", "configspace": "", "generation": 10, "fitness": 0.7670748246691795, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.767 with standard deviation 0.045. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.7244614215150951, 0.8300947988683294, 0.7466682536241139], "final_y": [0.12785166026355255, 0.12210534477998913, 0.12712129649749948]}, "mutation_prompt": null}
{"id": "37306062-b96f-4689-b7ec-b41ccdaeb0d1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 1, self.dim)  # Adjusted dimensional growth rate\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with adaptive scaling for improved exploration and convergence, adding robustness by adjusting dimensional growth.", "configspace": "", "generation": 10, "fitness": 0.8013834903746645, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.055. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8300947988683294, 0.7244416122698711], "final_y": [0.11874804534293504, 0.12210534477998913, 0.18500990431892295]}, "mutation_prompt": null}
{"id": "714bce1e-e16d-4980-a86c-9e7a0403e537", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = self.cr * (0.5 + 0.5 * (len(self.history) / self.budget))  # Adaptive crossover probability\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE strategy with adaptive CR adjustment for improved exploration and convergence.", "configspace": "", "generation": 10, "fitness": 0.8170951048827572, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.817 with standard deviation 0.071. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.8967489035100707, 0.8300947988683294, 0.7244416122698711], "final_y": [0.11616908591726549, 0.12210534477998913, 0.18500990431892295]}, "mutation_prompt": null}
{"id": "1911c411-c06e-42eb-8de6-bd60e77be534", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget)) * (1 - len(self.history) / (self.budget * 1.5))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduce a dynamic adaptive scaling factor based on the convergence rate to improve exploration and convergence balance.", "configspace": "", "generation": 10, "fitness": 0.8021227805614263, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.054. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8300947988683294, 0.7266594828301566], "final_y": [0.11874804534293504, 0.12210534477998913, 0.1569577650662356]}, "mutation_prompt": null}
{"id": "38ec027e-d5bb-4e18-8562-437f4a07ad95", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c) + 0.1 * np.random.randn(*a.shape), 0, 1)  # Added mutation\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE strategy with adaptive scaling and mutation strategy diversification for improved convergence.", "configspace": "", "generation": 10, "fitness": 0.8273431859441785, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.083. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.032.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.9274931466943351, 0.8300947988683294, 0.7244416122698711], "final_y": [0.11148532968248681, 0.12210534477998913, 0.18500990431892295]}, "mutation_prompt": null}
{"id": "584118e3-6110-4dba-9f08-cd83533ea5e4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        diversity_factor = np.std(pop) / np.mean(pop)  # Added line for diversity measure\n        adaptive_cr = self.cr * (1 + diversity_factor) # Changed line for adaptive crossover\n        cross_points = np.random.rand(self.dim) < adaptive_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved exploration by incorporating diversity preservation and adaptive crossover probability for better balance between exploration and exploitation.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'pop' is not defined\").", "error": "NameError(\"name 'pop' is not defined\")", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {}, "mutation_prompt": null}
{"id": "b6ad1a0d-369f-4734-88cd-9c140f2e2fc6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n        self.num_populations = 3  # Multi-population strategy\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, current_dim):\n        return min(current_dim + 2, self.dim)\n\n    def _multi_population_update(self, populations, best_solution):\n        new_populations = []\n        for pop in populations:\n            if np.random.rand() < 0.5:\n                new_populations.append(np.copy(pop))\n            else:\n                new_populations.append(np.copy(best_solution))\n        return new_populations\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        populations = [np.random.rand(self.population_size, current_dim) for _ in range(self.num_populations)]\n        populations = [bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0]) for pop in populations]\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_populations = []\n\n            for pop in populations:\n                new_pop = np.zeros_like(pop)\n                for i in range(self.population_size):\n                    target = pop[i]\n                    mutant = self._de_mutation(pop)\n                    trial = self._de_crossover(target, mutant)\n                    trial = self._local_search(trial, bounds, func)\n\n                    f_trial = func(trial)\n                    f_target = func(target)\n\n                    if f_trial < f_target:\n                        new_pop[i] = trial\n                    else:\n                        new_pop[i] = target\n\n                    evaluations += 1\n                    if evaluations >= self.budget:\n                        break\n\n                new_populations.append(new_pop)\n\n            populations = self._multi_population_update(new_populations, best_solution)\n\n            for pop in populations:\n                for individual in pop:\n                    value = func(individual)\n                    if value < best_value:\n                        best_value = value\n                        best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim)\n            for pop in populations:\n                extra_layers = np.random.rand(self.population_size, current_dim - pop.shape[1])\n                pop = np.hstack((pop, extra_layers))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic with multi-population strategy and memory-based adaptive scaling for robust exploration and fast convergence.", "configspace": "", "generation": 11, "fitness": 0.8477768201129677, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.024. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.8703839489879212, 0.8150324193982771, 0.8579140919527046], "final_y": [0.11873974410075305, 0.11873919663419796, 0.11874221353109848]}, "mutation_prompt": null}
{"id": "a52fb367-e410-4472-8f25-ab0f74c70913", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.92  # DE crossover probability (increased from 0.9)\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with slightly increased crossover probability for improved solution exploration. ", "configspace": "", "generation": 11, "fitness": 0.7600276725974182, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.760 with standard deviation 0.014. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.7435578055823915, 0.7787465662924828, 0.7577786459173804], "final_y": [0.1679081467010587, 0.12303390053234786, 0.12441090011552125]}, "mutation_prompt": null}
{"id": "cacb49e3-49fa-4574-8bcb-1063dd55d0ed", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, dim)  # Increased initial population size\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved HybridMetaheuristic with dynamic population size adjustment for enhanced exploration and convergence.", "configspace": "", "generation": 11, "fitness": 0.7857957542241194, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.786 with standard deviation 0.045. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.023.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.7555773333076617, 0.7521958693789036], "final_y": [0.11874804534293504, 0.1702433386818767, 0.12599642813030654]}, "mutation_prompt": null}
{"id": "9c03be01-17e4-4e2a-8b15-ddeeacc19f21", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        dynamic_cr = self.cr * np.random.uniform(0.8, 1.2)  # Dynamic crossover\n        cross_points = np.random.rand(self.dim) < dynamic_cr\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 2  # Extra evaluation for noise handling\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved adaptive DE strategy with noise handling and dynamic crossover for robust exploration and convergence.", "configspace": "", "generation": 11, "fitness": 0.8107398484788018, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.058. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.7301953483802466, 0.8377282178821939, 0.8642959791739651], "final_y": [0.18500990431892295, 0.1187561653258713, 0.11876210166759271]}, "mutation_prompt": null}
{"id": "5385d1b3-dfa8-486d-97b2-ba06430ff637", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.history = []\n\n    def _de_mutation(self, pop, layer_idx):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget)) * (1 + layer_idx / self.dim)  # Line changed\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop, i)  # Line changed\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            self.population_size = min(50, self.population_size + 1)  # Line changed\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduce a dynamic population size strategy and layer-specific adaptive mutation to enhance exploration and convergence.", "configspace": "", "generation": 12, "fitness": 0.8625105917464446, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.017. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8520292248461963], "final_y": [0.11874804534293504, 0.12198100740057771, 0.11874225726054155]}, "mutation_prompt": null}
{"id": "a5849b1c-51f6-4ced-a2b5-2f56736f38b8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget)**2)  # Improved adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 1 + (self.budget - len(self.history)) // 1000, self.dim)  # Improved dimension increase strategy\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved adaptive scaling and dimension increase strategy for enhanced exploration-exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.8437986565875247, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.037. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.7958934193694364], "final_y": [0.11874804534293504, 0.12198100740057771, 0.11874477060070188]}, "mutation_prompt": null}
{"id": "e9509ade-eb9f-4063-b7d3-cd77f1035f6c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.9  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Adjusted DE scaling factor to improve adaptive exploration and convergence.", "configspace": "", "generation": 12, "fitness": 0.8664158746301677, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.015. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8637450734973653], "final_y": [0.11874804534293504, 0.12198100740057771, 0.1187391927280782]}, "mutation_prompt": null}
{"id": "cd5c5aef-fded-40c5-89e5-bcd5f6ec2287", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _evaluate_with_noise_reduction(self, solution, func):\n        noisy_evaluations = [func(solution + np.random.normal(0, 0.01, size=self.dim)) for _ in range(5)]\n        return np.median(noisy_evaluations)\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = self._evaluate_with_noise_reduction(trial, func)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic by introducing noise-robust evaluation with diversity preservation.", "configspace": "", "generation": 12, "fitness": 0.8379490031795832, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.045. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.8496140835058713, 0.8858884904073446, 0.7783444356255336], "final_y": [0.11874801530626955, 0.12198100740057771, 0.12318171493172592]}, "mutation_prompt": null}
{"id": "342f5d84-0c84-4e4f-8713-577a8a64e5af", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.history = []\n        self.noise_tolerance = 1e-3\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n\n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + self.noise_tolerance * np.random.randn()\n                f_target = func(target) + self.noise_tolerance * np.random.randn()\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            if self.budget - evaluations > 50:\n                current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n                pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced adaptive hybrid algorithm combining DE and local search with dynamic population adjustment and perturbation resilience.", "configspace": "", "generation": 12, "fitness": 0.8670188935588158, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.015. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8867735446696742, 0.8646690760209804], "final_y": [0.11874804534293504, 0.11879679559225487, 0.11148839441794278]}, "mutation_prompt": null}
{"id": "de1e24d1-61c6-44a8-b51d-292aafe25a4c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n\n    def _adjust_population_size(self, evaluations):\n        self.population_size = int(20 + 10 * (1 - evaluations / self.budget))\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            self._adjust_population_size(evaluations)\n            new_pop = np.zeros((self.population_size, current_dim))\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with dynamic population size for improved convergence and exploration.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 25 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 25 is out of bounds for axis 0 with size 20')", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {}, "mutation_prompt": null}
{"id": "91c29feb-a917-4d1a-80eb-432fffc1268d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func, selective=False):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        if selective and np.random.rand() > 0.5:\n            return x\n\n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func, selective=True)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with adaptive scaling and selective local search for improved exploration and convergence.", "configspace": "", "generation": 13, "fitness": 0.8591087115586266, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.018. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.8465843431896272, 0.885258692082869, 0.8454830994033836], "final_y": [0.11874159215592484, 0.12198237552492752, 0.12198365454570559]}, "mutation_prompt": null}
{"id": "9e91d77b-a63c-411b-8957-f344a2a61797", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        self.cr = 0.9 - 0.5 * (len(self.history) / self.budget)  # Dynamic crossover probability\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with adaptive scaling for improved exploration and convergence, utilizing dynamic crossover probability for better diversity.", "configspace": "", "generation": 13, "fitness": 0.8588355422728343, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.019. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8855482850708658, 0.8413442817618442], "final_y": [0.11874804534293504, 0.11930396570507662, 0.11873978443841149]}, "mutation_prompt": null}
{"id": "4131d4c0-004f-4ba7-823d-98041b46939e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n        self.perturbation_scale = 0.05  # New: scale for stochastic perturbations\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        # Enhanced local search with random perturbation\n        perturb = np.random.uniform(-self.perturbation_scale, self.perturbation_scale, size=x.shape)\n        x = np.clip(x + perturb, bounds[:, 0], bounds[:, 1])\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "HybridMetaheuristic with enhanced local search diversity and stochastic perturbations for robust exploration and convergence.", "configspace": "", "generation": 13, "fitness": 0.8635741444747466, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.015. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.853376589665334, 0.885258692082869, 0.8520871516760365], "final_y": [0.11874246050322179, 0.12198237552492752, 0.12047998168291851]}, "mutation_prompt": null}
{"id": "31de5b6b-24ba-49dd-9d6b-ac8ff108801b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(20, int(budget / 50))  # Adjust population size\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved exploration through dynamic population size adjustment based on evaluation budget.", "configspace": "", "generation": 13, "fitness": 0.8259577137494317, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.060. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.885258692082869, 0.7430003891796331], "final_y": [0.11874804534293504, 0.12198237552492752, 0.1265461857518413]}, "mutation_prompt": null}
{"id": "c0a901d4-902f-40c2-ada9-fa9c97c0b3f1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        dynamic_cr = self.cr * (1 - (len(self.history) / self.budget))  # Dynamic crossover probability\n        cross_points = np.random.rand(self.dim) < dynamic_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B', options={'ftol': 1e-6})  # Enhanced tolerance\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved HybridMetaheuristic with dynamic crossover probability and enhanced local search refinement.", "configspace": "", "generation": 14, "fitness": 0.8688007345444121, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.021. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.8389188545787534, 0.8858884904073446, 0.8815948586471379], "final_y": [0.12701336303640542, 0.12198100740057771, 0.11148579853123786]}, "mutation_prompt": null}
{"id": "54b53bba-75df-45d6-9cca-3d4833bb70fe", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        # Dynamic crossover probability based on evaluations\n        dynamic_cr = self.cr * (1 + 0.1 * np.sin(2 * np.pi * len(self.history) / self.budget))\n        cross_points = np.random.rand(self.dim) < dynamic_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced mutation and crossover strategy with dynamic crossover probability to improve exploration and exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.8592286202683596, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.020. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8869072809941064, 0.8411645198251793], "final_y": [0.11874804534293504, 0.12101795761709144, 0.1187392339127501]}, "mutation_prompt": null}
{"id": "50463735-fa9c-43bd-a88f-5a9883ce2c0a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / (2 * self.budget)))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with adaptive and dynamic scaling for improved exploration and convergence.", "configspace": "", "generation": 14, "fitness": 0.8490225635344952, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.032. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8883352480756346, 0.8091183825420585], "final_y": [0.11874804534293504, 0.11874721856277104, 0.13205476655292692]}, "mutation_prompt": null}
{"id": "700a0f06-e6e7-411b-b3d5-b8beb7a42d3e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, 0.5 * (target + mutant))  # Changed line\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Slightly altered DE crossover to improve diversity in trial vector generation.", "configspace": "", "generation": 14, "fitness": 0.821079319821878, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.070. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.031.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.7233202060973637, 0.8858884904073446, 0.8540292629609256], "final_y": [0.18500984814971322, 0.12198100740057771, 0.11874611491220943]}, "mutation_prompt": null}
{"id": "5931756a-e7e1-4dd8-a2c2-d20af70f9912", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr * (1 - (len(self.history) / self.budget))  # Adaptive crossover\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with adaptive crossover probability for improved exploration and convergence.", "configspace": "", "generation": 14, "fitness": 0.8592854485173694, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.023. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8905163458815312, 0.8377259396847845], "final_y": [0.11874804534293504, 0.11874027544695542, 0.11874417806828685]}, "mutation_prompt": null}
{"id": "cd695089-5271-47f3-8ea4-a7f4ab8d901d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = self.cr * (0.5 + 0.5 * np.random.rand())  # Adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE with adaptive crossover and robustness metrics for improved convergence and solution stability.", "configspace": "", "generation": 15, "fitness": 0.8763049513241632, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.032. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.8815152266803208, 0.834269605317272, 0.9131300219748967], "final_y": [0.11489944152725351, 0.1187404154041447, 0.11148579853123786]}, "mutation_prompt": null}
{"id": "ca48b904-eac9-4a06-b8c0-33183237526f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def _layer_based_diversification(self, pop, bounds):\n        additional_layers = np.random.uniform(bounds[:, 0], bounds[:, 1], (self.population_size, pop.shape[1]))\n        return np.hstack((pop[:, :10], additional_layers))  # Diversify only after the first 10 layers\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = self._layer_based_diversification(pop, bounds)  # Apply diversification\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with adaptive scaling and layer-based diversification for improved exploration and convergence.", "configspace": "", "generation": 15, "fitness": 0.8442997278240892, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.016. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8611415223327503, 0.8221436011537242], "final_y": [0.11874804534293504, 0.116435719208691, 0.11873976540796771]}, "mutation_prompt": null}
{"id": "47175003-d571-4ca7-b903-cd10ccab702b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def _adaptive_population_size(self, evaluations):\n        return max(10, int(30 * (1 - evaluations / self.budget)))\n\n    def _perturbation(self, individual):\n        perturbation_scale = 0.05\n        perturbation = np.random.uniform(-perturbation_scale, perturbation_scale, size=individual.shape)\n        return individual + perturbation\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10\n\n        evaluations = 0\n        while evaluations < self.budget:\n            self.population_size = self._adaptive_population_size(evaluations)\n            pop = np.random.rand(self.population_size, current_dim)\n            pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n                trial = self._perturbation(trial)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic using adaptive population size and perturbation for improved exploration and exploitation balance.", "configspace": "", "generation": 15, "fitness": 0.7589717163257084, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.759 with standard deviation 0.032. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.034.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.7966247632733688, 0.7617589925159078, 0.7185313931878485], "final_y": [0.11148892770464247, 0.1702433386818767, 0.19061614428720186]}, "mutation_prompt": null}
{"id": "1b18a411-264c-4c65-acfb-d62bef450d2c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        self.cr = 0.9 * (1 - len(self.history) / self.budget)  # Dynamic crossover probability\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduce dynamic crossover probability to enhance diverse exploration in the DE strategy.", "configspace": "", "generation": 15, "fitness": 0.8330218376698836, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.044. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.7727884732728748, 0.8766629797509826], "final_y": [0.11874804534293504, 0.1259019929522619, 0.12415573227649013]}, "mutation_prompt": null}
{"id": "a5560af9-d44c-4b8a-809b-408baefc0768", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B', tol=1e-5)  # Adjusted tolerance\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved local search strategy by adjusting the L-BFGS-B method's tolerance for faster convergence.", "configspace": "", "generation": 15, "fitness": 0.8274749730082679, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.087. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.029.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.7100981351638016, 0.8552635227926298, 0.9170632610683724], "final_y": [0.1757860320211907, 0.11874637618620854, 0.11151925746583136]}, "mutation_prompt": null}
{"id": "c2cc389e-5d65-4ef4-a6d9-975ad347fd96", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = self.cr * (0.5 + 0.5 * np.random.rand())  # Adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE with adaptive crossover, robustness metrics, and improved local search for superior convergence and solution stability.", "configspace": "", "generation": 16, "fitness": 0.856119129105287, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.007. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "cd695089-5271-47f3-8ea4-a7f4ab8d901d", "metadata": {"aucs": [0.8598009857800877, 0.845928292003449, 0.862628109532324], "final_y": [0.12724565752944295, 0.12710548321060766, 0.12405575049276862]}, "mutation_prompt": null}
{"id": "25c8828c-c2c4-408b-81fc-593d8979a7c0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = self.cr * (0.5 + 0.5 * np.random.rand())  # Adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.05 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved robustness by adjusting the noise handling in the objective function evaluation.", "configspace": "", "generation": 16, "fitness": 0.8495530691752627, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.010. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "cd695089-5271-47f3-8ea4-a7f4ab8d901d", "metadata": {"aucs": [0.8401028059900152, 0.845928292003449, 0.862628109532324], "final_y": [0.1232923286547497, 0.12710548321060766, 0.12405575049276862]}, "mutation_prompt": null}
{"id": "8ecbdb75-a704-4122-b5b7-ad779b781820", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size\n        self.f = 0.8\n        self.cr = 0.9\n        self.history = []\n        self.noise_adaptation_factor = 0.05  # Introduced noise adaptation factor\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = self.cr * (0.5 + 0.5 * np.random.rand())\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        # Gradually increase layers to explore deeper designs\n        return min(current_dim + 3, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + self.noise_adaptation_factor * np.var(trial)\n                f_target = func(target) + self.noise_adaptation_factor * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + self.noise_adaptation_factor * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "EnhancedHybridMetaheuristic", "description": "Multi-phase optimization combining DE with adaptive learning rates and layered local search for enhanced convergence and robustness.", "configspace": "", "generation": 16, "fitness": 0.8564302517047362, "feedback": "The algorithm EnhancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.025. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "cd695089-5271-47f3-8ea4-a7f4ab8d901d", "metadata": {"aucs": [0.8223899537892183, 0.8801467172352612, 0.8667540840897292], "final_y": [0.12724565752944295, 0.11875060007179983, 0.11874716540015962]}, "mutation_prompt": null}
{"id": "fac01b7d-0b73-46f9-b0cf-b77356448231", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = self.cr * (0.5 + 0.5 * np.random.rand())  # Adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE with adaptive crossover, robustness metrics, and initial diversification for improved convergence and solution stability.", "configspace": "", "generation": 16, "fitness": 0.858263577026945, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.009. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "cd695089-5271-47f3-8ea4-a7f4ab8d901d", "metadata": {"aucs": [0.8662343295450621, 0.845928292003449, 0.862628109532324], "final_y": [0.11879815434452667, 0.12710548321060766, 0.12405575049276862]}, "mutation_prompt": null}
{"id": "40eecbfa-9c0f-4285-b2f9-4da590ba749b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = self.cr * (0.5 + 0.5 * np.random.rand())  # Adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n\n        result = minimize(wrapped_func, x, bounds=bounds, method='Nelder-Mead')  # Improved local search\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE with adaptive crossover and robustness metrics, and improved local search for better convergence and solution stability.", "configspace": "", "generation": 16, "fitness": 0.8493962915455269, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.010. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "cd695089-5271-47f3-8ea4-a7f4ab8d901d", "metadata": {"aucs": [0.8396324731008078, 0.845928292003449, 0.862628109532324], "final_y": [0.13744309734371996, 0.12710548321060766, 0.12405575049276862]}, "mutation_prompt": null}
{"id": "2512afb0-93b9-4d25-9dfe-bd813e97e0d9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = self.cr * (0.5 + 0.5 * np.random.rand())  # Adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + 0.5 * (bounds[:, 1] - bounds[:, 0])  # Changed line for better initialization\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Refined HybridMetaheuristic with enhanced layer initialization for improved exploration.", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 18 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 18 is out of bounds for axis 0 with size 10')", "parent_id": "cd695089-5271-47f3-8ea4-a7f4ab8d901d", "metadata": {}, "mutation_prompt": null}
{"id": "ba68bd2c-a4fe-466a-ae4f-eb30f1e1e5f0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = self.cr * (0.5 + 0.5 * np.random.rand())  # Adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.05 * np.var(trial)  # Include enhanced robustness metric\n                f_target = func(target) + 0.05 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.05 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Refined HybridMetaheuristic with enhanced robustness by tuning the weight of the variance penalty on the cost function.", "configspace": "", "generation": 17, "fitness": 0.8657676178076268, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.027. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "cd695089-5271-47f3-8ea4-a7f4ab8d901d", "metadata": {"aucs": [0.8272802633578802, 0.8894535837839789, 0.8805690062810213], "final_y": [0.1452702343927481, 0.1187396130122852, 0.1187460874829418]}, "mutation_prompt": null}
{"id": "6c2faf03-0b18-4e05-b49e-7671cc8fa264", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = self.cr * (0.5 + 0.5 * np.random.rand())  # Adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n            self.population_size = max(5, int(20 * (1 - evaluations / self.budget)))  # Dynamic population size\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Refined DE by introducing a dynamic population size adjustment for better exploration and exploitation balance.", "configspace": "", "generation": 17, "fitness": 0.8841342928369235, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.004. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "cd695089-5271-47f3-8ea4-a7f4ab8d901d", "metadata": {"aucs": [0.8823802884457699, 0.8894535837839789, 0.8805690062810213], "final_y": [0.11431209218093175, 0.1187396130122852, 0.1187460874829418]}, "mutation_prompt": null}
{"id": "b2877848-26d9-41f0-befb-7b33ea9b53b9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = max(self.cr * (0.5 + 0.5 * np.random.rand()), 0.6)  # Enhanced adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 4, self.dim)  # Adjusted layer growth increment\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Refined HybridMetaheuristic with enhanced adaptive crossover and layer growth strategy for improved convergence efficiency.", "configspace": "", "generation": 17, "fitness": 0.8877751427372477, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.005. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "cd695089-5271-47f3-8ea4-a7f4ab8d901d", "metadata": {"aucs": [0.89330221300993, 0.8894535837839789, 0.8805696314178342], "final_y": [0.11439877318544167, 0.1187396130122852, 0.11873944622333288]}, "mutation_prompt": null}
{"id": "cda29f3a-cc74-498a-abdc-d1e353f0e147", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = self.cr * (0.5 + 0.5 * np.random.rand())  # Adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B', options={'maxiter': 10})  # Increased max iterations\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE with adaptive crossover, robustness metrics, and improved local search for increased convergence and stability.", "configspace": "", "generation": 17, "fitness": 0.8790661976359792, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.009. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "cd695089-5271-47f3-8ea4-a7f4ab8d901d", "metadata": {"aucs": [0.8671760028429372, 0.8894535837839789, 0.8805690062810213], "final_y": [0.11712053752373963, 0.1187396130122852, 0.1187460874829418]}, "mutation_prompt": null}
{"id": "b45be84e-3ac1-47d1-ad03-021239861e83", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = max(self.cr * (0.5 + 0.5 * np.random.rand()), 0.6)  # Enhanced adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        # Change: Initialize with best_solution instead of initial x for potential refinement\n        result = minimize(wrapped_func, self.best_solution, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 4, self.dim)  # Adjusted layer growth increment\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        self.best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    self.best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return self.best_solution", "name": "HybridMetaheuristic", "description": "Improved local search initialization using the best current solution for enhanced local refinement.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The number of bounds is not compatible with the length of `x0`.').", "error": "ValueError('The number of bounds is not compatible with the length of `x0`.')", "parent_id": "b2877848-26d9-41f0-befb-7b33ea9b53b9", "metadata": {}, "mutation_prompt": null}
{"id": "b40caeb2-ef78-4ca2-bbd4-ece62a53d291", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = max(self.cr * (0.5 + 0.5 * np.random.rand()), 0.6)  # Enhanced adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)  # Adjusted layer growth increment\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic with dynamic layer adaptation and improved local search initialization for better convergence.", "configspace": "", "generation": 18, "fitness": 0.8787523065366875, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.010. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b2877848-26d9-41f0-befb-7b33ea9b53b9", "metadata": {"aucs": [0.8662343295450621, 0.8894535837839789, 0.8805690062810213], "final_y": [0.11879815434452667, 0.1187396130122852, 0.1187460874829418]}, "mutation_prompt": null}
{"id": "cb4a5e99-7d65-41ae-a3bd-fae3eecd5a95", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = max(self.cr * (0.5 + 0.5 * np.random.rand()), 0.6)\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 4, self.dim)\n    \n    def _adaptive_population_scaling(self, evaluations):  # New method\n        return max(10, int(self.population_size * (1 - evaluations / self.budget)))\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n            self.population_size = self._adaptive_population_scaling(evaluations)  # Adjust population size\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved HybridMetaheuristic with adaptive population scaling and noise filtering for enhanced robustness and efficiency.", "configspace": "", "generation": 18, "fitness": 0.8786525539378593, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.010. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b2877848-26d9-41f0-befb-7b33ea9b53b9", "metadata": {"aucs": [0.865935071748578, 0.8894535837839789, 0.8805690062810213], "final_y": [0.11469695628345034, 0.1187396130122852, 0.1187460874829418]}, "mutation_prompt": null}
{"id": "50ee70f1-6a73-47c1-9576-1837f18ddde6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = max(self.cr * (0.5 + 0.5 * np.random.rand()), 0.6)  # Enhanced adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 4, self.dim)  # Adjusted layer growth increment\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = bounds[:, 0] + np.random.rand(self.population_size, current_dim) * (bounds[:, 1] - bounds[:, 0]) # Improved initialization\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved HybridMetaheuristic with enhanced initialization strategy to enhance exploration diversity.", "configspace": "", "generation": 18, "fitness": 0.8657678261865644, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.027. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "b2877848-26d9-41f0-befb-7b33ea9b53b9", "metadata": {"aucs": [0.8272802633578802, 0.8894535837839789, 0.8805696314178342], "final_y": [0.1452702343927481, 0.1187396130122852, 0.11873944622333288]}, "mutation_prompt": null}
{"id": "78636d57-7e9f-4d10-80ea-cd01b400f76d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget)) * np.var(pop)  # Variance-dependent scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = max(self.cr * (0.5 + 0.5 * np.random.rand()), 0.6)  # Enhanced adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 4, self.dim)  # Adjusted layer growth increment\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced variance-dependent mutation scaling to improve exploration and exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.8877749343583101, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.005. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b2877848-26d9-41f0-befb-7b33ea9b53b9", "metadata": {"aucs": [0.89330221300993, 0.8894535837839789, 0.8805690062810213], "final_y": [0.11439877318544167, 0.1187396130122852, 0.1187460874829418]}, "mutation_prompt": null}
{"id": "120e60c9-d82b-4979-8b03-62858c9c0236", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        layer_scaling = np.linspace(1, 0.5, num=self.dim)  # Layer-specific scaling\n        adapt_f = self.f * (1 - (len(self.history) / self.budget)) * layer_scaling  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = max(self.cr * (0.5 + 0.5 * np.random.rand()), 0.6)  # Enhanced adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 4, self.dim)  # Adjusted layer growth increment\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Incorporate layer-specific adaptive scaling in DE mutation to better handle layer roles within photonic structures.", "configspace": "", "generation": 19, "fitness": 0.8787523065366875, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.010. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "b2877848-26d9-41f0-befb-7b33ea9b53b9", "metadata": {"aucs": [0.8662343295450621, 0.8894535837839789, 0.8805690062810213], "final_y": [0.11879815434452667, 0.1187396130122852, 0.1187460874829418]}, "mutation_prompt": null}
{"id": "961ed036-884a-427d-84c6-365bc7fa2576", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = max(self.cr * (0.5 + 0.5 * np.random.rand()), 0.6)  # Enhanced adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 4, self.dim)  # Adjusted layer growth increment\n    \n    def _manage_diversity(self, pop):\n        if np.std(pop) < 0.01:  # Maintain diversity\n            pop += np.random.normal(0, 0.01, size=pop.shape)\n        return pop\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n            pop = self._manage_diversity(pop)  # Maintain diversity\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n            \n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid algorithm with improved robustness via diversity maintenance and adaptive population size.", "configspace": "", "generation": 19, "fitness": 0.8657676178076268, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.027. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "b2877848-26d9-41f0-befb-7b33ea9b53b9", "metadata": {"aucs": [0.8272802633578802, 0.8894535837839789, 0.8805690062810213], "final_y": [0.1452702343927481, 0.1187396130122852, 0.1187460874829418]}, "mutation_prompt": null}
{"id": "8a51dc2c-662f-4d39-b8f4-14f1f95e8414", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = max(self.cr * (0.5 + 0.5 * np.random.rand()), 0.6)  # Enhanced adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)  # Adjusted layer growth increment\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced layer growth strategy by reducing the increment to improve convergence precision.", "configspace": "", "generation": 19, "fitness": 0.8841345012158609, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.004. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b2877848-26d9-41f0-befb-7b33ea9b53b9", "metadata": {"aucs": [0.8823802884457699, 0.8894535837839789, 0.8805696314178342], "final_y": [0.11431209218093175, 0.1187396130122852, 0.11873944622333288]}, "mutation_prompt": null}
{"id": "bfcace75-d984-4f8f-8460-7dabb414857f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        best_dist = np.linalg.norm(pop - np.min(pop, axis=0), axis=1).max()  # Adaptive mutation based on best-worst distance\n        worst_dist = np.linalg.norm(pop - np.max(pop, axis=0), axis=1).max()\n        adapt_f = self.f * (1 - (len(self.history) / self.budget)) * (best_dist / (worst_dist + 1e-9))\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = max(self.cr * (0.5 + 0.5 * np.random.rand()), 0.6)  # Enhanced adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 4, self.dim)  # Adjusted layer growth increment\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced the DE mutation strategy with an adaptive mutation factor that scales with the best and worst population distances for improved exploration.", "configspace": "", "generation": 19, "fitness": 0.8877749343583101, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.005. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b2877848-26d9-41f0-befb-7b33ea9b53b9", "metadata": {"aucs": [0.89330221300993, 0.8894535837839789, 0.8805690062810213], "final_y": [0.11439877318544167, 0.1187396130122852, 0.1187460874829418]}, "mutation_prompt": null}
{"id": "8563895c-7757-4868-833f-cfc9c50ee047", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / (2 * self.budget)))  # Enhanced adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = max(self.cr * (0.5 + 0.5 * np.random.rand()), 0.6)  # Enhanced adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 4, self.dim)  # Adjusted layer growth increment\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.2 * np.var(trial)  # Enhanced robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced scaling factor adaptation and robustness metric integration for improved convergence stability.", "configspace": "", "generation": 19, "fitness": 0.8655932374664769, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.028. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "b2877848-26d9-41f0-befb-7b33ea9b53b9", "metadata": {"aucs": [0.8267571223344305, 0.8894535837839789, 0.8805690062810213], "final_y": [0.14571207344199189, 0.1187396130122852, 0.1187460874829418]}, "mutation_prompt": null}
{"id": "610a9ed4-d8fb-468a-a29f-1efef5920f7b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = max(self.cr * (0.5 + 0.5 * np.random.rand()), 0.6)  # Enhanced adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        adapt_bounds = [(b[0] - 0.1, b[1] + 0.1) for b in bounds]  # Adaptive bounds adjustment\n        result = minimize(wrapped_func, x, bounds=adapt_bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 4, self.dim)  # Adjusted layer growth increment\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            if evaluations > self.budget // 2:  # Dynamic population resizing\n                self.population_size = min(self.population_size + 5, 50)\n                pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic with adaptive local search tuning and dynamic population resizing for improved exploration and robustness.", "configspace": "", "generation": 20, "fitness": 0.7948967637801355, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.795 with standard deviation 0.014. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b2877848-26d9-41f0-befb-7b33ea9b53b9", "metadata": {"aucs": [0.8136346767536659, 0.7924265329053843, 0.7786290816813565], "final_y": [0.14807798154734064, 0.1531704057066069, 0.14949851769358424]}, "mutation_prompt": null}
{"id": "ba395f97-4c57-4bab-9251-0d6057bb0dd8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (0.5 + np.random.rand() * 0.5) * (1 - (len(self.history) / self.budget))  # Enhanced mutation\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = max(self.cr * (0.5 + 0.5 * np.random.rand()), 0.6)\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 4, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.05 * np.var(trial)  # Adjusted robustness coefficient\n                f_target = func(target) + 0.05 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.05 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced mutation strategy and adaptive robustness coefficient for improved exploration and stability.", "configspace": "", "generation": 20, "fitness": 0.8163813931493357, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.037. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "b2877848-26d9-41f0-befb-7b33ea9b53b9", "metadata": {"aucs": [0.8686578179949096, 0.7924265329053843, 0.788059828547713], "final_y": [0.11873922431894324, 0.1531704057066069, 0.1529915884592431]}, "mutation_prompt": null}
{"id": "6d66a1bb-5484-49c9-9288-80f56d8f2f4f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Changed from 20 to 25\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = max(self.cr * (0.5 + 0.5 * np.random.rand()), 0.6)  # Enhanced adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 4, self.dim)  # Adjusted layer growth increment\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Increased population size from 20 to 25 for better exploration and diversity in search space.", "configspace": "", "generation": 20, "fitness": 0.7841703946223831, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.784 with standard deviation 0.036. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "b2877848-26d9-41f0-befb-7b33ea9b53b9", "metadata": {"aucs": [0.8240085769441249, 0.7924265329053843, 0.7360760740176403], "final_y": [0.1219333966850763, 0.1531704057066069, 0.18104575267202294]}, "mutation_prompt": null}
{"id": "0322bc95-a2fb-422d-aeec-d0c0317f0bb9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = max(self.cr * (0.5 + 0.5 * np.random.rand()), 0.6)  # Enhanced adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 5, self.dim)  # Adjusted layer growth increment\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                if np.random.rand() < 0.2:  # Introduce new strategy - randomness for diversity\n                    mutant = np.random.rand(current_dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved HybridMetaheuristic with enhanced population diversity and adaptive layer growth for optimal convergence in high-dimensional noisy optimization problems.", "configspace": "", "generation": 20, "fitness": 0.7993676814225111, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.054. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "b2877848-26d9-41f0-befb-7b33ea9b53b9", "metadata": {"aucs": [0.8686578179949096, 0.7924265329053843, 0.7370186933672396], "final_y": [0.11873922431894324, 0.1531704057066069, 0.18013022279517998]}, "mutation_prompt": null}
{"id": "523bd96e-2551-4de5-88ec-53ec85a483d7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 4, replace=False)  # Increased to 4 for more diversity\n        a, b, c, d = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c + d), 0, 1)  # Added d for enhanced mutation\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = max(self.cr * (0.5 + 0.5 * np.random.rand()), 0.6)  # Enhanced adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 4, self.dim)  # Adjusted layer growth increment\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + 0.1 * np.var(trial)  # Include robustness metric\n                f_target = func(target) + 0.1 * np.var(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + 0.1 * np.var(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration in DE mutation by increasing random index selection for improved diversity.", "configspace": "", "generation": 20, "fitness": 0.8255430000532425, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.031. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "b2877848-26d9-41f0-befb-7b33ea9b53b9", "metadata": {"aucs": [0.8662343295450621, 0.7924265329053843, 0.8179681377092813], "final_y": [0.11879815434452667, 0.1531704057066069, 0.12822614818480405]}, "mutation_prompt": null}
