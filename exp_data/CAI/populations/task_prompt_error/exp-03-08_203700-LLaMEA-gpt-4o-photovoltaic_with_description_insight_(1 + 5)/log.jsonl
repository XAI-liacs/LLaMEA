{"id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Multi-layer Adaptive Hybrid Optimization (MAHO) which combines differential evolution for exploration and adaptive local search for refinement, gradually increasing the problem complexity to manage computational cost while preserving solution robustness.", "configspace": "", "generation": 0, "fitness": 0.8014255414589018, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.007. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7919761021631633, 0.8046118976365253, 0.8076886245770165], "final_y": [0.15461080224244594, 0.13118175845832658, 0.13459700502320449]}, "mutation_prompt": null}
{"id": "4c147630-09da-492d-9a6d-0eb6ef10145a", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.5  # Increased local search probability\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced Multi-layer Adaptive Hybrid Optimization (MAHO+) with increased local search probability to improve refinement.", "configspace": "", "generation": 1, "fitness": 0.799447738105476, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.018. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.7840989331232361, 0.8253038805003883, 0.7889404006928036], "final_y": [0.1534251768710897, 0.14236211058626758, 0.14415371141768285]}, "mutation_prompt": null}
{"id": "feaff8c6-25e1-4e1c-95b2-bdc0052c80a8", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        dynamic_crossover_prob = self.crossover_prob + 0.1 * (1 - self.evaluations / self.budget)  # Adjusted line\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < dynamic_crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.normal(0, self.robustness_factor, x.shape)  # Adjusted line\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced Multi-layer Adaptive Hybrid Optimization (MAHO) with dynamic crossover probability adjustment and improved local search perturbation for better exploration-exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.7696333712916008, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.770 with standard deviation 0.008. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.7578387426380185, 0.7773100177218168, 0.7737513535149669], "final_y": [0.15421959410785135, 0.15321754010683486, 0.1553035667094056]}, "mutation_prompt": null}
{"id": "fcf154fb-d8e8-45d5-bfbb-f9d2d7ab9a72", "solution": "import numpy as np\n\nclass E_MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5\n        self.robustness_factor = 0.05\n        self.evaluations = 0\n        self.adaptive_rate = 0.9  # New: Adaptive mutation rate\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # New: Adaptive mutation factor\n            adaptive_mutation = self.mutation_factor * (1 - self.evaluations / self.budget)\n            mutant = np.clip(a + adaptive_mutation * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            # New: Adjust layer increment strategy\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment // 2)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "E_MAHO", "description": "Enhanced Multi-layer Adaptive Hybrid Optimization (E-MAHO) introduces adaptive mutation and dynamic layer adjustments, improving robustness and convergence in high-dimensional noisy problems.", "configspace": "", "generation": 1, "fitness": 0.7870249995325017, "feedback": "The algorithm E_MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.787 with standard deviation 0.018. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.76633160018563, 0.8100875669384802, 0.7846558314733949], "final_y": [0.14490552372951104, 0.1409444555205086, 0.1363966478872859]}, "mutation_prompt": null}
{"id": "e213de8c-7d28-4909-bb6d-b0ae52ebc9fa", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(dim * 2.5))  # Increased population size for better exploration\n        self.mutation_factor = 0.9  # Increased mutation factor for broader search\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced Multi-layer Adaptive Hybrid Optimization (Enhanced MAHO) with increased mutation factor and adaptive population size for improved exploration and solution robustness.", "configspace": "", "generation": 1, "fitness": 0.7966661027119325, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.033. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.8227835814377651, 0.8171101637208417, 0.7501045629771909], "final_y": [0.13737376978956373, 0.1447084233347674, 0.16248284688966397]}, "mutation_prompt": null}
{"id": "7827061e-e733-4b1c-9593-d66571e6b394", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptively adjust mutation factor based on budget usage\n            adaptive_mutation = self.mutation_factor * (1 - self.evaluations / self.budget)\n            mutant = np.clip(a + adaptive_mutation * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO with adaptive mutation factors for improved exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.7901256198426828, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.009. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.7791862134523967, 0.7899635772944218, 0.80122706878123], "final_y": [0.15522129028708564, 0.15283840369850332, 0.13996555297520363]}, "mutation_prompt": null}
{"id": "b30188f4-6011-40f4-ae5a-1ca9d250631e", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            adaptive_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget))\n            adaptive_crossover_prob = self.crossover_prob + (0.3 * (self.evaluations / self.budget))\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < adaptive_crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO with adaptive mutation and crossover strategies to improve exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.7997274627240444, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.014. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.8049144758017377, 0.813571955041513, 0.7806959573288828], "final_y": [0.13388623560009383, 0.14612193683222774, 0.1333484999587351]}, "mutation_prompt": null}
{"id": "b8410d26-d1f2-4e06-a108-4e9533b80e1d", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.85  # Fine-tuned mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Improved Multi-layer Adaptive Hybrid Optimization (MAHO) by fine-tuning the mutation factor.", "configspace": "", "generation": 2, "fitness": 0.7879095195927096, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.788 with standard deviation 0.012. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.805378000656074, 0.7780281704457821, 0.7803223876762727], "final_y": [0.13483361111700676, 0.14439661730229603, 0.1473768720760017]}, "mutation_prompt": null}
{"id": "b95e33b9-4a65-45fd-8a72-d633f008d2ac", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced Multi-layer Adaptive Hybrid Optimization (MAHO+) introduces a scaled mutation factor for better diversity and a dynamic local search probability to improve convergence.", "configspace": "", "generation": 2, "fitness": 0.8027004770627206, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.025. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.80751595806686, 0.7695050944484424, 0.8310803786728596], "final_y": [0.1454622841796348, 0.15568794211095083, 0.1380137264010518]}, "mutation_prompt": null}
{"id": "36ebb24a-7a5e-4e7f-b50c-e4468c9a1657", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.9  # Adjusted mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 3  # Reduced increment for finer control\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Refined Multi-layer Adaptive Hybrid Optimization (RMAHO) enhances robustness by adjusting layer increment strategies and incorporating adaptive mutation factors for more efficient exploration.", "configspace": "", "generation": 2, "fitness": 0.793774958605128, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.001. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.794054038660319, 0.7928129523793591, 0.7944578847757062], "final_y": [0.14839366180958014, 0.13966651144481168, 0.1479906963938763]}, "mutation_prompt": null}
{"id": "f8ec2a6b-0671-4edf-bb71-94c93ef83642", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            adaptive_mutation_factor = self.mutation_factor + np.random.uniform(-0.1, 0.1)  # Adaptive mutation\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            layer_perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if layer_perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO with adaptive mutation factor and layer-specific local search to improve exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.7720486692843224, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.772 with standard deviation 0.011. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.7857895314263594, 0.7594981538172785, 0.7708583226093293], "final_y": [0.15237374825459737, 0.1547931057431139, 0.15470515725882983]}, "mutation_prompt": null}
{"id": "c65e5574-62f8-47f3-912b-ea06dbc90038", "solution": "import numpy as np\n\nclass EMaho:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5\n        self.robustness_factor = 0.05\n        self.evaluations = 0\n        self.base_mutation_factor = 0.5\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = self.base_mutation_factor + 0.2 * np.random.rand()  # Adaptive mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and np.random.rand() < 0.3:  # Stochastic layer addition\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "EMaho", "description": "Enhanced MAHO (E-MAHO) introduces adaptive mutation factor and stochastic layer addition for improved exploration and convergence.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (15,) (10,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (15,) (10,) (10,) ')", "parent_id": "b95e33b9-4a65-45fd-8a72-d633f008d2ac", "metadata": {}, "mutation_prompt": null}
{"id": "d4212672-476e-4def-9f06-e9f852c59902", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO+ with adaptive crossover probability scaling to improve solution space exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8193930118499623, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.819 with standard deviation 0.015. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b95e33b9-4a65-45fd-8a72-d633f008d2ac", "metadata": {"aucs": [0.8377828116504928, 0.8010202926038, 0.8193759312955937], "final_y": [0.1358836509393062, 0.14572098167736958, 0.13040846147118623]}, "mutation_prompt": null}
{"id": "07384bad-0671-4be9-b05c-1ed0dc1907ea", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.3 * (self.evaluations / self.budget)  # Fine-tuned dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "MAHO++ optimizes layer adaptation by fine-tuning the dynamic local search probability for enhanced convergence.", "configspace": "", "generation": 3, "fitness": 0.8155229985633078, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.016. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b95e33b9-4a65-45fd-8a72-d633f008d2ac", "metadata": {"aucs": [0.8371260790640094, 0.7986369688115884, 0.8108059478143257], "final_y": [0.14482560097484054, 0.14019495648456604, 0.13470643242366132]}, "mutation_prompt": null}
{"id": "f3de2de9-1631-4b65-8da5-38a5f45cab1f", "solution": "import numpy as np\n\nclass IMAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.7 + 0.3 * np.random.rand()  # Adjusted mutation factor\n        self.crossover_prob = 0.6  # Adjusted for adaptivity\n        self.local_search_prob = 0.3\n        self.layers_increment = 5\n        self.robustness_factor = 0.05\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def layered_learning(self, pop, func):\n        fitness = np.array([func(ind) for ind in pop])\n        fitness_variance = np.var(fitness)\n        if fitness_variance > 0.01:  # Threshold for variance-based learning\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n        return pop\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            pop = self.layered_learning(pop, func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "IMAHO", "description": "Improved Multi-objective Adaptive Hybrid Optimization (IMAHO) adjusts mutation and crossover adaptively based on fitness variance and introduces layered learning for better convergence.", "configspace": "", "generation": 3, "fitness": 0.8115557680161757, "feedback": "The algorithm IMAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.027. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "b95e33b9-4a65-45fd-8a72-d633f008d2ac", "metadata": {"aucs": [0.774375046439123, 0.8396995525520968, 0.820592705057307], "final_y": [0.1552765303152288, 0.1233836973040815, 0.13071478117801216]}, "mutation_prompt": null}
{"id": "c5d1fe70-8d46-4eac-8636-44032aef94d0", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adapt mutation factor based on progress for exploration-exploitation balance\n            mutation_factor = self.mutation_factor * (0.5 + 0.5 * (self.evaluations / self.budget))\n            mutant = np.clip(a + mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "MAHO++ improves convergence by adapting the mutation factor based on iteration progress for better exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.812339023951795, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.024. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b95e33b9-4a65-45fd-8a72-d633f008d2ac", "metadata": {"aucs": [0.8209256839517725, 0.8364340015868834, 0.7796573863167294], "final_y": [0.13099497860581077, 0.12666535085060748, 0.1373497411064638]}, "mutation_prompt": null}
{"id": "e0f157f7-7c74-4e88-9d24-a52e7e3788db", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 3  # Increment layers gradually, reduced for frequent adaptation\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.3 + 0.4 * np.random.rand()  # More adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.3:  # Earlier dimensional increment\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Synergistic MAHO+ with adaptive exploration-exploitation balance and interleaved layer adaptation for enhanced convergence.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (13,) (10,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (13,) (10,) (10,) ')", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {}, "mutation_prompt": null}
{"id": "d2ebfee6-dcd6-4212-9626-0a694822e576", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.4 + 0.3 * np.random.rand()  # Adaptive mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        # Dynamic adjustment of local search probability based on evaluations\n        dynamic_local_search_prob = self.local_search_prob + 0.3 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO++ with adaptive mutation and dynamic local search scaling to improve balance and solution quality.", "configspace": "", "generation": 4, "fitness": 0.7820957481038967, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.024. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.8157853619460335, 0.7706165811067228, 0.7598853012589337], "final_y": [0.14087179800967065, 0.15321972304336362, 0.16271313012678168]}, "mutation_prompt": null}
{"id": "2cf7e3fd-c43d-42f4-81fd-21fd62ae3b4e", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.1 * (self.evaluations / self.budget)  # Adjusted factor\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO+ with adaptive local search probability scaling for better exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.7850913736934731, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.010. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7792648790463674, 0.7993233739000963, 0.7766858681339559], "final_y": [0.15251255570967726, 0.14344567592818236, 0.15739484364977152]}, "mutation_prompt": null}
{"id": "77bf84ec-12d7-4344-be3e-d71b9e77a442", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.3 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Slightly increase the dynamic local search probability to enhance local refinement while preserving the exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.7864038545444195, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.786 with standard deviation 0.030. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.8126181454585135, 0.8016503438775675, 0.7449430742971772], "final_y": [0.1443395805129548, 0.14373334124937187, 0.1672247281252699]}, "mutation_prompt": null}
{"id": "c6158575-5237-45f5-85b3-546a3de2c5f7", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n        self.adaptive_mutation = 0.5  # Adaptive mutation initial value\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.adaptive_mutation = 0.4 + 0.3 * (1 - self.evaluations / self.budget)  # Dynamic adaptation\n            mutant = np.clip(a + self.adaptive_mutation * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.6 + 0.1 * np.random.rand()  # Slightly modified adaptive crossover\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_search_width = self.robustness_factor * (1 - self.evaluations / self.budget)  # Adaptive perturbation\n        dynamic_local_search_prob = self.local_search_prob + 0.3 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-dynamic_search_width, dynamic_search_width, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Hybrid MAHO+ leveraging dynamic adaptive mutation and diversified local search strategies for enhanced exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.8066916045304472, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.014. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.809789145457823, 0.8215711534856175, 0.7887145146479011], "final_y": [0.14962888623647308, 0.1390385426695081, 0.14756404230592768]}, "mutation_prompt": null}
{"id": "6ae5fe37-2f5a-427a-8897-bcb100dcad32", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.3 + 0.4 * (self.evaluations / self.budget)  # Dynamic mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "MAHO+ with dynamically adaptive crossover and mutation factors to enhance exploration-exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.7961980718671172, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.038. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.8471286505400267, 0.7868164117234825, 0.7546491533378425], "final_y": [0.13234451077506637, 0.14860320988464049, 0.15471254918142552]}, "mutation_prompt": null}
{"id": "03d04825-ae74-4f42-982d-fc609509bbec", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            decaying_mutation_factor = self.mutation_factor * (1 - self.evaluations / self.budget)  # Decaying mutation factor\n            mutant = np.clip(a + decaying_mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Introduce a decaying mutation factor to enhance convergence stability and performance.", "configspace": "", "generation": 5, "fitness": 0.7794327152490018, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.779 with standard deviation 0.029. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7908892303343698, 0.8078404241945325, 0.7395684912181033], "final_y": [0.1486160646776602, 0.14179889767915876, 0.14812738476946785]}, "mutation_prompt": null}
{"id": "335e9fe5-e524-404e-aad4-06dbec69cb99", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.6 + 0.3 * np.random.rand()  # Adjusted mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.35  # Increased local search probability\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "MAHO++ with enhanced mutation and exploration for improved convergence and performance.", "configspace": "", "generation": 5, "fitness": 0.7811716470323334, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.781 with standard deviation 0.012. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7932576506165497, 0.7643079177722609, 0.7859493727081894], "final_y": [0.14263667506925282, 0.14524247410590785, 0.15480787332265256]}, "mutation_prompt": null}
{"id": "b41a654e-ed65-4c21-9f4b-08aa54edef77", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation_range = self.robustness_factor * (1 - self.evaluations / self.budget)  # Adjust perturbation based on budget usage\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "MAHO+ improvement by optimizing local search perturbation range based on budget utilization for enhanced solution refinement.", "configspace": "", "generation": 5, "fitness": 0.7829974997562456, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.038. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.8184268385400557, 0.7305056934665083, 0.8000599672621727], "final_y": [0.13958458485963632, 0.1650505997468511, 0.14890202614065762]}, "mutation_prompt": null}
{"id": "c0a60bef-454a-4d08-aabe-a53ac0ad547a", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 3)  # Increased initial population size\n        self.base_mutation_factor = 0.5\n        self.mutation_factor = self.base_mutation_factor + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        dynamic_pop_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))  # Dynamic population scaling\n        for i in range(dynamic_pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(dynamic_pop_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = self.base_mutation_factor + 0.2 * np.random.rand()  # Adaptive mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(len(pop)):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO++ with dynamic population scaling and adaptive mutation for improved exploration-exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.7776131129923084, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.778 with standard deviation 0.018. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7615226066912204, 0.8031413572786781, 0.7681753750070266], "final_y": [0.1478206926634852, 0.14084628800158483, 0.14352199722697545]}, "mutation_prompt": null}
{"id": "f88d9304-24f5-402a-9183-1ca025211347", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.4 + 0.5 * np.random.rand()  # Adaptive mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            if self.evaluations / self.budget > 0.3:\n                self.population_size = min(50, self.population_size + 1)  # Gradually increase population size\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO++ with adaptive population size and mutation factor for improved exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {}, "mutation_prompt": null}
{"id": "ee910d1d-0838-4bd6-8580-7fb6fa7430c6", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            # Adaptive robustness scaling based on evaluations\n            self.robustness_factor = 0.05 + 0.1 * (self.evaluations / self.budget)  \n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Improved MAHO+ by incorporating adaptive robustness scaling to enhance robustness and exploration in high-dimensional spaces.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {}, "mutation_prompt": null}
{"id": "c88e6ed7-8dd1-485e-876c-c9c87979eb28", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + int(self.layers_increment * (self.evaluations / self.budget)))  # Dynamic layer increment\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "MAHO++ now includes dynamic adjustment of layer increment to adapt complexity growth during the optimization process.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {}, "mutation_prompt": null}
{"id": "4470a5d3-f2d7-4ccc-8af0-5b9791dc075a", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5 \n        self.robustness_factor = 0.05\n        self.evaluations = 0\n        self.learning_rate = 0.01  # Learning rate for gradient-based local search\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand() \n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            gradient = (func(x + perturbation) - func(x)) / perturbation\n            x_perturbed = np.clip(x - self.learning_rate * gradient, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Hybridized MAHO+ with gradient-based local search and adaptive parameter control to improve convergence and solution quality.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {}, "mutation_prompt": null}
{"id": "5d6e39c0-bec7-457a-a43a-cae87aed1601", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.4 + 0.2 * np.random.rand()  # Adaptive mutation factor adjustment\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO+ with adaptive mutation factor adjustment to improve solution space exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {}, "mutation_prompt": null}
{"id": "e8cc0f83-e35c-4bd5-9604-e48514084687", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            if self.evaluations > self.budget / 2:  # Increase perturbation after half budget\n                perturbation *= 2\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "MAHO++ by elevating perturbation impact for local search refinement beyond mid-budget.", "configspace": "", "generation": 7, "fitness": 0.7883443759262878, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.788 with standard deviation 0.017. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7681363239907186, 0.7871241985719941, 0.8097726052161507], "final_y": [0.1432350621728693, 0.14510041184958422, 0.13896961779139905]}, "mutation_prompt": null}
{"id": "93862ce2-cf36-4948-b3f8-9cc1daf3d28a", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor scaling\n            self.mutation_factor = 0.4 + 0.3 * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO+ with adaptive mutation factor scaling for improved exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.7873891181117282, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.787 with standard deviation 0.013. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7732199703180187, 0.8041246914553603, 0.7848226925618057], "final_y": [0.15680081745277819, 0.14070658172714623, 0.13610033427591572]}, "mutation_prompt": null}
{"id": "12b47c76-459a-4a4a-9fcd-6d1061100d61", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial) + np.random.normal(0, 0.01)  # Adding noise to reflect realistic conditions\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Refined adaptive crossover strategy with noise-adjusted selection to improve solution quality under noisy conditions.", "configspace": "", "generation": 7, "fitness": 0.7904721689681667, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.004. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7855257489490222, 0.7917038809676948, 0.7941868769877831], "final_y": [0.14721520043778702, 0.14288708435118458, 0.13919942570195543]}, "mutation_prompt": null}
{"id": "8a8c02f5-0238-4654-ac5f-bf63335f86f4", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.4 + 0.4 * (self.evaluations / self.budget)  # Dynamic mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.6 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Improved adaptive crossover and dynamic mutation factor for enhanced exploration-exploitation balance in MAHO+.", "configspace": "", "generation": 7, "fitness": 0.7956142765600482, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.018. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.8202063697091175, 0.7756729033130056, 0.7909635566580213], "final_y": [0.1317084544622127, 0.15300247431604386, 0.14850846019627528]}, "mutation_prompt": null}
{"id": "4f9736e7-98e7-4e86-9674-b7034d4478a3", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 3  # Dynamic layer increment\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutation_rate = 0.4 + 0.1 * (1 - self.evaluations / self.budget)  # Adaptive mutation scaling\n            mutant = np.clip(a + mutation_rate * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO+ with dynamic layer increment and adaptive mutation for improved exploration and refinement balance.", "configspace": "", "generation": 7, "fitness": 0.7898065864019627, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.007. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7797038226357523, 0.7949687660634905, 0.7947471705066451], "final_y": [0.1558089128682526, 0.1330233822473229, 0.13905119572218383]}, "mutation_prompt": null}
{"id": "bcdff5fd-31ce-42af-aa0e-792e0b9335b6", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.6 + 0.2 * np.random.rand()  # Adjusted mutation factor scaling\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Improved MAHO+ by refining the mutation factor scaling for better exploration-exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8012135229886992, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.013. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.8190625973798433, 0.7952736381472881, 0.789304333438966], "final_y": [0.14409111430160992, 0.1270027532731598, 0.1378881214751615]}, "mutation_prompt": null}
{"id": "d4601135-4153-46e8-9d6d-252a1a862301", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05 \n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Dynamic mutation factor based on convergence\n            dynamic_mutation_factor = self.mutation_factor * (1 - self.evaluations / self.budget)\n            mutant = np.clip(a + dynamic_mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            # Layer-wise adaptive perturbation\n            perturbation = np.random.uniform(-self.robustness_factor / np.sqrt(self.dim), \n                                             self.robustness_factor / np.sqrt(self.dim), x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhance MAHO+ by integrating adaptive layer-wise perturbation and convergence-focused dynamic mutation.", "configspace": "", "generation": 8, "fitness": 0.798730515289432, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.015. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7803415910358388, 0.7988742508721083, 0.8169757039603488], "final_y": [0.15245288198679485, 0.12923601732566303, 0.12180579344723319]}, "mutation_prompt": null}
{"id": "094d63c1-a773-4dd0-aea7-2fc78581363a", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.3 + 0.4 * (self.evaluations / self.budget)  # Dynamic mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        self.population_size = min(self.population_size, int(self.budget / self.dim))  # Adaptive population size\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Improved MAHO+ with dynamic mutation factor and adaptive population size for better exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.7864970579980671, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.786 with standard deviation 0.052. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.816586050748549, 0.8295533196289043, 0.7133518036167483], "final_y": [0.13208248961978075, 0.12875872885781803, 0.18102684689897497]}, "mutation_prompt": null}
{"id": "9bd8a903-4f75-4de8-af8c-c5dd186c7718", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            adaptive_mutation_factor = self.mutation_factor * (0.9 + 0.1 * np.random.rand())  # Adaptive mutation factor\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            self.population_size = min(max(5, int(self.dimension_factor() * self.dim)), self.population_size)  # Adaptive population size\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]\n\n    def dimension_factor(self):\n        return 0.75 + 0.25 * (self.evaluations / self.budget)  # Scaling function for population size", "name": "MAHO", "description": "Improved MAHO+ with weighted mutation factor and adaptive population size adjustment for better exploration and exploitation.", "configspace": "", "generation": 8, "fitness": 0.8056365427618913, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.039. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.858788804077669, 0.7676987509037313, 0.7904220733042738], "final_y": [0.1289088808454547, 0.1439274151719815, 0.14146005078368606]}, "mutation_prompt": null}
{"id": "40efc2bc-9d2e-4879-935f-394486ca0283", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.3 * (self.evaluations / self.budget) ** 2  # Enhanced dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Improved dynamic tuning of local search probability to enhance convergence during late optimization stages.", "configspace": "", "generation": 8, "fitness": 0.7790802702218543, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.779 with standard deviation 0.025. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7636282885360628, 0.8147037183009592, 0.7589088038285409], "final_y": [0.15077034456885396, 0.12543922295792242, 0.15287614727586052]}, "mutation_prompt": null}
{"id": "6878bbd2-a4d3-4860-91a1-6e4873d6f1c1", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 2  # Dynamic increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * np.random.rand()  # Randomized dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO+ with dynamic layer increments and adaptive local search probability for improved convergence.", "configspace": "", "generation": 9, "fitness": 0.7920687920609865, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.015. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.803665330903154, 0.8014129926094737, 0.7711280526703319], "final_y": [0.1410777767143524, 0.1297916871873016, 0.15814925321729334]}, "mutation_prompt": null}
{"id": "4dc10a3d-ff9d-4f24-8e81-5b3976e1b788", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.5 * np.random.rand()  # Adaptive mutation scaling\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO+ with adaptive mutation scaling and improved search space exploration.", "configspace": "", "generation": 9, "fitness": 0.7960037701591688, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.024. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7699188347330699, 0.827290363644429, 0.7908021121000078], "final_y": [0.1561333670854682, 0.13666401757190672, 0.14296492321122445]}, "mutation_prompt": null}
{"id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Fine-tuned adaptive mutation factor adjustment for enhanced exploration-exploitation balance in MAHO+ algorithm.", "configspace": "", "generation": 9, "fitness": 0.8379249010217821, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.018. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.81253423304642, 0.854506551487999, 0.8467339185309272], "final_y": [0.135257654614648, 0.13233289015687788, 0.13065991960002088]}, "mutation_prompt": null}
{"id": "16a0336f-f95b-448d-a084-6582c50564f8", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 2  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + (0.9 - 0.4 * np.random.rand()) * (b - c), func.bounds.lb, func.bounds.ub)  # Enhanced mutation strategy\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Refined MAHO+ with enhanced mutation strategy and adaptive layer increment for improved convergence and diversity.", "configspace": "", "generation": 9, "fitness": 0.8060696374452009, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.025. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.8047157991236114, 0.7760822374825914, 0.8374108757294001], "final_y": [0.14637300226356076, 0.14009079163663551, 0.1325572802546504]}, "mutation_prompt": null}
{"id": "3d93e87d-ae62-459d-a5b6-d163a24f9f42", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 3  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO+ with improved layer increment strategy to balance complexity and convergence rate.", "configspace": "", "generation": 9, "fitness": 0.8031054995455925, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.022. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.8091407702311123, 0.7739574858439372, 0.8262182425617284], "final_y": [0.1411827439284491, 0.15475893752913106, 0.13788497299346503]}, "mutation_prompt": null}
{"id": "40451758-45aa-4108-b587-599e8372395e", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.3 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor * (0.8 + 0.4 * np.random.rand()), self.robustness_factor * (0.8 + 0.4 * np.random.rand()), x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Improved robustness through dynamic adjustment of local search probability and robustness factor for better adaptability.", "configspace": "", "generation": 10, "fitness": 0.8257848505209336, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.015. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.8388155015516453, 0.8329940423246361, 0.8055450076865195], "final_y": [0.12730626678929313, 0.13136536323358228, 0.14769355977455234]}, "mutation_prompt": null}
{"id": "fdec95fa-35c7-4e4d-86db-1cc0572a3458", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.3 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced dynamic local search probability scaling for improved exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.790926401696077, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.010. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.792383438039581, 0.8027369727849784, 0.7776587942636715], "final_y": [0.1476522284224807, 0.1447143533772346, 0.13509515767450964]}, "mutation_prompt": null}
{"id": "e3ea011e-e360-452e-9a1f-e7452ca7c230", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            # Change: Introduced a layer-specific mutation factor\n            layer_specific_factor = np.random.rand(self.dim)  # New line added\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * layer_specific_factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Introduce a layer-specific adaptive mutation factor to enhance diversity and solution quality in MAHO+.", "configspace": "", "generation": 10, "fitness": 0.7931255784871464, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.011. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.8018687301919892, 0.7774293875850471, 0.8000786176844026], "final_y": [0.14037173085531607, 0.13011672812375563, 0.13477429082327708]}, "mutation_prompt": null}
{"id": "6884f460-0efb-4190-b4cf-426ab8a360c2", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Enhanced adaptive mutation factor adjustment for improved convergence\n            self.mutation_factor = 0.6 + 0.4 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced adaptive mutation factor for improved solution diversity and convergence speed in MAHO+ algorithm.", "configspace": "", "generation": 10, "fitness": 0.7890319675759244, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.004. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7873278692973333, 0.7942002348701107, 0.7855677985603295], "final_y": [0.1420486378970881, 0.1421563902232963, 0.13764836635895605]}, "mutation_prompt": null}
{"id": "4de39b05-72db-4d23-9a0c-d43fab4865b0", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n            if self.evaluations / self.budget < 0.25:  # Adaptive layer scaling\n                self.layers_increment = 3  # Reduce complexity early\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Implement adaptive layer scaling to enhance exploration at early stages.", "configspace": "", "generation": 10, "fitness": 0.796178608203733, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.010. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.8040561061727021, 0.7814899887000282, 0.8029897297384687], "final_y": [0.13301540383845234, 0.15029015389465872, 0.14936332089012794]}, "mutation_prompt": null}
{"id": "21115f81-c431-4a2f-936c-d2e2f404a776", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.4 * (self.evaluations / self.budget) * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.3 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced local search probability scaling and dynamic adjustment of crossover probability in MAHO+ for improved optimization performance.", "configspace": "", "generation": 11, "fitness": 0.7846194847210443, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.011. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7859555910783149, 0.7706181346179198, 0.7972847284668979], "final_y": [0.14625928207402505, 0.1621005741578102, 0.141031359520293]}, "mutation_prompt": null}
{"id": "3383c442-2c49-4e8c-b116-ddd0ac16a566", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.4 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO+ with tuned adaptive crossover probability for improved exploration-exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.8016261612570398, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.019. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.8221618446398286, 0.7760408798587353, 0.8066757592725551], "final_y": [0.14000790462401602, 0.14253817788043044, 0.13491063704687478]}, "mutation_prompt": null}
{"id": "aac10b74-c4c4-405d-9989-bd73c1a90ee4", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Enhanced adaptive mutation factor adjustment\n            self.mutation_factor = 0.7 + 0.3 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced adaptive mutation factor adjustment in the MAHO+ algorithm for improved convergence in high-dimensional, noisy optimization problems.", "configspace": "", "generation": 11, "fitness": 0.7784144089476283, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.778 with standard deviation 0.013. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7967312377059692, 0.7669548847207565, 0.7715571044161589], "final_y": [0.14402870251408728, 0.1549949694080378, 0.15789488643118754]}, "mutation_prompt": null}
{"id": "e2427966-451b-4bd8-9f54-7bfd64c9b15a", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop_size_factor = 1.5 if self.evaluations / self.budget < 0.3 or self.evaluations / self.budget > 0.7 else 1.0\n        self.population_size = int(self.population_size * pop_size_factor)\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhance exploration via adaptive population sizing and dimensional expansion for improved convergence.", "configspace": "", "generation": 11, "fitness": 0.7890812697246284, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.005. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.793733790353312, 0.7921300680007577, 0.7813799508198157], "final_y": [0.1441697846949611, 0.14154794469661436, 0.14307704618953798]}, "mutation_prompt": null}
{"id": "46eb734d-c30d-47dd-9485-6b6be4539229", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            adaptive_robustness_factor = self.robustness_factor * (1 - self.evaluations / self.budget)  # Adaptive robustness factor\n            perturbation = np.random.uniform(-adaptive_robustness_factor, adaptive_robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Introduced adaptive robustness factor to improve local search by adjusting perturbation dynamically based on the evaluation progress.", "configspace": "", "generation": 11, "fitness": 0.7977164997115352, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.798 with standard deviation 0.024. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7656693699835712, 0.8250985585520216, 0.8023815705990127], "final_y": [0.16183563331372974, 0.1360859078437351, 0.1431214252707409]}, "mutation_prompt": null}
{"id": "038c7d03-3165-47da-b8aa-e97b54179dec", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            # Dynamically adjust crossover probability based on evaluations ratio\n            self.crossover_prob = 0.5 + 0.5 * (self.evaluations / self.budget)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced convergence by dynamically adjusting crossover probability based on evaluations ratio.", "configspace": "", "generation": 12, "fitness": 0.7887310908856602, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.017. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7803292493345472, 0.7734101469224322, 0.8124538764000009], "final_y": [0.14835116375463697, 0.1452571339126859, 0.13983186323364039]}, "mutation_prompt": null}
{"id": "789c6dcd-9422-4302-a906-b757d22cca0e", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            weighted_random = 0.5 + 0.5 * np.random.rand()  # Introduced weighted randomness\n            mutant = np.clip(a + self.mutation_factor * (b - c) * weighted_random, func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced exploration by introducing a weighted randomness component for more diverse candidate solutions.", "configspace": "", "generation": 12, "fitness": 0.7999078568270116, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.007. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.8085673381731415, 0.7925462779430945, 0.7986099543647989], "final_y": [0.13906715139357761, 0.14541010436534896, 0.1461693869016656]}, "mutation_prompt": null}
{"id": "74c597df-ad79-4ee0-89d6-aa640d76d742", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 4  # Adjusted increment layers gradually\n        self.robustness_factor = 0.05\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.4 + 0.6 * (self.evaluations / self.budget) * np.random.rand()  # Adjusted scaling\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.55 + 0.25 * np.random.rand()  # Adjusted crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.3 * (self.evaluations / self.budget)  # Adjusted dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n            else:  # Secondary local search phase\n                secondary_perturbation = np.random.uniform(-self.robustness_factor / 2, self.robustness_factor / 2, x.shape)\n                x_secondary = np.clip(x + secondary_perturbation, func.bounds.lb, func.bounds.ub)\n                secondary_cost = func(x_secondary)\n                self.evaluations += 1\n                return x_secondary if secondary_cost < func(x) else x\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO with adaptive mutation factor scaling and a dual-phase local search strategy to optimize exploration and exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.8197853029821247, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.011. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.8039706011640276, 0.826116471678959, 0.8292688361033875], "final_y": [0.14724901155128156, 0.13568771095235566, 0.14062675823792337]}, "mutation_prompt": null}
{"id": "accf8d45-5183-4199-9c19-6713799bdfef", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 3  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced layer increment strategy for gradual complexity adaptation in MAHO+ algorithm.", "configspace": "", "generation": 12, "fitness": 0.7930252491069457, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.017. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.8143764190929349, 0.7911222668958706, 0.7735770613320314], "final_y": [0.13997192734573172, 0.14835399663123017, 0.13856823670232177]}, "mutation_prompt": null}
{"id": "8bdd5d02-2fbb-4813-8e98-5cc03a17236f", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.3 * np.random.rand()  # Increased variability in crossover probability\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n            if self.budget - self.evaluations < self.population_size and self.dim < 32:\n                self.dim = min(32, self.dim + 1)  # Increment layers individually for final stages\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Adaptive layer-wise perturbation and dynamic crossover for improved exploration-exploitation in photovoltaic optimization.", "configspace": "", "generation": 12, "fitness": 0.7787469045064336, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.779 with standard deviation 0.011. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7945907831751036, 0.7722052524419094, 0.7694446779022878], "final_y": [0.13571776909818, 0.15505864855071327, 0.15543344063094233]}, "mutation_prompt": null}
{"id": "8a7b7dc7-ceb9-4b7b-aa16-548bd1270a1b", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (1 - self.evaluations / self.budget) * np.random.rand()  # Change made here\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced mutation factor adaptation to dynamically balance exploration and exploitation in MAHO+ algorithm.", "configspace": "", "generation": 13, "fitness": 0.7940597703093962, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.009. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7924340299532692, 0.8056920590218686, 0.7840532219530509], "final_y": [0.14534690408931272, 0.1408246780042811, 0.1543597478623926]}, "mutation_prompt": null}
{"id": "cbc0add1-aa8c-4f7b-aeaf-74f654036fad", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 3)  # Modified to enhance exploration\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5\n        self.robustness_factor = 0.05\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            if np.random.rand() < 0.3:  # Hybrid crossover strategy\n                trial = np.clip((pop[i] + mutant) / 2, func.bounds.lb, func.bounds.ub)\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Improved exploration via adaptive population and hybrid crossover in enhanced MAHO algorithm.", "configspace": "", "generation": 13, "fitness": 0.8005258663489183, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.006. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.795066433922295, 0.7970404519754325, 0.8094707131490273], "final_y": [0.15119637237638128, 0.13892864435877728, 0.1358208866634485]}, "mutation_prompt": null}
{"id": "e8c0f5b9-c4ad-4977-bda5-12c1530d414a", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor * (1 - self.evaluations / self.budget), self.robustness_factor * (1 - self.evaluations / self.budget), x.shape)  # Adjusted perturbation\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced robustness adaptation improves local search by dynamically adjusting perturbation magnitude based on progress.", "configspace": "", "generation": 13, "fitness": 0.8149059642174793, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.023. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.844902031712829, 0.7890822652372946, 0.8107335957023145], "final_y": [0.1422177645400532, 0.1378169798406471, 0.14120814862590225]}, "mutation_prompt": null}
{"id": "1d506bab-c2ab-4361-8fd3-caf3ee4494bc", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 3  # Increment layers gradually, adjusted\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.3 * np.random.rand()  # Adjusted crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced crossover strategy and dynamic layer increment for better exploration-exploitation balance in MAHO.", "configspace": "", "generation": 13, "fitness": 0.7923498420493768, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.022. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.8112646112502065, 0.7609210468754971, 0.8048638680224267], "final_y": [0.13636122494402525, 0.1480243225994915, 0.1327609678812025]}, "mutation_prompt": null}
{"id": "ca9aa6d4-03f7-4da2-81b0-c605416c792f", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5\n        self.robustness_factor = 0.05\n        self.evaluations = 0\n        self.best_cost = float('inf')  # New addition for convergence checking\n        self.best_solution = None  # Track the best solution found\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.4 + 0.4 * np.random.rand()  # More aggressive scaling on crossover\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n                if trial_cost < self.best_cost:  # Update if new best\n                    self.best_cost = trial_cost\n                    self.best_solution = trial\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n            if self.evaluations % 100 == 0:  # Convergence check every 100 evaluations\n                print(f\"Evaluations: {self.evaluations}, Best Cost: {self.best_cost}\")\n        return self.best_solution if self.best_solution is not None else pop[np.argmin([func(ind) for ind in pop])]", "name": "MAHO", "description": "Dynamic hybrid optimization combining adaptive differential evolution with layer-specific modular learning and enhanced convergence checking.", "configspace": "", "generation": 13, "fitness": 0.8152102037394743, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.023. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7828963118705919, 0.8292364003594357, 0.8334978989883951], "final_y": [0.15255579273200293, 0.14363187711242664, 0.13692184883103786]}, "mutation_prompt": null}
{"id": "c12c653f-4f65-47a6-b983-f265e1114959", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 3  # Adaptive layer increment\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb - 0.1, func.bounds.ub + 0.1, (self.population_size, self.dim))  # Diverse initialization\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + 2)  # Adaptive layer increment\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO with diverse population initialization and adaptive layer increment for better convergence and performance.", "configspace": "", "generation": 14, "fitness": 0.8113564358020399, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.009. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7993595278345811, 0.8208106929291523, 0.8138990866423863], "final_y": [0.14872910493609304, 0.13520491992395278, 0.13677751121140747]}, "mutation_prompt": null}
{"id": "75941203-6ad8-433e-b7d8-31749b5d72bf", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        # Adaptive robustness factor scaling for local search\n        adaptive_robustness_factor = self.robustness_factor * (1 - self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-adaptive_robustness_factor, adaptive_robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Introduced adaptive robustness factor scaling to enhance local search efficiency in MAHO+ algorithm.", "configspace": "", "generation": 14, "fitness": 0.783196255848228, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.005. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7870102642534906, 0.787004827634299, 0.7755736756568945], "final_y": [0.13693859655116702, 0.14661667003287215, 0.1575191656621091]}, "mutation_prompt": null}
{"id": "c8a95315-ac73-4936-a7bc-ff0739e7bc42", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.4 + 0.6 * (self.evaluations / self.budget) * np.random.rand()  # Adjusted mutation strategy\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.6 + 0.2 * np.random.rand()  # Adjusted crossover probability\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.3 * (self.evaluations / self.budget)  # Increased dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced local search integration and differential evolution mutation strategy for improved solution refinement.", "configspace": "", "generation": 14, "fitness": 0.8152857800072772, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.016. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.8256683827933629, 0.8275200901066206, 0.7926688671218483], "final_y": [0.1323826367210631, 0.13673368552668597, 0.14383886117607092]}, "mutation_prompt": null}
{"id": "5aac702c-ca59-4a72-9a4a-2c60dca3e1a5", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Dynamic mutation factor for better exploration-exploitation\n            self.mutation_factor = 0.5 + (0.5 * np.random.rand() * (1 - self.evaluations / self.budget))\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            # More adaptive perturbation for enhanced local search\n            perturbation = np.random.uniform(-self.robustness_factor * (1 - self.evaluations / self.budget), \n                                             self.robustness_factor * (1 - self.evaluations / self.budget), x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Improved MAHO with dynamic mutation factor and adaptive perturbation for enhanced exploitation.", "configspace": "", "generation": 14, "fitness": 0.796164282688196, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.010. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7879207052800237, 0.7903908348207365, 0.8101813079638278], "final_y": [0.155274719468234, 0.13706429572767398, 0.14142639019094505]}, "mutation_prompt": null}
{"id": "512bc519-3cdf-4c55-acc3-8d69de299368", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5\n        self.robustness_factor = 0.05\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Enhanced adaptive mutation factor\n            self.mutation_factor = 0.4 + 0.6 * (1 - self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            # Diversity-preserving mechanism\n            if trial_cost < func(pop[i]) or np.random.rand() < 0.1:\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced exploration via adaptive mutation and diversity-preserving strategies in MAHO++ algorithm.", "configspace": "", "generation": 14, "fitness": 0.7819600573489747, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.004. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7782475962019729, 0.7879443013343604, 0.7796882745105908], "final_y": [0.1590960106971412, 0.14593331545551302, 0.15030229978813647]}, "mutation_prompt": null}
{"id": "e59cfc5f-0d4b-4f2f-94b8-fa50569c585a", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.4 * (self.evaluations / self.budget) * np.random.rand()  # Adjusted scaling\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.3 * np.random.rand()  # Adjusted crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced balance between exploration and exploitation by fine-tuning mutation factor scaling and crossover probability adjustment in MAHO+.", "configspace": "", "generation": 15, "fitness": 0.7830677259362518, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.009. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7708446254685112, 0.7854039186593013, 0.7929546336809432], "final_y": [0.14969028517921656, 0.13524344952948975, 0.15569335287510766]}, "mutation_prompt": null}
{"id": "0d55d2ee-2ce7-4b29-a254-5b620dccbbda", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + int(self.layers_increment * 0.5))  # Adaptive layer increment\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhance the MAHO algorithm by introducing an adaptive layer increment strategy to balance complexity and exploration.", "configspace": "", "generation": 15, "fitness": 0.7839258593001374, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.784 with standard deviation 0.012. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7802790228435222, 0.7996309965547636, 0.7718675585021263], "final_y": [0.14964078715894336, 0.1408646013556133, 0.14904279933142595]}, "mutation_prompt": null}
{"id": "1d8634af-9e96-4983-8ce2-70442517a184", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 2  # Increment layers gradually  # Reduced increment for finer control\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.4 * np.random.rand()  # Increased adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhancing crossover probability adaptation and layer increment strategy for improved convergence in MAHO+ algorithm.", "configspace": "", "generation": 15, "fitness": 0.7991020933165783, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.017. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7763864157876417, 0.805568217180692, 0.8153516469814013], "final_y": [0.1403019722312031, 0.13417150077855344, 0.13787646398142617]}, "mutation_prompt": null}
{"id": "1d50e4e1-64d9-4a48-9a5e-54c14232f622", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget)**2 * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.normal(0, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced adaptive mutation factor and improved local search strategy for better exploration-exploitation balance in MAHO+ algorithm.", "configspace": "", "generation": 15, "fitness": 0.7985411578852865, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.006. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7974945547895902, 0.805952388037551, 0.7921765308287182], "final_y": [0.1346700029779454, 0.13785923609839645, 0.14229620243667707]}, "mutation_prompt": null}
{"id": "7b9dbbd2-6904-43e8-a5d8-2fbafb9aab57", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        best_idx = np.argmin([func(ind) for ind in pop])\n        best_ind = pop[best_idx]\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            self.mutation_factor *= np.linalg.norm(pop[i] - best_ind) / np.linalg.norm(func.bounds.ub - func.bounds.lb)  # Gradual scaling based on distance to best\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Introduce gradual mutation factor scaling based on distance-to-best to enhance adaptive exploration.", "configspace": "", "generation": 15, "fitness": 0.7853616955558073, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.016. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7763392734673196, 0.772242975470324, 0.8075028377297786], "final_y": [0.1498745564586157, 0.15456221622995414, 0.13934615050659405]}, "mutation_prompt": null}
{"id": "c4aea08a-fb3c-4564-91e5-d8b9d1da6451", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05 + 0.1 * np.random.rand()  # Adaptive robustness factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Introduce an adaptive robustness factor for improved perturbation resilience in the MAHO+ algorithm.", "configspace": "", "generation": 16, "fitness": 0.8012577923395677, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.018. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.8039521950965651, 0.7785949577093124, 0.8212262242128254], "final_y": [0.13516437474965015, 0.14298323366764865, 0.1414737804312819]}, "mutation_prompt": null}
{"id": "3c5a348b-f081-4363-8b94-bd926e63dc91", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation_scale = 1.0 - (self.evaluations / self.budget)  # Adaptive perturbation scaling\n            perturbation = np.random.uniform(-self.robustness_factor * perturbation_scale, self.robustness_factor * perturbation_scale, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Introduce adaptive local search perturbation scaling for enhanced robustness and solution refinement in the MAHO+ algorithm.", "configspace": "", "generation": 16, "fitness": 0.7910148435742842, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.011. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7750339076895334, 0.7983294074166257, 0.7996812156166933], "final_y": [0.14444017867668446, 0.13874102767448804, 0.14368495000338033]}, "mutation_prompt": null}
{"id": "4963eb1e-ab65-4304-8d49-1837423bf3d6", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_population_size = max(5, dim * 2)\n        self.population_size = self.base_population_size\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5\n        self.robustness_factor = 0.05\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n            # Adaptively adjust population size to promote exploration/discovery\n            if self.evaluations % (self.budget // 5) == 0:\n                self.population_size = max(5, int(self.base_population_size * (1.5 - self.evaluations / self.budget)))\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO with adaptive population size and diversity boost for improved exploration and convergence.", "configspace": "", "generation": 16, "fitness": 0.8073502531681375, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.005. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.8011253371559865, 0.8127504839188291, 0.8081749384295965], "final_y": [0.1404093127339443, 0.14012331890771956, 0.15159304490090408]}, "mutation_prompt": null}
{"id": "c52fd653-d8d3-4837-95f9-aab05f64bcde", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.35  # Increased local search probability\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Fine-tuned adaptive mutation factor adjustment for enhanced exploration-exploitation balance in MAHO+ algorithm with increased local search probability.", "configspace": "", "generation": 16, "fitness": 0.7831847918893766, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.005. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.784683116218486, 0.7765250080070389, 0.7883462514426047], "final_y": [0.14594247802927707, 0.12845355064215802, 0.15199552984324705]}, "mutation_prompt": null}
{"id": "b82e931f-5ea6-4f8e-bad9-35e17e0263c2", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            # Dynamically adjust robustness factor\n            self.robustness_factor = 0.03 + 0.02 * (1 - self.evaluations / self.budget)\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced exploration-exploitation balance by dynamically adjusting the robustness factor during local search.", "configspace": "", "generation": 16, "fitness": 0.8069668795391961, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.011. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7914934755355487, 0.814236048268647, 0.8151711148133924], "final_y": [0.1424936052904725, 0.13239458381771252, 0.1295477736670888]}, "mutation_prompt": null}
{"id": "3eef97de-389c-4477-8d38-e246c333390c", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.5 + 0.5 * (1 - self.evaluations / self.budget) * np.random.rand()  # Improved adjustment\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.3 * (self.evaluations / self.budget)  # Enhanced dynamic LS probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.normal(0, self.robustness_factor, x.shape)  # Changed to normal distribution\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced local search and mutation factor adjustment to improve solution refinement in MAHO+ algorithm.", "configspace": "", "generation": 17, "fitness": 0.7927243962148106, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.001. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7942008759424091, 0.7918691515683993, 0.7921031611336237], "final_y": [0.14776782919005482, 0.13719757229188745, 0.14583151607868494]}, "mutation_prompt": null}
{"id": "5903fa96-46e1-4cc0-8d5a-ad90047a7dd0", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.uniform(0.8, 1.2)\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.3 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Integrates adaptive mutation and crossover adjustments with dynamic robustness refinement to enhance MAHO+ algorithm's exploration-exploitation balance.", "configspace": "", "generation": 17, "fitness": 0.7866390555067805, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.787 with standard deviation 0.012. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7743397143417696, 0.8025224717704904, 0.7830549804080813], "final_y": [0.15156011355480692, 0.1449488946351073, 0.1404876891021215]}, "mutation_prompt": null}
{"id": "c7379665-4b7c-41b6-9e51-370ec3358e72", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.normal(0, self.robustness_factor, x.shape)  # Adaptive perturbation using normal distribution\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n                self.population_size = min(self.population_size + 2, 2*self.dim)  # Increase population size to maintain diversity\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhance MAHO by introducing adaptive perturbation and diversity-preserving mechanisms to improve robustness and exploration.", "configspace": "", "generation": 17, "fitness": 0.7898744536118508, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.011. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.8008381298471927, 0.7755215297605947, 0.7932637012277648], "final_y": [0.14136936441643277, 0.1500466192579497, 0.15005895151674575]}, "mutation_prompt": null}
{"id": "cb8e01a3-d091-4c97-b0b2-2f4b61e1433d", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            # Modified crossover probability scaling with robustness factor\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand() + 0.1 * self.robustness_factor\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Improved adaptive strategy by incorporating crossover probability scaling with robustness to enhance solution refinement.", "configspace": "", "generation": 17, "fitness": 0.7929845501220578, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.003. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7933351145579333, 0.7961151815312774, 0.7895033542769627], "final_y": [0.1385242578705841, 0.1439599312865908, 0.135601899896315]}, "mutation_prompt": null}
{"id": "4de5bde5-d81f-4df0-8af9-9f7c225a03f9", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        self.population_size = max(5, int(self.dim * 2 * (1 + 0.2 * (self.evaluations / self.budget))))  # Dynamic population size\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Introduced dynamic population size scaling based on budget utilization to enhance exploration and exploitation balance.", "configspace": "", "generation": 17, "fitness": 0.8083977933889068, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.007. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.8167270970671909, 0.8079903082646654, 0.800475974834864], "final_y": [0.1284690590162777, 0.142866255448294, 0.14876345425577764]}, "mutation_prompt": null}
{"id": "0ece2034-ceca-4cbc-9f10-a7d070626c01", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            self.population_size = max(5, int(self.dim * (1.5 + 0.5 * np.sin(self.evaluations / self.budget * np.pi))))  # Dynamic population size\n            pop = self.differential_evolution(pop, func)\n            for i in range(len(pop)):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhance exploration-exploitation balance by introducing dynamic population size adjustment in MAHO+ algorithm.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 15 is out of bounds for axis 0 with size 15').", "error": "IndexError('index 15 is out of bounds for axis 0 with size 15')", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {}, "mutation_prompt": null}
{"id": "117d792c-df61-4701-a2d5-67885932bdfd", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  \n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  \n        self.robustness_factor = 0.05  \n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.5 + 0.5 * (1 - self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.7 * (1 - self.evaluations / self.budget) \n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  \n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.25:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Introduced adaptive scaling for mutation and crossover based on convergence rate and added a dynamic layer adjustment mechanism in MAHO+.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (15,) (10,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (15,) (10,) (10,) ')", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {}, "mutation_prompt": null}
{"id": "ab9abf4c-8b75-4b47-9ecc-ac8b7b3c4022", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment with decay\n            self.mutation_factor = (0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()) * (1 - 0.01 * (self.evaluations / self.budget))\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced exploration-exploitation balance by introducing a decay factor to the mutation factor in MAHO algorithm.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (15,) (10,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (15,) (10,) (10,) ')", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {}, "mutation_prompt": null}
{"id": "e62dc45d-20db-4a4d-a5ff-60fa8161a884", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor * (1 + self.evaluations/self.budget), self.robustness_factor * (1 + self.evaluations/self.budget), x.shape)  # Adaptive scaling for robustness factor\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Introduced adaptive scaling for robustness factor to enhance exploration and exploitation balance.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (15,) (10,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (15,) (10,) (10,) ')", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {}, "mutation_prompt": null}
{"id": "6039ef5b-aad0-447b-99a5-2d7fe6f9cc4d", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 3 + (self.dim // 10)  # Adaptive layer increment\n        self.robustness_factor = 0.05 + 0.02 * np.random.rand()  # Slightly adaptive perturbation scale\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Refined MAHO with adaptive layer increment and perturbation scaling for enhanced robustness and exploration.", "configspace": "", "generation": 18, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (15,) (10,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (15,) (10,) (10,) ')", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {}, "mutation_prompt": null}
{"id": "5552467e-2bfe-4ca9-ad92-7b2fbbaa4e97", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.6 + 0.4 * (self.evaluations / self.budget) * np.random.rand()  # Changed\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.6 + 0.3 * np.random.rand()  # Changed\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced adaptive mutation and crossover strategies for improved convergence and robustness.", "configspace": "", "generation": 19, "fitness": 0.8076383370642836, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.003. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.8095380119292863, 0.8036001985510762, 0.8097768007124879], "final_y": [0.13956460423603623, 0.13664321522687062, 0.12954056677928705]}, "mutation_prompt": null}
{"id": "7500731a-5b7a-4330-bd04-32097f2b08fa", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.6 + 0.3 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor * 1.1, self.robustness_factor * 1.1, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Refined adaptive crossover and mutation strategies with dynamic robustness for improved exploration-exploitation balance in MAHO+ algorithm.", "configspace": "", "generation": 19, "fitness": 0.8123565389454982, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.011. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.8038981667072647, 0.8055506546320349, 0.8276207954971947], "final_y": [0.15449677380852334, 0.1353266370394175, 0.1436723783880216]}, "mutation_prompt": null}
{"id": "a0659c56-a8b4-4420-978f-dc9fa0e78074", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.25 * np.random.rand()  # Enhanced adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced exploration-exploitation balance by fine-tuning adaptive crossover probability in MAHO+ algorithm.", "configspace": "", "generation": 19, "fitness": 0.7892706031329569, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.004. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7862005453526901, 0.7954574338576902, 0.7861538301884904], "final_y": [0.14945590368884676, 0.1493444451299203, 0.1441156380573434]}, "mutation_prompt": null}
{"id": "9cb13049-025f-4ec4-98c2-c4dbb7737bc8", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]) or np.random.rand() < 0.1:  # Stochastic element added\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Introduced a stochastic selection mechanism in differential evolution to enhance exploration.", "configspace": "", "generation": 19, "fitness": 0.7937010459932736, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.009. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.79745694274915, 0.8020790300067963, 0.7815671652238744], "final_y": [0.13132387547140978, 0.13917280183468883, 0.14595301024706164]}, "mutation_prompt": null}
{"id": "2340645a-7842-4a33-b208-d6a295bef928", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.3 + 0.4 * (self.evaluations / self.budget)  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced exploration-exploitation balance by dynamically adjusting crossover probability based on evaluations.", "configspace": "", "generation": 19, "fitness": 0.7929204563548163, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.012. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.8062037077377647, 0.7960220891647631, 0.7765355721619215], "final_y": [0.14531752786401353, 0.14791866946328724, 0.15320319920933745]}, "mutation_prompt": null}
{"id": "1b041dfa-6201-454b-9dc9-793f4e27bcbb", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5\n        self.robustness_factor = 0.05\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        dynamic_pop_size = self.population_size  # Dynamic population control\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            dynamic_pop_size = max(5, self.population_size - int(self.evaluations / self.budget * self.population_size // 2))  # Adjust pop size\n            pop = pop[:dynamic_pop_size]  # Truncate population\n            for i in range(dynamic_pop_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced adaptive exploration-exploitation balance via dynamic population size adjustment in MAHO++ algorithm.", "configspace": "", "generation": 20, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 19 is out of bounds for axis 0 with size 19').", "error": "IndexError('index 19 is out of bounds for axis 0 with size 19')", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {}, "mutation_prompt": null}
{"id": "92480f30-f892-4951-891e-ef20524d6f9a", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Enhanced adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.6 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.3 * np.random.rand()  # Enhanced adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced adaptive mutation and crossover strategies in MAHO algorithm improve convergence by increasing the mutation range and crossover variability.", "configspace": "", "generation": 20, "fitness": 0.7774754337675951, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.777 with standard deviation 0.012. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7856096092133453, 0.786647239296932, 0.7601694527925078], "final_y": [0.14630432547850591, 0.14781224529841797, 0.15302549647561992]}, "mutation_prompt": null}
{"id": "0ea85cf6-e493-4319-b415-ca1ca25ed8bc", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Enhanced adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (1 - (self.evaluations / self.budget)**2) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced mutation factor adaptation for improved convergence in noise-prone optimization landscapes.", "configspace": "", "generation": 20, "fitness": 0.8029588111537788, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.017. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7814533677716237, 0.8034841415143597, 0.8239389241753534], "final_y": [0.15351889242347927, 0.15115613265621275, 0.14365156906335252]}, "mutation_prompt": null}
{"id": "3f033c23-4b5e-458a-a738-af9c697051c3", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor adjustment\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if np.random.rand() < 0.1 and self.dim < 32:  # New probabilistic layer recombination\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Introduce a probabilistic layer recombination strategy to improve exploration in the MAHO algorithm.", "configspace": "", "generation": 20, "fitness": 0.8080129090813893, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.027. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.8466822070236322, 0.7902441681176131, 0.7871123521029225], "final_y": [0.1307863267248025, 0.14819485515794473, 0.15253137897479874]}, "mutation_prompt": null}
{"id": "75a07013-c5f5-4ffe-a996-278f03be1045", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 3)  # Adjusted population size factor\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 3  # More gradual layer increment\n        self.robustness_factor = 0.05\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.5 + 0.5 * (self.evaluations / self.budget) * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.3 * np.random.rand()  # Increased crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        improved_local_search_prob = self.local_search_prob + 0.3 * (self.evaluations / self.budget)\n        if np.random.rand() < improved_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO algorithm with adaptive population size and layer increment for improved exploration-exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.7725025534337516, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.773 with standard deviation 0.022. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "c2c35b8c-f6bf-4a20-b1a1-df9a58d24b73", "metadata": {"aucs": [0.7873739729406345, 0.741858000158186, 0.7882756872024346], "final_y": [0.1349980438119167, 0.15558363114419627, 0.14508467721910023]}, "mutation_prompt": null}
