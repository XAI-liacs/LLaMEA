{"id": "a9e91274-0ed5-4159-bf1f-fe08f9157e57", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates):\n        a, b, c = candidates[np.random.choice(len(candidates), 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_refinement(self, candidate, func, bounds):\n        perturbation_strength = 0.05\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates)\n                trial = self.crossover(self.population[i], mutant)\n                trial = self.local_refinement(trial, func, bounds)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic combining Differential Evolution (DE) for global exploration and a local greedy search for refinement, which gradually increases problem dimensionality to efficiently allocate computational resources and maintain robustness to perturbations.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 46, in __call__\n  File \"<string>\", line 17, in mutate\nTypeError: only integer scalar arrays can be converted to a scalar index\n.", "error": "TypeError('only integer scalar arrays can be converted to a scalar index')Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 46, in __call__\n  File \"<string>\", line 17, in mutate\nTypeError: only integer scalar arrays can be converted to a scalar index\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "25a3c569-3874-4cd7-8b06-01fec151734e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates):  # Changed line\n        unique_candidates = np.random.choice(candidates, 3, replace=False)\n        a, b, c = self.population[unique_candidates]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_refinement(self, candidate, func, bounds):\n        perturbation_strength = 0.05\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates)\n                trial = self.crossover(self.population[i], mutant)\n                trial = self.local_refinement(trial, func, bounds)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "A modified hybrid metaheuristic that refines the mutation process by selecting unique candidates and utilizes an adaptive crossover probability to improve robustness.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'bounds' is not defined\").", "error": "NameError(\"name 'bounds' is not defined\")", "parent_id": "a9e91274-0ed5-4159-bf1f-fe08f9157e57", "metadata": {}, "mutation_prompt": null}
{"id": "36b3ee97-52af-4e3d-895f-ca5c9cb29fe5", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates):\n        a, b, c = candidates[np.random.choice(len(candidates), 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        # Enhanced: Use a weighted average of target and mutant for crossover\n        trial = (trial + target) / 2\n        return trial\n\n    def local_refinement(self, candidate, func, bounds):\n        perturbation_strength = 0.05\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates)\n                trial = self.crossover(self.population[i], mutant)\n                trial = self.local_refinement(trial, func, bounds)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced crossover method to improve candidate solutions in hybrid metaheuristic algorithm for optimizing multilayered photonic structures", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('only integer scalar arrays can be converted to a scalar index').", "error": "TypeError('only integer scalar arrays can be converted to a scalar index')", "parent_id": "a9e91274-0ed5-4159-bf1f-fe08f9157e57", "metadata": {}, "mutation_prompt": null}
{"id": "ef2d5a4d-346c-4050-9ae6-a442f60fb682", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "A novel hybrid metaheuristic combining Differential Evolution (DE) with adaptive local search that dynamically balances exploration and exploitation by adjusting mutation and crossover rates based on convergence trends, with progressive dimensionality increase and robustness checks. ", "configspace": "", "generation": 1, "fitness": 0.7689548190749266, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.019. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a9e91274-0ed5-4159-bf1f-fe08f9157e57", "metadata": {"aucs": [0.7512004582207262, 0.7945901820562783, 0.7610738169477751], "final_y": [0.16979333661861096, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "9623a4b1-8c6f-472f-811c-b8e6c0053b08", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = np.random.choice(candidates, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_refinement(self, candidate, func, bounds):\n        perturbation_strength = 0.05\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)  # Pass bounds to mutate\n                trial = self.crossover(self.population[i], mutant)\n                trial = self.local_refinement(trial, func, bounds)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "An optimized hybrid metaheuristic with a refined mutation strategy to improve solution diversity and robustness in high-dimensional noisy optimization problems.", "configspace": "", "generation": 1, "fitness": 0.7666347468393259, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.767 with standard deviation 0.021. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "a9e91274-0ed5-4159-bf1f-fe08f9157e57", "metadata": {"aucs": [0.744240241513924, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17456825053300673, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "5f52d6dc-2994-4298-a030-df90655dde52", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = np.random.choice(candidates, 3, replace=False)\n        mutant = self.population[a] + self.F * (self.population[b] - self.population[c])  # Fix mutation selection\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def local_refinement(self, candidate, func, bounds):\n        perturbation_strength = 0.05\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)  # Added bounds parameter\n                trial = self.crossover(self.population[i], mutant)\n                trial = self.local_refinement(trial, func, bounds)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "A robust hybrid metaheuristic using Differential Evolution with improved mutation selection and convergence handling, integrating local search for refinement.", "configspace": "", "generation": 1, "fitness": 0.7686321541141382, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.019. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "a9e91274-0ed5-4159-bf1f-fe08f9157e57", "metadata": {"aucs": [0.750232463338361, 0.7945901820562783, 0.7610738169477751], "final_y": [0.1752357927112017, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "c21741ab-cb05-4c74-8c4b-b62c1b11d855", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.adapt_factor = 0.1  # New adaptive factor\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        self.F = self.adapt_factor + np.random.rand() * (1 - self.adapt_factor)  # Dynamic mutation\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n                break\n        # Layer-wise refinement\n        for i in range(self.dim):\n            perturbation = np.zeros(self.dim)\n            perturbation[i] = perturbation_strength\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced evolutionary strategy integrating Differential Evolution with dynamic mutation rates and adaptive layer-wise refinement, promoting solution robustness and convergence speed.", "configspace": "", "generation": 2, "fitness": 0.7668004694466646, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.767 with standard deviation 0.021. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef2d5a4d-346c-4050-9ae6-a442f60fb682", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.763429189974257], "final_y": [0.17924064183162647, 0.1601017669387199, 0.16994503471183153]}, "mutation_prompt": null}
{"id": "6fb8f2d1-7bc2-46d3-89e1-5b2c6b5723a5", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        diversity = np.mean(np.std(self.population, axis=0))  # Change\n        perturbation_strength = max(0.05 * convergence_speed, 0.01) * diversity\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic that dynamically adjusts perturbation strength in local refinement based on population diversity to enhance exploitation capabilities.", "configspace": "", "generation": 2, "fitness": 0.7929113485273924, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.011. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "ef2d5a4d-346c-4050-9ae6-a442f60fb682", "metadata": {"aucs": [0.7964709344104117, 0.8037974311586034, 0.7784656800131622], "final_y": [0.1542376976201687, 0.1560641082426233, 0.16534550159554562]}, "mutation_prompt": null}
{"id": "ef06491e-085b-44d3-af35-869de5187333", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Refined hybrid metaheuristic using statistical noise reduction and adaptive crossover, enhancing exploratory search in black box optimization.", "configspace": "", "generation": 2, "fitness": 0.7932884431602875, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.010. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ef2d5a4d-346c-4050-9ae6-a442f60fb682", "metadata": {"aucs": [0.8047914220416277, 0.7945901820562783, 0.7804837253829562], "final_y": [0.15209378859051326, 0.1601017669387199, 0.1565672338409151]}, "mutation_prompt": null}
{"id": "3d5e96ac-28e0-4404-b1ac-9b97f7166038", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n        self.reinit_frequency = 0.1  # New feature: reinitialization frequency\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            if num_evaluations % int(self.budget * self.reinit_frequency) == 0:  # Reinitialize some individuals\n                num_reinit = self.pop_size // 10  # Reinitialize 10% of the population\n                reinit_indices = np.random.choice(self.pop_size, num_reinit, replace=False)\n                for idx in reinit_indices:\n                    self.population[idx] = self.initialize_population(bounds)[0]\n                    fitness[idx] = func(self.population[idx])\n                    num_evaluations += 1\n\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhancing exploration by increasing Differential Evolution's population diversity and adaptability through random re-initializations.", "configspace": "", "generation": 2, "fitness": 0.7700321836748444, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.770 with standard deviation 0.018. And the mean value of best solutions found was 0.164 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "ef2d5a4d-346c-4050-9ae6-a442f60fb682", "metadata": {"aucs": [0.750725879555134, 0.7945901820562783, 0.7647804894131207], "final_y": [0.1625046757947568, 0.1601017669387199, 0.16872176105188785]}, "mutation_prompt": null}
{"id": "5d205b08-4966-4b9a-be0f-a715a6c46f29", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        adaptive_F = self.F * np.random.uniform(0.8, 1.2)  # Adaptive mutation\n        mutant = a + adaptive_F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.normal(0, perturbation_strength, self.dim)  # Normal perturbation\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if func(trial) > func(candidate):\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n                \n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic with adaptive mutation and layered optimization, leveraging perturbation-based robustness and progressive layer increase for improved convergence.", "configspace": "", "generation": 2, "fitness": 0.7784362665905284, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.778 with standard deviation 0.020. And the mean value of best solutions found was 0.163 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef2d5a4d-346c-4050-9ae6-a442f60fb682", "metadata": {"aucs": [0.7500746686546612, 0.7945901820562783, 0.7906439490606456], "final_y": [0.17256950137456617, 0.1601017669387199, 0.1554038781899012]}, "mutation_prompt": null}
{"id": "aed6b912-96c9-4388-86ef-5f67d64cd7a2", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(7):  # small local search steps, increased from 5 to 7\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced local search by increasing iteration steps for better refinement.", "configspace": "", "generation": 3, "fitness": 0.7766959834981125, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.777 with standard deviation 0.020. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7494287067033523, 0.7945901820562783, 0.786069061734707], "final_y": [0.1753006403861338, 0.1601017669387199, 0.16145711389005235]}, "mutation_prompt": null}
{"id": "aa00df4c-2326-4ad0-9f0f-23fb68b6a302", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        fitness_variance = np.var([func(ind) for ind in self.population])  # Calculate variance of fitness\n        perturbation_strength = max(0.05 * convergence_speed * (1 + fitness_variance), 0.01)  # Dynamic scaling\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced adaptive local refinement by incorporating dynamic perturbation scaling based on fitness variance.", "configspace": "", "generation": 3, "fitness": 0.7687188620576272, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.021. And the mean value of best solutions found was 0.164 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.769184367807145], "final_y": [0.17924064183162647, 0.1601017669387199, 0.15379635044308093]}, "mutation_prompt": null}
{"id": "5e655a3b-3ca2-47b8-8bb7-f27c421ee65e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.normal(0, perturbation_strength, self.dim)  # Changed to normal distribution\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.median([func(trial) for _ in range(5)]) > func(candidate):  # Increased noise sample size\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / max(prev_best_fitness, 1e-6)  # Avoid division by zero\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive noise handling and dynamic local search for improved convergence.", "configspace": "", "generation": 3, "fitness": 0.769207951866195, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.021. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7706516372328482], "final_y": [0.17924064183162647, 0.1601017669387199, 0.1662876910968617]}, "mutation_prompt": null}
{"id": "f8c0cab1-2253-4eda-a905-4c8da1b72876", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(7):  # increased local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improve adaptive local refinement by increasing the number of local search steps for better noise tolerance.", "configspace": "", "generation": 3, "fitness": 0.7727294588324818, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.773 with standard deviation 0.031. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.8147325232402121, 0.7610738169477751], "final_y": [0.17924064183162647, 0.14520821530639672, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "fd709ad3-1859-4cf0-9791-b9205723e55b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            self.pop_size = min(max(5 * self.dim, int(self.pop_size * (1 + 0.1 * np.sign(convergence_speed)))), self.budget // 10)\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced exploration strategy through dynamic population size adjustment based on convergence speed.", "configspace": "", "generation": 3, "fitness": 0.7722296327762047, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.772 with standard deviation 0.019. And the mean value of best solutions found was 0.162 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7534695329170054, 0.7983533894217112, 0.7648659759898978], "final_y": [0.1716248503069575, 0.1560256603903608, 0.1585017310236152]}, "mutation_prompt": null}
{"id": "08204894-b766-42f5-bb2b-53740db18bfb", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(7):  # Modified from 5 to 7 small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhance local refinement by increasing perturbation attempts for better exploration.", "configspace": "", "generation": 4, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "0ebad2bd-56a5-4881-b7eb-c2cfaaa55126", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(7):  # small local search steps, increased iterations for noise reduction\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced the adaptive local refinement by increasing noise reduction iterations for better optimization in noisy environments.", "configspace": "", "generation": 4, "fitness": 0.7694372608224596, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.018. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.752647783463325, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17249293681791844, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "1c2df54f-166c-4290-b446-d202d3a60f26", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5 * dim, 20)  # Adjusted population size for better exploration\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        scale_factor = np.random.uniform(0.4, 0.8)  # Dynamic scaling factor for mutation\n        mutant = a + scale_factor * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with dynamic population size adjustment and improved mutation mechanism for better exploration and convergence in noisy environments.", "configspace": "", "generation": 4, "fitness": 0.7628248591102441, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.763 with standard deviation 0.025. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7328105783266791, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17780119682218087, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "633538d2-7e6b-4ac1-aa80-8afb0a74c118", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        diversity_factor = np.std(self.population) / self.dim  # Diversity calculation\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength * (1 + diversity_factor), perturbation_strength * (1 + diversity_factor), self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic by incorporating a diversity maintenance mechanism and improved local search adaptability for robust exploration.", "configspace": "", "generation": 4, "fitness": 0.7746875546351366, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.775 with standard deviation 0.019. And the mean value of best solutions found was 0.161 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7489913920920925, 0.7945901820562783, 0.7804810897570391], "final_y": [0.17016191292497995, 0.1601017669387199, 0.15325766775649385]}, "mutation_prompt": null}
{"id": "f98abca3-6cb1-4cd0-a33c-5dd629ab64e6", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5 * dim, 100)  # Dynamic Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic with dynamic population size adjustment for enhanced exploration and convergence.", "configspace": "", "generation": 4, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "bc53e934-475e-441e-a83c-cb937fc26b71", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            self.pop_size = max(4, int(self.pop_size * (1 + convergence_speed)))\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with dynamic population sizing based on convergence rates to improve adaptability.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'convergence_speed' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'convergence_speed' referenced before assignment\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "7c54b767-631e-4f6e-b952-72cd42122096", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed, eval_budget):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(min(5, eval_budget // 10)):  # Adjust local search steps dynamically\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed, self.budget - num_evaluations)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic utilizing adaptive population sizing and dynamic local refinement to boost high-dimensional black box optimization.", "configspace": "", "generation": 5, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "5a05b04d-a49c-4941-bea0-d6ba01e0daed", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def gradually_increase_dimensionality(self, current_dim):\n        return min(self.dim, current_dim + max(1, self.dim // 10))\n\n    def __call__(self, func):\n        bounds = func.bounds\n        current_dim = self.dim // 2\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = np.mean([func(trial) for _ in range(3)])  # Noise-resilient fitness evaluation\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n            current_dim = self.gradually_increase_dimensionality(current_dim)\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid optimization using adaptive layer-wise dimensionality increase and noise-resilient fitness evaluation.", "configspace": "", "generation": 5, "fitness": 0.7896863242647573, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.007. And the mean value of best solutions found was 0.155 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7952499188044653, 0.7945901820562783, 0.7792188719335283], "final_y": [0.15583636498013087, 0.1601017669387199, 0.14990468350799935]}, "mutation_prompt": null}
{"id": "2c06059a-0e6f-4651-b946-fe657bfc3c5d", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(5 * dim, 50)  # Adjusted population size for better balance\n        self.F = 0.6  # Increased differential weight for diversity\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.03 * convergence_speed, 0.01)  # Adjusted local search strength\n        for _ in range(7):  # Longer local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced refined hybrid metaheuristic with improved local refinement and dynamic population size adjustment for better exploration-exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.7662582563839625, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.043. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7057753312001642, 0.7945901820562783, 0.7984092558954449], "final_y": [0.1962493555245659, 0.1601017669387199, 0.1504681414031811]}, "mutation_prompt": null}
{"id": "edac7b71-e751-4e67-9683-75865be8f8b3", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        diversity = np.std(self.population) / (bounds.ub - bounds.lb)\n        self.F = 0.3 + 0.4 * (1 - diversity)  # Adjust F based on diversity\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Introduced variable differential weight F based on population diversity to enhance exploration-exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.7731473820208293, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.773 with standard deviation 0.016. And the mean value of best solutions found was 0.163 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7583766688241499, 0.7945901820562783, 0.7664752951820595], "final_y": [0.1599358328528131, 0.1601017669387199, 0.16988310902113224]}, "mutation_prompt": null}
{"id": "22233a6f-9fe8-4c9e-a212-25a55d40c66d", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.03 * convergence_speed, 0.005)  # Changed perturbation coefficients\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Refined hybrid metaheuristic with an enhanced adaptive local refinement strategy for improved precision in black box optimization.", "configspace": "", "generation": 6, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "f1b203f9-dc35-4608-b5e2-53a0ad214197", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + np.random.uniform(0.4, 0.6) * (b - c)  # Improved mutation strategy\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.02)  # Dynamic perturbation tuning\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with improved mutation strategy and dynamic perturbation tuning for superior exploration.", "configspace": "", "generation": 6, "fitness": 0.7731689733339602, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.773 with standard deviation 0.022. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7825347016361437], "final_y": [0.17924064183162647, 0.1601017669387199, 0.1586300117719177]}, "mutation_prompt": null}
{"id": "1aaed82b-e8fe-4fdf-8522-18d9c85f5e4b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        dynamic_perturbation = perturbation_strength * (1 + convergence_speed)  # Dynamic neighborhood size\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-dynamic_perturbation, dynamic_perturbation, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced local refinement by incorporating a dynamic neighborhood size based on convergence speed, improving local search adaptability.", "configspace": "", "generation": 6, "fitness": 0.7669080601794538, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.767 with standard deviation 0.023. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7972683272811281, 0.7610738169477751], "final_y": [0.17924064183162647, 0.15684437429242626, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "2d72cdc3-9eb7-4a3c-a39f-e2a9eebb8eaf", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 5 * dim  # Reduced initial population size for better focus\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(5)]) > func(candidate):  # Increased noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with dynamic population resizing and noise-aware evaluation for improved exploration and convergence.", "configspace": "", "generation": 6, "fitness": 0.7625411567415806, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.763 with standard deviation 0.026. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.731959471220688, 0.7945901820562783, 0.7610738169477751], "final_y": [0.1812292654023231, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "6586818e-b045-4474-92a1-f1a60953668e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n                # Adjust population size adaptively based on convergence speed\n                self.pop_size = min(int(10 * self.dim * (1 - convergence_speed)), self.budget - num_evaluations)\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic utilizing adaptive population size adjustment for improved exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "2879cfb2-477f-4529-b558-9aea3095b3de", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(np.random.randint(3, 7)):  # Adjust search steps probabilistically\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(np.random.randint(2, 4))]) > func(candidate):  # Adaptive evaluation strategy\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced exploration with probabilistic perturbation and adaptive evaluation strategy for improved local search.", "configspace": "", "generation": 7, "fitness": 0.7670295559246156, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.767 with standard deviation 0.021. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.744189272763133, 0.7945901820562783, 0.7623092129544353], "final_y": [0.17627002658491686, 0.1601017669387199, 0.16922029897918167]}, "mutation_prompt": null}
{"id": "b7ba897d-d2e3-46d9-87b7-1e7a81969de6", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.03 * convergence_speed, 0.005)  # Modified perturbation strength\n        for _ in range(7):  # Increased local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            self.pop_size = max(5, self.pop_size - 1)  # Dynamic population reduction\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic with dynamic population adjustments and enhanced local refinement for better convergence in black box optimization.", "configspace": "", "generation": 7, "fitness": 0.7661228588658467, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.021. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7427045775934872, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17795275741016003, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "135067ff-1343-4e67-bec0-92190af6e12c", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = max(10 * dim, 50)  # Dynamic population size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                # Layer-by-layer optimization\n                for layer in range(self.dim):\n                    trial[layer] += np.random.normal(0, 0.01)\n                trial = np.clip(trial, bounds.lb, bounds.ub)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic that introduces a dynamic population size adjustment and layer-by-layer optimization for improved convergence in complex black box optimization tasks.", "configspace": "", "generation": 7, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "b4b5a315-80d2-46e4-8aeb-fd3f9e491524", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.03 * convergence_speed, 0.01)  # Reduced perturbation scale\n        for _ in range(7):  # Increased local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced adaptive refinement through dynamic perturbation scaling and improved noise handling to optimize photovoltaic structures.", "configspace": "", "generation": 7, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "22a1a06e-1846-406e-a6c5-cedfc093425b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.median([func(trial) for _ in range(5)]) > func(candidate):  # Improved noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improved local refinement step by enhancing noise reduction strategy for more robust convergence.", "configspace": "", "generation": 7, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "0abbf117-a88b-47d2-9385-4d1b4d6b5042", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        # Change 1: Adaptive scaling for mutation\n        adaptive_F = self.F * np.random.uniform(0.5, 1.5)  \n        mutant = a + adaptive_F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        # Change 2: Dynamic crossover probability\n        self.CR = 0.9 * (1 - num_evaluations / self.budget) + 0.1\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic using adaptive scaling for mutation and dynamic crossover for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'num_evaluations' is not defined\").", "error": "NameError(\"name 'num_evaluations' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "a75e1eae-54c4-4c77-a106-d74ae3b7ba27", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + np.random.uniform(0.5, self.F) * (b - c)  # Adaptive F\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(5)]) > func(candidate):  # Noise tolerance increase\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic incorporating adaptive mutation strategies and noise-tolerant local search for enhanced solution accuracy in black box optimization.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'num_evaluations' is not defined\").", "error": "NameError(\"name 'num_evaluations' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "169ac9ec-63a9-4ffa-bc39-0cee1d9d0b9c", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        candidate += np.random.uniform(-0.01, 0.01, self.dim) # Minor random exploration\n        return np.clip(candidate, bounds.lb, bounds.ub)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic integrates neighborhood exploration with adaptive refinements for accelerated convergence.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'num_evaluations' is not defined\").", "error": "NameError(\"name 'num_evaluations' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "18d90e52-02f8-4115-b542-11e432d74c38", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        perturbation_strength *= (1 + np.std([func(candidate + np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)) for _ in range(5)]))  # Added stochastic perturbation based on fitness variance\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced the adaptive local refinement strategy to introduce stochastic perturbation based on fitness variance to improve robustness against noisy evaluations.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'num_evaluations' is not defined\").", "error": "NameError(\"name 'num_evaluations' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "752b1c90-8090-409b-8617-5aa3678fbecd", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        convergence_speed = 1  # Placeholder to use later\n        adaptive_F = self.F + convergence_speed * 0.1  # Adaptive mutation scaling\n        mutant = a + adaptive_F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive mutation scaling based on convergence speed for improved exploration.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'num_evaluations' is not defined\").", "error": "NameError(\"name 'num_evaluations' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "4ac9d383-55f9-44ad-b0ff-231d79872095", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.02 * convergence_speed, 0.005)  # Reduced perturbation strength\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.median([func(trial) for _ in range(3)]) > func(candidate):  # Median-based noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with improved adaptive local refinement for robust optimization in black box scenarios.", "configspace": "", "generation": 9, "fitness": 0.7712001083682324, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.771 with standard deviation 0.022. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7766281067389607], "final_y": [0.17924064183162647, 0.1601017669387199, 0.16453648713069857]}, "mutation_prompt": null}
{"id": "48ff1f31-8dc8-4df9-9823-7639e053f57c", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                \n                # Change 1: Dynamically adjust the population size based on convergence speed\n                self.pop_size = max(5, int(self.pop_size * (1 + convergence_speed)))\n                \n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic by introducing dynamic population size based on convergence analysis to balance exploration and exploitation.", "configspace": "", "generation": 9, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "d8870e01-b6aa-457f-ada6-6211eb5a1dec", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * (1 - convergence_speed), 0.01)  # Changed line\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced adaptive local refinement with a dynamic perturbation strength tied to convergence.", "configspace": "", "generation": 9, "fitness": 0.7713171778343609, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.771 with standard deviation 0.017. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7581514189479502, 0.7945901820562783, 0.7612099324988546], "final_y": [0.16097793924187098, 0.1601017669387199, 0.1725772526092867]}, "mutation_prompt": null}
{"id": "a6e10e49-4e58-456f-8503-d25a051acfbb", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        layer_factor = np.random.normal(1, 0.05, self.dim)  # layer-specific mutation\n        mutant *= layer_factor\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(5)]) > func(candidate):  # Increase noise tolerance in evaluation\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhance exploration and local refinement by introducing layer-specific mutation and noise-tolerant fitness evaluation.", "configspace": "", "generation": 9, "fitness": 0.7705961997693409, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.771 with standard deviation 0.017. And the mean value of best solutions found was 0.164 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7561246003039692, 0.7945901820562783, 0.7610738169477751], "final_y": [0.15856349083431875, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "d297b455-7493-4dcb-b094-2efb2b5cc2f0", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR, 0.5, 1)  # Adjusted fixed CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.1 * convergence_speed, 0.01)  # Increased multiplier\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic leveraging dynamic perturbation strength and improved adaptive crossover to better explore and exploit the search space.", "configspace": "", "generation": 9, "fitness": 0.7705702389061421, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.771 with standard deviation 0.017. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7548656131745974, 0.7945901820562783, 0.7622549214875503], "final_y": [0.16873706415044465, 0.1601017669387199, 0.14989625336679857]}, "mutation_prompt": null}
{"id": "2ff009c5-8d87-418e-b7a3-1ecedc18fd96", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Initial population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n    \n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        # Layered mutation strategy\n        layered_mutation_strength = np.random.normal(0, 0.05, self.dim)\n        mutant += layered_mutation_strength * (bounds.ub - bounds.lb)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            if num_evaluations % 100 == 0:  # Adaptive population size\n                self.pop_size = min(self.pop_size + 1, 20 * self.dim)\n\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with a layered mutation strategy and adaptive population size for improved exploration in noisy black-box optimization.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 100 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 100 is out of bounds for axis 0 with size 100')", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "8e48b046-816d-4d94-b83e-814d94ab2761", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(5)]) > func(candidate):  # More trials for noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced noise reduction by averaging more trials for improved candidate selection.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 100 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 100 is out of bounds for axis 0 with size 100')", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "eb80ec7f-ba98-4eb3-a993-e355dd71b75b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n            self.pop_size = max(2, int(10 * self.dim * (1 - convergence_speed)))  # Adjust population size dynamically\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with dynamic population size adjustment based on convergence speed for improved exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 100 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 100 is out of bounds for axis 0 with size 100')", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "0992f0cf-28da-403a-8f45-4a6ced9a0b89", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(7):  # Increased local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced adaptive local refinement step with increased trials for better exploitation.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 100 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 100 is out of bounds for axis 0 with size 100')", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "6b1d3889-037b-405d-9790-0eaba0aa7f21", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.median([func(trial) for _ in range(3)]) > func(candidate):  # Median filtering\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic by improving noise reduction in trial evaluation using median filtering for robust exploration.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 100 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 100 is out of bounds for axis 0 with size 100')", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "50f9e220-2a83-46a2-9232-f8e9f326c373", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        current_best_fitness = np.max([func(ind) for ind in self.population])\n        prev_best_fitness = np.max([func(ind) for ind in self.population])  # Assume previous best fitness is known\n        convergence_speed = (current_best_fitness - prev_best_fitness) / (prev_best_fitness + np.finfo(float).eps)\n        adaptive_F = self.F * (1 + convergence_speed)  # Adaptive F based on convergence speed\n        mutant = a + adaptive_F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic by including an adaptive mutation scale based on convergence speed to improve exploration.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "e974d90e-d596-4015-8c61-9ddbc41da318", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def modular_detection(self, candidate):\n        # Placeholder for modular detection logic\n        return candidate  # Modify candidate based on detected modular structures\n\n    def robustness_check(self, candidate, func, bounds):\n        perturbations = np.random.uniform(-0.01, 0.01, self.dim)  # Small perturbations\n        perturbed_candidate = np.clip(candidate + perturbations, bounds.lb, bounds.ub)\n        return np.mean([func(perturbed_candidate) for _ in range(5)])  # Average over perturbations\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                trial = self.modular_detection(trial)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = self.robustness_check(trial, func, bounds)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid algorithm incorporating modular detection and robustness checking to optimize absorption while reducing noise impact.", "configspace": "", "generation": 11, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "13127be8-7f80-4953-9089-aaa6a4d8464e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.8  # Differential weight (changed from 0.5 to improve mutation diversity)\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.1 * convergence_speed, 0.01)  # Adjusted perturbation strength (changed from 0.05)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improved hybrid metaheuristic by enhancing mutation diversity and refining local search perturbation strength for better exploration and exploitation.", "configspace": "", "generation": 11, "fitness": 0.7773210694026478, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.777 with standard deviation 0.012. And the mean value of best solutions found was 0.164 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7714069974367965, 0.7945901820562783, 0.7659660287148686], "final_y": [0.1614044703054528, 0.1601017669387199, 0.1698498032618746]}, "mutation_prompt": null}
{"id": "f5c869bd-e705-4b53-a068-ad60683e83c8", "solution": "import numpy as np\nfrom scipy.stats.qmc import Sobol\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        sampler = Sobol(d=self.dim, scramble=True)\n        return lb + (ub - lb) * sampler.random_base2(m=int(np.ceil(np.log2(self.pop_size))))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improved population initialization with quasi-random Sobol sequence to enhance diversity and convergence.", "configspace": "", "generation": 11, "fitness": 0.7841729081727111, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.784 with standard deviation 0.008. And the mean value of best solutions found was 0.162 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7828360387702262, 0.7945901820562783, 0.7750925036916287], "final_y": [0.16171341432472341, 0.1601017669387199, 0.16495683385652526]}, "mutation_prompt": null}
{"id": "9b636215-7d9e-4a5b-8222-a3db5b5b16e6", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n            self.pop_size = max(5, int(self.pop_size * (1 + 0.1 * convergence_speed)))  # Dynamic population size adjustment\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Incorporate dynamic population size adjustment based on convergence speed to balance exploration and exploitation.", "configspace": "", "generation": 11, "fitness": 0.7699116175647432, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.770 with standard deviation 0.021. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7727626343284932], "final_y": [0.17924064183162647, 0.1601017669387199, 0.1670151164847158]}, "mutation_prompt": null}
{"id": "21f5b8db-57b3-4d14-a2f5-bfe5bb99a5fc", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n                self.CR = max(0.6, self.CR - 0.01)  # Incremental adjustment of CR\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Incrementally adjust the crossover probability to improve the exploration-exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.7686842743724922, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.019. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7503888241134236, 0.7945901820562783, 0.7610738169477751], "final_y": [0.1690823373822976, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "3f4b6b83-0dcb-4690-bb75-a8abbcc7581e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.normal((lb + ub) / 2, (ub - lb) / 6, (self.pop_size, self.dim))  # Changed line: Normal distribution instead of uniform\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.05), 0, 1)  # Changed line: Reduced noise variance in CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with improved population initialization and crossover dynamics to boost exploration efficiency in black box optimization.", "configspace": "", "generation": 12, "fitness": 0.7673766131205931, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.767 with standard deviation 0.020. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7464658403577261, 0.7945901820562783, 0.7610738169477751], "final_y": [0.1715380781994208, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "76e3f889-f5e2-488e-9e01-71bb78e5a82d", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n            # Dynamically adjust population size based on convergence speed\n            self.pop_size = max(10, int(10 * self.dim * (1 - convergence_speed)))\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improved HybridMetaheuristic with dynamic population size based on convergence speed to enhance exploration and exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "3bc61eef-f845-4c78-9b84-b344a0c4aaef", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c) + (self.population[idx] - a) * 0.1  # Directional bias\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced mutation strategy with directional bias to improve exploration and convergence in hybrid metaheuristic optimization.", "configspace": "", "generation": 12, "fitness": 0.7676253151549828, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.768 with standard deviation 0.022. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7445256824401498, 0.7972764460770235, 0.7610738169477751], "final_y": [0.17577751836333266, 0.158093477859641, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "6665b19e-e04f-4fd4-a4c3-039add1f66de", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n            # Adjust population size based on convergence\n            if convergence_speed < 0.01:  # Example threshold, adjust as needed\n                self.pop_size = max(self.pop_size // 2, 4)  # Prevent population from being too small\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improved robustness by incorporating a dynamic population size adjustment during the optimization process.", "configspace": "", "generation": 12, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "de630817-3e9a-4012-919e-201606dce985", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        elite = self.population[np.argmax([func(ind) for ind in self.population])]  # Elite candidate preservation\n        trial = np.where(cross_points, mutant, elite)\n        return np.clip(trial, target, mutant)  # Ensures new trial is between elite and mutant\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced crossover using elite candidate preservation to boost solution quality in hybrid metaheuristics.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "825f3ebb-6024-42f9-9531-d0330c31cdc1", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.03 * convergence_speed, 0.005)  # Reduced perturbation\n        for _ in range(7):  # Increased local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced adaptive local refinement and crossover strategy to improve convergence in black box optimization.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "b016e79a-75c9-4f2a-a807-636e4cc33c58", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            avg_trial_fitness = np.mean([func(trial) for _ in range(5)])  # Increased noise reduction\n            if avg_trial_fitness > func(candidate):\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            self.pop_size = max(5, int(0.9 * self.pop_size))  # Dynamic population size adjustment\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic using dynamic population size adjustment and improved noise reduction for better convergence in noisy optimization environments.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "cef182f7-f992-4208-b9eb-c4a055282d05", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(int(5 * (1 - convergence_speed))):  # Adaptive local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic by adjusting local refinement step frequency based on convergence dynamics for improved search efficiency.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "a05299b8-576b-48a0-83d1-f2989bbc5698", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            self.pop_size = int(self.pop_size * 0.9)  # Reduce population size dynamically\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with dynamic population size to improve convergence speed.", "configspace": "", "generation": 13, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "f07fef16-02e4-40f1-b0ee-8bb3e9a55181", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        # Change: Adaptive mutation factor based on the difference between individuals\n        adaptive_F = self.F * np.mean(np.abs(b - c)) / np.std(b - c)\n        mutant = a + adaptive_F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive mutation scaling for improved exploration and convergence in black box optimization.", "configspace": "", "generation": 14, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "a5f1f59e-daa9-4ec1-9471-1268172d34cd", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        adaptive_F = np.clip(np.random.normal(self.F, 0.1), 0, 1)  # Dynamic F adjustment\n        mutant = a + adaptive_F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic by increasing mutation adaptability through dynamic F value adjustment.", "configspace": "", "generation": 14, "fitness": 0.7694359509510759, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.026. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.8048519995959944, 0.7610738169477751], "final_y": [0.17924064183162647, 0.15530024229239092, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "8a117e9d-7351-4b32-a548-b713e88b448f", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.03 * convergence_speed, 0.01)  # Changed from 0.05 to 0.03\n        for _ in range(5): \n            perturbation = np.random.normal(0, perturbation_strength, self.dim)  # Changed perturbation type\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            dynamic_pop_size = min(self.pop_size, self.budget - num_evaluations)  # Dynamic population size\n            for i in range(dynamic_pop_size):  # Adjusted for dynamic size\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with dynamic population adaptation and improved perturbation strategy for robust exploration.", "configspace": "", "generation": 14, "fitness": 0.7678643667346611, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.768 with standard deviation 0.020. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7479291011999301, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17639459812457714, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "76199643-a210-46c8-bea4-75199b76f6e6", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.15), 0, 1)  # Fine-tuned adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with fine-tuned adaptive crossover for improved convergence in black box optimization.", "configspace": "", "generation": 14, "fitness": 0.7733466935302086, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.773 with standard deviation 0.022. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7830678622248892], "final_y": [0.17924064183162647, 0.1601017669387199, 0.15510504983404594]}, "mutation_prompt": null}
{"id": "e7688037-5f0a-4db6-87eb-f6c3671d07eb", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        adapt_F = np.clip(self.F + np.random.normal(0, 0.1), 0.1, 0.9)  # Adaptive mutation factor\n        mutant = a + adapt_F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic using adaptive mutation scaling and layer-preserving crossover to boost black-box optimization performance.", "configspace": "", "generation": 14, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "820a9c78-1e19-4d26-a1d2-ed776eb81d09", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.2), 0, 1)  # Modified to improve exploration\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(7):  # Increased steps for more thorough local search\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with improved crossover strategy and increased perturbation steps for optimized exploration and exploitation balance.", "configspace": "", "generation": 15, "fitness": 0.7764024859730156, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.776 with standard deviation 0.019. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7499523895167537, 0.7945901820562783, 0.7846648863460153], "final_y": [0.17446867565592816, 0.1601017669387199, 0.16182483784598767]}, "mutation_prompt": null}
{"id": "5af6affc-f886-4184-b75c-ac15499fc0be", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        dynamic_F = self.F * (0.5 + np.random.rand())  # Dynamic mutation scaling\n        mutant = a + dynamic_F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        perturbed_candidates = [np.clip(candidate + np.random.uniform(-perturbation_strength, perturbation_strength, self.dim), bounds.lb, bounds.ub) for _ in range(5)]\n        trial = max(perturbed_candidates, key=lambda x: np.mean([func(x) for _ in range(3)]))  # Noise-aware refinement\n        return trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with dynamic mutation scaling and noise-aware local refinement to improve exploration and convergence in noisy optimization problems.", "configspace": "", "generation": 15, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "b51d9a2a-5e15-4eda-bce8-2f776824b083", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        F_adaptive = np.clip(self.F + np.random.normal(0, 0.1), 0.4, 0.6)  # Adaptive mutation strategy\n        mutant = a + F_adaptive * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with an adaptive mutation strategy to improve diversity and exploration in the search space.", "configspace": "", "generation": 15, "fitness": 0.7678991592574986, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.768 with standard deviation 0.020. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7480334787684425, 0.7945901820562783, 0.7610738169477751], "final_y": [0.1717057295107942, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "39e1314b-b500-4f04-a808-b5b4f109cf85", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.85  # Crossover probability (changed from 0.9 to 0.85)\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.02)  # Increased minimum perturbation (changed from 0.01 to 0.02)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Slightly adjusted the crossover probability and local refinement to enhance exploration-exploitation balance in black box optimization.", "configspace": "", "generation": 15, "fitness": 0.7661702593763554, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.021. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7428467791250133, 0.7945901820562783, 0.7610738169477751], "final_y": [0.1786790390865003, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "968bacc4-a0d0-430a-8077-aaaff613967a", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            self.pop_size = max(5, int(self.pop_size * 0.95))  # Adaptive population size\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic using adaptive population size and feedback-driven mutation for improved convergence.", "configspace": "", "generation": 15, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "175c9fd0-260c-4e49-a690-07a13bb56420", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            self.pop_size = max(int(5 * self.dim * (self.budget - num_evaluations) / self.budget), 5)  # Dynamic population size\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with dynamic population size adjustment and improved adaptive strategies for black box optimization.", "configspace": "", "generation": 16, "fitness": 0.7664734931976699, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7624482612272732], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17212003076803828]}, "mutation_prompt": null}
{"id": "db7bf50d-2314-42b0-b2c9-79397358ecac", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip((self.CR + np.random.normal(0, 0.1)) * (1 - np.exp(-0.01 * self.pop_size)), 0, 1)  # Enhanced adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced adaptive crossover with noise resilience and convergence speed adjustments, boosting search efficiency.", "configspace": "", "generation": 16, "fitness": 0.7741591435045713, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.774 with standard deviation 0.031. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.8157615081191673, 0.764333886085088], "final_y": [0.17924064183162647, 0.12775578290103873, 0.16885225510708468]}, "mutation_prompt": null}
{"id": "afe84d84-9cc4-4366-a2ac-1dc8916a70cc", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(5)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced statistical noise reduction by averaging five evaluations instead of three for adaptive local refinement.", "configspace": "", "generation": 16, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "0953f77f-b524-406e-988a-ea06d7a94e51", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(7):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced local refinement strategy by increasing the number of local search steps for improved solution precision.", "configspace": "", "generation": 16, "fitness": 0.7685652910374973, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.022. And the mean value of best solutions found was 0.163 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.746024916374268, 0.7985971397904488, 0.7610738169477751], "final_y": [0.16118453565784152, 0.15396339906982315, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "659dbd48-9e2e-43bd-b32e-b4d20e05204f", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        self.F = np.clip(self.F + np.random.normal(0, 0.05), 0.1, 0.9)  # Dynamic adjustment of F\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced adaptive crossover by incorporating dynamic adjustment of Differential weight (F) to improve exploration and exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.7677014087395914, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.768 with standard deviation 0.020. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.746901432523887, 0.7945901820562783, 0.7616126116386092], "final_y": [0.1767935114763417, 0.1601017669387199, 0.17217100011251518]}, "mutation_prompt": null}
{"id": "ce85d88f-1458-43a8-802e-0aa9db0bcde5", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(5)]) > np.mean([func(candidate) for _ in range(5)]):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Improved adaptive local refinement with enhanced exploration in noisy environments.", "configspace": "", "generation": 17, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "0ff61bb5-aa93-45db-bd09-575ce9ea2294", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim  # Initial population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.initial_pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.initial_pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            current_pop_size = min(self.initial_pop_size, self.budget - num_evaluations)  # Dynamic adjustment\n            for i in range(current_pop_size):\n                candidates = [idx for idx in range(current_pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic by incorporating dynamic population size adjustment for improved exploration and exploitation balance.", "configspace": "", "generation": 17, "fitness": 0.7768413288632908, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.777 with standard deviation 0.017. And the mean value of best solutions found was 0.164 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7542514333712558, 0.7945901820562783, 0.781682371162338], "final_y": [0.16995898013099886, 0.1601017669387199, 0.1615104719710101]}, "mutation_prompt": null}
{"id": "1ccef2c8-83db-405f-8882-51121c644e70", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.reinit_interval = int(budget * 0.1)  # Reinitialize every 10% of the budget\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            if num_evaluations % self.reinit_interval == 0:  # Reinitialize part of the population\n                worst_indices = np.argsort(fitness)[:self.pop_size // 2]\n                self.population[worst_indices] = self.initialize_population(bounds)[worst_indices]\n                fitness[worst_indices] = [func(ind) for ind in self.population[worst_indices]]\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic incorporating periodic reinitialization and diversity-based selection to improve exploration in noisy black box optimization.", "configspace": "", "generation": 17, "fitness": 0.7748307907685787, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.775 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7688283733016829, 0.7945901820562783, 0.7610738169477751], "final_y": [0.16154286450695587, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "0db3b7ee-4071-4060-806a-392226843ab3", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        # Modify differential weight F adaptively based on current fitness\n        self.F = 0.5 + 0.3 * (np.max(self.population) - np.min(self.population)) / (np.max(self.population) + 1e-9)\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced differential weight adaptation in the hybrid metaheuristic for improved exploration-exploitation balance.", "configspace": "", "generation": 17, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "21805dac-8a68-4542-9a22-74472d40f80b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength * 0.5, perturbation_strength * 0.5, self.dim)  # Modified perturbation range\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced adaptive local refinement by modifying perturbation to better handle noisy evaluations.", "configspace": "", "generation": 17, "fitness": 0.7684638816553567, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.768 with standard deviation 0.019. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.749727645962017, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17350432898984558, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "af9f99e7-b9c5-4584-828b-f345c6433d3a", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = min(20 * dim, 100)  # Increased initial population size cap\n        self.F = 0.6  # Adjusted differential weight\n        self.CR = 0.8  # Adjusted crossover probability\n        self.population = None\n        self.layerwise_evolution = True  # New strategy flag\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.03 * convergence_speed, 0.005)  # Adjusted\n        for _ in range(5):\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(2)]) > func(candidate):  # Reduced evaluations\n                candidate = trial\n                break\n        return candidate\n\n    def layer_wise_optimization(self, func, bounds):\n        evol_dim = int(self.dim * 0.1)  # Optimize 10% of layers\n        indices = np.random.choice(self.dim, evol_dim, replace=False)\n        for idx in indices:\n            candidates = [i for i in range(self.pop_size)]\n            mutant = self.mutate(idx, candidates, bounds)\n            trial = self.crossover(self.population[idx], mutant)\n            if func(trial) > func(self.population[idx]):\n                self.population[idx] = trial\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            if self.layerwise_evolution:\n                self.layer_wise_optimization(func, bounds)\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with layer-wise evolutionary strategy and dynamic population size adjustments for improved exploration and exploitation.", "configspace": "", "generation": 18, "fitness": 0.768203293868139, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.768 with standard deviation 0.019. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7489458826003634, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17574775771727336, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "f22912eb-ceb1-4e5f-9657-3d35062ddd48", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.median([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with improved noise reduction using median-based fitness evaluation.", "configspace": "", "generation": 18, "fitness": 0.7782116479438264, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.778 with standard deviation 0.014. And the mean value of best solutions found was 0.163 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7789709448274257, 0.7945901820562783, 0.7610738169477751], "final_y": [0.15694841504071722, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "e62fadce-ccc1-4b09-ac39-f7b077e8c23b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01 * (1 - convergence_speed))\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Introduce a dynamic adaptation for the perturbation strength in local refinement to better explore solution space.", "configspace": "", "generation": 18, "fitness": 0.7855468705235813, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.786 with standard deviation 0.018. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.8009766125666903, 0.7945901820562783, 0.7610738169477751], "final_y": [0.14448904841122268, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "c6a4ea18-5086-40e4-9591-513419ff87c4", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 5 * dim  # Adjusted Population size for better exploration-exploitation balance\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with improved population size strategy for adaptable exploration-exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.769529092586153, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.770 with standard deviation 0.019. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7482115998392692, 0.7945901820562783, 0.7657854958629117], "final_y": [0.16880939065409506, 0.1601017669387199, 0.16937220682644416]}, "mutation_prompt": null}
{"id": "aaa45926-8262-4a7c-9196-f1a690100a12", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_pop_size = 10 * dim  # Initial population size for DE\n        self.pop_size = self.initial_pop_size\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(5)]) > func(candidate):  # Enhanced noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            if num_evaluations > self.budget / 2:\n                self.pop_size = self.initial_pop_size // 2  # Dynamic population size adjustment\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic incorporating dynamic population size adjustment and improved noise reduction to optimize exploratory search.", "configspace": "", "generation": 18, "fitness": 0.7660153451045039, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.022. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "8670618a-66c5-4d8f-96c3-73eda1e19c09", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n        self.layer_growth_rate = 0.1  # New parameter for adaptive layer growth\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):\n                candidate = trial\n                break\n        return candidate\n\n    def detect_modular_structure(self, candidate):\n        \"\"\"Detect modular structures in candidate solutions.\"\"\"\n        # Placeholder for modular structure detection logic\n        return candidate\n\n    def adapt_layer_growth(self, num_evaluations):\n        if num_evaluations / self.budget > self.layer_growth_rate:\n            self.dim = min(self.dim + 1, func.bounds.ub.shape[0])\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                trial = self.detect_modular_structure(trial)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            self.adapt_layer_growth(num_evaluations)\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Novel hybrid metaheuristic that leverages layer-wise modular detection and adaptive layer growth to enhance optimization of high-dimensional noisy black-box problems.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "f61244da-f982-481c-bbc3-8a8d71cd8c11", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.median([func(trial) for _ in range(5)]) > func(candidate):  # Enhanced noise reduction\n                candidate = np.mean([candidate, trial], axis=0)  # Improved refinement\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced adaptive noise reduction and local refinement strategy for improved optimization.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "51d0a90b-71af-4678-96fe-10099902ecbf", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.08 * convergence_speed, 0.02)  # More robust perturbation\n        for _ in range(7):  # Enhanced local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.median([func(trial) for _ in range(5)]) > func(candidate):  # Targeted noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with targeted noise-resistant local refinement and adaptive perturbation.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "5607ba06-a746-4d53-9c5b-77ce65d1f0f3", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        mutant = np.clip(mutant, bounds.lb, bounds.ub)\n        mutation_strength = np.random.uniform(0.4, 0.6)  # Adaptive mutation strength\n        return a + mutation_strength * (b - c)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive mutation rates for improved exploration and convergence in noisy optimization problems.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'func' is not defined\").", "error": "NameError(\"name 'func' is not defined\")", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {}, "mutation_prompt": null}
{"id": "7f372864-3538-4f82-a1b9-976fff39b1bf", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 15 * dim  # Population size for DE (changed from 10 to 15)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(3):  # small local search steps (changed from 5 to 3)\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced exploration and exploitation by fine-tuning population size and local search steps for improved performance in noisy optimization problems.", "configspace": "", "generation": 19, "fitness": 0.7762068600523767, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.776 with standard deviation 0.014. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7729565811530771, 0.7945901820562783, 0.7610738169477751], "final_y": [0.16524602120879872, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "0fa4cdc9-fa0f-4224-b128-b8c6fd8084c6", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + np.random.uniform(0.4, 0.6) * (b - c)  # Dynamic F\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(7):  # Increased local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with dynamic parameter tuning and local search diversification for improved solution quality.", "configspace": "", "generation": 20, "fitness": 0.7665450636019759, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.767 with standard deviation 0.021. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7626629724401913], "final_y": [0.17924064183162647, 0.1601017669387199, 0.17199307065096847]}, "mutation_prompt": null}
{"id": "c11b997c-3ccd-4841-9c05-7f8efe7dd200", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        noise_level = np.std([func(candidate) for _ in range(5)])  # Estimate noise level\n        perturbation_strength *= (1 + noise_level)  # Dynamic adjustment\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced adaptive local refinement with dynamic perturbation strength based on noise level and convergence speed.", "configspace": "", "generation": 20, "fitness": 0.7674701383840361, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.767 with standard deviation 0.021. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7423820363094582, 0.7945901820562783, 0.7654381967863715], "final_y": [0.17924064183162647, 0.1601017669387199, 0.16967850162146159]}, "mutation_prompt": null}
{"id": "5637c5b1-dd38-4b56-8f9c-4f3436565962", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def dynamic_population(self, current_fitness, initial_pop):\n        sorted_indices = np.argsort(current_fitness)[::-1]\n        top_half = sorted_indices[:len(sorted_indices) // 2]\n        bottom_half = sorted_indices[len(sorted_indices) // 2:]\n        self.population[bottom_half] = initial_pop[bottom_half]\n    \n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        initial_pop = self.initialize_population(bounds)\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            self.dynamic_population(fitness, initial_pop)\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic combining dynamic population control and stochastic ranking for improved balance of exploration and exploitation in noisy black box optimization.", "configspace": "", "generation": 20, "fitness": 0.7667840259827434, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.767 with standard deviation 0.021. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.744688078944177, 0.7945901820562783, 0.7610738169477751], "final_y": [0.17701513391873813, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "2275258f-7885-45ed-b2f6-5f9f83ecabd8", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = int(10 * dim * np.clip(budget / 1000, 0.5, 2.0))  # Adaptive population scaling based on budget\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        for _ in range(5):  # small local search steps\n            perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)\n            trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n            if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                candidate = trial\n                break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced hybrid metaheuristic with adaptive population scaling for improved exploitation and exploration.", "configspace": "", "generation": 20, "fitness": 0.7789347015727289, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.779 with standard deviation 0.014. And the mean value of best solutions found was 0.163 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7811401057141332, 0.7945901820562783, 0.7610738169477751], "final_y": [0.1559788209999986, 0.1601017669387199, 0.17296403364081692]}, "mutation_prompt": null}
{"id": "10057d45-5d10-413c-a6fd-fb934bc487d7", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.pop_size = 10 * dim  # Population size for DE\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.population = None\n\n    def initialize_population(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        return np.random.uniform(lb, ub, (self.pop_size, self.dim))\n\n    def mutate(self, idx, candidates, bounds):\n        a, b, c = self.population[np.random.choice(candidates, 3, replace=False)]\n        mutant = a + self.F * (b - c)\n        return np.clip(mutant, bounds.lb, bounds.ub)\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < np.clip(self.CR + np.random.normal(0, 0.1), 0, 1)  # Adaptive CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def adaptive_local_refinement(self, candidate, func, bounds, convergence_speed):\n        perturbation_strength = max(0.05 * convergence_speed, 0.01)\n        perturbation_probability = np.clip(0.1 * (1 - convergence_speed), 0.01, 0.2)  # Added line\n        for _ in range(5):  # small local search steps\n            if np.random.rand() < perturbation_probability:  # Added line\n                perturbation = np.random.uniform(-perturbation_strength, perturbation_strength, self.dim)  # Modified line\n                trial = np.clip(candidate + perturbation, bounds.lb, bounds.ub)\n                if np.mean([func(trial) for _ in range(3)]) > func(candidate):  # Noise reduction\n                    candidate = trial\n                    break\n        return candidate\n\n    def __call__(self, func):\n        bounds = func.bounds\n        self.population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in self.population])\n        num_evaluations = self.pop_size\n        prev_best_fitness = np.max(fitness)\n\n        while num_evaluations < self.budget:\n            for i in range(self.pop_size):\n                candidates = [idx for idx in range(self.pop_size) if idx != i]\n                mutant = self.mutate(i, candidates, bounds)\n                trial = self.crossover(self.population[i], mutant)\n                current_best_fitness = np.max(fitness)\n                convergence_speed = (current_best_fitness - prev_best_fitness) / prev_best_fitness\n                trial = self.adaptive_local_refinement(trial, func, bounds, convergence_speed)\n\n                trial_fitness = func(trial)\n                num_evaluations += 1\n                if trial_fitness > fitness[i]:\n                    self.population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if num_evaluations >= self.budget:\n                    break\n\n            prev_best_fitness = current_best_fitness\n\n        best_idx = np.argmax(fitness)\n        return self.population[best_idx]", "name": "HybridMetaheuristic", "description": "Enhanced adaptive strategy with probabilistic perturbation for robust exploration and exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.7692984035910634, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.021. And the mean value of best solutions found was 0.168 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "ef06491e-085b-44d3-af35-869de5187333", "metadata": {"aucs": [0.7429905484495386, 0.7945901820562783, 0.7703144802673731], "final_y": [0.17656041830909963, 0.1601017669387199, 0.16716564790697785]}, "mutation_prompt": null}
