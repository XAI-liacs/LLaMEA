{"id": "9d02e1ac-3e2b-4820-be41-557aeac4f4c4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Population size for DE\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        return result.x if result.success else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "A hybrid Differential Evolution with Quasi-Oppositional Initialization and Local Search (BFGS) that encourages periodicity for optimizing multilayered photonic structures.", "configspace": "", "generation": 0, "fitness": 0.9064377285298809, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.034. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": null, "metadata": {"aucs": [0.932260367920839, 0.928572906741042, 0.8584799109277618], "final_y": [0.1818843949325728, 0.18187968060544402, 0.16485701886074233]}, "mutation_prompt": null}
{"id": "2d5bc589-1e54-4533-bc4c-8f169b5a77d0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F = 0.8\n        self.CR = 0.9\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        best_idx = np.argmin([self._evaluate(ind, func) for ind in population])\n        best_candidate = population[best_idx]\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            adaptive_CR = self.CR * (0.5 + 0.5 * np.random.rand())\n            cross_points = np.random.rand(self.dim) < adaptive_CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        new_population[0] = best_candidate  # Elitism: preserve best candidate\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        return result.x if result.success else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with variable adaptive crossover rates and elitism for improved exploration and convergence.", "configspace": "", "generation": 1, "fitness": 0.8726571782520628, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.081. And the mean value of best solutions found was 0.195 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "9d02e1ac-3e2b-4820-be41-557aeac4f4c4", "metadata": {"aucs": [0.9316850436274102, 0.9281262670372369, 0.7581602240915417], "final_y": [0.1818843949325728, 0.18187968060544402, 0.2206526147280521]}, "mutation_prompt": null}
{"id": "86491395-50da-4bea-844c-810edf32ef61", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, dim)  # Adaptive population size\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            F_adaptive = 0.5 + np.random.rand() * 0.5  # Adaptive F\n            mutant = np.clip(a + F_adaptive * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        return result.x if result.success else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        # Bias towards periodicity by introducing penalty for non-periodicity\n        periodicity_penalty = np.std(candidate) * 0.1\n        return func(candidate) + periodicity_penalty\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "An Enhanced HybridDE with Adaptive Parameters and Periodicity-Promoting Bias integrated for optimizing multilayered photonic structures.", "configspace": "", "generation": 1, "fitness": 0.953139591548954, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.040. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9d02e1ac-3e2b-4820-be41-557aeac4f4c4", "metadata": {"aucs": [0.9833565445780522, 0.9790283677029205, 0.8970338623658891], "final_y": [0.16485727886349832, 0.16485722052580187, 0.16485616820735127]}, "mutation_prompt": null}
{"id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with adaptive parameter control and periodicity-driven local search to improve optimization of multilayered photonic structures.", "configspace": "", "generation": 1, "fitness": 0.9615442321860804, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9d02e1ac-3e2b-4820-be41-557aeac4f4c4", "metadata": {"aucs": [0.9572093655645889, 0.9802334090574292, 0.9471899219362233], "final_y": [0.16485591495707597, 0.16485597358016013, 0.1648581941757935]}, "mutation_prompt": null}
{"id": "5058eb24-6ed1-4d7a-9649-507662344b06", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Population size for DE\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _periodicity_mutation(self, a, b, c, lb, ub):\n        mutation = a + self.F * (b - c)\n        # Encourage periodicity by adding a sinusoidal component\n        mutation += np.sin(np.arange(self.dim) * np.pi / self.dim)\n        return np.clip(mutation, lb, ub)\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = self._periodicity_mutation(a, b, c, bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        return result.x if result.success else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE algorithm introducing a periodicity-aware mutation operator and adaptive crossover rate to better navigate the complex optimization landscape of multilayered photonic structures.", "configspace": "", "generation": 1, "fitness": 0.9278292860989681, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.052. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "9d02e1ac-3e2b-4820-be41-557aeac4f4c4", "metadata": {"aucs": [0.9801708801487562, 0.856948212954853, 0.9463687651932952], "final_y": [0.16486010797611128, 0.2072587157028981, 0.16485726121579514]}, "mutation_prompt": null}
{"id": "8a436ae1-bfd0-4459-8bb0-b24d76ec4cc8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20  # Population size for DE\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.CR * (1 - self.used_budget / self.budget)\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        return result.x if result.success else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhancing exploration by adapting crossover probability dynamically for improved performance in HybridDE.", "configspace": "", "generation": 1, "fitness": 0.932436238787882, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.932 with standard deviation 0.020. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "9d02e1ac-3e2b-4820-be41-557aeac4f4c4", "metadata": {"aucs": [0.9322678863958425, 0.9085488444507169, 0.9564919855170866], "final_y": [0.1818843949325728, 0.1881326818252269, 0.16485922956047538]}, "mutation_prompt": null}
{"id": "41ee0150-d782-4573-b104-cf3cbcd9ffc5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9\n        self.CR_min, self.CR_max = 0.4, 0.9\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 4], 4)  # Enforce stronger periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Augmented HybridDE with dynamic population resizing and enhanced periodicity enforcement to optimize photonic structures.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\").", "error": "UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\")", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {}, "mutation_prompt": null}
{"id": "28fd639f-6a9a-4a4d-ac91-1c844242b895", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c) + 0.1 * (population[i] - a), bounds.lb, bounds.ub)  # Added exploration term\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE by modifying mutation strategy to enhance exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\").", "error": "UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\")", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {}, "mutation_prompt": null}
{"id": "969182cc-2382-4118-9a73-a126cab8381f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            mirrored_population = lb + ub - population  # Mirror the population for diversity\n            population = np.vstack((population, mirrored_population))\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with adaptive parameter control and periodicity-driven local search using mirrored candidates for diversity.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\").", "error": "UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\")", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {}, "mutation_prompt": null}
{"id": "678c93de-715c-4e43-9f10-5feca0b4d0bc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.4, 0.9  # Adjusted differential weight range\n        self.CR_min, self.CR_max = 0.5, 0.9  # Adjusted crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        periodic_population = np.tile(population[:, :self.dim // 2], (1, 2))  # Enforce periodicity in initialization\n        return np.vstack((population, q_opposite_population, periodic_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with periodicity-guided initialization and enhanced adaptive parameter scaling to improve exploration-exploitation balance for photonic optimization.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\").", "error": "UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\")", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {}, "mutation_prompt": null}
{"id": "07bbfd30-545b-4a27-a72f-416593df083d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        # Introduced a refined local search with gradient check\n        refined_candidate = minimize(func, periodic_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='CG').x\n        return refined_candidate if self._evaluate(refined_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with opposition-based learning and improved local search for higher precision in photonic structure optimization.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\").", "error": "UnboundLocalError(\"cannot access local variable 'ub' where it is not associated with a value\")", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {}, "mutation_prompt": null}
{"id": "914cfa7b-ccf3-4bbf-9ad0-4c062ac730cd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n        self.best_solution = None\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n    \n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        candidate_score = func(candidate)\n        if self.best_solution is None or candidate_score < self._evaluate(self.best_solution, func):\n            self.best_solution = candidate\n        return candidate_score\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        return self.best_solution", "name": "HybridDE", "description": "Introduced elitism in DE to preserve the best solution found so far, enhancing convergence stability and solution quality.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: RecursionError('maximum recursion depth exceeded').", "error": "RecursionError('maximum recursion depth exceeded')", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {}, "mutation_prompt": null}
{"id": "5bb64756-8b71-4b1c-9c8f-7cf05e45badb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), options={'maxiter': 50}, method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Introduces a refined local search mechanism using periodicity-driven L-BFGS-B for enhanced convergence.", "configspace": "", "generation": 3, "fitness": 0.9539699595778145, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.018. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9323883486073707, 0.9773032679736233, 0.9522182621524496], "final_y": [0.1818843949325728, 0.16485626993216673, 0.16485754722212642]}, "mutation_prompt": null}
{"id": "b4014d0b-6332-4b5e-938f-dd477f7aafed", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(20, self.budget // 10)  # Dynamic population size adjustment\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhance the HybridDE algorithm by incorporating dynamic population size adjustment to better adapt to the optimization landscape.", "configspace": "", "generation": 3, "fitness": 0.9538691722209629, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.024. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9460750593925976, 0.9287219669279333, 0.9868104903423578], "final_y": [0.16485752975277768, 0.18187884026907986, 0.16485715719903726]}, "mutation_prompt": null}
{"id": "332c5e00-f5b5-475f-9e91-1d901d5f112b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c) + 0.1 * (np.random.rand(self.dim) - 0.5), bounds.lb, bounds.ub)  # Added mutation\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            best_candidate = result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE by enhancing local search with periodicity constraints and augmenting DE step with a mutation mechanism to better explore the search space.", "configspace": "", "generation": 3, "fitness": 0.9585058986997609, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.019. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9328207898293956, 0.979925904739329, 0.9627710015305582], "final_y": [0.18187884304024848, 0.16485620153450142, 0.16486129690354834]}, "mutation_prompt": null}
{"id": "a117ce1f-c6b8-408f-9cdc-cd4e2d60d76e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.95  # Enhanced adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with enhanced adaptive crossover probability strategy for improved black-box optimization performance.", "configspace": "", "generation": 3, "fitness": 0.9460844536498745, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.946 with standard deviation 0.010. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9328506061866707, 0.9488169356714886, 0.956585819091464], "final_y": [0.18188076587508006, 0.16485775304841366, 0.16485705842817555]}, "mutation_prompt": null}
{"id": "cead6b02-5eef-420c-8a92-03ecad896252", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='TNC')  # Changed method\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE with slight adaptation to the local search strategy for optimizing multilayered photonic structures.", "configspace": "", "generation": 4, "fitness": 0.9390763139823216, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.939 with standard deviation 0.027. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9122937569927821, 0.9281635013685161, 0.9767716835856667], "final_y": [0.18532101578879023, 0.18187968060544402, 0.1648569763517287]}, "mutation_prompt": null}
{"id": "2567bb5a-54f0-44d0-a212-ad42f65286bb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            best_candidate = result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity with adaptive segment\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved Enhanced HybridDE by incorporating adaptive periodicity updates in local search for better reflection maximization.", "configspace": "", "generation": 4, "fitness": 0.95011738243584, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.950 with standard deviation 0.028. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9427894660508279, 0.9195450850754168, 0.9880175961812752], "final_y": [0.16485686652172726, 0.16485724937269308, 0.16485667368891854]}, "mutation_prompt": null}
{"id": "a533941c-2829-458a-89e9-c7f3b910846f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n        self.chaos = 0.7\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        self.chaos = 4 * self.chaos * (1 - self.chaos)  # Logistic map\n        F = self.F_min + self.chaos * (self.F_max - self.F_min)\n        CR = self.CR_max - self.chaos * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.roll(best_candidate, shift=self.dim // 4)  # Improved periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE by incorporating chaotic maps for adaptive parameter generation and enhanced local search for better convergence.", "configspace": "", "generation": 4, "fitness": 0.9502409281438494, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.950 with standard deviation 0.016. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9328886376616977, 0.9467786815318608, 0.9710554652379896], "final_y": [0.1818843949325728, 0.1648558918962021, 0.16485976130212154]}, "mutation_prompt": null}
{"id": "8c49b43e-8eea-4341-b06c-74388ae9f36b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size += int(self.budget * 0.001)  # Adjust population size dynamically based on budget\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved convergence speed by incorporating a dynamic population size adjustment based on the budget used, enhancing exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.9508054016097978, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.017. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9556360431227449, 0.9276640275306911, 0.9691161341759575], "final_y": [0.1648560753470193, 0.18187836420890346, 0.16485702141301106]}, "mutation_prompt": null}
{"id": "bd21d6ab-02c2-4bac-8157-4451d7c6ed7e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            periodic_candidate = np.tile(result.x[:self.dim // 2], 2)  # Enforce periodicity\n            return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(result.x, func) else result.x\n        return best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with enhanced local search periodicity enforcement to improve convergence on multilayered photonic structures.", "configspace": "", "generation": 4, "fitness": 0.9274078865583893, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.927 with standard deviation 0.037. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.933865290714287, 0.9692100339156233, 0.8791483350452575], "final_y": [0.1818843949325728, 0.16485775684363524, 0.16485599085052283]}, "mutation_prompt": null}
{"id": "f236f399-65a6-4a5b-a3a0-0a1fc532b0f0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        adapt_ratio = self.used_budget / self.budget  # New line added for adaptive periodicity\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * adapt_ratio  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Introducing adaptive periodicity enforcement in the local search phase to refine solution convergence for multilayered photonic structures.", "configspace": "", "generation": 5, "fitness": 0.9470408864984167, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.024. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9323954411827853, 0.9281377692484372, 0.9805894490640277], "final_y": [0.18187988208374817, 0.18187968060544402, 0.16485608532406204]}, "mutation_prompt": null}
{"id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with selective local search and adaptive periodic enforcement for improved optimization of multilayered photonic structures.", "configspace": "", "generation": 5, "fitness": 0.9774319130564436, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.977 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9659358417787995, 0.9825754186899682, 0.9837844787005632], "final_y": [0.16485586311153322, 0.16485615487090866, 0.16485612930374927]}, "mutation_prompt": null}
{"id": "b0e513f9-4cc9-456c-9130-63225a41a369", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            best_candidate = result.x  # Update the best_candidate to the result of local search\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Enforce periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved exploitation stage in HybridDE by integrating local search with gradient-based optimization and symmetry enforcement.", "configspace": "", "generation": 5, "fitness": 0.9649133415244702, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.023. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9324908807442617, 0.9814147382218101, 0.9808344056073386], "final_y": [0.1818843949325728, 0.16485656115930825, 0.16485608532406204]}, "mutation_prompt": null}
{"id": "7b5174bb-5382-4996-9534-e20d340de178", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9\n        self.CR_min, self.CR_max = 0.4, 0.9\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            diversity_factor = np.random.uniform(0.9, 1.1)\n            trial = np.clip(trial * diversity_factor, bounds.lb, bounds.ub)\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        enhanced_candidate = best_candidate + np.sin(np.linspace(0, np.pi, self.dim)) * 0.01\n        return enhanced_candidate if self._evaluate(enhanced_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE by integrating a diversity enhancement mechanism and a more effective local search strategy to better explore and exploit the optimization landscape.", "configspace": "", "generation": 5, "fitness": 0.9484976749277637, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.948 with standard deviation 0.023. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.9322601978305017, 0.9812760978284236, 0.9319567291243656], "final_y": [0.1818843949325728, 0.1648564658680527, 0.16485950103500524]}, "mutation_prompt": null}
{"id": "802878ae-27e4-40d0-872d-123965bf5c64", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9\n        self.CR_min, self.CR_max = 0.4, 0.9\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)\n        result = minimize(func, periodic_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success:\n            return result.x\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Fine-tune local search strategy by initializing with a periodic candidate to improve solution refinement.", "configspace": "", "generation": 5, "fitness": 0.9468121901430577, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.048. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "fec413e1-9d9c-40d8-a3a1-9639e81b5459", "metadata": {"aucs": [0.8782907916822619, 0.9811288974737834, 0.9810168812731279], "final_y": [0.164857319727171, 0.1648564658680527, 0.16485608532406204]}, "mutation_prompt": null}
{"id": "05ea294d-7bf1-4fca-95fa-1e0439a3f0ba", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.05 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with improved adaptive periodic enforcement for more robust optimization of multilayered photonic structures.", "configspace": "", "generation": 6, "fitness": 0.9399062417368257, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.940 with standard deviation 0.030. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9495116461089518, 0.9703694202475723, 0.8998376588539531], "final_y": [0.16485910269274273, 0.1648563643504959, 0.16485657976219437]}, "mutation_prompt": null}
{"id": "c8bb64d2-6b54-4e92-8c9a-72b929eff2a7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = (self.used_budget / self.budget) ** 2\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with selective local search and adaptive periodic enforcement with improved adaptive parameter scaling.", "configspace": "", "generation": 6, "fitness": 0.9014184686580086, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.063. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9250237247068067, 0.8156718954405102, 0.9635597858267088], "final_y": [0.1818843949325728, 0.16485740577450503, 0.16485750331951643]}, "mutation_prompt": null}
{"id": "ff91a210-5aff-48f8-abdf-e88b765fbc10", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.3, 0.8  # Adjusted crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Increased probability for selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with optimized crossover mechanism and refined local search for superior optimization of multilayered photonic structures.", "configspace": "", "generation": 6, "fitness": 0.8436802602543843, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.077. And the mean value of best solutions found was 0.207 (0. is the best) with standard deviation 0.036.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9322744884249233, 0.7443133098250665, 0.8544529825131629], "final_y": [0.1818843949325728, 0.25781124525436083, 0.18187864380544116]}, "mutation_prompt": null}
{"id": "e6dc6f10-d9ab-458f-bfca-f3fc11cde34d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size\n        self.F_min, self.F_max = 0.6, 0.9  # Slightly adjusted differential weight range\n        self.CR_min, self.CR_max = 0.3, 0.8  # Adjusted crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Increased probability of local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.02 * np.random.randn(self.dim // 2, 2)).flatten()  # Adjusted periodic scale\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with enhanced local search and improved periodicity enforcement, ensuring better exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.9625962775510978, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9515719780712447, 0.9801421106683987, 0.9560747439136497], "final_y": [0.16485658079529342, 0.1648580950622821, 0.16485707331784094]}, "mutation_prompt": null}
{"id": "972546b9-a870-4093-9864-b0c264e3e819", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.3, 0.9  # Enhanced adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE with enhanced adaptive crossover probability range for better local exploration.", "configspace": "", "generation": 6, "fitness": 0.9578907647407102, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.017. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9347536419081863, 0.9633250595930044, 0.9755935927209399], "final_y": [0.1818784953130974, 0.1648655471753514, 0.16485811904348546]}, "mutation_prompt": null}
{"id": "c3cac10c-dae6-4c5d-8bb3-f7e2069bf7e9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = int(self.population_size * (1 + 0.1 * np.sin(self.used_budget / self.budget * np.pi)))  # Dynamic population size adjustment\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE using dynamic population size adjustment for enhanced exploration and exploitation.", "configspace": "", "generation": 7, "fitness": 0.9474743323594197, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.015. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9495116461089518, 0.928137947720281, 0.964773403249026], "final_y": [0.16485910269274273, 0.18187843003622783, 0.16485731948282956]}, "mutation_prompt": null}
{"id": "35321744-0ac6-459a-9a39-b557bb146c4b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Increased probability for selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Adjusted adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Optimized HybridDE with enhanced local search activation probability and refined adaptive periodic enforcement for improved searching efficiency.", "configspace": "", "generation": 7, "fitness": 0.9743404544654882, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9540224011494443, 0.9855437130675199, 0.9834552491795009], "final_y": [0.1648559682336116, 0.16485595410826492, 0.1648564400364383]}, "mutation_prompt": null}
{"id": "02dde78c-fbc1-488a-8fe4-4f83e8573228", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9\n        self.CR_min, self.CR_max = 0.4, 0.9\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        if self.used_budget / self.budget > 0.6:  # Dynamic population sizing\n            self.population_size = max(10, self.population_size // 2)\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "The Adaptive HybridDE now incorporates dynamic population sizing and enhanced mutation strategies to further improve optimization performance for multilayered photonic structures.", "configspace": "", "generation": 7, "fitness": 0.9683900599918916, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9791095751902177, 0.9589546371956238, 0.9671059675898334], "final_y": [0.16485691032190242, 0.16485714575519006, 0.16485617238178019]}, "mutation_prompt": null}
{"id": "04969c86-1567-4fec-85e6-58389bbfb9ba", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        chaotic_population = np.sin(np.pi * (population - lb) / (ub - lb)) * (ub - lb) + lb  # Enhanced initialization\n        return np.vstack((population, q_opposite_population, chaotic_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x * (1 + 0.005 * np.random.randn(self.dim))  # Improved refinement\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Introduced a chaotic initialization and enhanced local search to refine promising candidate solutions.", "configspace": "", "generation": 7, "fitness": 0.9423946975156836, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.942 with standard deviation 0.021. And the mean value of best solutions found was 0.175 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9300297378649937, 0.925815216991787, 0.9713391376902705], "final_y": [0.18187916592069164, 0.17722453837866037, 0.1648561424116186]}, "mutation_prompt": null}
{"id": "400cf348-d1d1-46f6-935c-d62a31388e7e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Selective local search (modified probability)\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                best_candidate = result.x  # Accept the improved local search result\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with improved local search strategy and adaptive periodic enforcement for optimized multilayered photonic structures.", "configspace": "", "generation": 7, "fitness": 0.9552597880568077, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.955 with standard deviation 0.023. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.925424980624604, 0.9822867016595566, 0.9580676818862625], "final_y": [0.1818790476884461, 0.16485620431066872, 0.16485827762556904]}, "mutation_prompt": null}
{"id": "92723291-a295-4a7d-98e4-8e33e90a637d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.6:  # Adjusted selective local search probability\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                best_candidate = result.x  # Ensure updated candidate on success\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.02 * np.random.randn(self.dim // 2, 2)).flatten()  # Slight perturbation increase\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with adaptive periodic constraints and integrated perturbation to improve convergence towards optimal solutions in complex optimization landscapes.", "configspace": "", "generation": 8, "fitness": 0.9441825101368583, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.031. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9324088786539487, 0.9129916025621889, 0.9871470491944373], "final_y": [0.17713837257717735, 0.16486130850945457, 0.16485660159643323]}, "mutation_prompt": null}
{"id": "0d4c4866-3890-452f-8296-f98e0360d222", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x + 0.01 * np.random.randn(self.dim)  # Adaptive gradient-based adjustment\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved local search by adding an adaptive gradient-based adjustment to enhance exploration near optimal solutions.", "configspace": "", "generation": 8, "fitness": 0.9466352730446571, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9577935582357853, 0.931228286441005, 0.950883974457181], "final_y": [0.16485638465531205, 0.16485663042931276, 0.1648566479506951]}, "mutation_prompt": null}
{"id": "564c9b80-b37a-4ad8-87b9-3f3a975b7bd3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Selective local search probability increased\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.005 * np.random.randn(self.dim // 2, 2)).flatten()  # Refined periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with strategic local search and refined adaptive periodic enforcement for optimal multilayered photonic structures.", "configspace": "", "generation": 8, "fitness": 0.9509079151095552, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9601808788368694, 0.953433534297912, 0.9391093321938843], "final_y": [0.16485627876178288, 0.16485769735969547, 0.1648563095575244]}, "mutation_prompt": null}
{"id": "57179de0-b753-4094-b76b-468c28dff423", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.4, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.8  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.05 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with refined local search and adaptive parameter tuning to boost multilayer photonic structure optimization.", "configspace": "", "generation": 8, "fitness": 0.9328908560854982, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.933 with standard deviation 0.031. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9760580315779228, 0.9171575336246626, 0.9054570030539093], "final_y": [0.16485836508341856, 0.16485639966367893, 0.16485671227941134]}, "mutation_prompt": null}
{"id": "deb26507-ff58-4406-96b6-49774c1962c4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population) * np.random.uniform(0.9, 1.1)  # Enhanced initialization\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        search_chance = 0.4 + 0.1 * np.cos(self.used_budget * np.pi / self.budget)  # Dynamic adjustment\n        if np.random.rand() < search_chance:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with enhanced initialization and dynamic local search adjustment for improved convergence in photonic structure optimization.", "configspace": "", "generation": 8, "fitness": 0.926953786009514, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.927 with standard deviation 0.015. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9347753238515651, 0.9396867276821181, 0.9063993064948586], "final_y": [0.16485717416361445, 0.1648598791903736, 0.18187878448638373]}, "mutation_prompt": null}
{"id": "fe01042d-6034-4f70-9d38-2a751b679370", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        # Changed line: Introduce stochastic factor in periodic enforcement\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.1 * np.random.randn(self.dim // 2, 2)).flatten()\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Introduce stochastic periodic enforcement in the local search to enhance solution periodicity.", "configspace": "", "generation": 9, "fitness": 0.9590126224920573, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.030. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9675118618865666, 0.9902862726056813, 0.9192397329839239], "final_y": [0.16485603775187052, 0.16485840538188823, 0.18187873255539755]}, "mutation_prompt": null}
{"id": "25e9617b-2c0c-45a7-9c64-78f39e32719f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Selective local search probability increased\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.02 * np.random.randn(self.dim // 2, 2)).flatten()  # Increased adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE with enhanced adaptive periodic enforcement and refined local search for optimization of multilayered photonic structures.", "configspace": "", "generation": 9, "fitness": 0.9461683870276737, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.946 with standard deviation 0.028. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9804391851251503, 0.9464174231869135, 0.9116485527709575], "final_y": [0.16485616028740568, 0.16485618031106053, 0.18187879941711693]}, "mutation_prompt": null}
{"id": "4ecbf3e6-56fd-4f7c-a1d3-5589785ba8bf", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.6:  # Increased probability for selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with improved selective local search triggering for optimized multilayered photonic structure results.", "configspace": "", "generation": 9, "fitness": 0.9214313849505326, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.013. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9323828103137138, 0.9281863715893417, 0.9037249729485423], "final_y": [0.1818843949325728, 0.18187968060544402, 0.18188030938472932]}, "mutation_prompt": null}
{"id": "485a2650-ad1f-4bfd-821c-e3711c42c726", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        local_search_prob = 0.7 if self.used_budget < self.budget * 0.5 else 0.3  # Dynamic local search probability\n        if np.random.rand() < local_search_prob:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.02 * np.random.randn(self.dim // 2, 2)).flatten()  # Enhanced periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with dynamic local search probability and enhanced periodic enforcement for improved solution refinement.", "configspace": "", "generation": 9, "fitness": 0.8899815605136249, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.043. And the mean value of best solutions found was 0.188 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9249067969206215, 0.9151580653750038, 0.8298798192452495], "final_y": [0.1818843949325728, 0.18188141637634458, 0.20044694443046163]}, "mutation_prompt": null}
{"id": "4b932651-00a0-4771-8b0c-c1dfa1ec13f6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.4, 0.95  # Adjusted adaptive differential weight range\n        self.CR_min, self.CR_max = 0.3, 0.95  # Adjusted adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.6:  # Increased local search probability\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Fine-tuning of the HybridDE with enhanced adaptive parameters and improved local search strategy for better convergence.", "configspace": "", "generation": 9, "fitness": 0.9413858070018412, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.009. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9323603389554784, 0.9537103023691502, 0.9380867796808946], "final_y": [0.18187827603317197, 0.16485955264161056, 0.16485666953464273]}, "mutation_prompt": null}
{"id": "8026b2e3-f2e4-4461-b78a-e0d70050eb28", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved local search selection probability to enhance convergence in the HybridDE algorithm.", "configspace": "", "generation": 10, "fitness": 0.943620718543861, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.019. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9324004478349093, 0.9281389384014427, 0.9703227693952312], "final_y": [0.18187918196401498, 0.1818785089231446, 0.16485678715660124]}, "mutation_prompt": null}
{"id": "1c50d0ad-9007-43c7-addd-daff3d8f95bb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        if adapt_ratio > 0.5:  # New condition to adjust CR dynamically\n            CR += 0.1 * (1 - adapt_ratio)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)  # Removed random scaling for stability\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE with enhanced exploitation through periodic local search and adaptive crossover strategies for superior optimization of photonic structures.", "configspace": "", "generation": 10, "fitness": 0.9495550935865785, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.950 with standard deviation 0.028. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9101786850432956, 0.9765658797498585, 0.9619207159665814], "final_y": [0.18187997079676632, 0.1648573834910838, 0.16485604724479397]}, "mutation_prompt": null}
{"id": "31b5817a-6a79-491d-8fb6-fb7157fbbd4f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        # Dynamic adjustment of CR for faster convergence\n        CR = max(self.CR_min, CR * (1.1 if adapt_ratio < 0.5 else 0.9))\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Fine-tune crossover strategy with dynamic CR adjustment for faster convergence.", "configspace": "", "generation": 10, "fitness": 0.9631473910059712, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.027. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9249080795421725, 0.982388324155296, 0.9821457693204454], "final_y": [0.18188040422611496, 0.16485620431066872, 0.16485630714475497]}, "mutation_prompt": null}
{"id": "41159a33-a468-4c31-ad29-d56841257328", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.2, 0.8  # Adjusted adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE by adjusting the adaptive crossover probability range for better exploration-exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.9408257264358232, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.040. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9870180507598192, 0.8895706135875705, 0.9458885149600795], "final_y": [0.16485737804074185, 0.1818785814364945, 0.16485600351405794]}, "mutation_prompt": null}
{"id": "6e701a51-e5fc-4ca9-b359-63099e905169", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9\n        self.CR_min, self.CR_max = 0.4, 0.9\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _dynamic_population(self, population):\n        # Reducing population size dynamically as budget depletes\n        if self.used_budget > 0.5 * self.budget:\n            return population[:self.population_size // 2]\n        return population\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        # Stronger periodic enforcement with slight randomization\n        period_len = self.dim // 10\n        periodic_candidate = np.tile(best_candidate[:period_len], self.dim // period_len)\n        periodic_candidate += 0.01 * np.random.randn(self.dim)  # Random noise\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            population = self._dynamic_population(population)  # Apply dynamic population resizing\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE by integrating dynamic population resizing and enhanced periodic enforcement for more efficient exploration and exploitation.", "configspace": "", "generation": 10, "fitness": 0.9084661775281475, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.023. And the mean value of best solutions found was 0.183 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9142162366680999, 0.878146241237769, 0.9330360546785734], "final_y": [0.18813154573325852, 0.18187979043487823, 0.17930155122115943]}, "mutation_prompt": null}
{"id": "b6a8e508-7a6d-4f7b-8438-9eed7f98db05", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Selective local search with modified probability\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.02 * np.random.randn(self.dim // 2, 2)).flatten()  # Increased diversity in periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Modify the local search strategy and increase the diversity of periodic candidates for more robust optimization.", "configspace": "", "generation": 11, "fitness": 0.9376371249705028, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.938 with standard deviation 0.019. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9324004478349093, 0.9177472920011613, 0.9627636350754377], "final_y": [0.18187918196401498, 0.18187968060544402, 0.16485785045632018]}, "mutation_prompt": null}
{"id": "aaf122a7-2881-4cff-ae3d-371e71a74a5e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Enhanced selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.02 * np.random.randn(self.dim // 2, 2)).flatten()  # Stochastic periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE with stochastic periodic enforcement and enhanced local search for optimized performance on multilayered photonic structures.", "configspace": "", "generation": 11, "fitness": 0.9072788303126839, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.066. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9372751086182605, 0.8153797457416826, 0.9691816365781086], "final_y": [0.16485588405678475, 0.18187837189755673, 0.1648559475201784]}, "mutation_prompt": null}
{"id": "e77b56d6-bd6c-486a-b89f-2dbad4374b3b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + (adapt_ratio + np.random.uniform(-0.05, 0.05)) * (self.F_max - self.F_min)  # Changed line\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Introduced a probability-based mutation factor in the adaptive parameter function to enhance solution diversity.", "configspace": "", "generation": 11, "fitness": 0.944744179952631, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.945 with standard deviation 0.028. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9681575143211925, 0.9051171735099734, 0.9609578520267272], "final_y": [0.16485685702379482, 0.18188002540778514, 0.16485609665358714]}, "mutation_prompt": null}
{"id": "c4b63c93-e2bc-4438-af3f-3900597e034a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Enhanced selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        # Symmetry leveraging in periodic candidate\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.02 * np.random.randn(self.dim // 2, 2)).flatten() \n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE with enhanced local search and symmetry leveraging for optimal multilayered photonic structures.", "configspace": "", "generation": 11, "fitness": 0.9396061344235642, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.940 with standard deviation 0.017. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9326731588519998, 0.9634309185741388, 0.9227143258445538], "final_y": [0.18188220548028144, 0.1648578324410449, 0.16485642812144097]}, "mutation_prompt": null}
{"id": "63f9276a-56ba-4177-b5dd-336c0ab026a8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            periodicity_factor = 1 + 0.05 * np.sin(np.linspace(0, np.pi, self.dim))  # Adding periodicity-inspired crossover\n            trial = np.where(cross_points, mutant, population[i]) * periodicity_factor\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()\n        improved_candidate = 0.5 * (best_candidate + periodic_candidate)\n        return improved_candidate if self._evaluate(improved_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE with periodicity-inspired crossover and enhanced local search for efficient optimization.", "configspace": "", "generation": 11, "fitness": 0.9699241029804012, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.970 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9602339177956367, 0.9690373764849589, 0.980501014660608], "final_y": [0.16485624749329542, 0.1648560292574378, 0.16485597341089409]}, "mutation_prompt": null}
{"id": "31f39d8f-45a7-4a2a-a86d-c55e5dbb897c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F + 0.05 * adapt_ratio, CR  # Improvement: Added small adaptive boost to F\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.02 * np.random.randn(self.dim // 2, 2)).flatten()  # Improvement: Increased mutation strength\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved adaptive parameters and local search strategy for enhanced optimization performance.", "configspace": "", "generation": 12, "fitness": 0.9294584842213389, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.017. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9347378216079502, 0.9064920966172703, 0.947145534438796], "final_y": [0.16485602984067027, 0.18813668608263268, 0.1648584225300398]}, "mutation_prompt": null}
{"id": "6b9f5c4f-2f97-4c75-b61f-4e43d80176d5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim))[:self.dim]  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = max(10, int(self.budget / 50))  # Dynamic population size adjustment\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with dynamic population size adjustment and adaptive periodicity for enhanced exploratory and exploitative balance in multilayered photonic structure optimization.", "configspace": "", "generation": 12, "fitness": 0.9002257223229612, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.014. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.8982811790155464, 0.8835785969522049, 0.9188173910011322], "final_y": [0.1818843949325728, 0.18187959221186756, 0.1648583006348039]}, "mutation_prompt": null}
{"id": "99c3b808-96a6-466f-8894-4c0f9b50d95c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.75:  # Selective local search with improved probability\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with improved local search probability to refine solutions more effectively.", "configspace": "", "generation": 12, "fitness": 0.9437131422237646, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.014. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9577248008246401, 0.9492387961712004, 0.9241758296754531], "final_y": [0.16485623887379441, 0.16485614577062835, 0.16485787021957476]}, "mutation_prompt": null}
{"id": "aca394f4-5b0e-4f6c-8e1b-9b7e3402f734", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c + np.random.randn() * (a - b)), bounds.lb, bounds.ub)  # Refined mutation\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        local_search_prob = 0.3 + 0.2 * (self.budget - self.used_budget) / self.budget  # Dynamic local search probability\n        if np.random.rand() < local_search_prob:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved exploitation through dynamic local search probability adjustment and refined mutation strategy for better convergence.", "configspace": "", "generation": 12, "fitness": 0.9172019346562528, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.013. And the mean value of best solutions found was 0.184 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9249012690885756, 0.9275806637180937, 0.8991238711620891], "final_y": [0.1818805553562235, 0.18187968060544402, 0.18813261553103955]}, "mutation_prompt": null}
{"id": "8718cdbf-6b0f-49ea-a49c-4612f74a940e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c) + 0.01 * np.random.randn(self.dim), bounds.lb, bounds.ub)  # Perturbation scaling\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE by enhancing mutation strategy with perturbation scaling for better local refinement.", "configspace": "", "generation": 12, "fitness": 0.9255548643512536, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.033. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.8915350525961081, 0.914913295530162, 0.9702162449274905], "final_y": [0.18813132501034013, 0.18187941190835755, 0.16485587180163608]}, "mutation_prompt": null}
{"id": "551d5160-0d4f-46d3-b953-00b10913a312", "solution": "class HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.65, 0.95  # Enhanced adaptive differential weight range\n        self.CR_min, self.CR_max = 0.5, 0.95  # Enhanced adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with improved adaptive strategies and enhanced periodic candidate generation for more efficient optimization.", "configspace": "", "generation": 13, "fitness": 0.9485804829625524, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.949 with standard deviation 0.018. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9323899757739227, 0.9404071119718596, 0.9729443611418748], "final_y": [0.1818843949325728, 0.16485679036469703, 0.1648602675243327]}, "mutation_prompt": null}
{"id": "71175016-85d1-4506-8783-6ff0e89e1fe8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n        if result.success and self._evaluate(result.x, func) < self._evaluate(best_candidate, func):\n            return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.05 * np.random.randn(self.dim // 2, 2)).flatten()  # Increased periodic adaptation\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with improved selection method and periodic adaptation to optimize multilayered photonic structures.", "configspace": "", "generation": 13, "fitness": 0.8709218812776114, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.092. And the mean value of best solutions found was 0.202 (0. is the best) with standard deviation 0.040.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9333420659404825, 0.9380818974921654, 0.7413416804001862], "final_y": [0.1818843949325728, 0.16485670894479687, 0.2578105480539308]}, "mutation_prompt": null}
{"id": "f8260576-4eaf-4709-a68a-a6f5d70eb1df", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        # Elitism: Ensure the best candidate is retained in new_population\n        best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n        worst_idx = np.argmax([self._evaluate(ind, func) for ind in new_population])\n        new_population[worst_idx] = best_candidate\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Introduced elitism in DE step ensuring best candidates are retained, enhancing convergence reliability.", "configspace": "", "generation": 13, "fitness": 0.9684823505024518, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.968 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9563717053132141, 0.9865681605380819, 0.9625071856560594], "final_y": [0.1648613212677782, 0.16485661234253635, 0.16485607828707172]}, "mutation_prompt": null}
{"id": "f8f58040-6d46-4fa7-900b-5ac90118b6be", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.3, 0.9  # Adjusted adaptive differential weight range\n        self.CR_min, self.CR_max = 0.5, 0.9  # Adjusted adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with improved adaptive parameter tuning and robust local search for optimized photonic structure design.", "configspace": "", "generation": 13, "fitness": 0.9486347180607146, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.949 with standard deviation 0.030. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9616215287889653, 0.9076761609141891, 0.9766064644789895], "final_y": [0.16485628406022457, 0.18187937765647366, 0.16485684111528542]}, "mutation_prompt": null}
{"id": "fd19dbfa-b827-4ae6-86c3-477ba6bd98aa", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.02 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Introduced a small mutation rate for periodic adaptation to enhance solution diversity and convergence in multilayer photonic optimization.", "configspace": "", "generation": 13, "fitness": 0.9390937063453458, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.939 with standard deviation 0.012. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9323918462119989, 0.9285638138213053, 0.956325459002733], "final_y": [0.18187868546595365, 0.18187968060544402, 0.16485597161041776]}, "mutation_prompt": null}
{"id": "c59f76da-d537-479a-8e60-1af45c12a378", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.005 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement with reduced noise\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with improved adaptive periodic enforcement using noise reduction for enhanced optimization outcomes.", "configspace": "", "generation": 14, "fitness": 0.9319393786535786, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.932 with standard deviation 0.006. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9324004478349093, 0.9239842912199834, 0.9394333969058429], "final_y": [0.18187918196401498, 0.1818796874752412, 0.16485841357487396]}, "mutation_prompt": null}
{"id": "0d126884-6b67-4025-8e9e-528338d1176d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9\n        self.CR_min, self.CR_max = 0.4, 0.9\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        if self.used_budget > self.budget * 0.6:  # Dual-phase adaptation\n            CR = max(0.7, CR)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # More frequent local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced DE with dual-phase adaptive exploration, gradient-assisted convergence, and periodicity adaptation, optimizing multilayered photonic structures.", "configspace": "", "generation": 14, "fitness": 0.9537216732000194, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.024. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9250128830240716, 0.9532234736651207, 0.9829286629108659], "final_y": [0.18187854171890272, 0.16485641530655648, 0.16485625924450853]}, "mutation_prompt": null}
{"id": "bf0ecf22-2531-4eb8-9f13-25ff6fd8e286", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        # Perform periodic refinement by averaging with periodic_candidate\n        refined_candidate = (best_candidate + periodic_candidate) / 2\n        return refined_candidate if self._evaluate(refined_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Introduce a selective periodic refinement step in the local search to enhance convergence and exploit periodicity.", "configspace": "", "generation": 14, "fitness": 0.9456428863676593, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.946 with standard deviation 0.015. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9446931746049358, 0.9281400517920212, 0.9640954327060205], "final_y": [0.16485692460837897, 0.1818784771063907, 0.16485581659945592]}, "mutation_prompt": null}
{"id": "08c39e5a-d9e9-4722-aba4-91b16d3e1834", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + 0.8 * F * (b - c), bounds.lb, bounds.ub)  # Modified mutation strategy\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with modified mutation strategy for better exploration of the search space in optimizing multilayered photonic structures.", "configspace": "", "generation": 14, "fitness": 0.9621843779882573, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.024. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9743442755114896, 0.9285718918721706, 0.983636966581112], "final_y": [0.16485636784894153, 0.18188013165101247, 0.1648562907412664]}, "mutation_prompt": null}
{"id": "0919856b-9ae0-4374-846b-2b3bbe29d4db", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Increased probability for local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.005 * np.random.randn(self.dim // 2, 2)).flatten()  # Tighter periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with stochastic local search adjustment and precise periodic tuning for superior optimization of multilayered photonic structures.", "configspace": "", "generation": 14, "fitness": 0.9184933663749256, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.031. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9572928582783736, 0.9175420964354875, 0.8806451444109157], "final_y": [0.16486377124801754, 0.18187849143228962, 0.16485984275827048]}, "mutation_prompt": null}
{"id": "7bfe3970-7d95-4b36-874e-e3886e19d00f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        elite = min(population, key=lambda x: self._evaluate(x, func))  # Preserve elite\n        for i in range(len(population)):\n            if np.array_equal(population[i], elite):\n                new_population[i] = elite\n                continue\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_factor = 1 + 0.01 * np.random.randn(self.dim // 2)  # Dynamic periodicity adjustment\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * periodic_factor.flatten()\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with elite preservation and dynamic periodicity adjustment for improved optimization of multilayered photonic structures.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (10,) (5,) ').", "error": "ValueError('operands could not be broadcast together with shapes (10,) (5,) ')", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {}, "mutation_prompt": null}
{"id": "393ebc9c-ae17-464e-9be5-ca3d7392d311", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Increased probability of local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.005 * np.random.randn(self.dim // 2, 2)).flatten()  # Reduced randomness in periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with improved adaptive periodic enforcement and balanced local search for superior optimization of multilayered photonic structures.", "configspace": "", "generation": 15, "fitness": 0.9129403109408161, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.051. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9529752083693105, 0.8404815617392345, 0.9453641627139034], "final_y": [0.16485833832632957, 0.16485655186750936, 0.1648596047926043]}, "mutation_prompt": null}
{"id": "8925192f-43ae-4bec-a0c7-d12a3e7dc1c0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Increased probability for local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2 * np.random.randint(1, 3))[:self.dim]  # Enhanced periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with enhanced adaptive periodicity and dynamic local search for superior optimization of multilayered photonic structures.", "configspace": "", "generation": 15, "fitness": 0.9269876922859371, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.927 with standard deviation 0.034. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.8808025347501081, 0.9366480071439074, 0.9635125349637963], "final_y": [0.18813248611053202, 0.16485759965177182, 0.164856518548528]}, "mutation_prompt": null}
{"id": "1132b70a-f7ab-45ca-a689-da1d225fe699", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.6:  # Enhanced local search probability\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.015 * np.random.randn(self.dim // 2, 2)).flatten()  # Enhanced periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with enhanced local search probability and periodic enforcement for optimizing multilayered structures.", "configspace": "", "generation": 15, "fitness": 0.914040807576238, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.040. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9324009145653336, 0.858817204894536, 0.9509043032688446], "final_y": [0.1818785857213463, 0.16485627368785738, 0.16485636953920269]}, "mutation_prompt": null}
{"id": "aba3a6f3-9217-4ae9-a9bf-5caedf40f55c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < (CR + 0.05)  # Enhanced crossover\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2 + int(0.1 * np.random.randn()))  # Enhanced periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Optimized HybridDE with enhanced crossover and periodicity enforcement for superior reflectivity optimization.", "configspace": "", "generation": 15, "fitness": 0.9185854300512141, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.030. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.953896313793598, 0.8802005203662093, 0.9216594559938351], "final_y": [0.16485670201643654, 0.18187920721625817, 0.16485709529385895]}, "mutation_prompt": null}
{"id": "661580f8-6039-4379-8e38-7f0a1a2ef3b3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.6:  # Changed probability for selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.02 * np.random.randn(self.dim // 2, 2)).flatten()  # Modified adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with more efficient local search selection and periodic structural mutation for optimal photonic structure design.", "configspace": "", "generation": 16, "fitness": 0.928648688813507, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.023. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9324004478349093, 0.9544090270730051, 0.8991365915326067], "final_y": [0.18187918196401498, 0.16485698541202898, 0.18813105459770973]}, "mutation_prompt": null}
{"id": "81c1495e-b7bc-4a00-8035-9e221f89c460", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < (CR + 0.1)  # Enhanced crossover probability\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE with enhanced crossover for more diverse exploration in multilayered photonic optimization.", "configspace": "", "generation": 16, "fitness": 0.9624996122426803, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.015. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.945311571568922, 0.9823246954173357, 0.9598625697417832], "final_y": [0.1648578181657504, 0.16485620431066872, 0.16485585077579945]}, "mutation_prompt": null}
{"id": "404604fc-0587-4659-9ddf-5b50e33b4582", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                best_candidate = result.x  # Refined best candidate update\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()\n        periodic_candidate = np.clip(periodic_candidate, bounds.lb, bounds.ub)  # Ensure periodic candidate within bounds\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "HybridDE is refined with improved local search and enhanced adaptive periodic enforcement for optimal photonic structure optimization.", "configspace": "", "generation": 16, "fitness": 0.9468689397878198, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.026. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9516128322646279, 0.9761315116611672, 0.9128624754376643], "final_y": [0.16485659596837365, 0.1648631402649985, 0.16485653797102295]}, "mutation_prompt": null}
{"id": "fdab5640-c431-45cc-88f4-0a6e4ddcce76", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.6, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.5, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined Enhanced HybridDE by modifying adaptive parameters and initial population strategy to improve convergence for multilayered photonic optimization.", "configspace": "", "generation": 16, "fitness": 0.9501207637363613, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.950 with standard deviation 0.028. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9523344476131687, 0.9837032606665569, 0.9143245829293587], "final_y": [0.164859698632971, 0.16485620431066872, 0.18188103774495568]}, "mutation_prompt": null}
{"id": "7c073e07-da2d-4174-a02e-2e5040849ef0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        annealing_factor = (0.99 ** self.used_budget)  # New annealing factor\n        F = self.F_min + annealing_factor * (adapt_ratio * (self.F_max - self.F_min))\n        CR = self.CR_max - annealing_factor * (adapt_ratio * (self.CR_max - self.CR_min))\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Introduced annealing factor in adaptive parameters for enhanced exploration-exploitation balance in HybridDE.", "configspace": "", "generation": 16, "fitness": 0.9501733605804802, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.950 with standard deviation 0.037. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9734739456220355, 0.8980720709479978, 0.9789740651714072], "final_y": [0.16485592032148522, 0.16485722019680205, 0.16485811904348546]}, "mutation_prompt": null}
{"id": "2db0403c-f3bd-4d8d-8913-19245230b8c1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.55:  # Small change: increased local search probability from 0.5 to 0.55\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with slightly increased local search probability for improved local convergence in multilayered photonic optimization.", "configspace": "", "generation": 17, "fitness": 0.9037724849089637, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.073. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9522122525309816, 0.9587332510699736, 0.800371951125936], "final_y": [0.1648604876949199, 0.16485893586067923, 0.1648566065919389]}, "mutation_prompt": null}
{"id": "692cbf74-0abb-4c91-a33c-65215bdcaf05", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        search_prob = 0.5 + 0.4 * (self.used_budget / self.budget)  # Dynamic threshold\n        if np.random.rand() < search_prob:\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved exploration-exploitation tradeoff by adjusting local search probability in HybridDE using dynamic threshold.", "configspace": "", "generation": 17, "fitness": 0.9615282749235033, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.020. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9331850551263912, 0.9739902713696929, 0.977409498274426], "final_y": [0.18188162997615487, 0.16485603026467766, 0.1648568525493409]}, "mutation_prompt": null}
{"id": "b59bd071-1b5c-4859-ab4b-5a3bf6f88a2b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        if self.used_budget < self.budget * 0.5:  # Dynamic population size adjustment\n            new_population = np.vstack((new_population, np.random.uniform(bounds.lb, bounds.ub, (5, self.dim))))\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()\n        improved_candidate = minimize(func, periodic_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B').x  # Advanced local search\n        return improved_candidate if self._evaluate(improved_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with dynamic population size adjustment and advanced local search for optimizing multilayered photonic structures.", "configspace": "", "generation": 17, "fitness": 0.9269892096134952, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.927 with standard deviation 0.022. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9170091010685704, 0.906869859430017, 0.957088668341898], "final_y": [0.1818843949325728, 0.18187968060544402, 0.16485698698955153]}, "mutation_prompt": null}
{"id": "a52b3a4b-0381-43d4-b6dd-ca7d05e38561", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.6:  # Increased selective local search probability\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.02 * np.random.randn(self.dim // 2, 2)).flatten()  # Enhanced periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with improved periodic enforcement and selective local search probability.", "configspace": "", "generation": 17, "fitness": 0.9410916553365372, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.027. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9327904071347578, 0.9135679281452711, 0.9769166307295825], "final_y": [0.1818843949325728, 0.16485592811359795, 0.1648567373337706]}, "mutation_prompt": null}
{"id": "e34e881b-9714-496e-99be-11068ce04083", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.lr_min, self.lr_max = 0.01, 0.1  # Adaptive learning rate range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        lr = self.lr_min + adapt_ratio * (self.lr_max - self.lr_min)\n        return F, CR, lr\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR, lr = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with strategic adaptive learning rate to improve optimization of multilayered photonic structures.", "configspace": "", "generation": 17, "fitness": 0.9629473961330627, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.015. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9639690372626767, 0.9444401701000954, 0.980432981036416], "final_y": [0.16485622605860684, 0.164856016283928, 0.16486385317774133]}, "mutation_prompt": null}
{"id": "04e741d1-9ec3-461e-b457-af46d4d3695c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.6:  # Selective local search probability adjusted\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.015 * np.random.randn(self.dim // 2, 2)).flatten()  # Enhanced adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Optimized HybridDE by refining local search selection probability and enhancing adaptive periodic enforcement for better convergence.", "configspace": "", "generation": 18, "fitness": 0.8605271192196744, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.128. And the mean value of best solutions found was 0.210 (0. is the best) with standard deviation 0.052.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9324004478349093, 0.6806988579170382, 0.9684820519070759], "final_y": [0.18187918196401498, 0.2827478263773693, 0.16485647854856433]}, "mutation_prompt": null}
{"id": "9d2fae01-e937-4485-bb05-0cc8ff816bd9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(20, 10 + dim // 2)  # Dynamic population size adjustment\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Improved HybridDE with dynamic population size adjustment for enhanced exploration-exploitation balance in multilayered photonic structure optimization.", "configspace": "", "generation": 18, "fitness": 0.9298230008807341, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.003. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.933051623551151, 0.9267753183300149, 0.9296420607610367], "final_y": [0.18187839038438336, 0.1818787887768788, 0.18187848869734402]}, "mutation_prompt": null}
{"id": "ee51d52b-720d-4e81-beee-81b27a42e92a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.02 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Slightly enhanced the local search strategy to bolster periodicity adaptation and improve convergence.", "configspace": "", "generation": 18, "fitness": 0.8961307577849366, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.023. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9249622599063498, 0.8937192465205704, 0.8697107669278896], "final_y": [0.1818843949325728, 0.16485723114090978, 0.1818797165033441]}, "mutation_prompt": null}
{"id": "41307332-493c-457c-8cb2-dd6603b7c65d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size for better exploration\n        self.F_min, self.F_max = 0.4, 0.95  # Adjusted differential weight range\n        self.CR_min, self.CR_max = 0.5, 0.95  # Adjusted crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = np.sin(np.pi * self.used_budget / (2 * self.budget))  # Sinusoidal adaptation for smoother changes\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.6:  # Increased chance of local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.02 * np.random.randn(self.dim // 2, 2)).flatten()  # Adjusted periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "HybridDE-Periodic: Enhanced HybridDE with periodic patterns and improved adaptive parameter control for multilayer photonic structure optimization.", "configspace": "", "generation": 18, "fitness": 0.8995022806769234, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.078. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9210350481965688, 0.794802839389531, 0.9826689544446702], "final_y": [0.1818787294384947, 0.18187971040925288, 0.16485598456041461]}, "mutation_prompt": null}
{"id": "79da2a0f-18e3-420c-b485-33553f5ea3d0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.4, 0.8  # Narrowed differential weight range for enhanced exploitation\n        self.CR_min, self.CR_max = 0.5, 0.95  # Expanded crossover probability range for better exploration\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_max - adapt_ratio * (self.F_max - self.F_min)  # Enhanced tuning for F\n        CR = self.CR_min + adapt_ratio * (self.CR_max - self.CR_min)  # Enhanced tuning for CR\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Improved selective local search probability\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.02 * np.random.randn(self.dim // 2, 2)).flatten()  # Adjusted adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Refined HybridDE with enhanced adaptive parameter tuning and dynamic diversity preservation for optimizing multilayered photonic structures.", "configspace": "", "generation": 18, "fitness": 0.9018199441757074, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.039. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9175306256177684, 0.939571251612826, 0.8483579552965278], "final_y": [0.1818843949325728, 0.1648562657234316, 0.18187858600809392]}, "mutation_prompt": null}
{"id": "ba49104c-2a37-450c-a5ed-fd7ee42a6b27", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.6, 0.9  # Adjusted adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Increased probability for selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with improved adaptive parameter tuning and selective local search probability for optimizing multilayered photonic structures.", "configspace": "", "generation": 19, "fitness": 0.9369856045450659, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.937 with standard deviation 0.016. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9328194470266711, 0.9196228356347181, 0.9585145309738079], "final_y": [0.1818843949325728, 0.16485611254307542, 0.16485883294119208]}, "mutation_prompt": null}
{"id": "6d781da6-2a3e-4732-aaea-61971f359d22", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.005 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with improved adaptive periodic enforcement and selective local search for optimization of multilayered photonic structures.", "configspace": "", "generation": 19, "fitness": 0.9244354767446379, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.032. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9688266176320435, 0.9068560046180286, 0.8976238079838414], "final_y": [0.1648568946494452, 0.18187968060544402, 0.18188121785541467]}, "mutation_prompt": null}
{"id": "e9c09f37-5a26-450f-b182-ff6cca27584c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9\n        self.CR_min, self.CR_max = 0.1, 0.9  # Increased variability in crossover probability\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population) * np.random.uniform(0.9, 1.1, population.shape)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        CR = 0.1 + CR * adapt_ratio  # Dynamic scaling of CR\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2)\n        periodic_candidate *= 1 + 0.01 * np.random.randn(self.dim // 2, 2).flatten() * (1 - self.used_budget / self.budget)  # Local adaptive periodicity\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with quasi-oppositional learning, dynamic scaling of crossover, and local adaptive periodicity for improved optimization efficiency.", "configspace": "", "generation": 19, "fitness": 0.9379407528197893, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.938 with standard deviation 0.029. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9757382010588089, 0.9068560046180286, 0.9312280527825305], "final_y": [0.16485637127326802, 0.18187968060544402, 0.16485588325129152]}, "mutation_prompt": null}
{"id": "75df323a-954d-4bf1-8287-577b64e09fa7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.3:  # Enhanced selective local search trigger\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.02 * np.random.randn(self.dim // 2, 2)).flatten()  # Improved periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Optimized HybridDE with enhanced local search trigger and improved periodic enforcement strategy for better convergence.", "configspace": "", "generation": 19, "fitness": 0.8932115234732363, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.061. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.971549135105527, 0.8863942456499805, 0.8216911896642015], "final_y": [0.16485813318346876, 0.1818783901720067, 0.18188211995404613]}, "mutation_prompt": null}
{"id": "8fdb459a-9bbd-40b5-af70-cf312c84ad26", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c) + 0.1 * (np.mean(population, axis=0) - a), bounds.lb, bounds.ub)  # Enhanced mutation\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with improved mutation strategy and selective local search for optimized multilayered photonic structure design.", "configspace": "", "generation": 19, "fitness": 0.9382285960337823, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.938 with standard deviation 0.008. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.932798789560223, 0.9321728068776755, 0.9497141916634482], "final_y": [0.18187830283763595, 0.16485680471608832, 0.1648562786020321]}, "mutation_prompt": null}
{"id": "b1997264-5bb4-4e35-8e9c-8ff7e7dfb260", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        self.population_size = max(20, int(20 + 10 * (self.used_budget / self.budget)))  # Dynamic population sizing\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Introduced dynamic population sizing based on budget utilization to enhance diversity and adaptability during optimization.", "configspace": "", "generation": 20, "fitness": 0.9156443252304983, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.067. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9495116461089518, 0.8215251592405806, 0.9758961703419624], "final_y": [0.16485910269274273, 0.16485858653191632, 0.16485757959365177]}, "mutation_prompt": null}
{"id": "f48e002a-e041-47db-bfea-4d6ad591a0e6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func):\n            if np.random.rand() < 0.1:  # Adding a chance to perform another layer of L-BFGS-B\n                result = minimize(func, periodic_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n                if result.success:\n                    return result.x\n            return periodic_candidate\n        return best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Introduced a small chance of performing a second layer of L-BFGS-B local search to further refine the best candidate's periodicity enforcement.", "configspace": "", "generation": 20, "fitness": 0.9602557553379046, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9659835499634191, 0.9578499843390688, 0.9569337317112259], "final_y": [0.16486160405327344, 0.16486135271069613, 0.1648576200989209]}, "mutation_prompt": null}
{"id": "1e8f5aa9-e6ec-4f62-86cf-81ede4e832d1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = np.log1p(self.used_budget) / np.log1p(self.budget)  # Change 1: logarithmic adaptation\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Change 2: Increased local search probability\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Enhanced HybridDE with refined adaptive parameters and improved local search for superior optimization of multilayered photonic structures.", "configspace": "", "generation": 20, "fitness": 0.9551604566305499, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.955 with standard deviation 0.017. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9325834862838662, 0.9592216514641076, 0.9736762321436756], "final_y": [0.18187853139429577, 0.16485704550370794, 0.1648559680259707]}, "mutation_prompt": null}
{"id": "2a04a8fc-a10a-4384-90f4-899b8d5e7017", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.2, 0.9  # Adjusted adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.5:  # Selective local search\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Fine-tuning the adaptive crossover probability range in HybridDE to improve convergence by making CR_min dynamic.", "configspace": "", "generation": 20, "fitness": 0.9459721462364339, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.946 with standard deviation 0.021. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9760965627563706, 0.9281356027070906, 0.9336842732458407], "final_y": [0.1648567784681949, 0.18187968060544402, 0.18187846754652826]}, "mutation_prompt": null}
{"id": "447dec88-ba7d-453d-b7e4-576d6ac05ef7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.F_min, self.F_max = 0.5, 0.9  # Adaptive differential weight range\n        self.CR_min, self.CR_max = 0.4, 0.9  # Adaptive crossover probability range\n        self.used_budget = 0\n\n    def _quasi_oppositional_init(self, lb, ub):\n        population = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        midpoint = (lb + ub) / 2.0\n        q_opposite_population = midpoint + (midpoint - population)\n        return np.vstack((population, q_opposite_population))\n\n    def _adaptive_parameters(self):\n        adapt_ratio = self.used_budget / self.budget\n        F = self.F_min + adapt_ratio * (self.F_max - self.F_min)\n        CR = self.CR_max - adapt_ratio * (self.CR_max - self.CR_min)\n        return F, CR\n\n    def _de_step(self, population, func, bounds):\n        new_population = np.empty_like(population)\n        F, CR = self._adaptive_parameters()\n        for i in range(len(population)):\n            indices = [idx for idx in range(len(population)) if idx != i]\n            a, b, c = population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds.lb, bounds.ub)\n            cross_points = np.random.rand(self.dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            if self._evaluate(trial, func) < self._evaluate(population[i], func):\n                new_population[i] = trial\n            else:\n                new_population[i] = population[i]\n        return new_population\n\n    def _local_search(self, best_candidate, func, bounds):\n        if np.random.rand() < 0.7:  # Selective local search with increased probability\n            result = minimize(func, best_candidate, bounds=list(zip(bounds.lb, bounds.ub)), method='L-BFGS-B')\n            if result.success:\n                return result.x\n        periodic_candidate = np.tile(best_candidate[:self.dim // 2], 2) * (1 + 0.01 * np.random.randn(self.dim // 2, 2)).flatten()  # Adaptive periodic enforcement\n        return periodic_candidate if self._evaluate(periodic_candidate, func) < self._evaluate(best_candidate, func) else best_candidate\n\n    def _evaluate(self, candidate, func):\n        if self.used_budget >= self.budget:\n            return float('inf')\n        self.used_budget += 1\n        return func(candidate)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        lb, ub = bounds.lb, bounds.ub\n        population = self._quasi_oppositional_init(lb, ub)\n\n        while self.used_budget < self.budget:\n            population = self._de_step(population, func, bounds)\n            best_candidate = min(population, key=lambda x: self._evaluate(x, func))\n            best_candidate = self._local_search(best_candidate, func, bounds)\n            if self.used_budget >= self.budget:\n                break\n\n        best_solution = min(population, key=lambda x: self._evaluate(x, func))\n        return best_solution", "name": "HybridDE", "description": "Optimized adaptive parameters in Enhanced HybridDE for improved local search performance.", "configspace": "", "generation": 20, "fitness": 0.9425379256719152, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.943 with standard deviation 0.021. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "737d9c34-4c97-494a-88df-1a6b979f32bc", "metadata": {"aucs": [0.9322799275893016, 0.9716205291484897, 0.9237133202779542], "final_y": [0.1818785039748394, 0.16485585227498423, 0.1648592544570432]}, "mutation_prompt": null}
