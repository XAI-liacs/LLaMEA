{"id": "84ec153b-8c32-4e7c-877e-9a5848a254d8", "solution": "import numpy as np\n\nclass HybridOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 * self.dim\n        crossover_rate = 0.9\n        mutation_factor = 0.8\n\n        # Generate initial population\n        population = np.random.rand(population_size, self.dim)\n        population = func.bounds.lb + population * (func.bounds.ub - func.bounds.lb)\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        best_idx = np.argmin(fitness)\n        best_ind = population[best_idx]\n        best_fit = fitness[best_idx]\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n                    \n                # Differential Evolution mutation and crossover\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(population[a] + mutation_factor * (population[b] - population[c]), func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate trial\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select based on fitness\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update the best individual\n                    if trial_fitness < best_fit:\n                        best_ind = trial\n                        best_fit = trial_fitness\n\n            # Adaptive random search\n            for _ in range(population_size // 5):\n                if evaluations >= self.budget:\n                    break\n\n                candidate = np.random.randn(self.dim) * 0.1 + best_ind\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                \n                if candidate_fitness < best_fit:\n                    best_ind = candidate\n                    best_fit = candidate_fitness\n\n        return best_ind", "name": "HybridOptimization", "description": "The algorithm employs a hybrid approach combining differential evolution with adaptive step-size control and random search to balance exploration and exploitation in optimizing black box functions.", "configspace": "", "generation": 0, "fitness": 0.805740492257985, "feedback": "The algorithm HybridOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.023. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7777642128483861, 0.8058644752174582, 0.8335927887081105], "final_y": [0.14524359483633387, 0.1434529683237521, 0.1324831866435482]}, "mutation_prompt": null}
{"id": "1d8a793c-fdb0-44c7-8dbd-9852712c71b6", "solution": "import numpy as np\n\nclass AdaptiveHybridOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.temperature = 1.0\n        self.num_parents = 5\n\n    def __call__(self, func):\n        bounds = (func.bounds.lb, func.bounds.ub)\n        num_evaluations = 0\n\n        # Initialize parent population randomly\n        parents = np.random.uniform(bounds[0], bounds[1], (self.num_parents, self.dim))\n        parent_fitness = np.array([func(ind) for ind in parents])\n        num_evaluations += self.num_parents\n\n        best_solution = parents[np.argmin(parent_fitness)]\n        best_fitness = np.min(parent_fitness)\n\n        while num_evaluations < self.budget:\n            # Generate offspring through mutation\n            offspring = []\n            for parent in parents:\n                if num_evaluations >= self.budget:\n                    break\n                candidate = parent + np.random.normal(0, self.temperature, self.dim)\n                candidate = np.clip(candidate, bounds[0], bounds[1])\n                offspring.append(candidate)\n                num_evaluations += 1\n\n            # Evaluate offspring\n            offspring_fitness = np.array([func(ind) for ind in offspring])\n\n            # Combine parents and offspring\n            combined_population = np.vstack((parents, offspring))\n            combined_fitness = np.hstack((parent_fitness, offspring_fitness))\n\n            # Select the top num_parents individuals to form new parents\n            selected_indices = np.argsort(combined_fitness)[:self.num_parents]\n            parents = combined_population[selected_indices]\n            parent_fitness = combined_fitness[selected_indices]\n\n            # Update the best solution found\n            if np.min(parent_fitness) < best_fitness:\n                best_fitness = np.min(parent_fitness)\n                best_solution = parents[np.argmin(parent_fitness)]\n\n            # Simulated annealing: adapt temperature\n            self.temperature *= 0.95  # Simple cooling strategy\n\n        return best_solution", "name": "AdaptiveHybridOptimizer", "description": "A hybrid metaheuristic algorithm combining evolutionary strategies and simulated annealing to adaptively explore and exploit the search space for optimal solutions.", "configspace": "", "generation": 0, "fitness": 0.7663490220907976, "feedback": "The algorithm AdaptiveHybridOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.040. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7130848007665483, 0.8104212545274703, 0.7755410109783745], "final_y": [0.19199526134042744, 0.15327188859430896, 0.1653908435339163]}, "mutation_prompt": null}
{"id": "874263f7-7591-47ef-8da6-1c05ac52d62f", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Pitch adjustment through random local search\n                pitch_adj_rate = 0.2\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "The Harmony Search-inspired Bee Optimization (HSBO) algorithm combines the concepts of harmony search and bee algorithms to efficiently explore and exploit the search space in black-box optimization.", "configspace": "", "generation": 0, "fitness": 0.9045708329188402, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.024. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8724758610818312, 0.9119392500210127, 0.9292973876536765], "final_y": [0.1210065943514197, 0.1169290858381653, 0.11222758973012881]}, "mutation_prompt": null}
{"id": "a21364af-0726-480b-8b3b-5b3bc60928cf", "solution": "import numpy as np\n\nclass AdaptivePathExploration:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_solution = np.random.uniform(lb, ub, self.dim)\n        best_value = func(best_solution)\n        evaluations = 1\n\n        while evaluations < self.budget:\n            alpha = 1.0 - (evaluations / self.budget)  # Dynamic adjustment factor\n            gradient = self.estimate_gradient(func, best_solution, lb, ub)\n            candidate_solution = best_solution + alpha * gradient + np.random.uniform(-0.1, 0.1, self.dim)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n            evaluations += 1\n            \n            if candidate_value < best_value:\n                best_solution, best_value = candidate_solution, candidate_value\n        \n        return best_solution\n\n    def estimate_gradient(self, func, solution, lb, ub):\n        epsilon = 1e-8\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            step = np.zeros(self.dim)\n            step[i] = epsilon\n            upper_value = func(np.clip(solution + step, lb, ub))\n            lower_value = func(np.clip(solution - step, lb, ub))\n            grad[i] = (upper_value - lower_value) / (2 * epsilon)\n        return grad", "name": "AdaptivePathExploration", "description": "A novel 'Adaptive Path-Exploration' algorithm that dynamically adjusts exploration and exploitation phases based on feedback from the search path and gradient-like information, optimizing solutions efficiently within complex, high-dimensional spaces.", "configspace": "", "generation": 0, "fitness": 0.6138710856774195, "feedback": "The algorithm AdaptivePathExploration got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.614 with standard deviation 0.086. And the mean value of best solutions found was 0.247 (0. is the best) with standard deviation 0.048.", "error": "", "parent_id": null, "metadata": {"aucs": [0.6069940942087155, 0.5124955905596666, 0.7221235722638766], "final_y": [0.24677500121138884, 0.30686596676343836, 0.18811737840435028]}, "mutation_prompt": null}
{"id": "135eaee6-1d53-42ae-9467-0708ec2448c7", "solution": "import numpy as np\n\nclass HybridPSOSA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_particles = min(40, budget // 10)\n        self.position = np.random.rand(self.num_particles, dim)\n        self.velocity = np.zeros((self.num_particles, dim))\n        self.personal_best_position = np.copy(self.position)\n        self.personal_best_value = np.full(self.num_particles, np.inf)\n        self.global_best_position = None\n        self.global_best_value = np.inf\n        self.temperature = 1.0\n\n    def update_velocity(self, inertia=0.5, cognitive=1.5, social=1.5):\n        r1, r2 = np.random.rand(self.num_particles, self.dim), np.random.rand(self.num_particles, self.dim)\n        cognitive_velocity = cognitive * r1 * (self.personal_best_position - self.position)\n        social_velocity = social * r2 * (self.global_best_position - self.position)\n        self.velocity = inertia * self.velocity + cognitive_velocity + social_velocity\n\n    def update_position(self, bounds):\n        self.position += self.velocity\n        self.position = np.clip(self.position, bounds.lb, bounds.ub)\n\n    def anneal(self):\n        self.temperature *= 0.99\n\n    def acceptance_probability(self, candidate_value):\n        if candidate_value < self.global_best_value:\n            return 1.0\n        else:\n            return np.exp((self.global_best_value - candidate_value) / self.temperature)\n\n    def __call__(self, func):\n        bounds = func.bounds\n        evaluations = 0\n\n        while evaluations < self.budget:\n            for i in range(self.num_particles):\n                candidate_value = func(self.position[i])\n                evaluations += 1\n\n                if candidate_value < self.personal_best_value[i]:\n                    self.personal_best_value[i] = candidate_value\n                    self.personal_best_position[i] = self.position[i]\n\n                if self.global_best_position is None or candidate_value < self.global_best_value:\n                    self.global_best_value = candidate_value\n                    self.global_best_position = self.position[i]\n\n            self.update_velocity()\n            self.update_position(bounds)\n            self.anneal()\n\n            for i in range(self.num_particles):\n                candidate_value = func(self.position[i])\n                evaluations += 1\n\n                if np.random.rand() < self.acceptance_probability(candidate_value):\n                    self.position[i] = self.position[i]\n\n        return self.global_best_position", "name": "HybridPSOSA", "description": "A hybrid metaheuristic combining principles of Particle Swarm Optimization and Simulated Annealing to explore and exploit the search space effectively, balancing global and local search.", "configspace": "", "generation": 0, "fitness": 0.660056797745749, "feedback": "The algorithm HybridPSOSA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.660 with standard deviation 0.000. And the mean value of best solutions found was 0.219 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": null, "metadata": {"aucs": [0.660056797745749, 0.660056797745749, 0.660056797745749], "final_y": [0.21891901516198964, 0.21891901516198964, 0.21891901516198964]}, "mutation_prompt": null}
{"id": "773f7177-aecc-4d88-a186-ef42336a4ae4", "solution": "import numpy as np\n\nclass AdaptivePathExploration:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_solution = np.random.uniform(lb, ub, self.dim)\n        best_value = func(best_solution)\n        evaluations = 1\n\n        while evaluations < self.budget:\n            alpha = 1.0 - (evaluations / self.budget)  # Dynamic adjustment factor\n            gradient = self.estimate_gradient(func, best_solution, lb, ub)\n            # Reduced random range over time for noise reduction\n            random_range = (0.1 - 0.05 * (evaluations / self.budget))\n            candidate_solution = best_solution + alpha * gradient + np.random.uniform(-random_range, random_range, self.dim)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n            evaluations += 1\n            \n            if candidate_value < best_value:\n                best_solution, best_value = candidate_solution, candidate_value\n        \n        return best_solution\n\n    def estimate_gradient(self, func, solution, lb, ub):\n        epsilon = 1e-8\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            step = np.zeros(self.dim)\n            step[i] = epsilon\n            upper_value = func(np.clip(solution + step, lb, ub))\n            lower_value = func(np.clip(solution - step, lb, ub))\n            grad[i] = (upper_value - lower_value) / (2 * epsilon)\n        return grad", "name": "AdaptivePathExploration", "description": "A refined 'Adaptive Path-Exploration' algorithm that introduces noise reduction by decreasing the random perturbation range over time, enhancing solution stability and convergence.", "configspace": "", "generation": 1, "fitness": 0.6145395347787382, "feedback": "The algorithm AdaptivePathExploration got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.615 with standard deviation 0.086. And the mean value of best solutions found was 0.247 (0. is the best) with standard deviation 0.049.", "error": "", "parent_id": "a21364af-0726-480b-8b3b-5b3bc60928cf", "metadata": {"aucs": [0.6073384505634956, 0.5123896683697335, 0.7238904854029855], "final_y": [0.2465305214397705, 0.30702118145138135, 0.1867716277745327]}, "mutation_prompt": null}
{"id": "f8587822-a2d0-4d70-9604-c39f79db1da7", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.2 + 0.1 * (self.budget - evals) / self.budget\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced HSBO with adaptive pitch adjustment and improved greedy selection for superior solution refinement.", "configspace": "", "generation": 1, "fitness": 0.8906788704910961, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.034. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "874263f7-7591-47ef-8da6-1c05ac52d62f", "metadata": {"aucs": [0.8443763861205644, 0.9047015282821972, 0.9229586970705266], "final_y": [0.13084452811548664, 0.11631139615322883, 0.11264869600644001]}, "mutation_prompt": null}
{"id": "7b78a12d-cfd4-4189-81ce-c978a174f1e6", "solution": "import numpy as np\n\nclass HybridOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 * self.dim\n        crossover_rate = 0.9\n        mutation_factor = 0.8\n\n        # Generate initial population\n        population = np.random.rand(population_size, self.dim)\n        population = func.bounds.lb + population * (func.bounds.ub - func.bounds.lb)\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        best_idx = np.argmin(fitness)\n        best_ind = population[best_idx]\n        best_fit = fitness[best_idx]\n\n        # Elite selection: retain the best solution\n        elite_ind = best_ind.copy()\n        elite_fit = best_fit\n        \n        while evaluations < self.budget:\n            # Dynamic mutation factor adjustment\n            mutation_factor = 0.5 + 0.5 * (self.budget - evaluations) / self.budget\n            \n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover with dynamic mutation factor\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(population[a] + mutation_factor * (population[b] - population[c]), func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate trial\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select based on fitness\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    \n                    # Update the best individual\n                    if trial_fitness < best_fit:\n                        best_ind = trial\n                        best_fit = trial_fitness\n\n            # Adaptive random search\n            for _ in range(population_size // 5):\n                if evaluations >= self.budget:\n                    break\n\n                candidate = np.random.randn(self.dim) * 0.1 + elite_ind\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                \n                # Elite replacement strategy\n                if candidate_fitness < elite_fit:\n                    elite_ind = candidate\n                    elite_fit = candidate_fitness\n\n                if candidate_fitness < best_fit:\n                    best_ind = candidate\n                    best_fit = candidate_fitness\n\n        return best_ind", "name": "HybridOptimization", "description": "Refined HybridOptimization with enhanced adaptive exploration using a dynamic mutation strategy and elite selection mechanism.", "configspace": "", "generation": 1, "fitness": 0.781950563637139, "feedback": "The algorithm HybridOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.014. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "84ec153b-8c32-4e7c-877e-9a5848a254d8", "metadata": {"aucs": [0.7719091299173507, 0.8021553183254493, 0.7717872426686169], "final_y": [0.15558277381965602, 0.15590924036711107, 0.16195296216997834]}, "mutation_prompt": null}
{"id": "42eb0992-65cf-4260-ac3a-598c5f8840fc", "solution": "import numpy as np\n\nclass AdaptivePathExploration:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        best_solution = np.random.uniform(lb, ub, self.dim)\n        best_value = func(best_solution)\n        evaluations = 1\n\n        while evaluations < self.budget:\n            alpha = 1.0 - (evaluations / self.budget)  # Dynamic adjustment factor\n            gradient = self.estimate_gradient(func, best_solution, lb, ub)\n            candidate_solution = best_solution + alpha * gradient + np.random.uniform(-0.1, 0.1, self.dim)\n            candidate_solution = np.clip(candidate_solution, lb, ub)\n            candidate_value = func(candidate_solution)\n            evaluations += 1\n            \n            if candidate_value < best_value:\n                best_solution, best_value = candidate_solution, candidate_value\n        \n        return best_solution\n\n    def estimate_gradient(self, func, solution, lb, ub):\n        epsilon = 1e-8 + 1e-2 * (1.0 - (self.budget / (2 * self.budget)))  # Dynamic epsilon adjustment\n        grad = np.zeros(self.dim)\n        for i in range(self.dim):\n            step = np.zeros(self.dim)\n            step[i] = epsilon\n            upper_value = func(np.clip(solution + step, lb, ub))\n            lower_value = func(np.clip(solution - step, lb, ub))\n            grad[i] = (upper_value - lower_value) / (2 * epsilon)\n        return grad", "name": "AdaptivePathExploration", "description": "AdaptivePathExploration now includes a refined gradient estimation with a dynamic epsilon adjustment for enhanced solution precision.", "configspace": "", "generation": 1, "fitness": 0.6141350352554288, "feedback": "The algorithm AdaptivePathExploration got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.614 with standard deviation 0.086. And the mean value of best solutions found was 0.247 (0. is the best) with standard deviation 0.049.", "error": "", "parent_id": "a21364af-0726-480b-8b3b-5b3bc60928cf", "metadata": {"aucs": [0.6073509468523277, 0.5124717238077927, 0.722582435106166], "final_y": [0.24650841770703757, 0.3072261741523109, 0.18768977413461052]}, "mutation_prompt": null}
{"id": "7a224ce9-3bcc-4e4e-96a4-c815a2c74ad5", "solution": "import numpy as np\n\nclass HybridOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 * self.dim\n        crossover_rate = 0.9\n        mutation_factor = 0.8\n\n        # Generate initial population\n        population = np.random.rand(population_size, self.dim)\n        population = func.bounds.lb + population * (func.bounds.ub - func.bounds.lb)\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        best_idx = np.argmin(fitness)\n        best_ind = population[best_idx]\n        best_fit = fitness[best_idx]\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n                    \n                # Differential Evolution mutation and crossover\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                # Adjust mutation factor dynamically based on progress\n                dynamic_mutation_factor = mutation_factor * (1 - evaluations / self.budget)\n                mutant = np.clip(population[a] + dynamic_mutation_factor * (population[b] - population[c]), func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate trial\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select based on fitness\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update the best individual\n                    if trial_fitness < best_fit:\n                        best_ind = trial\n                        best_fit = trial_fitness\n\n            # Adaptive random search\n            for _ in range(max(population_size // 5, 2)):  # Ensure a minimum number of candidates\n                if evaluations >= self.budget:\n                    break\n\n                candidate = np.random.randn(self.dim) * 0.1 + best_ind\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                \n                if candidate_fitness < best_fit:\n                    best_ind = candidate\n                    best_fit = candidate_fitness\n\n            # Reduce population size dynamically\n            population_size = max(5, population_size - self.dim // 10)\n\n        return best_ind", "name": "HybridOptimization", "description": "The optimized HybridOptimization algorithm introduces a dynamic mutation factor and adaptive population size reduction to enhance exploration-exploitation balance within the constraints of line modification.", "configspace": "", "generation": 1, "fitness": 0.7873583577150466, "feedback": "The algorithm HybridOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.787 with standard deviation 0.014. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "84ec153b-8c32-4e7c-877e-9a5848a254d8", "metadata": {"aucs": [0.77951667786232, 0.8069456648524043, 0.7756127304304157], "final_y": [0.1443091407638457, 0.14632614161000312, 0.15207473223344448]}, "mutation_prompt": null}
{"id": "e622bc35-ee92-498a-8cf3-7ae411e35862", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.15 + 0.1 * (self.budget - evals) / self.budget\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Improved adaptive pitch adjustment by tweaking the dynamic local search factor for better solution refinement.", "configspace": "", "generation": 2, "fitness": 0.8956719583934142, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.015. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "f8587822-a2d0-4d70-9604-c39f79db1da7", "metadata": {"aucs": [0.878690733126798, 0.894153624633201, 0.9141715174202438], "final_y": [0.12064605972090459, 0.11646789957828108, 0.11238185025146796]}, "mutation_prompt": null}
{"id": "6387ad46-2ff8-4d71-b812-d99a23dc0971", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 12  # Increased harmony memory size\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.2 + 0.1 * (self.budget - evals) / self.budget\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refined Enhanced HSBO with increased harmony memory size to improve exploration and solution refinement.", "configspace": "", "generation": 2, "fitness": 0.8661652896655495, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.040. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "f8587822-a2d0-4d70-9604-c39f79db1da7", "metadata": {"aucs": [0.8099948805300057, 0.889015614041331, 0.8994853744253122], "final_y": [0.14407856993928891, 0.1163140121170324, 0.11294509677293763]}, "mutation_prompt": null}
{"id": "361fde5c-9e72-47f1-8032-865fad2e9208", "solution": "import numpy as np\n\nclass HybridOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 * self.dim\n        crossover_rate = 0.9\n        mutation_factor = 0.8\n\n        # Generate initial population\n        population = np.random.rand(population_size, self.dim)\n        population = func.bounds.lb + population * (func.bounds.ub - func.bounds.lb)\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        best_idx = np.argmin(fitness)\n        best_ind = population[best_idx]\n        best_fit = fitness[best_idx]\n\n        # Elite selection: retain the best solution\n        elite_ind = best_ind.copy()\n        elite_fit = best_fit\n        \n        while evaluations < self.budget:\n            # Adjust mutation factor dynamically, considering convergence\n            mutation_factor = 0.4 + 0.4 * (self.budget - evaluations) / self.budget\n            \n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover with dynamic mutation factor\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(population[a] + mutation_factor * (population[b] - population[c]), func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate trial\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select based on fitness\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    \n                    # Update the best individual\n                    if trial_fitness < best_fit:\n                        best_ind = trial\n                        best_fit = trial_fitness\n\n            # Adaptive random search\n            for _ in range(population_size // 5):\n                if evaluations >= self.budget:\n                    break\n\n                candidate = np.random.randn(self.dim) * 0.1 + elite_ind\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                \n                # Elite replacement strategy\n                if candidate_fitness < elite_fit:\n                    elite_ind = candidate\n                    elite_fit = candidate_fitness\n\n                if candidate_fitness < best_fit:\n                    best_ind = candidate\n                    best_fit = candidate_fitness\n\n        return best_ind", "name": "HybridOptimization", "description": "Enhanced HybridOptimization with a refined dynamic mutation strategy for improved solution convergence.", "configspace": "", "generation": 2, "fitness": 0.7942344492953705, "feedback": "The algorithm HybridOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.006. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "7b78a12d-cfd4-4189-81ce-c978a174f1e6", "metadata": {"aucs": [0.7856826581221874, 0.7972248354110592, 0.7997958543528647], "final_y": [0.15728423317404772, 0.15799611215271392, 0.1385592376592385]}, "mutation_prompt": null}
{"id": "89d3070a-4640-4262-b19e-f66aaaad01df", "solution": "import numpy as np\n\nclass HybridOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 * self.dim\n        crossover_rate = 0.9\n        mutation_factor = 0.8\n\n        # Generate initial population\n        population = np.random.rand(population_size, self.dim)\n        population = func.bounds.lb + population * (func.bounds.ub - func.bounds.lb)\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        best_idx = np.argmin(fitness)\n        best_ind = population[best_idx]\n        best_fit = fitness[best_idx]\n\n        # Elite selection: retain the best solution\n        elite_ind = best_ind.copy()\n        elite_fit = best_fit\n        \n        while evaluations < self.budget:\n            # Dynamic mutation factor adjustment\n            mutation_factor = 0.4 + 0.6 * (self.budget - evaluations) / self.budget\n            \n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n\n                # Differential Evolution mutation and crossover with dynamic mutation factor\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(population[a] + mutation_factor * (population[b] - population[c]), func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate trial\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select based on fitness\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    \n                    # Update the best individual\n                    if trial_fitness < best_fit:\n                        best_ind = trial\n                        best_fit = trial_fitness\n\n            # Adaptive random search\n            for _ in range(population_size // 5):\n                if evaluations >= self.budget:\n                    break\n\n                candidate = np.random.randn(self.dim) * 0.05 + elite_ind\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                \n                # Elite replacement strategy\n                if candidate_fitness < elite_fit:\n                    elite_ind = candidate\n                    elite_fit = candidate_fitness\n\n                if candidate_fitness < best_fit:\n                    best_ind = candidate\n                    best_fit = candidate_fitness\n\n        return best_ind", "name": "HybridOptimization", "description": "Enhanced HybridOptimization with improved mutation factor schedule and elite candidate selection mechanism for better convergence.", "configspace": "", "generation": 2, "fitness": 0.8043667774924783, "feedback": "The algorithm HybridOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.019. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "7b78a12d-cfd4-4189-81ce-c978a174f1e6", "metadata": {"aucs": [0.7781462837855957, 0.8199333773115032, 0.8150206713803361], "final_y": [0.1515859664075273, 0.14321329199284294, 0.1464922226300891]}, "mutation_prompt": null}
{"id": "4051ba02-7a1e-44b6-a623-463b1d42f04c", "solution": "import numpy as np\n\nclass HybridOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 * self.dim\n        crossover_rate = 0.9\n        mutation_factor = 0.8\n\n        # Generate initial population\n        population = np.random.rand(population_size, self.dim)\n        population = func.bounds.lb + population * (func.bounds.ub - func.bounds.lb)\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        best_idx = np.argmin(fitness)\n        best_ind = population[best_idx]\n        best_fit = fitness[best_idx]\n\n        while evaluations < self.budget:\n            # Dynamically adjust mutation factor based on fitness diversity\n            mutation_factor = 0.5 + 0.5 * np.std(fitness) / np.mean(fitness) \n\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n                    \n                # Differential Evolution mutation and crossover\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(population[a] + mutation_factor * (population[b] - population[c]), func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate trial\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select based on fitness\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update the best individual\n                    if trial_fitness < best_fit:\n                        best_ind = trial\n                        best_fit = trial_fitness\n\n            # Adaptive random search\n            for _ in range(population_size // 5):\n                if evaluations >= self.budget:\n                    break\n\n                candidate = np.random.randn(self.dim) * 0.1 + best_ind\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                \n                if candidate_fitness < best_fit:\n                    best_ind = candidate\n                    best_fit = candidate_fitness\n\n        return best_ind", "name": "HybridOptimization", "description": "Enhanced mutation factor through dynamic scaling based on fitness diversity to improve exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.789381063384753, "feedback": "The algorithm HybridOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.016. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "84ec153b-8c32-4e7c-877e-9a5848a254d8", "metadata": {"aucs": [0.767709533953424, 0.8062896303023529, 0.794144025898482], "final_y": [0.15863424613700405, 0.14338534590676966, 0.15359537885846408]}, "mutation_prompt": null}
{"id": "dfa581b3-2c6b-449e-847b-eb89bc983d9f", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.2 + 0.1 * (self.budget - evals) / self.budget\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Stochastic reinitialization\n                if np.random.rand() < 0.05:\n                    new_solution = np.random.uniform(lb, ub, self.dim)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refined Enhanced HSBO with adaptive pitch adjustment, stochastic reinitialization, and improved greedy selection for superior solution refinement.", "configspace": "", "generation": 3, "fitness": 0.8834788206722498, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.883 with standard deviation 0.035. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "f8587822-a2d0-4d70-9604-c39f79db1da7", "metadata": {"aucs": [0.835169552709759, 0.8982414303281196, 0.9170254789788708], "final_y": [0.13072161543951188, 0.11659169250335755, 0.11285871351084587]}, "mutation_prompt": null}
{"id": "db94bb7d-7280-437e-adbb-5bf45730e576", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.15 + 0.2 * (self.budget - evals) / self.budget\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced HSBO using time-varying adaptive pitch adjustment rate for better convergence.", "configspace": "", "generation": 3, "fitness": 0.8776948429275405, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.028. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "e622bc35-ee92-498a-8cf3-7ae411e35862", "metadata": {"aucs": [0.8388727369621711, 0.8940196490903576, 0.9001921427300928], "final_y": [0.1304682303118243, 0.11633948849578213, 0.11611317800489895]}, "mutation_prompt": null}
{"id": "8f782ce8-866b-49ac-be1e-9437495cb85b", "solution": "import numpy as np\n\nclass HybridOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        # Initialize parameters\n        population_size = 10 * self.dim\n        crossover_rate = 0.9\n        mutation_factor = 0.8\n\n        # Generate initial population\n        population = np.random.rand(population_size, self.dim)\n        population = func.bounds.lb + population * (func.bounds.ub - func.bounds.lb)\n        fitness = np.array([func(ind) for ind in population])\n        evaluations = population_size\n\n        best_idx = np.argmin(fitness)\n        best_ind = population[best_idx]\n        best_fit = fitness[best_idx]\n\n        while evaluations < self.budget:\n            for i in range(population_size):\n                if evaluations >= self.budget:\n                    break\n                    \n                # Differential Evolution mutation and crossover\n                indices = list(range(population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = np.clip(population[a] + mutation_factor * (population[b] - population[c]), func.bounds.lb, func.bounds.ub)\n                \n                # Crossover\n                cross_points = np.random.rand(self.dim) < crossover_rate\n                trial = np.where(cross_points, mutant, population[i])\n                \n                # Evaluate trial\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                # Select based on fitness\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                    # Update the best individual\n                    if trial_fitness < best_fit:\n                        best_ind = trial\n                        best_fit = trial_fitness\n\n            # Adaptive random search\n            elite_set = population[np.argsort(fitness)[:5]]\n            for _ in range(population_size // 5):\n                if evaluations >= self.budget:\n                    break\n\n                candidate = np.random.randn(self.dim) * 0.1 + elite_set[np.random.randint(5)]\n                candidate = np.clip(candidate, func.bounds.lb, func.bounds.ub)\n                candidate_fitness = func(candidate)\n                evaluations += 1\n                \n                if candidate_fitness < best_fit:\n                    best_ind = candidate\n                    best_fit = candidate_fitness\n\n        return best_ind", "name": "HybridOptimization", "description": "Improved HybridOptimization by incorporating elite selection to enhance convergence speed in black-box optimization.", "configspace": "", "generation": 3, "fitness": 0.7942221386036433, "feedback": "The algorithm HybridOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.021. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "84ec153b-8c32-4e7c-877e-9a5848a254d8", "metadata": {"aucs": [0.7751238584680182, 0.8232163065541078, 0.7843262507888042], "final_y": [0.1536274139123548, 0.13750772330502237, 0.15890455673332415]}, "mutation_prompt": null}
{"id": "1d381e13-300b-4d93-8949-49550d64db94", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 12  # Increased harmony memory size\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Enhanced Adaptive pitch adjustment\n                pitch_adj_rate = 0.3 + 0.2 * (self.budget - evals) / self.budget  # was 0.2 + 0.1\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.3, 0.3) * (ub[i] - lb[i]) * 0.05  # was 0.5 and 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved greedy selection with strategic memory update\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "An improved HSBO algorithm leveraging enhanced adaptive pitch adjustment and strategic memory update to optimize black-box functions.", "configspace": "", "generation": 3, "fitness": 0.8670199182013664, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.060. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "6387ad46-2ff8-4d71-b812-d99a23dc0971", "metadata": {"aucs": [0.7843693013350196, 0.8942097799328903, 0.9224806733361891], "final_y": [0.14292660838324733, 0.11653358676626036, 0.11249084434165901]}, "mutation_prompt": null}
{"id": "ebd76888-9a4d-4c09-bd39-65cea9314e55", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 12  # Increased harmony memory size\n        bees_count = 7  # Increased bee count for better exploration\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.3 + 0.1 * (self.budget - evals) / self.budget  # Adjusted pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.6, 0.6) * (ub[i] - lb[i]) * 0.1  # Adjusted step size\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved selective update strategy\n                if new_fitness < np.median(harmony_memory_fitness):  # Selectively update based on median\n                    worst_idx = np.argmax(harmony_memory_fitness)\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced HSBO with adaptive pitch adjustment, increased exploration through dynamic bee count, and selective update strategy for improved optimization performance.", "configspace": "", "generation": 3, "fitness": 0.8915651206618627, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.019. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "6387ad46-2ff8-4d71-b812-d99a23dc0971", "metadata": {"aucs": [0.8702181499163308, 0.8879203348458065, 0.9165568772234506], "final_y": [0.12111090025787352, 0.1165539752548852, 0.11266234888008131]}, "mutation_prompt": null}
{"id": "f5d29941-94eb-4034-b8b8-b1f9704d6593", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = min(5, int(10 * (self.budget - evals) / self.budget))  # Dynamic bee count\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.15 + 0.1 * (self.budget - evals) / self.budget\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced exploration with dynamic bee count adjustment for improved search space coverage.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'evals' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'evals' referenced before assignment\")", "parent_id": "e622bc35-ee92-498a-8cf3-7ae411e35862", "metadata": {}, "mutation_prompt": null}
{"id": "aeb3afb7-afa7-4681-8c9f-07eb9932c794", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Enhanced adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.2 + 0.2 * (self.budget - evals) / self.budget\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n                \n                # Dynamic bee count adjustment\n                bees_count = max(3, int(5 * (self.budget - evals) / self.budget))\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refined HSBO with improved adaptive pitch adjustment and dynamic bee count based on current evaluation state.", "configspace": "", "generation": 4, "fitness": 0.8864214960160086, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.035. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "f8587822-a2d0-4d70-9604-c39f79db1da7", "metadata": {"aucs": [0.8385955332331356, 0.9009638961465878, 0.9197050586683025], "final_y": [0.13066024454010816, 0.11634503889104941, 0.11113790264363221]}, "mutation_prompt": null}
{"id": "01c02a25-92c6-4e68-9a46-752b9e777a1a", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Dynamic pitch adjustment through random local search\n                pitch_adj_rate = 0.2 + 0.8 * (np.std(harmony_memory_fitness) / np.mean(harmony_memory_fitness))\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "The HSBO algorithm is improved by dynamically adjusting the pitch adjustment rate based on the current fitness landscape, enhancing exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.9018056381818669, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.016. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "874263f7-7591-47ef-8da6-1c05ac52d62f", "metadata": {"aucs": [0.8995143389804043, 0.8840284194946335, 0.9218741560705627], "final_y": [0.11127644794266311, 0.11690859864437575, 0.11268667867415927]}, "mutation_prompt": null}
{"id": "2afa50f2-bc14-43dc-9188-e200efc910d9", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.15 + 0.1 * (1 + np.cos(np.pi * evals / self.budget)) / 2\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refined HSBO with enhanced pitch adjustment rate calculation based on cosine decay for better solution refinement.", "configspace": "", "generation": 4, "fitness": 0.8874597515094355, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.032. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "e622bc35-ee92-498a-8cf3-7ae411e35862", "metadata": {"aucs": [0.8430636740362389, 0.9009898044223773, 0.9183257760696902], "final_y": [0.1305287923164945, 0.11628210186517796, 0.1122652531960131]}, "mutation_prompt": null}
{"id": "ebbe4a3c-7e67-426b-83e2-4ae803211a7e", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = max(8, min(20, self.budget // 50))  # Dynamic harmony memory size\n        bees_count = 7  # Increased bee count for better exploration\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment with increased range\n                pitch_adj_rate = 0.3 + 0.2 * (self.budget - evals) / self.budget  # Adjusted pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.8, 0.8) * (ub[i] - lb[i]) * 0.1  # Adjusted step size\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved selective update strategy\n                if new_fitness < np.median(harmony_memory_fitness):  # Selectively update based on median\n                    worst_idx = np.argmax(harmony_memory_fitness)\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced HSBO with dynamic adaptation of harmony memory size and improved pitch adjustment for superior exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.8922574823159198, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.019. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ebd76888-9a4d-4c09-bd39-65cea9314e55", "metadata": {"aucs": [0.8705264290873626, 0.8884856848373732, 0.9177603330230238], "final_y": [0.1145040294677836, 0.11656223460924342, 0.11227003971309435]}, "mutation_prompt": null}
{"id": "b0a7d117-7ae4-4dd9-b1d3-ec2cca54b537", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = max(8, min(20, self.budget // 50))  # Dynamic harmony memory size\n        bees_count = 7  # Increased bee count for better exploration\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment with increased range\n                pitch_adj_rate = 0.35 + 0.2 * (self.budget - evals) / self.budget  # Adjusted pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.9, 0.9) * (ub[i] - lb[i]) * 0.1  # Adjusted step size\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved selective update strategy\n                if new_fitness < np.percentile(harmony_memory_fitness, 75):  # Selectively update based on 75th percentile\n                    worst_idx = np.argmax(harmony_memory_fitness)\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhance exploitation by updating the pitch adjustment strategy and harmony memory replacement criterion.", "configspace": "", "generation": 5, "fitness": 0.8906567618685671, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.025. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ebbe4a3c-7e67-426b-83e2-4ae803211a7e", "metadata": {"aucs": [0.8573139955922318, 0.8981853738510601, 0.9164709161624093], "final_y": [0.11972933648695483, 0.11708719987546434, 0.11313769816367647]}, "mutation_prompt": null}
{"id": "5f5d6fb8-a310-4236-b5b8-2e185138739e", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 12  # Increased harmony memory size\n        bees_count = 7  # Increased bee count for better exploration\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.3 + 0.1 * (self.budget - evals) / self.budget  # Adjusted pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.6, 0.6) * (ub[i] - lb[i]) * 0.1  # Adjusted step size\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved selective update strategy\n                if new_fitness < np.percentile(harmony_memory_fitness, 75):  # Selectively update based on 75th percentile\n                    worst_idx = np.argmax(harmony_memory_fitness)\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced HSBO with a refined selective update strategy to prioritize replacement of solutions based on the worst percentile of harmony memory fitness.", "configspace": "", "generation": 5, "fitness": 0.9112749694468407, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.005. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "ebd76888-9a4d-4c09-bd39-65cea9314e55", "metadata": {"aucs": [0.9039808085975376, 0.9131381340647549, 0.9167059656782298], "final_y": [0.11326289287465396, 0.11644054245227442, 0.1136391224400981]}, "mutation_prompt": null}
{"id": "45530345-b2f6-4866-9875-f64569e8fa3c", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            # Dynamic adjustment of harmony memory size\n            if evals % 20 == 0:\n                harmony_memory_size = max(5, int(10 + 5 * np.std(harmony_memory_fitness)))\n                harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n                harmony_memory_fitness = np.resize(harmony_memory_fitness, harmony_memory_size)\n\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                pitch_adj_rate = 0.1 + 0.9 * (np.std(harmony_memory_fitness) / np.mean(harmony_memory_fitness))\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.1\n                \n                new_solution = np.clip(new_solution, lb, ub)\n                new_fitness = func(new_solution)\n                evals += 1\n\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "The improved HSBO algorithm introduces a dual adaptive mechanism by adjusting both the harmony memory size and the pitch adjustment rate dynamically based on fitness landscape variations.", "configspace": "", "generation": 5, "fitness": 0.8581824160167238, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.033. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "01c02a25-92c6-4e68-9a46-752b9e777a1a", "metadata": {"aucs": [0.823048816385791, 0.9016323253353271, 0.8498661063290534], "final_y": [0.13071437227237526, 0.11693102597247862, 0.13036745233059632]}, "mutation_prompt": null}
{"id": "30709b9a-15ae-4943-b65c-f00496e36600", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Pitch adjustment through random local search\n                pitch_adj_rate = 0.3  # Adjusted pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.2  # Enhanced local search\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refined HSBO by increasing the pitch adjustment rate dynamically during optimization and enhancing local search strength.", "configspace": "", "generation": 5, "fitness": 0.8978898945368842, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.030. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "874263f7-7591-47ef-8da6-1c05ac52d62f", "metadata": {"aucs": [0.8607000137847032, 0.8986052084215381, 0.9343644614044109], "final_y": [0.1307006539212262, 0.11696836316514136, 0.11119473186172568]}, "mutation_prompt": null}
{"id": "d6bf14bb-4f31-4347-8e35-5700f310dbea", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = max(8, min(20, self.budget // 50))  # Dynamic harmony memory size\n        bees_count = 7  # Increased bee count for better exploration\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment with increased range\n                pitch_adj_rate = 0.3 + 0.2 * (self.budget - evals) / self.budget  # Adjusted pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.6, 0.6) * (ub[i] - lb[i]) * 0.1  # Adjusted step size\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved selective update strategy\n                if new_fitness < np.median(harmony_memory_fitness):  # Selectively update based on median\n                    worst_idx = np.argmax(harmony_memory_fitness)\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Slightly adjusted the new solution's step size for pitch adjustment to improve solution refinement.", "configspace": "", "generation": 5, "fitness": 0.8728570942919275, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.049. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "ebbe4a3c-7e67-426b-83e2-4ae803211a7e", "metadata": {"aucs": [0.8053667781612686, 0.8948736778212186, 0.9183308268932953], "final_y": [0.13345047346871186, 0.11775447863688415, 0.11292013145279178]}, "mutation_prompt": null}
{"id": "de20d210-bd08-4a17-be4d-ad187944763c", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 12\n        bees_count = 7\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            harmony_memory_size = int(12 + 3 * evals / self.budget)  # Dynamic memory size\n            bees_count = int(7 + 2 * (1 - evals / self.budget))  # Dynamic bee count\n            \n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                pitch_adj_rate = 0.3 + 0.1 * (self.budget - evals) / self.budget\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.6, 0.6) * (ub[i] - lb[i]) * 0.1\n                \n                new_solution = np.clip(new_solution, lb, ub)\n                \n                new_fitness = func(new_solution)\n                evals += 1\n\n                if new_fitness < np.percentile(harmony_memory_fitness, 75):\n                    worst_idx = np.argmax(harmony_memory_fitness)\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refined HSBO with adaptive exploration and exploitation balance by dynamically adjusting harmony memory size and bee count based on optimization progress.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 12 is out of bounds for axis 0 with size 12').", "error": "IndexError('index 12 is out of bounds for axis 0 with size 12')", "parent_id": "5f5d6fb8-a310-4236-b5b8-2e185138739e", "metadata": {}, "mutation_prompt": null}
{"id": "40d56004-827b-4744-b52a-5586c7180ac1", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n\n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment based on fitness diversity\n                pitch_adj_rate = 0.3 + 0.2 * np.std(harmony_memory_fitness) / np.mean(harmony_memory_fitness)  # Adjusted pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.2  # Enhanced local search\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced solution exploration by integrating adaptive pitch adjustment rate based on the fitness diversity within harmony memory.", "configspace": "", "generation": 6, "fitness": 0.8979720330790993, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "30709b9a-15ae-4943-b65c-f00496e36600", "metadata": {"aucs": [0.8909180759524239, 0.882314440396077, 0.920683582888797], "final_y": [0.12009129517423955, 0.11718431021519826, 0.1127460211846304]}, "mutation_prompt": null}
{"id": "5b2d1c9d-c493-44cc-ae6b-925deeb0db9e", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.15 + 0.1 * (self.budget - evals) / self.budget\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.7, 0.7) * (ub[i] - lb[i]) * 0.1  # Adjusted range\n                \n                # Boundary check\n                adaptive_lb, adaptive_ub = lb - 0.1 * (ub - lb), ub + 0.1 * (ub - lb)  # Expanded boundaries\n                new_solution = np.clip(new_solution, adaptive_lb, adaptive_ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Improved HSBO with adaptive boundary expansion for enhanced exploration during optimization.", "configspace": "", "generation": 6, "fitness": 0.8883089227874624, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.029. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "e622bc35-ee92-498a-8cf3-7ae411e35862", "metadata": {"aucs": [0.8497752139645827, 0.8953055190776922, 0.9198460353201127], "final_y": [0.1305391377115641, 0.11679935012490228, 0.1128008949779562]}, "mutation_prompt": null}
{"id": "ea2832f1-707a-4c30-9e22-a15c4b871c12", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Dynamic pitch adjustment through random local search\n                pitch_adj_rate = 0.2 + 0.8 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + np.mean(harmony_memory_fitness)))\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhance exploration by altering pitch adjustment rate calculation to include a factor of mean fitness.", "configspace": "", "generation": 6, "fitness": 0.8991126054801711, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.018. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "01c02a25-92c6-4e68-9a46-752b9e777a1a", "metadata": {"aucs": [0.8764816880474615, 0.899575120095599, 0.9212810082974527], "final_y": [0.12104160851433465, 0.11756281816818648, 0.11248433532984059]}, "mutation_prompt": null}
{"id": "5cf7ac90-dfb3-4ff9-b57a-0b0fa8dc77b6", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = int(10 + 0.02 * self.budget)  # Adaptive harmony memory size\n        bees_count = 5 + int(0.01 * self.budget)  # Variable bee count\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.3 + 0.1 * (self.budget - evals) / self.budget  # Adjusted pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.15  # Adjusted step size\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved selective update strategy\n                if new_fitness < np.percentile(harmony_memory_fitness, 75):  # Selectively update based on 75th percentile\n                    worst_idx = np.argmax(harmony_memory_fitness)\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced HSBO with adaptive harmony memory size and variable bee exploration strategies for improved convergence.", "configspace": "", "generation": 6, "fitness": 0.8982971764972393, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.025. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "5f5d6fb8-a310-4236-b5b8-2e185138739e", "metadata": {"aucs": [0.8698048764293069, 0.8944633007795764, 0.9306233522828343], "final_y": [0.11565074005004417, 0.11651432665802375, 0.11291765946596843]}, "mutation_prompt": null}
{"id": "75d8b2d3-db2c-4ed4-8cd1-bd960c7b8344", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            # Adaptive bees count based on fitness variance\n            bees_count = int(5 + 5 * (np.std(harmony_memory_fitness) / np.mean(harmony_memory_fitness)))\n            \n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Dynamic pitch adjustment through random local search\n                pitch_adj_rate = 0.2 + 0.8 * (np.std(harmony_memory_fitness) / np.mean(harmony_memory_fitness))\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Integrate adaptive bee count based on fitness variance to enhance exploration-exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.8712406968532198, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.014. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "01c02a25-92c6-4e68-9a46-752b9e777a1a", "metadata": {"aucs": [0.8512294967784471, 0.8819876778861386, 0.8805049158950737], "final_y": [0.13061088170331725, 0.11981398971882296, 0.11614042637506072]}, "mutation_prompt": null}
{"id": "04e816e0-9e28-418e-b198-2ed489c5bd2e", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 12\n        bees_count = 7\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                pitch_adj_rate = 0.3 + 0.1 * (self.budget - evals) / self.budget\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.6, 0.6) * (ub[i] - lb[i]) * 0.1\n                \n                new_solution = np.clip(new_solution, lb, ub)\n                \n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Dynamic selective update strategy\n                fitness_improvement_rate = (np.mean(harmony_memory_fitness) - new_fitness) / np.std(harmony_memory_fitness)\n                dynamic_percentile = min(75, max(50, 75 - fitness_improvement_rate * 5))\n                if new_fitness < np.percentile(harmony_memory_fitness, dynamic_percentile):\n                    worst_idx = np.argmax(harmony_memory_fitness)\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refined HSBO by using a dynamic selective update strategy based on a percentile that adapts with the fitness improvement rate, balancing exploration and exploitation more effectively.", "configspace": "", "generation": 7, "fitness": 0.876913715253417, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.004. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "5f5d6fb8-a310-4236-b5b8-2e185138739e", "metadata": {"aucs": [0.8772252012467396, 0.8721997582456704, 0.8813161862678409], "final_y": [0.12117395475930659, 0.12278597310120809, 0.1228380294461]}, "mutation_prompt": null}
{"id": "1daad8b6-6545-4a96-9324-70ae5ec63727", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Pitch adjustment through random local search\n                pitch_adj_rate = 0.2 * (1 - evals / self.budget)  # Adaptive pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Introduced an adaptive pitch adjustment rate based on iteration progress to balance exploration and exploitation dynamically. ", "configspace": "", "generation": 7, "fitness": 0.8467529657052285, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.018. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "874263f7-7591-47ef-8da6-1c05ac52d62f", "metadata": {"aucs": [0.8223619878945208, 0.8525311404011524, 0.8653657688200125], "final_y": [0.1442261686712033, 0.13359779329347055, 0.12546764905242136]}, "mutation_prompt": null}
{"id": "d67049d4-b76e-48d2-8d88-b51067335d4c", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Dynamic pitch adjustment through random local search\n                pitch_adj_rate = 0.2 + 0.8 * (np.std(harmony_memory_fitness) / np.mean(harmony_memory_fitness))\n                scaling_factor = 0.05 + 0.95 * (np.mean(harmony_memory_fitness) / (np.max(harmony_memory_fitness) + 1e-9))  # New scaling factor\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * scaling_factor\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced HSBO with adaptive scaling factor in pitch adjustment to better adapt to the fitness landscape.", "configspace": "", "generation": 7, "fitness": 0.8556702453814902, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.012. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "01c02a25-92c6-4e68-9a46-752b9e777a1a", "metadata": {"aucs": [0.8590847419472583, 0.8685177893225307, 0.8394082048746818], "final_y": [0.12363896897323179, 0.12432291324615052, 0.1313692212899622]}, "mutation_prompt": null}
{"id": "fad08949-09d7-44bb-875b-afbc0e50628f", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 12\n        bees_count = max(5, min(10, int(self.budget / 100)))  # Adaptive bee count based on budget\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                pitch_adj_rate = 0.3 + 0.1 * (self.budget - evals) / self.budget\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.6, 0.6) * (ub[i] - lb[i]) * 0.1\n                \n                new_solution = np.clip(new_solution, lb, ub) * 0.95 + 0.05 * np.random.uniform(lb, ub, self.dim)  # Improved boundary handling\n                \n                new_fitness = func(new_solution)\n                evals += 1\n\n                if new_fitness < np.percentile(harmony_memory_fitness, 75):\n                    worst_idx = np.argmax(harmony_memory_fitness)\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced HSBO with adaptive bee count and improved boundary handling for better exploration and exploitation.  ", "configspace": "", "generation": 7, "fitness": 0.8451372024262213, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.019. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "5f5d6fb8-a310-4236-b5b8-2e185138739e", "metadata": {"aucs": [0.8219222023915251, 0.8692115360895538, 0.8442778687975849], "final_y": [0.12723765831047062, 0.1286290798384483, 0.12849568652812837]}, "mutation_prompt": null}
{"id": "7cd7332c-3394-4f3c-9927-d8b251741824", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Adaptive harmony memory consideration\n                memory_consideration_rate = 0.8 - 0.4 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8))\n                if np.random.rand() < memory_consideration_rate:\n                    new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                else:\n                    new_solution = np.random.uniform(lb, ub, self.dim)\n                \n                # Enhanced dynamic pitch adjustment\n                pitch_adj_rate = 0.1 + 0.9 * (np.max(harmony_memory_fitness) - np.min(harmony_memory_fitness)) / (np.mean(harmony_memory_fitness) + 1e-8)\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        variance = (ub[i] - lb[i]) * 0.05 * np.sqrt(np.abs(new_solution[i]))\n                        new_solution[i] += np.random.uniform(-1, 1) * variance\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Introduced an adaptive memory consideration rate and improved pitch adjustment with fitness-weighted variance to enhance exploration and exploitation balance in the HSBO algorithm. ", "configspace": "", "generation": 8, "fitness": 0.8649123915398954, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.008. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ea2832f1-707a-4c30-9e22-a15c4b871c12", "metadata": {"aucs": [0.8540828396678251, 0.8738326922341515, 0.8668216427177093], "final_y": [0.12993949569135033, 0.12295942475845167, 0.12376253732284004]}, "mutation_prompt": null}
{"id": "7cd2a5b2-ec09-42c9-a8f7-6b58bb4e29be", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = int(10 + 0.02 * self.budget)  # Adaptive harmony memory size\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            fitness_variance = np.var(harmony_memory_fitness)\n            bees_count = max(5, int(10 + fitness_variance * 50))  # Dynamic bees count adjustment based on fitness variance\n            \n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.3 + 0.1 * (self.budget - evals) / self.budget  # Adjusted pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.15  # Adjusted step size\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved selective update strategy\n                if new_fitness < np.percentile(harmony_memory_fitness, 75):  # Selectively update based on 75th percentile\n                    worst_idx = np.argmax(harmony_memory_fitness)\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced HSBO with dynamic bees count adjustment based on fitness variance to improve exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8595373505388201, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.020. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "5cf7ac90-dfb3-4ff9-b57a-0b0fa8dc77b6", "metadata": {"aucs": [0.8722474294047906, 0.8313445016119076, 0.8750201205997616], "final_y": [0.11653583331363782, 0.13660955092182103, 0.1242906653622462]}, "mutation_prompt": null}
{"id": "6cbb8743-8ac6-4732-9458-04c5c62e7cf0", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 12  # Increased harmony memory size\n        bees_count = 7  # Increased bee count for better exploration\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.3 + 0.1 * (self.budget - evals) / self.budget  # Adjusted pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.6, 0.6) * (ub[i] - lb[i]) * 0.1  # Adjusted step size\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved selective update strategy\n                if new_fitness < np.percentile(harmony_memory_fitness, 75):  # Selectively update based on 75th percentile\n                    worst_idx = np.argmax(harmony_memory_fitness)\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n            \n            # Dynamically adjust harmony memory size\n            harmony_memory_size = max(5, int(12 * (self.budget - evals) / self.budget))\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Introduced a dynamic adaptation for the harmony memory size to enhance convergence and solution quality.", "configspace": "", "generation": 8, "fitness": 0.8805034493311622, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.008. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "5f5d6fb8-a310-4236-b5b8-2e185138739e", "metadata": {"aucs": [0.8761626148417259, 0.8734401563976086, 0.891907576754152], "final_y": [0.11370952506069698, 0.12778943444826352, 0.11815301880095197]}, "mutation_prompt": null}
{"id": "d44f4165-c435-4108-babd-baa3b0ec2ef0", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Dynamic pitch adjustment through random local search\n                pitch_adj_rate = 0.2 + 0.8 * (np.std(harmony_memory_fitness) / np.mean(harmony_memory_fitness))\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.1\n                \n                # Neighborhood search refinement\n                new_solution = new_solution + np.random.normal(0, 0.01, self.dim)\n\n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "The HSBO algorithm is enhanced by incorporating a neighborhood search strategy for better local refinement after the dynamic pitch adjustment step.", "configspace": "", "generation": 8, "fitness": 0.8623957927924111, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.024. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "01c02a25-92c6-4e68-9a46-752b9e777a1a", "metadata": {"aucs": [0.8953617917777488, 0.8500601295011814, 0.8417654570983032], "final_y": [0.11243883920633002, 0.12467564863972869, 0.13009636137795866]}, "mutation_prompt": null}
{"id": "b40374c0-19c2-4671-834e-8d652e34739d", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Dynamic pitch adjustment through random local search\n                pitch_adj_rate = 0.2 + 0.8 * (np.std(harmony_memory_fitness) / np.mean(harmony_memory_fitness))\n                diversity_factor = np.std(harmony_memory, axis=0).mean()  # Compute the diversity factor\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.1 * diversity_factor  # Adjust with diversity factor\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refine HSBO by incorporating adaptive bee movement based on solution diversity, which enhances convergence.", "configspace": "", "generation": 8, "fitness": 0.844029567849813, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.024. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "01c02a25-92c6-4e68-9a46-752b9e777a1a", "metadata": {"aucs": [0.8173155272548305, 0.8758725395089687, 0.8389006367856402], "final_y": [0.13398109740624953, 0.1263465508546796, 0.1333656727806367]}, "mutation_prompt": null}
{"id": "b07d6a4d-0529-4bf2-aaa9-8a0f82979860", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Dynamic pitch adjustment through random local search\n                pitch_adj_rate = 0.1 + 0.1 * np.var(harmony_memory_fitness)\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refinement of HSBO by updating pitch adjustment rate dynamically based on harmony memory fitness variance to enhance search efficiency.", "configspace": "", "generation": 9, "fitness": 0.8951360518362428, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.044. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "874263f7-7591-47ef-8da6-1c05ac52d62f", "metadata": {"aucs": [0.8340387949852237, 0.9141414786265964, 0.9372278818969083], "final_y": [0.13086837768862225, 0.11629108368817442, 0.11030230286094134]}, "mutation_prompt": null}
{"id": "5b49e2f3-0ca1-4b51-bba3-869e5af6b3de", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            # Dynamically adjust bees_count based on fitness diversity\n            bees_count = 5 + int(5 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8)))\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Dynamic pitch adjustment through random local search\n                pitch_adj_rate = 0.2 + 0.8 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8))\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Improved HSBO algorithm by introducing adaptive bee exploration strategies, dynamically adjusting the number of bees based on the standard deviation of fitness to balance exploration and exploitation.", "configspace": "", "generation": 9, "fitness": 0.9119214475711231, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.029. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "ea2832f1-707a-4c30-9e22-a15c4b871c12", "metadata": {"aucs": [0.8731734576100384, 0.9182119520210141, 0.9443789330823165], "final_y": [0.12114442058124897, 0.11650918655359987, 0.11073444127414067]}, "mutation_prompt": null}
{"id": "7c1e802c-c48f-42c4-a694-c7565c37b831", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 12  # Increased harmony memory size\n        bees_count = 7  # Increased bee count for better exploration\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.3 + 0.1 * (self.budget - evals) / self.budget  # Adjusted pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.6, 0.6) * (ub[i] - lb[i]) * 0.1  # Adjusted step size\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved selective update strategy\n                if new_fitness < np.percentile(harmony_memory_fitness, 75):  # Selectively update based on 75th percentile\n                    worst_idx = np.argsort(harmony_memory_fitness)[-2]  # Consider second-worst for updating\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced selective update strategy by considering both the worst and second-worst fitness in harmony memory for more robust solution replacement.", "configspace": "", "generation": 9, "fitness": 0.8991889006108719, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.036. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "5f5d6fb8-a310-4236-b5b8-2e185138739e", "metadata": {"aucs": [0.8492945083324619, 0.9147301660621153, 0.9335420274380385], "final_y": [0.13072341347199912, 0.11641542812558603, 0.11283689065002012]}, "mutation_prompt": null}
{"id": "7ca25a6b-df48-47c2-bef5-30972d8ddcdc", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Select best and random solution for better exploration\n                if np.random.rand() < 0.5:\n                    best_idx = np.argmin(harmony_memory_fitness)\n                    new_solution = np.copy(harmony_memory[best_idx])\n                else:\n                    new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment rate\n                pitch_adj_rate = 0.1 + (0.3 - 0.1) * (1 - evals / self.budget)\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.2\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced HSBO with adaptive pitch adjustment rate and selection of best and random solutions to enhance exploration and exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.924047826559319, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.009. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "874263f7-7591-47ef-8da6-1c05ac52d62f", "metadata": {"aucs": [0.9181926727135877, 0.9178265775080039, 0.9361242294563653], "final_y": [0.11388674814742239, 0.11650619700627396, 0.11303040431284794]}, "mutation_prompt": null}
{"id": "1a5c7a1d-587d-48fd-b85a-6e780fc10407", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Stochastic memory consideration\n                selected_idx = np.random.choice(harmony_memory_size)\n                new_solution = np.copy(harmony_memory[selected_idx])\n                \n                # Adaptive pitch adjustment with stochastic component\n                fitness_std = np.std(harmony_memory_fitness)\n                fitness_mean = np.mean(harmony_memory_fitness)\n                pitch_adj_rate = 0.2 + 0.8 * (fitness_std / (fitness_mean + 1e-8))\n                stochastic_factor = np.random.rand() * pitch_adj_rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        adjustment = np.random.uniform(-1, 1) * (ub[i] - lb[i]) * stochastic_factor\n                        new_solution[i] += adjustment\n                \n                # Adaptive neighborhood search\n                if np.random.rand() < 0.5:\n                    neighbor = np.random.randint(0, harmony_memory_size)\n                    new_solution = 0.5 * (new_solution + harmony_memory[neighbor])\n                \n                new_solution = np.clip(new_solution, lb, ub)\n                \n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Replace using a probabilistic acceptance criterion\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Introduce an adaptive neighborhood search mechanism and stochastic component in solution update to enhance HSBO convergence.", "configspace": "", "generation": 9, "fitness": 0.9200727169637316, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.014. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ea2832f1-707a-4c30-9e22-a15c4b871c12", "metadata": {"aucs": [0.9030449851028379, 0.9204379587230663, 0.9367352070652905], "final_y": [0.11218898311870718, 0.11683836600448982, 0.11239158632695634]}, "mutation_prompt": null}
{"id": "1d0c62ff-566e-420e-9536-003987022848", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through random local search\n                pitch_adj_rate = np.exp(-harmony_memory_fitness.min() / (1 + harmony_memory_fitness.std()))\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n                    # Dynamic memory size adjustment\n                    harmony_memory_size = min(max(5, int(harmony_memory_size * 1.1)), 15)\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced HSBO by introducing adaptive pitch adjustment based on solution quality and dynamic harmony memory size adjustment to better balance exploration and exploitation.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 10 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 10 is out of bounds for axis 0 with size 10')", "parent_id": "874263f7-7591-47ef-8da6-1c05ac52d62f", "metadata": {}, "mutation_prompt": null}
{"id": "44025106-5893-43bc-a431-0d7dd315230f", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Stochastic memory consideration\n                selected_idx = np.random.choice(harmony_memory_size)\n                new_solution = np.copy(harmony_memory[selected_idx])\n                \n                # Adaptive pitch adjustment with stochastic component\n                fitness_std = np.std(harmony_memory_fitness)\n                fitness_mean = np.mean(harmony_memory_fitness)\n                pitch_adj_rate = 0.25 + 0.8 * (fitness_std / (fitness_mean + 1e-8))  # Slightly increased\n                stochastic_factor = np.random.rand() * pitch_adj_rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        adjustment = np.random.uniform(-1, 1) * (ub[i] - lb[i]) * stochastic_factor\n                        new_solution[i] += adjustment\n                \n                # Adaptive neighborhood search\n                if np.random.rand() < 0.5:\n                    neighbor = np.random.randint(0, harmony_memory_size)\n                    new_solution = 0.5 * (new_solution + harmony_memory[neighbor])\n                \n                new_solution = np.clip(new_solution, lb, ub)\n                \n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Replace using a probabilistic acceptance criterion\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Slightly increase the pitch adjustment rate to potentially improve exploration and exploitation balance in HSBO.", "configspace": "", "generation": 10, "fitness": 0.9037852706878556, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.015. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "1a5c7a1d-587d-48fd-b85a-6e780fc10407", "metadata": {"aucs": [0.9056554705422383, 0.8849694144022154, 0.9207309271191133], "final_y": [0.10982140901673476, 0.11639271757847247, 0.11247212203507773]}, "mutation_prompt": null}
{"id": "158d5a97-8c92-467a-8018-9cb896e29908", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            # Dynamically adjust bees_count based on fitness diversity\n            bees_count = 5 + int(5 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8)))\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Dynamic pitch adjustment through random local search\n                pitch_adj_rate = 0.2 + 0.8 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8))\n                scaling_factor = np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8)\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.1 * scaling_factor\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Improved HSBO algorithm by augmenting pitch adjustment through adaptive scaling based on fitness variance to enhance local search capabilities.", "configspace": "", "generation": 10, "fitness": 0.8300138491716765, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.110. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.046.", "error": "", "parent_id": "5b49e2f3-0ca1-4b51-bba3-869e5af6b3de", "metadata": {"aucs": [0.674785452672493, 0.8986044799321751, 0.9166516149103614], "final_y": [0.21149687473044776, 0.11658230038799633, 0.11259307547615705]}, "mutation_prompt": null}
{"id": "4825105f-06d9-4140-bb42-a5fd40c6027d", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            # Dynamically adjust bees_count based on fitness diversity\n            bees_count = 5 + int(5 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8)))\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Dynamic pitch adjustment through random local search\n                pitch_adj_rate = 0.2 + 0.8 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8))\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.1  # Adjusted range for precision\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refined exploration by enhancing local search with more precise pitch adjustment to improve solution quality.", "configspace": "", "generation": 10, "fitness": 0.8849787919534613, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.035. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "5b49e2f3-0ca1-4b51-bba3-869e5af6b3de", "metadata": {"aucs": [0.8365661755478091, 0.9007276339759743, 0.9176425663366006], "final_y": [0.13126767242700366, 0.11673339881012557, 0.11110073193779857]}, "mutation_prompt": null}
{"id": "6a0b3b07-2a7f-400d-ac48-4d878af57a0a", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 12  # Increased harmony memory size\n        bees_count = 7  # Increased bee count for better exploration\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.3 + 0.1 * (self.budget - evals) / self.budget  # Adjusted pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.1  # Adjusted step size\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved selective update strategy\n                if new_fitness < np.percentile(harmony_memory_fitness, 50):  # Selectively update based on 50th percentile\n                    worst_idx = np.argmax(harmony_memory_fitness)\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refine HSBO by adjusting pitch step size and updating based on the 50th percentile for better balance.", "configspace": "", "generation": 10, "fitness": 0.877741292609625, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.032. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "5f5d6fb8-a310-4236-b5b8-2e185138739e", "metadata": {"aucs": [0.8349488206497462, 0.886092298552193, 0.9121827586269359], "final_y": [0.1308546585746494, 0.11668399444142807, 0.11247787529026898]}, "mutation_prompt": null}
{"id": "29bcf300-96c2-4ecb-9bc6-534bae13f615", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Dynamic pitch adjustment through random local search\n                pitch_adj_rate = 0.1 + 0.1 * (evals / self.budget)\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection targeting the worst solution\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Improved HSBO by introducing dynamic pitch adjustment rate and targeted exploration of the worst solution.", "configspace": "", "generation": 11, "fitness": 0.8851552248204625, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.025. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "874263f7-7591-47ef-8da6-1c05ac52d62f", "metadata": {"aucs": [0.8513926069335143, 0.8949802664814297, 0.9090928010464436], "final_y": [0.13054537910977448, 0.12011339888074546, 0.11083636555748311]}, "mutation_prompt": null}
{"id": "534df8f5-d4bb-43b8-b820-99209046ad65", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Pitch adjustment through random local search\n                pitch_adj_rate = 0.2 * (1 - (np.min(harmony_memory_fitness) / np.max(harmony_memory_fitness)))\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhance the pitch adjustment by introducing a dynamic adjustment based on solution fitness relative to the best known fitness to improve exploration and exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.8278604180303245, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.110. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.046.", "error": "", "parent_id": "874263f7-7591-47ef-8da6-1c05ac52d62f", "metadata": {"aucs": [0.6740698633506605, 0.8857429217606965, 0.9237684689796167], "final_y": [0.21185908847573987, 0.11647608983657076, 0.11161030258047411]}, "mutation_prompt": null}
{"id": "48ab088e-0ecf-4af3-9b47-2c7bfd989ee7", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            # Dynamically adjust bees_count based on fitness diversity\n            bees_count = 5 + int(5 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8)))\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Dynamic pitch adjustment through random local search\n                pitch_adj_rate = 0.2 + 0.8 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8))\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-2, 2) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhance exploration by increasing the range of dynamic pitch adjustment to improve solution diversity.", "configspace": "", "generation": 11, "fitness": 0.9014713109198756, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.015. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "5b49e2f3-0ca1-4b51-bba3-869e5af6b3de", "metadata": {"aucs": [0.8823255176819658, 0.9027473889642349, 0.9193410261134263], "final_y": [0.11892339040791922, 0.11627123352336344, 0.11297304865615154]}, "mutation_prompt": null}
{"id": "5d064ea7-25f0-494f-b458-415a9920dc80", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Pitch adjustment through random local search\n                pitch_adj_rate = 0.3  # Increased pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refined HSBO by increasing the pitch adjustment rate to enhance exploration capability.", "configspace": "", "generation": 11, "fitness": 0.9087762753291342, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "874263f7-7591-47ef-8da6-1c05ac52d62f", "metadata": {"aucs": [0.9009685418582413, 0.900807794791918, 0.9245524893372437], "final_y": [0.11344246307938921, 0.11648552351732133, 0.11033843462742576]}, "mutation_prompt": null}
{"id": "0c36905f-2cc0-49f7-9512-d66c90979d53", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Stochastic memory consideration\n                selected_idx = np.random.choice(harmony_memory_size)\n                new_solution = np.copy(harmony_memory[selected_idx])\n                \n                # Adaptive pitch adjustment with Gaussian factor\n                fitness_std = np.std(harmony_memory_fitness)\n                fitness_mean = np.mean(harmony_memory_fitness)\n                pitch_adj_rate = 0.2 + 0.8 * (fitness_std / (fitness_mean + 1e-8))\n                stochastic_factor = np.random.randn() * pitch_adj_rate  # Changed rand() to randn()\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        adjustment = np.random.uniform(-1, 1) * (ub[i] - lb[i]) * stochastic_factor\n                        new_solution[i] += adjustment\n                \n                # Adaptive neighborhood search\n                if np.random.rand() < 0.5:\n                    neighbor = np.random.randint(0, harmony_memory_size)\n                    new_solution = 0.5 * (new_solution + harmony_memory[neighbor])\n                \n                new_solution = np.clip(new_solution, lb, ub)\n                \n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Replace using a probabilistic acceptance criterion\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refining stochastic pitch adjustment by incorporating a Gaussian factor for improved diversity in solution updates.", "configspace": "", "generation": 11, "fitness": 0.899677531954079, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.024. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "1a5c7a1d-587d-48fd-b85a-6e780fc10407", "metadata": {"aucs": [0.8668834269805452, 0.9082681188685319, 0.9238810500131593], "final_y": [0.1266482865418761, 0.1166197900224436, 0.11260333992087035]}, "mutation_prompt": null}
{"id": "685d2c11-725b-42c3-88c5-4c7ce01ea0ad", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Adaptive memory consideration rate\n                fitness_variance = np.var(harmony_memory_fitness)\n                mem_consideration_rate = 0.9 * (1 - fitness_variance / (fitness_variance + 1e-8))\n                if np.random.rand() < mem_consideration_rate:\n                    selected_idx = np.random.choice(harmony_memory_size)\n                    new_solution = np.copy(harmony_memory[selected_idx])\n                \n                    # Adaptive pitch adjustment with stochastic component\n                    fitness_std = np.std(harmony_memory_fitness)\n                    fitness_mean = np.mean(harmony_memory_fitness)\n                    pitch_adj_rate = 0.2 + 0.8 * (fitness_std / (fitness_mean + 1e-8))\n                    stochastic_factor = np.random.rand() * pitch_adj_rate\n                    for i in range(self.dim):\n                        if np.random.rand() < pitch_adj_rate:\n                            adjustment = np.random.uniform(-1, 1) * (ub[i] - lb[i]) * stochastic_factor\n                            new_solution[i] += adjustment\n                \n                    # Adaptive neighborhood search\n                    if np.random.rand() < 0.5:\n                        neighbor = np.random.randint(0, harmony_memory_size)\n                        new_solution = 0.5 * (new_solution + harmony_memory[neighbor])\n                \n                    new_solution = np.clip(new_solution, lb, ub)\n                \n                    new_fitness = func(new_solution)\n                    evals += 1\n\n                    # Replace using a probabilistic acceptance criterion\n                    worst_idx = np.argmax(harmony_memory_fitness)\n                    if new_fitness < harmony_memory_fitness[worst_idx]:\n                        harmony_memory[worst_idx] = new_solution\n                        harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhance HSBO by introducing an adaptive memory consideration rate based on fitness variance to improve exploitation and exploration balance.", "configspace": "", "generation": 12, "fitness": 0.9013487869626918, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.022. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "1a5c7a1d-587d-48fd-b85a-6e780fc10407", "metadata": {"aucs": [0.871549544458767, 0.9080440988389846, 0.9244527175903235], "final_y": [0.12103942689505376, 0.11667911444994405, 0.1106619915722793]}, "mutation_prompt": null}
{"id": "58a6b610-d3c5-4c72-aec4-102f046d5c7f", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            # Dynamically adjust harmony memory size based on fitness diversity\n            harmony_memory_size = 10 + int(5 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8)))\n            harmony_memory = harmony_memory[:harmony_memory_size]\n            harmony_memory_fitness = harmony_memory_fitness[:harmony_memory_size]\n            \n            bees_count = 5 + int(5 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8)))\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Improved pitch adjustment strategy\n                pitch_adj_rate = 0.2 + 0.6 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8))\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.15\n                \n                new_solution = np.clip(new_solution, lb, ub)\n                \n                new_fitness = func(new_solution)\n                evals += 1\n\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "The modified HSBO introduces a selective exploration strategy by integrating a diversity-based pitch adjustment mechanism and dynamic memory size to improve convergence.", "configspace": "", "generation": 12, "fitness": 0.903809229181587, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.002. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "5b49e2f3-0ca1-4b51-bba3-869e5af6b3de", "metadata": {"aucs": [0.9064893528335292, 0.9006831600467984, 0.9042551746644336], "final_y": [0.11387868442381288, 0.11724580634723902, 0.11236596540482113]}, "mutation_prompt": null}
{"id": "d35fcd09-4ac6-4ceb-9ac5-386b46f36892", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Select best and random solution for better exploration\n                if np.random.rand() < 0.5:\n                    best_idx = np.argmin(harmony_memory_fitness)\n                    new_solution = np.copy(harmony_memory[best_idx])\n                else:\n                    new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment rate\n                pitch_adj_rate = 0.1 + (0.3 - 0.1) * (1 - evals / self.budget)\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.2\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n            \n            # Dynamic harmony memory size reduction\n            harmony_memory_size = max(5, int(10 * (1 - evals / self.budget)))\n            harmony_memory = harmony_memory[:harmony_memory_size]\n            harmony_memory_fitness = harmony_memory_fitness[:harmony_memory_size]\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refined HSBO by incorporating a dynamic harmony memory size based on a linear schedule, reducing memory size as evaluations increase to focus on exploitation.", "configspace": "", "generation": 12, "fitness": 0.8977185941122671, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.023. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "7ca25a6b-df48-47c2-bef5-30972d8ddcdc", "metadata": {"aucs": [0.8701384678613077, 0.8970769298112454, 0.9259403846642481], "final_y": [0.1304566173834999, 0.11655215421944254, 0.11240382507511892]}, "mutation_prompt": null}
{"id": "fada2545-d1e1-4c0a-810e-4888a99bc6f3", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n\n                # Dynamic memory selection mechanism\n                selected_idx = np.random.choice(harmony_memory_size, p=harmony_memory_fitness / harmony_memory_fitness.sum())\n                new_solution = np.copy(harmony_memory[selected_idx])\n                \n                # Adaptive pitch adjustment with stochastic component\n                fitness_std = np.std(harmony_memory_fitness)\n                fitness_mean = np.mean(harmony_memory_fitness)\n                pitch_adj_rate = 0.2 + 0.8 * (fitness_std / (fitness_mean + 1e-8))\n                stochastic_factor = np.random.rand() * pitch_adj_rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        adjustment = np.random.uniform(-1, 1) * (ub[i] - lb[i]) * stochastic_factor\n                        new_solution[i] += adjustment\n                \n                # Multi-point neighborhood search\n                neighbors = np.random.choice(harmony_memory_size, 2, replace=False)\n                new_solution = np.mean([new_solution, harmony_memory[neighbors[0]], harmony_memory[neighbors[1]]], axis=0)\n                \n                new_solution = np.clip(new_solution, lb, ub)\n                \n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Replace using a probabilistic acceptance criterion\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Introduce a dynamic selection mechanism and a multi-point neighborhood search to further enhance exploration and exploitation in HSBO.", "configspace": "", "generation": 12, "fitness": 0.8840526108983268, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.029. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "1a5c7a1d-587d-48fd-b85a-6e780fc10407", "metadata": {"aucs": [0.8502764039754962, 0.8808497438876016, 0.9210316848318824], "final_y": [0.11756672585666494, 0.12632063100994295, 0.11310961173221268]}, "mutation_prompt": null}
{"id": "023431cc-899d-4bfe-a14d-b2ce51873d2d", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Stochastic memory consideration\n                selected_idx = np.random.choice(harmony_memory_size)\n                new_solution = np.copy(harmony_memory[selected_idx])\n                \n                # Adaptive pitch adjustment with stochastic component\n                fitness_std = np.std(harmony_memory_fitness)\n                fitness_mean = np.mean(harmony_memory_fitness)\n                pitch_adj_rate = 0.2 + 0.8 * (fitness_std / (fitness_mean + 1e-8))\n                stochastic_factor = np.random.rand() * pitch_adj_rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        adjustment = np.random.uniform(-1, 1) * (ub[i] - lb[i]) * stochastic_factor\n                        new_solution[i] += adjustment\n                \n                # Adaptive neighborhood search\n                if np.random.rand() < 0.5:\n                    neighbor = np.random.randint(0, harmony_memory_size)\n                    new_solution = 0.5 * (new_solution + harmony_memory[neighbor])\n                \n                new_solution = np.clip(new_solution, lb, ub)\n                \n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Replace using a probabilistic acceptance criterion\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refine HSBO by introducing a hybrid search strategy that combines global and local search to enhance exploitation capability.", "configspace": "", "generation": 12, "fitness": 0.8728223190091154, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.043. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "1a5c7a1d-587d-48fd-b85a-6e780fc10407", "metadata": {"aucs": [0.8127249213950525, 0.8956820931019311, 0.9100599425303628], "final_y": [0.14548518409306654, 0.11675228842765584, 0.11124365173646822]}, "mutation_prompt": null}
{"id": "351dd11f-4af1-4cd3-9f5a-064474d51f5b", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            # Dynamically adjust bees_count based on fitness diversity\n            bees_count = 5 + int(5 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8)))\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Dynamic pitch adjustment through random local search\n                pitch_adj_rate = 0.2 + 0.8 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8))\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1.5, 1.5) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = lb + (new_solution - lb) % (ub - lb)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced HSBO with improved boundary handling and increased exploration range in the pitch adjustment phase to improve solution diversity.", "configspace": "", "generation": 13, "fitness": 0.7823695511337779, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.058. And the mean value of best solutions found was 0.162 (0. is the best) with standard deviation 0.028.", "error": "", "parent_id": "5b49e2f3-0ca1-4b51-bba3-869e5af6b3de", "metadata": {"aucs": [0.8590350188509321, 0.76890311738062, 0.7191705171697818], "final_y": [0.12501741408306277, 0.1702433386818767, 0.19103396660959382]}, "mutation_prompt": null}
{"id": "323fcb86-65bc-4f37-b0e9-457e1266ad82", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Select best and random solution for better exploration\n                if np.random.rand() < 0.5:\n                    best_idx = np.argmin(harmony_memory_fitness)\n                    new_solution = np.copy(harmony_memory[best_idx])\n                else:\n                    new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment rate\n                pitch_adj_rate = 0.1 + (0.3 - 0.1) * (1 - evals / self.budget)\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.2\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n            \n            # Dynamically adjust harmony memory size based on fitness variance\n            fitness_variance = np.var(harmony_memory_fitness)\n            if fitness_variance > np.mean(harmony_memory_fitness):  # New adjustment condition\n                harmony_memory_size = min(harmony_memory_size + 1, len(harmony_memory_fitness))\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhance HSBO by dynamically adjusting the harmony memory size based on fitness variance for better adaptability.", "configspace": "", "generation": 13, "fitness": 0.8125490493869706, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.040. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "7ca25a6b-df48-47c2-bef5-30972d8ddcdc", "metadata": {"aucs": [0.8651780451052641, 0.76890311738062, 0.8035659856750278], "final_y": [0.13073821188435164, 0.1702433386818767, 0.15558205726068286]}, "mutation_prompt": null}
{"id": "fb57467f-d416-4b87-9a17-16ef7e415e94", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Select best and random solution for better exploration\n                if np.random.rand() < 0.5:\n                    best_idx = np.argmin(harmony_memory_fitness)\n                    new_solution = np.copy(harmony_memory[best_idx])\n                else:\n                    new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment rate\n                pitch_adj_rate = 0.1 + (0.3 - 0.1) * (1 - evals / self.budget)\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.2\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Dynamic harmony memory size adjustment\n                if evals % 20 == 0 and harmony_memory_size < 20:\n                    harmony_memory_size += 1\n                    harmony_memory = np.vstack((harmony_memory, np.random.uniform(lb, ub, self.dim)))\n                    harmony_memory_fitness = np.append(harmony_memory_fitness, func(harmony_memory[-1]))\n                \n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Improved HSBO with dynamic adjustment of harmony memory size to enhance adaptability and convergence.", "configspace": "", "generation": 13, "fitness": 0.8503580315728715, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.064. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "7ca25a6b-df48-47c2-bef5-30972d8ddcdc", "metadata": {"aucs": [0.9254310487877284, 0.76890311738062, 0.856739928550266], "final_y": [0.11137869492765051, 0.1702433386818767, 0.13624465418480558]}, "mutation_prompt": null}
{"id": "064df928-2032-4900-9073-70031883103a", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Select best and random solution for better exploration\n                if np.random.rand() < 0.4:  # Changed from 0.5 to 0.4 for more exploitation\n                    best_idx = np.argmin(harmony_memory_fitness)\n                    new_solution = np.copy(harmony_memory[best_idx])\n                else:\n                    new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment rate\n                pitch_adj_rate = 0.1 + (0.4 - 0.1) * (1 - evals / self.budget)  # Changed upper limit from 0.3 to 0.4\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.6, 0.6) * (ub[i] - lb[i]) * 0.2  # Changed range from 0.5 to 0.6\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refined HSBO with dynamic adaptation of exploration-exploitation balance and improved pitch adjustment for enhanced convergence.", "configspace": "", "generation": 13, "fitness": 0.8080624989169544, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.067. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.025.", "error": "", "parent_id": "7ca25a6b-df48-47c2-bef5-30972d8ddcdc", "metadata": {"aucs": [0.9024204941575454, 0.76890311738062, 0.7528638852126973], "final_y": [0.1205409118859071, 0.1702433386818767, 0.17594624180956997]}, "mutation_prompt": null}
{"id": "05c4d3e9-5f13-439c-afb2-461753757dd8", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Stochastic memory consideration\n                selected_idx = np.random.choice(harmony_memory_size)\n                new_solution = np.copy(harmony_memory[selected_idx])\n                \n                # Adaptive pitch adjustment with stochastic component\n                fitness_std = np.std(harmony_memory_fitness)\n                fitness_mean = np.mean(harmony_memory_fitness)\n                pitch_adj_rate = 0.2 + 0.8 * (fitness_std / (fitness_mean + 1e-8))\n                stochastic_factor = np.random.rand() * pitch_adj_rate\n                best_harmony = harmony_memory[np.argmin(harmony_memory_fitness)]\n                dynamic_factor = np.linalg.norm(new_solution - best_harmony) / self.dim\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        adjustment = np.random.uniform(-1, 1) * (ub[i] - lb[i]) * stochastic_factor * dynamic_factor\n                        new_solution[i] += adjustment\n                \n                # Adaptive neighborhood search\n                if np.random.rand() < 0.5:\n                    neighbor = np.random.randint(0, harmony_memory_size)\n                    new_solution = 0.5 * (new_solution + harmony_memory[neighbor])\n                \n                new_solution = np.clip(new_solution, lb, ub)\n                \n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Replace using a probabilistic acceptance criterion\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Introduce an additional dynamic pitch adjustment influenced by the best harmony to further improve convergence.", "configspace": "", "generation": 13, "fitness": 0.8131766053002556, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.099. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.041.", "error": "", "parent_id": "1a5c7a1d-587d-48fd-b85a-6e780fc10407", "metadata": {"aucs": [0.6740698633506605, 0.868838212065608, 0.8966217404844984], "final_y": [0.21185908847573987, 0.13351946715550111, 0.11756324528021522]}, "mutation_prompt": null}
{"id": "6144c12b-3727-4094-aa87-c3f85546d734", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            # Dynamic harmony memory size based on convergence\n            if evals % 10 == 0:\n                mean_fitness = np.mean(harmony_memory_fitness)\n                if np.std(harmony_memory_fitness) < 0.01 * mean_fitness:\n                    harmony_memory_size = min(harmony_memory_size + 1, self.budget // self.dim)\n\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Select best and random solution for better exploration\n                if np.random.rand() < 0.5:\n                    best_idx = np.argmin(harmony_memory_fitness)\n                    new_solution = np.copy(harmony_memory[best_idx])\n                else:\n                    new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment rate\n                pitch_adj_rate = 0.1 + (0.3 - 0.1) * (1 - evals / self.budget)\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.2\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced HSBO with dynamic harmony memory size based on convergence to improve exploration and exploitation balance.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 13 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 13 is out of bounds for axis 0 with size 10')", "parent_id": "7ca25a6b-df48-47c2-bef5-30972d8ddcdc", "metadata": {}, "mutation_prompt": null}
{"id": "aa310bb6-e144-4cea-87bf-007fa15fcc22", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 12  # Increased harmony memory size\n        bees_count = 7  # Increased bee count for better exploration\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.3 + 0.1 * (self.budget - evals) / self.budget  # Adjusted pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.6, 0.6) * (ub[i] - lb[i]) * 0.1  # Adjusted step size\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved selective update strategy\n                if new_fitness < np.percentile(harmony_memory_fitness, 70):  # Selectively update based on 70th percentile\n                    worst_idx = np.argmax(harmony_memory_fitness)\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced selective update strategy by adjusting the percentile threshold for solution replacement.", "configspace": "", "generation": 14, "fitness": 0.8739411027598024, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.024. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5f5d6fb8-a310-4236-b5b8-2e185138739e", "metadata": {"aucs": [0.8394754027593407, 0.8919638010629912, 0.8903841044570754], "final_y": [0.1306891516017572, 0.12096133037045453, 0.12267075517454806]}, "mutation_prompt": null}
{"id": "1a4ef836-04a4-40b0-8b32-5d5b75dc6279", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            # Dynamically adjust harmony_memory_size based on fitness diversity\n            harmony_memory_size = 10 + int(5 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8)))\n            harmony_memory = np.resize(harmony_memory, (harmony_memory_size, self.dim))\n            harmony_memory_fitness = np.resize(harmony_memory_fitness, harmony_memory_size)\n\n            bees_count = 5 + int(5 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8)))\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Dynamic pitch adjustment through enhanced local search\n                pitch_adj_rate = 0.3 + 0.7 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8))\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.2\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Improved HSBO with adaptive harmony memory size and enhanced pitch adjustment for dynamic exploration-exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.8706741088253196, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.014. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "5b49e2f3-0ca1-4b51-bba3-869e5af6b3de", "metadata": {"aucs": [0.8524067201166393, 0.8868316458803011, 0.8727839604790186], "final_y": [0.13192974663777401, 0.11866521174737299, 0.11955000437290175]}, "mutation_prompt": null}
{"id": "90b45f5f-bff9-4613-9fff-c8a3faf960e7", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Select best and random solution for better exploration\n                if np.random.rand() < 0.5:\n                    best_idx = np.argmin(harmony_memory_fitness)\n                    new_solution = np.copy(harmony_memory[best_idx])\n                else:\n                    new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment rate\n                pitch_adj_rate = 0.05 + (0.35 - 0.05) * (1 - evals / self.budget)  # Modified line\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.2\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refined HSBO with enhanced pitch adjustment rate range for improved exploration and solution diversity.", "configspace": "", "generation": 14, "fitness": 0.8909258199823373, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.008. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "7ca25a6b-df48-47c2-bef5-30972d8ddcdc", "metadata": {"aucs": [0.8793656129086646, 0.8983346908654755, 0.895077156172872], "final_y": [0.1253485199096469, 0.12072864240207604, 0.1150480101515945]}, "mutation_prompt": null}
{"id": "08cecc07-628d-4253-b195-bb7467d22865", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through random local search\n                diversity = np.std(harmony_memory, axis=0).mean()  # Calculate diversity\n                pitch_adj_rate = 0.3 + 0.2 * diversity  # Adaptive pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced HSBO by introducing adaptive pitch adjustment rate based on solution diversity to balance exploration and exploitation.", "configspace": "", "generation": 14, "fitness": 0.8965110217106963, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.014. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "5d064ea7-25f0-494f-b458-415a9920dc80", "metadata": {"aucs": [0.8826504524609002, 0.8917241094821444, 0.9151585031890441], "final_y": [0.1244666634920859, 0.11938051869199418, 0.11293008975656493]}, "mutation_prompt": null}
{"id": "bbd62b64-26f5-44a8-b5f5-906490167d7c", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment based on fitness\n                pitch_adj_rate = 0.2 + 0.4 * (1 - (np.min(harmony_memory_fitness) / np.max(harmony_memory_fitness)))\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.1\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refined HSBO by implementing adaptive pitch adjustment rates based on current solution quality to better balance exploration and exploitation.", "configspace": "", "generation": 15, "fitness": 0.8995566278113616, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.034. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "5d064ea7-25f0-494f-b458-415a9920dc80", "metadata": {"aucs": [0.8545650148278092, 0.9078892371030152, 0.9362156315032606], "final_y": [0.13059283055464832, 0.12034088087924555, 0.11233847429501886]}, "mutation_prompt": null}
{"id": "832fae04-ec2a-49e4-9466-9eccdd021f72", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 12\n        bees_count = 7\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            fitness_variance = np.var(harmony_memory_fitness)\n            dynamic_bees_count = max(3, int(bees_count * (1 + fitness_variance)))  # Dynamic bee count\n            for bee in range(dynamic_bees_count):\n                if evals >= self.budget:\n                    break\n                \n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                pitch_adj_rate = 0.3 + 0.1 * (self.budget - evals) / self.budget\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.6, 0.6) * (ub[i] - lb[i]) * 0.1\n                \n                new_solution = np.clip(new_solution, lb, ub)\n                \n                new_fitness = func(new_solution)\n                evals += 1\n\n                if new_fitness < np.percentile(harmony_memory_fitness, 50):  # Update based on 50th percentile\n                    worst_idx = np.argmax(harmony_memory_fitness)\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced HSBO by incorporating a dynamic bee count adjustment based on fitness variance and improved solution replacement strategy targeting the bottom 50th percentile.", "configspace": "", "generation": 15, "fitness": 0.898842114385254, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.042. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "5f5d6fb8-a310-4236-b5b8-2e185138739e", "metadata": {"aucs": [0.8405787306622874, 0.9185759399361694, 0.9373716725573049], "final_y": [0.13210123946992125, 0.11639267704763179, 0.11021632160072115]}, "mutation_prompt": null}
{"id": "ea70ed63-93b7-43a5-8efa-b0560976fafd", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 12  # Increased harmony memory size\n        bees_count = 7  # Increased bee count for better exploration\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.3 + 0.1 * (self.budget - evals) / self.budget  # Adjusted pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        step_size = 0.1 if harmony_memory_fitness[np.argmin(harmony_memory_fitness)] < 0.1 else 0.2  # Dynamically adjust step size\n                        new_solution[i] += np.random.uniform(-0.6, 0.6) * (ub[i] - lb[i]) * step_size\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved selective update strategy\n                if new_fitness < np.percentile(harmony_memory_fitness, 75):  # Selectively update based on 75th percentile\n                    worst_idx = np.argmax(harmony_memory_fitness)\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Introduced an adaptive approach to dynamically adjust the step size based on solution quality.", "configspace": "", "generation": 15, "fitness": 0.9181250027493725, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.015. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "5f5d6fb8-a310-4236-b5b8-2e185138739e", "metadata": {"aucs": [0.8984196085914523, 0.922887240339374, 0.9330681593172908], "final_y": [0.11212989892740088, 0.11637618871817745, 0.11271452151520689]}, "mutation_prompt": null}
{"id": "459cd504-b145-4638-877a-f655c95f096c", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            # Dynamic bees count based on remaining budget\n            bees_count = max(1, int(5 * (1 - evals / self.budget)))\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Select best and random solution for better exploration\n                if np.random.rand() < 0.5:\n                    best_idx = np.argmin(harmony_memory_fitness)\n                    new_solution = np.copy(harmony_memory[best_idx])\n                else:\n                    new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment rate\n                pitch_adj_rate = 0.1 + (0.3 - 0.1) * (1 - evals / self.budget)\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.2\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refined HSBO by introducing a dynamic number of bees based on the remaining budget to enhance adaptive exploration.", "configspace": "", "generation": 15, "fitness": 0.915984031711523, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.014. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "7ca25a6b-df48-47c2-bef5-30972d8ddcdc", "metadata": {"aucs": [0.8973509952526164, 0.9207155674749428, 0.9298855324070098], "final_y": [0.12070178674080723, 0.11629421902867954, 0.11056062871035843]}, "mutation_prompt": null}
{"id": "adca6e09-c87b-43b3-8e93-0975780ce410", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        decay_factor = 0.95  # New decay factor\n\n        while evals < self.budget:\n            bees_count = 5 + int(5 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8)))\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                pitch_adj_rate = 0.2 + 0.8 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8))\n                pitch_adj_rate *= decay_factor ** evals  # Apply decay factor\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.1\n                \n                new_solution = np.clip(new_solution, lb, ub)\n                \n                new_fitness = func(new_solution)\n                evals += 1\n\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhance HSBO by introducing a decay factor to the pitch adjustment rate, improving exploration-exploitation balance.", "configspace": "", "generation": 15, "fitness": 0.8455941482490559, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.120. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.045.", "error": "", "parent_id": "5b49e2f3-0ca1-4b51-bba3-869e5af6b3de", "metadata": {"aucs": [0.6768645089500118, 0.9186766746618715, 0.9412412611352844], "final_y": [0.2104276777588231, 0.11637623976541078, 0.11229679849711838]}, "mutation_prompt": null}
{"id": "ff076730-fa21-418c-801e-fd5b2ed44e8c", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            # Dynamically adjust bees_count based on fitness diversity\n            bees_count = 5 + int(5 * (np.std(harmony_memory_fitness) / (np.mean(harmony_memory_fitness) + 1e-8)))\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Multilevel selection\n                prob_select = np.exp(-harmony_memory_fitness)\n                prob_select /= np.sum(prob_select)\n                selected_idx = np.random.choice(harmony_memory_size, p=prob_select)\n                new_solution = np.copy(harmony_memory[selected_idx])\n                \n                # Fitness-proportional learning\n                pitch_adj_rate = 0.2 + 0.8 * (1 / (1 + np.min(harmony_memory_fitness)))\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.2\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Introduce multilevel selection and fitness-proportional learning to enhance adaptive exploration and exploitation balance in HSBO.", "configspace": "", "generation": 16, "fitness": 0.8982958923494109, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.039. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "5b49e2f3-0ca1-4b51-bba3-869e5af6b3de", "metadata": {"aucs": [0.8433057333755943, 0.920117034806487, 0.9314649088661514], "final_y": [0.13214884422841022, 0.1163941526537905, 0.11223782440614694]}, "mutation_prompt": null}
{"id": "0df587c6-2e89-4dce-9957-90dbab71814e", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            # Dynamic bees count based on remaining budget\n            bees_count = max(1, int(5 * (1 - evals / self.budget)))\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Select best and random solution for better exploration\n                if np.random.rand() < 0.5:\n                    best_idx = np.argmin(harmony_memory_fitness)\n                    new_solution = np.copy(harmony_memory[best_idx])\n                else:\n                    new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment rate\n                pitch_adj_rate = 0.1 + (0.3 - 0.1) * (1 - evals / self.budget)\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.2\n                \n                # Mutation mechanism for diversity\n                if np.random.rand() < 0.1:\n                    mut_idx = np.random.randint(self.dim)\n                    new_solution[mut_idx] += np.random.uniform(-1, 1) * (ub[mut_idx] - lb[mut_idx]) * 0.05\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Incorporate diversity by introducing a mutation mechanism that perturbs solutions with a small probability for improved exploration.", "configspace": "", "generation": 16, "fitness": 0.9090185530136309, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.027. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "459cd504-b145-4638-877a-f655c95f096c", "metadata": {"aucs": [0.8723789978924029, 0.9185556302915527, 0.936121030856937], "final_y": [0.13042554967289777, 0.11686709497174752, 0.11049062234648044]}, "mutation_prompt": null}
{"id": "1d67ff34-3438-49a9-8c55-6d93622dfa45", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Stochastic memory consideration\n                selected_idx = np.random.choice(harmony_memory_size)\n                new_solution = np.copy(harmony_memory[selected_idx])\n                \n                # Adaptive pitch adjustment with stochastic component\n                fitness_std = np.std(harmony_memory_fitness)\n                fitness_mean = np.mean(harmony_memory_fitness)\n                pitch_adj_rate = 0.2 + 0.8 * (fitness_std / (fitness_mean + 1e-8))\n                stochastic_factor = np.random.rand() * pitch_adj_rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        adjustment = np.random.uniform(-1, 1) * (ub[i] - lb[i]) * stochastic_factor\n                        new_solution[i] += adjustment\n                \n                # Adaptive neighborhood search\n                if np.random.rand() < 0.7:  # Increased probability for diverse exploration\n                    neighbor = np.random.randint(0, harmony_memory_size)\n                    new_solution = 0.5 * (new_solution + harmony_memory[neighbor])\n                \n                new_solution = np.clip(new_solution, lb, ub)\n                \n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Replace using a probabilistic acceptance criterion\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhance diversity during neighborhood search by increasing probabilistic acceptance of diverse solutions.", "configspace": "", "generation": 16, "fitness": 0.9140492207100851, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.024. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "1a5c7a1d-587d-48fd-b85a-6e780fc10407", "metadata": {"aucs": [0.8815249493625004, 0.923031173887069, 0.9375915388806857], "final_y": [0.11722433788701014, 0.11626623960358506, 0.1127241408522468]}, "mutation_prompt": null}
{"id": "dce279db-3d1d-4eae-bb2d-c8f280d1b0d1", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n\n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n\n                # Stochastic memory consideration\n                selected_idx = np.random.choice(harmony_memory_size)\n                new_solution = np.copy(harmony_memory[selected_idx])\n\n                # Adaptive pitch adjustment with stochastic component\n                fitness_std = np.std(harmony_memory_fitness)\n                fitness_mean = np.mean(harmony_memory_fitness)\n                pitch_adj_rate = 0.2 + 0.8 * (fitness_std / (fitness_mean + 1e-8))\n                stochastic_factor = np.random.rand() * pitch_adj_rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        adjustment = np.random.uniform(-1, 1) * (ub[i] - lb[i]) * stochastic_factor\n                        new_solution[i] += adjustment\n\n                # Adaptive neighborhood search\n                if np.random.rand() < 0.5:\n                    neighbor = np.random.randint(0, harmony_memory_size)\n                    new_solution = 0.5 * (new_solution + harmony_memory[neighbor])\n\n                new_solution = np.clip(new_solution, lb, ub)\n\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Replace using a probabilistic acceptance criterion\n                worst_idx = np.argmax(harmony_memory_fitness)\n                acceptance_probability = 1 / (1 + np.exp((new_fitness - harmony_memory_fitness[worst_idx]) / (fitness_std + 1e-8)))\n                if new_fitness < harmony_memory_fitness[worst_idx] or np.random.rand() < acceptance_probability:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced solution acceptance by incorporating a fitness-proportional acceptance criterion for better convergence.", "configspace": "", "generation": 16, "fitness": 0.9218682563053299, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.012. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "1a5c7a1d-587d-48fd-b85a-6e780fc10407", "metadata": {"aucs": [0.9072711354594524, 0.9205568538783261, 0.9377767795782112], "final_y": [0.11156493744975937, 0.11632754232262321, 0.11235093316423006]}, "mutation_prompt": null}
{"id": "c0c16057-8a90-48a7-aa65-96d32a1ebaab", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n\n        while evals < self.budget:\n            # Adaptive harmony memory size based on diversity\n            diversity = np.std(harmony_memory_fitness)\n            harmony_memory_size = max(5, int(10 * diversity / (diversity + 1)))\n            bees_count = max(1, int(4 * (1 - evals / self.budget)))  # Changed to 4\n\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                if np.random.rand() < 0.5:\n                    best_idx = np.argmin(harmony_memory_fitness)\n                    new_solution = np.copy(harmony_memory[best_idx])\n                else:\n                    new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                pitch_adj_rate = 0.1 + (0.4 - 0.1) * (1 - evals / self.budget)  # Changed to 0.4\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.15  # Changed to 0.15\n                \n                new_solution = np.clip(new_solution, lb, ub)\n                \n                new_fitness = func(new_solution)\n                evals += 1\n\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Improved HSBO with adaptive harmony memory size based on diversity and dynamic exploration-exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.9054998286452264, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.028. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "459cd504-b145-4638-877a-f655c95f096c", "metadata": {"aucs": [0.868707536919912, 0.9126204539129821, 0.9351714951027852], "final_y": [0.13043747588029975, 0.1164490536572933, 0.1128302324304824]}, "mutation_prompt": null}
{"id": "ae9bc0ef-0ba7-43a8-ae40-ca54b8a4e9cd", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n\n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Stochastic memory consideration\n                selected_idx = np.random.choice(harmony_memory_size)\n                new_solution = np.copy(harmony_memory[selected_idx])\n                \n                # Adaptive pitch adjustment with stochastic component\n                fitness_std = np.std(harmony_memory_fitness)\n                fitness_mean = np.mean(harmony_memory_fitness)\n                pitch_adj_rate = 0.2 + 0.8 * (fitness_std / (fitness_mean + 1e-8))\n                stochastic_factor = np.random.rand() * pitch_adj_rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        adjustment = np.random.uniform(-1, 1) * (ub[i] - lb[i]) * stochastic_factor\n                        new_solution[i] += adjustment\n                \n                # Adaptive neighborhood search\n                if np.random.rand() < 0.5:\n                    neighbor = np.random.randint(0, harmony_memory_size)\n                    new_solution = 0.5 * (new_solution + harmony_memory[neighbor])\n                \n                # Incorporate best solution for weighted averaging\n                best_idx = np.argmin(harmony_memory_fitness)\n                new_solution = 0.7 * new_solution + 0.3 * harmony_memory[best_idx]\n\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Replace using a probabilistic acceptance criterion\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced exploitation by introducing a weighted average with the best solution for refined solution updates.", "configspace": "", "generation": 17, "fitness": 0.90654733161086, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "1a5c7a1d-587d-48fd-b85a-6e780fc10407", "metadata": {"aucs": [0.921202434952529, 0.8938171844451434, 0.9046223754349081], "final_y": [0.11087159007756442, 0.11660986235746107, 0.11065880928266192]}, "mutation_prompt": null}
{"id": "70d694aa-eadb-4d6a-9b60-076ca7d1990d", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            # Dynamic bees count based on remaining budget\n            bees_count = max(1, int(5 * (1 - evals / self.budget)))\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Select best and random solution for better exploration\n                if np.random.rand() < 0.5:\n                    best_idx = np.argmin(harmony_memory_fitness)\n                    new_solution = np.copy(harmony_memory[best_idx])\n                else:\n                    new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment rate\n                pitch_adj_rate = 0.1 + (0.5 - 0.1) * (1 - evals / self.budget)  # Increased upper limit for adjustment\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-1, 1) * (ub[i] - lb[i]) * 0.1  # Adjusted range and scale\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Greedy selection\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refinement of HSBO by introducing a dynamic pitch adjustment rate scaled with the remaining budget to boost exploration and convergence. ", "configspace": "", "generation": 17, "fitness": 0.9016775256390047, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.016. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "459cd504-b145-4638-877a-f655c95f096c", "metadata": {"aucs": [0.8786778314068533, 0.9111348058325013, 0.9152199396776597], "final_y": [0.12657434616225138, 0.11633490611643038, 0.1134590304758123]}, "mutation_prompt": null}
{"id": "d979ac42-ee9a-4be3-b7a0-8859d224bf27", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n\n        # Identify elite solution\n        elite_idx = np.argmin(harmony_memory_fitness)\n        elite_solution = harmony_memory[elite_idx]\n\n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n\n                selected_idx = np.random.choice(harmony_memory_size)\n                new_solution = np.copy(harmony_memory[selected_idx])\n\n                fitness_std = np.std(harmony_memory_fitness)\n                fitness_mean = np.mean(harmony_memory_fitness)\n                \n                # Introduce self-adaptive scaling factor\n                scaling_factor = 0.5 + 0.5 * (fitness_std / (fitness_mean + 1e-8))\n                stochastic_factor = np.random.rand() * scaling_factor\n                for i in range(self.dim):\n                    if np.random.rand() < scaling_factor:\n                        adjustment = np.random.uniform(-1, 1) * (ub[i] - lb[i]) * stochastic_factor\n                        new_solution[i] += adjustment\n\n                if np.random.rand() < 0.5:\n                    neighbor = np.random.randint(0, harmony_memory_size)\n                    new_solution = 0.5 * (new_solution + harmony_memory[neighbor])\n\n                new_solution = np.clip(new_solution, lb, ub)\n\n                new_fitness = func(new_solution)\n                evals += 1\n\n                worst_idx = np.argmax(harmony_memory_fitness)\n                acceptance_probability = 1 / (1 + np.exp((new_fitness - harmony_memory_fitness[worst_idx]) / (fitness_std + 1e-8)))\n                \n                # Preserve elite solution\n                if new_fitness < harmony_memory_fitness[worst_idx] or np.random.rand() < acceptance_probability:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n                    if new_fitness < harmony_memory_fitness[elite_idx]:\n                        elite_solution = new_solution\n\n        return elite_solution", "name": "HSBO", "description": "Enhance HSBO by integrating a self-adaptive scaling factor and elite preservation strategy for improved convergence.", "configspace": "", "generation": 17, "fitness": 0.9101636294897245, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.006. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "dce279db-3d1d-4eae-bb2d-c8f280d1b0d1", "metadata": {"aucs": [0.9133641371882392, 0.9022602596591023, 0.9148664916218319], "final_y": [0.11698974337870172, 0.11648000679540393, 0.1127597997422497]}, "mutation_prompt": null}
{"id": "4692b2e5-4321-4eda-9e5d-1e3ce86b1841", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Select best and random solution for better exploration\n                if np.random.rand() < 0.4:  # Changed rate to improve balance\n                    best_idx = np.argmin(harmony_memory_fitness)\n                    new_solution = np.copy(harmony_memory[best_idx])\n                else:\n                    new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment rate\n                pitch_adj_rate = 0.15 + (0.25 - 0.15) * (1 - evals / self.budget)  # Adjusted range\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        mutation_factor = np.random.uniform(-1.0, 1.0)  # Altered mutation range\n                        new_solution[i] += mutation_factor * (ub[i] - lb[i]) * 0.1  # Adjusted scale\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved greedy selection with stochastic acceptance\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx] or np.random.rand() < 0.05:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Introduced adaptive mutation strategy and enhanced solution acceptance criteria to improve exploration and convergence in HSBO.", "configspace": "", "generation": 17, "fitness": 0.8960958906839194, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.020. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "7ca25a6b-df48-47c2-bef5-30972d8ddcdc", "metadata": {"aucs": [0.8704346945039592, 0.8978489401392844, 0.9200040374085146], "final_y": [0.1264046177421434, 0.11628080676969677, 0.1129667456306781]}, "mutation_prompt": null}
{"id": "7af59b34-8fba-452f-8cf4-de8c80033b2a", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n\n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n\n                # Stochastic memory consideration\n                selected_idx = np.random.choice(harmony_memory_size)\n                new_solution = np.copy(harmony_memory[selected_idx])\n\n                # Adaptive pitch adjustment with stochastic component\n                fitness_std = np.std(harmony_memory_fitness)\n                fitness_mean = np.mean(harmony_memory_fitness)\n                pitch_adj_rate = 0.2 + 0.8 * (fitness_std / (fitness_mean + 1e-8))\n                stochastic_factor = np.random.rand() * pitch_adj_rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        adjustment = np.random.uniform(-1, 1) * (ub[i] - lb[i]) * stochastic_factor\n                        new_solution[i] += adjustment\n\n                # Adaptive neighborhood search\n                if np.random.rand() < 0.5:\n                    neighbor = np.random.randint(0, harmony_memory_size)\n                    new_solution = 0.5 * (new_solution + harmony_memory[neighbor])\n\n                new_solution = np.clip(new_solution, lb, ub)\n\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Replace using a probabilistic acceptance criterion\n                worst_idx = np.argmax(harmony_memory_fitness)\n                acceptance_probability = 1 / (1 + np.exp((new_fitness - harmony_memory_fitness[worst_idx]) / (fitness_std + 1e-8))) * (harmony_memory_size - sorted(range(len(harmony_memory_fitness)), key=lambda k: harmony_memory_fitness[k]).index(worst_idx)) / harmony_memory_size\n                if new_fitness < harmony_memory_fitness[worst_idx] or np.random.rand() < acceptance_probability:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Introduce scaled acceptance probability based on dynamic fitness rank to improve convergence.", "configspace": "", "generation": 17, "fitness": 0.9048774547859453, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.022. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "dce279db-3d1d-4eae-bb2d-c8f280d1b0d1", "metadata": {"aucs": [0.8792928651402805, 0.902906713547219, 0.9324327856703363], "final_y": [0.1129194622534202, 0.11711096029152201, 0.11017560127583714]}, "mutation_prompt": null}
{"id": "5c9baf20-7eac-4f9b-911b-836c0f45e233", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 12  # Increased harmony memory size\n        bees_count = 7  # Increased bee count for better exploration\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.3 + 0.2 * (self.budget - evals) / self.budget  # Adjusted pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        step_size = 0.1 if harmony_memory_fitness[np.argmin(harmony_memory_fitness)] < 0.1 else 0.2  # Dynamically adjust step size\n                        new_solution[i] += np.random.uniform(-0.6, 0.6) * (ub[i] - lb[i]) * step_size\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved selective update strategy\n                if new_fitness < np.percentile(harmony_memory_fitness, 75):  # Selectively update based on 75th percentile\n                    worst_idx = np.argmax(harmony_memory_fitness)\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced HSBO by adjusting the pitch adjustment rate formula to better balance exploration and exploitation.", "configspace": "", "generation": 18, "fitness": 0.9017989383408235, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.011. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "ea70ed63-93b7-43a5-8efa-b0560976fafd", "metadata": {"aucs": [0.8883215785659517, 0.9019751828958125, 0.9151000535607063], "final_y": [0.11371095593273195, 0.11640126620305036, 0.11480673553725762]}, "mutation_prompt": null}
{"id": "213e4fa1-53dc-4726-adc0-60d747b0a16e", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = max(1, int(0.1 * self.budget))  # Dynamic bees count based on budget\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n\n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n\n                # Stochastic memory consideration\n                selected_idx = np.random.choice(harmony_memory_size)\n                new_solution = np.copy(harmony_memory[selected_idx])\n\n                # Adaptive pitch adjustment with stochastic component\n                fitness_std = np.std(harmony_memory_fitness)\n                fitness_mean = np.mean(harmony_memory_fitness)\n                pitch_adj_rate = 0.2 + 0.8 * (fitness_std / (fitness_mean + 1e-8))\n                stochastic_factor = np.random.rand() * pitch_adj_rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        adjustment = np.random.uniform(-1, 1) * (ub[i] - lb[i]) * stochastic_factor\n                        new_solution[i] += adjustment\n\n                # Adaptive neighborhood search\n                if np.random.rand() < 0.5:\n                    neighbor = np.random.randint(0, harmony_memory_size)\n                    new_solution = 0.5 * (new_solution + harmony_memory[neighbor])\n\n                new_solution = np.clip(new_solution, lb, ub)\n\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Replace using a probabilistic acceptance criterion\n                worst_idx = np.argmax(harmony_memory_fitness)\n                acceptance_probability = 1 / (1 + np.exp((new_fitness - harmony_memory_fitness[worst_idx]) / (fitness_std + 1e-8)))\n                if new_fitness < harmony_memory_fitness[worst_idx] or np.random.rand() < acceptance_probability:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Introduce a dynamic bees count that adapts based on remaining budget to improve exploration-exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.8815751726324009, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.037. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "dce279db-3d1d-4eae-bb2d-c8f280d1b0d1", "metadata": {"aucs": [0.8309089251047658, 0.8963034197773669, 0.9175131730150696], "final_y": [0.13480849992210586, 0.11641026076178185, 0.11077727085956335]}, "mutation_prompt": null}
{"id": "2b19b475-fedf-4e50-8bc5-329a62fa29a4", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 12  # Increased harmony memory size\n        bees_count = 7  # Increased bee count for better exploration\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Harmony memory consideration\n                new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Adaptive pitch adjustment through dynamic local search\n                pitch_adj_rate = 0.3 + 0.1 * (self.budget - evals) / self.budget  # Adjusted pitch adjustment rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        step_size = 0.1 if harmony_memory_fitness[np.argmin(harmony_memory_fitness)] < 0.1 else 0.2  # Dynamically adjust step size\n                        new_solution[i] += np.random.uniform(-0.6, 0.6) * (ub[i] - lb[i]) * step_size\n                \n                # Boundary check\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                # Evaluate new solution\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Improved selective update strategy\n                if new_fitness < np.percentile(harmony_memory_fitness, 70):  # Selectively update based on 70th percentile\n                    worst_idx = np.argmax(harmony_memory_fitness)\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refined solution update by utilizing a more aggressive percentile threshold to enhance selective updates.", "configspace": "", "generation": 18, "fitness": 0.8896592191149564, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.025. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "ea70ed63-93b7-43a5-8efa-b0560976fafd", "metadata": {"aucs": [0.8551185327066539, 0.9004138457843974, 0.9134452788538179], "final_y": [0.13098968244962372, 0.11646840343828224, 0.11311138773007601]}, "mutation_prompt": null}
{"id": "0d6a243a-7f0d-49be-8a4f-6703b6b8d0c6", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        secondary_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        secondary_memory_fitness = np.array([func(sol) for sol in secondary_memory])\n        evals = 2 * harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                if np.random.rand() < 0.5:\n                    best_idx = np.argmin(harmony_memory_fitness)\n                    new_solution = np.copy(harmony_memory[best_idx])\n                else:\n                    if np.random.rand() < 0.7:\n                        new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                    else:\n                        new_solution = np.copy(secondary_memory[np.random.choice(harmony_memory_size)])\n                \n                pitch_adj_rate = 0.15 + (0.35 - 0.15) * (1 - evals / self.budget)\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.3, 0.3) * (ub[i] - lb[i]) * 0.3\n                \n                new_solution = np.clip(new_solution, lb, ub)\n                new_fitness = func(new_solution)\n                evals += 1\n\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n                \n                worst_secondary_idx = np.argmax(secondary_memory_fitness)\n                if new_fitness < secondary_memory_fitness[worst_secondary_idx]:\n                    secondary_memory[worst_secondary_idx] = new_solution\n                    secondary_memory_fitness[worst_secondary_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Introducing a dual-memory model in HSBO with adaptive solutions migration to enhance exploration and exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.8924094481648916, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.016. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "7ca25a6b-df48-47c2-bef5-30972d8ddcdc", "metadata": {"aucs": [0.8705578768058899, 0.8988501259096148, 0.9078203417791706], "final_y": [0.1265655390586683, 0.11691837509927028, 0.11106755541634916]}, "mutation_prompt": null}
{"id": "bdcb52b9-01ed-4c29-92ae-cd32fce01a3c", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n\n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n\n                # Adaptive memory consideration\n                probabilities = harmony_memory_fitness / harmony_memory_fitness.sum()\n                selected_idx = np.random.choice(harmony_memory_size, p=probabilities)\n                new_solution = np.copy(harmony_memory[selected_idx])\n\n                # Modified pitch adjustment with controlled stochastic factor\n                fitness_std = np.std(harmony_memory_fitness)\n                fitness_mean = np.mean(harmony_memory_fitness)\n                pitch_adj_rate = 0.3 + 0.7 * (fitness_std / (fitness_mean + 1e-8))\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        adjustment = np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * pitch_adj_rate\n                        new_solution[i] += adjustment\n\n                # Adaptive neighborhood search\n                if np.random.rand() < 0.5:\n                    neighbor = np.random.randint(0, harmony_memory_size)\n                    new_solution = 0.7 * new_solution + 0.3 * harmony_memory[neighbor]\n\n                new_solution = np.clip(new_solution, lb, ub)\n\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Enhanced probabilistic acceptance criterion\n                worst_idx = np.argmax(harmony_memory_fitness)\n                acceptance_probability = np.exp(-abs(new_fitness - harmony_memory_fitness[worst_idx]) / (fitness_std + 1e-8))\n                if new_fitness < harmony_memory_fitness[worst_idx] or np.random.rand() < acceptance_probability:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced HSBO by integrating an adaptive memory consideration and probabilistic selection strategy to balance exploration and exploitation.", "configspace": "", "generation": 18, "fitness": 0.914640871791374, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.009. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "dce279db-3d1d-4eae-bb2d-c8f280d1b0d1", "metadata": {"aucs": [0.9131877861283995, 0.9040240598768314, 0.9267107693688907], "final_y": [0.11358900692163632, 0.11636559495340348, 0.11247381515496224]}, "mutation_prompt": null}
{"id": "8e93e356-7428-43a0-a4b4-0e53c4e3c3f9", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            bees_count = max(1, int(5 * (1 - evals / self.budget)))\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n\n                if np.random.rand() < 0.5:\n                    best_idx = np.argmin(harmony_memory_fitness)\n                    new_solution = np.copy(harmony_memory[best_idx])\n                else:\n                    new_solution = np.copy(harmony_memory[np.random.choice(harmony_memory_size)])\n                \n                # Dynamic pitch adjustment rate based on improvement\n                pitch_adj_rate = 0.1 + (0.3 - 0.1) * (np.exp(-0.5 * harmony_memory_fitness[best_idx])) \n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        new_solution[i] += np.random.uniform(-0.5, 0.5) * (ub[i] - lb[i]) * 0.2\n                \n                new_solution = np.clip(new_solution, lb, ub)\n                \n                new_fitness = func(new_solution)\n                evals += 1\n\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Refined HSBO by introducing a dynamic pitch adjustment rate based on solution improvement rate for enhanced exploration-exploitation trade-off.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'best_idx' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'best_idx' referenced before assignment\")", "parent_id": "459cd504-b145-4638-877a-f655c95f096c", "metadata": {}, "mutation_prompt": null}
{"id": "734168b0-c222-408c-9591-7b84949eb739", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 12  # Increased memory size for more diversity\n        bees_count = 6  # Adjusted bees count for better sampling\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n\n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n\n                # Adaptive memory consideration\n                selected_idx = np.random.choice(harmony_memory_size, p=(1 / harmony_memory_fitness) / np.sum(1 / harmony_memory_fitness))\n                new_solution = np.copy(harmony_memory[selected_idx])\n\n                # Adaptive pitch adjustment with stochastic component\n                fitness_std = np.std(harmony_memory_fitness)\n                fitness_mean = np.mean(harmony_memory_fitness)\n                pitch_adj_rate = 0.3 + 0.7 * (fitness_std / (fitness_mean + 1e-8))  # Adjusted pitch rate\n                stochastic_factor = np.random.rand() * pitch_adj_rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        adjustment = np.random.uniform(-1, 1) * (ub[i] - lb[i]) * stochastic_factor\n                        new_solution[i] += adjustment\n\n                # Enhanced neighborhood search\n                if np.random.rand() < 0.6:  # Increased probability\n                    neighbor = np.random.randint(0, harmony_memory_size)\n                    new_solution = 0.5 * (new_solution + harmony_memory[neighbor]) + 0.5 * np.random.uniform(lb, ub, self.dim)\n\n                new_solution = np.clip(new_solution, lb, ub)\n                \n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Replace using a probabilistic acceptance criterion\n                worst_idx = np.argmax(harmony_memory_fitness)\n                acceptance_probability = 1 / (1 + np.exp((new_fitness - harmony_memory_fitness[worst_idx]) / (fitness_std + 1e-8)))\n                if new_fitness < harmony_memory_fitness[worst_idx] or np.random.rand() < acceptance_probability:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Introduced an adaptive memory consideration and neighborhood search strategy for enhanced solution diversity and convergence.", "configspace": "", "generation": 19, "fitness": 0.8377928931619936, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.016. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "dce279db-3d1d-4eae-bb2d-c8f280d1b0d1", "metadata": {"aucs": [0.8305604957426034, 0.8602584210570006, 0.822559762686377], "final_y": [0.13055669958260308, 0.11905210546801703, 0.1335446930172951]}, "mutation_prompt": null}
{"id": "c79997dc-4188-487b-bbd1-6f5ac5f74327", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n\n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n\n                # Dynamic memory consideration\n                selected_idx = np.random.choice(harmony_memory_size, p=harmony_memory_fitness / np.sum(harmony_memory_fitness))\n                new_solution = np.copy(harmony_memory[selected_idx])\n\n                # Adaptive pitch adjustment with stochastic component\n                fitness_std = np.std(harmony_memory_fitness)\n                fitness_mean = np.mean(harmony_memory_fitness)\n                pitch_adj_rate = 0.2 + 0.8 * (fitness_std / (fitness_mean + 1e-8))\n                stochastic_factor = np.random.rand() * pitch_adj_rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        adjustment = np.random.uniform(-1, 1) * (ub[i] - lb[i]) * stochastic_factor\n                        new_solution[i] += adjustment\n\n                # Adaptive neighborhood search\n                if np.random.rand() < 0.5:\n                    neighbor = np.random.randint(0, harmony_memory_size)\n                    new_solution = 0.5 * (new_solution + harmony_memory[neighbor])\n\n                new_solution = np.clip(new_solution, lb, ub)\n\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Replace using a probabilistic acceptance criterion\n                worst_idx = np.argmax(harmony_memory_fitness)\n                acceptance_probability = 1 / (1 + np.exp((new_fitness - harmony_memory_fitness[worst_idx]) / (fitness_std + 1e-8)))\n                if new_fitness < harmony_memory_fitness[worst_idx] or np.random.rand() < acceptance_probability:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Enhanced HSBO by integrating a dynamic memory consideration mechanism to improve exploration-exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.8592174564140088, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.020. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "dce279db-3d1d-4eae-bb2d-c8f280d1b0d1", "metadata": {"aucs": [0.8876644628847727, 0.8484838014151835, 0.8415041049420702], "final_y": [0.11725393857967648, 0.12981243220868255, 0.12215839422310382]}, "mutation_prompt": null}
{"id": "c6af68bf-c6a5-4a53-b84e-2d952de884c2", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n        \n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n                \n                # Stochastic memory consideration\n                selected_idx = np.random.choice(harmony_memory_size)\n                new_solution = np.copy(harmony_memory[selected_idx])\n                \n                # Adaptive pitch adjustment with stochastic component\n                fitness_std = np.std(harmony_memory_fitness)\n                fitness_mean = np.mean(harmony_memory_fitness)\n                pitch_adj_rate = 0.2 + 0.8 * (fitness_std / (fitness_mean + 1e-8)) * (1 - evals/self.budget)\n                stochastic_factor = np.random.rand() * pitch_adj_rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        adjustment = np.random.uniform(-1, 1) * (ub[i] - lb[i]) * stochastic_factor\n                        new_solution[i] += adjustment\n                \n                # Adaptive neighborhood search\n                if np.random.rand() < 0.5:\n                    neighbor = np.random.randint(0, harmony_memory_size)\n                    new_solution = 0.5 * (new_solution + harmony_memory[neighbor])\n                \n                new_solution = np.clip(new_solution, lb, ub)\n                \n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Replace using a probabilistic acceptance criterion\n                worst_idx = np.argmax(harmony_memory_fitness)\n                if new_fitness < harmony_memory_fitness[worst_idx]:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Introduced a dynamic pitch adjustment factor based on a combination of fitness variance and evals progress to improve exploration-exploitation balance.", "configspace": "", "generation": 19, "fitness": 0.8613900244107988, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.014. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "1a5c7a1d-587d-48fd-b85a-6e780fc10407", "metadata": {"aucs": [0.8415717934944607, 0.8676245922551103, 0.8749736874828256], "final_y": [0.13357303158583966, 0.12001687185174914, 0.11903499081719959]}, "mutation_prompt": null}
{"id": "5e0de629-fa1d-403f-a611-90688ab77050", "solution": "import numpy as np\n\nclass HSBO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        harmony_memory_size = 10\n        bees_count = 5\n        harmony_memory = np.random.uniform(lb, ub, (harmony_memory_size, self.dim))\n        harmony_memory_fitness = np.array([func(sol) for sol in harmony_memory])\n        evals = harmony_memory_size\n\n        while evals < self.budget:\n            for bee in range(bees_count):\n                if evals >= self.budget:\n                    break\n\n                # Stochastic memory consideration\n                selected_idx = np.random.choice(harmony_memory_size)\n                new_solution = np.copy(harmony_memory[selected_idx])\n\n                # Adaptive pitch adjustment with stochastic component\n                fitness_std = np.std(harmony_memory_fitness)\n                fitness_mean = np.mean(harmony_memory_fitness)\n                pitch_adj_rate = 0.2 + 0.8 * (fitness_std / (fitness_mean + 1e-8))\n                stochastic_factor = np.random.rand() * pitch_adj_rate\n                for i in range(self.dim):\n                    if np.random.rand() < pitch_adj_rate:\n                        adjustment = np.random.uniform(-1, 1) * (ub[i] - lb[i]) * stochastic_factor\n                        new_solution[i] += adjustment\n\n                # Adaptive neighborhood search\n                if np.random.rand() < 0.5:\n                    neighbor = np.random.randint(0, harmony_memory_size)\n                    weight = np.random.rand()  # Weighted approach\n                    new_solution = weight * new_solution + (1 - weight) * harmony_memory[neighbor]\n\n                new_solution = np.clip(new_solution, lb, ub)\n\n                new_fitness = func(new_solution)\n                evals += 1\n\n                # Replace using a probabilistic acceptance criterion\n                worst_idx = np.argmax(harmony_memory_fitness)\n                acceptance_probability = 1 / (1 + np.exp((new_fitness - harmony_memory_fitness[worst_idx]) / (fitness_std + 1e-8)))\n                if new_fitness < harmony_memory_fitness[worst_idx] or np.random.rand() < acceptance_probability:\n                    harmony_memory[worst_idx] = new_solution\n                    harmony_memory_fitness[worst_idx] = new_fitness\n\n        best_idx = np.argmin(harmony_memory_fitness)\n        return harmony_memory[best_idx]", "name": "HSBO", "description": "Improved harmony memory updating by introducing a weighted approach in neighborhood search.", "configspace": "", "generation": 19, "fitness": 0.8580312256313762, "feedback": "The algorithm HSBO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.004. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "dce279db-3d1d-4eae-bb2d-c8f280d1b0d1", "metadata": {"aucs": [0.852990479308831, 0.8626775899258604, 0.8584256076594377], "final_y": [0.13081587402627737, 0.1205039052362411, 0.11891545388294722]}, "mutation_prompt": null}
