{"id": "acd9b743-7c6f-4c7d-9242-5dce6acbc8da", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]\n\n# Usage of this class would involve creating an instance with a budget and dimensionality, \n# and then calling it with the function to be optimized.", "name": "HybridDE", "description": "A hybrid Differential Evolution algorithm enhanced with Quasi-Oppositional learning and periodicity constraints, combined with local BFGS optimization for fine-tuning.", "configspace": "", "generation": 0, "fitness": 0.9168291241873066, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.045. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": null, "metadata": {"aucs": [0.9608267181775404, 0.9347702977347986, 0.8548903566495809], "final_y": [0.16485629721472783, 0.1648566010583914, 0.2004451527650314]}, "mutation_prompt": null}
{"id": "394b2385-e361-4dbc-9dc1-4314ac82b316", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            F_dynamic = self.F + 0.1 * np.random.rand()  # Dynamic F\n            mutant = np.clip(a + F_dynamic * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        method = 'L-BFGS-B' if np.random.rand() > 0.5 else 'TNC'  # Diversified local search\n        res = minimize(self.func, x, method=method, bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with dynamic parameter tuning and diversified local search strategies for improved convergence and exploitative efficiency.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('`x0` violates bound constraints.').", "error": "ValueError('`x0` violates bound constraints.')", "parent_id": "acd9b743-7c6f-4c7d-9242-5dce6acbc8da", "metadata": {}, "mutation_prompt": null}
{"id": "81a75920-ad13-412e-9d00-245eea10b892", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]\n\n# Usage of this class would involve creating an instance with a budget and dimensionality, \n# and then calling it with the function to be optimized.", "name": "HybridDE", "description": "Enhanced HybridDE by adjusting crossover probability for improved exploration-exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.925444574656317, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.046. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "acd9b743-7c6f-4c7d-9242-5dce6acbc8da", "metadata": {"aucs": [0.9608265290293865, 0.8607520865476423, 0.9547551083919223], "final_y": [0.1648568120720293, 0.20044561257493576, 0.16485615500419037]}, "mutation_prompt": null}
{"id": "36a0680a-3bf0-4e2d-854a-087d32513386", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x = np.tile(x[:period], self.dim // period)  # Ensure full replication\n        return x\n\n    def local_optimization(self, x):\n        if np.random.rand() < 0.2:  # Adjusted probability\n            res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n            return res.x if res.success else x\n        return x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with improved periodic pattern application and selective local optimization.", "configspace": "", "generation": 1, "fitness": 0.9002775369006609, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.041. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "acd9b743-7c6f-4c7d-9242-5dce6acbc8da", "metadata": {"aucs": [0.9559306175049186, 0.8594236628069559, 0.8854783303901084], "final_y": [0.16485622814187484, 0.18813073690422855, 0.1818843309747039]}, "mutation_prompt": null}
{"id": "3f632166-89d5-4277-a1b3-bb02ac27b159", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.4 + 0.3 * np.random.rand()  # Adaptive F\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            self.CR = 0.8 + 0.2 * np.random.rand()  # Adaptive CR\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "An improved HybridDE algorithm with adaptive Differential weight and crossover probability for enhanced exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.880429234234334, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.028. And the mean value of best solutions found was 0.188 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "acd9b743-7c6f-4c7d-9242-5dce6acbc8da", "metadata": {"aucs": [0.8961155712472076, 0.8409735061034865, 0.9041986253523073], "final_y": [0.18187832609588306, 0.20044678943551242, 0.18188377320867566]}, "mutation_prompt": null}
{"id": "99e826b1-b55e-4824-897b-3e6671b8ee3c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = np.random.choice(range(self.population_size), 3, replace=False)\n            a, b, c = population[idxs]  # Modify this line to select random individuals\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved the selection of individuals for DE mutation to enhance diversity and exploration capability.", "configspace": "", "generation": 1, "fitness": 0.8672210306755433, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.026. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "acd9b743-7c6f-4c7d-9242-5dce6acbc8da", "metadata": {"aucs": [0.9035496025539506, 0.8468325949786677, 0.8512808944940117], "final_y": [0.18187834609944697, 0.1881318466940749, 0.18813377433440315]}, "mutation_prompt": null}
{"id": "d439a279-11d4-4c3b-82e8-09b8259bc377", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.3  # Differential weight (reduced for better fine-tuning)\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhance hybrid exploration-exploitation by reducing differential weight for better fine-tuning.", "configspace": "", "generation": 2, "fitness": 0.9151170403910012, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.067. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.9608265290293865, 0.9634983556407362, 0.8210262365028811], "final_y": [0.1648568120720293, 0.16485656290281558, 0.1818843309747039]}, "mutation_prompt": null}
{"id": "1505eaff-f3e0-40f2-9c2e-dce3850f3921", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            self.CR = 0.9 + 0.1 * (self.evaluations / self.budget)  # Adaptive CR\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < (0.05 + 0.05 * (1 - fitness[i]/max(fitness))):  # Dynamic frequency\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduced adaptive crossover probability and dynamic local optimization frequency in HybridDE for enhanced performance.", "configspace": "", "generation": 2, "fitness": 0.8823247672952016, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.033. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.863078613459181, 0.9290949165702167, 0.8548007718562072], "final_y": [0.18187950887489912, 0.1648566010583914, 0.2004450301152726]}, "mutation_prompt": null}
{"id": "8fa643d0-b3bf-4b0e-9870-9ecc29964e0d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            adapted_F = 0.4 + 0.1 * np.random.rand()  # Adaptive differential weight\n            mutant = np.clip(a + adapted_F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE by incorporating adaptive differential weight for improved convergence speed and precision.", "configspace": "", "generation": 2, "fitness": 0.8871226923702139, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.013. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.8889293812866808, 0.8707188270490158, 0.9017198687749455], "final_y": [0.18187908472922565, 0.18187971045709161, 0.16485615500419037]}, "mutation_prompt": null}
{"id": "680a94ee-14c5-43e0-beea-f9ccd4756f47", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def dynamic_mutation(self, population, i):\n        idxs = [idx for idx in range(self.population_size) if idx != i]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        return np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            mutant = self.dynamic_mutation(population, i)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)\n        repetitions = self.dim // period\n        x[:period] = np.repeat(np.mean(x[:period]), period)\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1: \n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved HybridDE by introducing adaptive mutation strategies and enhancing periodicity constraints.", "configspace": "", "generation": 2, "fitness": 0.9148370166252976, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.032. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.9580166102213953, 0.9041700467092451, 0.8823243929452526], "final_y": [0.1648605080497576, 0.16485791396692184, 0.18813377433440315]}, "mutation_prompt": null}
{"id": "e48ac7e3-ff61-40a9-9c79-3987526423e6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.15:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Refined HybridDE by adjusting local optimization probability to improve local search accuracy.", "configspace": "", "generation": 2, "fitness": 0.901909628079185, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.045. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.9373503042948572, 0.8380409003282145, 0.9303376796144831], "final_y": [0.16485851521328132, 0.20725467842384904, 0.16485615500419037]}, "mutation_prompt": null}
{"id": "44b04491-eff5-4a74-9ad2-af8e4615d33c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.95  # Crossover probability (unchanged)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.5 + np.random.rand() * 0.3  # Adaptive differential weight\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period\n        pattern = np.tile(x[:period], self.dim // period)\n        x[:len(pattern)] = pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with adaptive differential weight and periodicity-based local search for improved performance.", "configspace": "", "generation": 3, "fitness": 0.8886211921921392, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.025. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.906421255021853, 0.9061486262493954, 0.8532936953051694], "final_y": [0.16485646396897013, 0.1648566010583914, 0.20044557117307593]}, "mutation_prompt": null}
{"id": "47a04412-6ff8-4ec6-9b7a-e1bb888ea6f9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Slightly reduce the crossover probability in HybridDE for better exploration capabilities.", "configspace": "", "generation": 3, "fitness": 0.8556832897016343, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.028. And the mean value of best solutions found was 0.197 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.8432121515956537, 0.8296166187139522, 0.8942210987952971], "final_y": [0.20725523120693268, 0.20044699469129656, 0.18187939951712428]}, "mutation_prompt": null}
{"id": "150442c0-8083-492f-abc2-56163e6627b5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.4 + 0.1 * np.random.rand()  # Adaptive mutation strategy (changed line)\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved HybridDE by integrating adaptive mutation strategies to enhance search adaptability without increasing code length.", "configspace": "", "generation": 3, "fitness": 0.8642304790053528, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.028. And the mean value of best solutions found was 0.185 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.8906005464835173, 0.8762555771746441, 0.8258353133578971], "final_y": [0.1818785424609325, 0.16485791396692184, 0.2072565648364656]}, "mutation_prompt": null}
{"id": "0df25355-1c6a-4cba-90ed-11271a9a696e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.85  # Crossover probability (reduced for better genetic diversity)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved exploration in HybridDE by reducing crossover probability to increase genetic diversity.", "configspace": "", "generation": 3, "fitness": 0.8745727043680174, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.021. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.8652943063495946, 0.9033765032101788, 0.8550473035442786], "final_y": [0.18187878472236674, 0.16485791396692184, 0.18813377433440315]}, "mutation_prompt": null}
{"id": "b4be5f27-6519-482b-b2b9-9dac0f7721e1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        best_idx = np.argmin(fitness)  # Elitism: track the best solution\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.5 + 0.3 * np.random.rand()  # Adaptive mutation factor\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        new_population[0] = population[best_idx]  # Retain the best individual\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with adaptive mutation and elitism to balance exploration and exploitation while leveraging periodicity.", "configspace": "", "generation": 3, "fitness": 0.8690248646987279, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.027. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.8911416235528871, 0.8854157969874277, 0.8305171735558692], "final_y": [0.16485623343029143, 0.18188004870843022, 0.20044569388494426]}, "mutation_prompt": null}
{"id": "d811f7da-3a9b-4861-a004-bb55bdf2496f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = np.random.uniform(0.3, 0.9)  # Adaptive differential weight\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduced adaptive differential weight in HybridDE for improved exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.9463651069800018, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.946 with standard deviation 0.018. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.9418160652037058, 0.9264758162296349, 0.9708034395066645], "final_y": [0.16485790130074462, 0.1648566010583914, 0.16485641635669301]}, "mutation_prompt": null}
{"id": "697d4320-6090-4b6f-a8de-10f5688d7837", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            if np.random.rand() < 0.1:  # Occasionally reinitialize population\n                population, fitness = self.quasi_oppositional_initialization(func.bounds)\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhancing exploration by applying quasi-oppositional initialization multiple times within the optimization process.", "configspace": "", "generation": 4, "fitness": 0.9426442913419137, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.943 with standard deviation 0.035. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.8928660777519419, 0.9659615965758631, 0.9691051996979362], "final_y": [0.1648625468803926, 0.16485649502413602, 0.16485619143696528]}, "mutation_prompt": null}
{"id": "42675df6-c414-4630-bc98-cf081d5bbf17", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.5 + 0.3 * np.random.rand()  # Adaptive mutation factor\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2) \n        x[:period] = x[:period] * (self.dim // period) \n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.15:  # Increased local optimization frequency\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE by integrating adaptive mutation factor and increased local search frequency for improved convergence speed and solution quality.", "configspace": "", "generation": 4, "fitness": 0.9410255874476233, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.038. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.8869927853860224, 0.9659615965758631, 0.9701223803809843], "final_y": [0.18187902113597298, 0.16485649502413602, 0.16485601471948885]}, "mutation_prompt": null}
{"id": "41d6adec-cf0f-48e3-a17d-803fa9b8cecc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            F_adaptive = np.random.uniform(0.4, 0.9)  # Adaptive differential weight\n            mutant = np.clip(a + F_adaptive * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x_transformed = x[:period].repeat(self.dim // period)  # Improved periodicity application\n        return x_transformed\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved HybridDE by introducing adaptive differential weight (F) and periodic constraint adjustments for better solution convergence.", "configspace": "", "generation": 4, "fitness": 0.9494533890329633, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.949 with standard deviation 0.026. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.9122763820134582, 0.9659619167145106, 0.9701218683709214], "final_y": [0.16485749974743746, 0.1648561271165253, 0.16485619143696528]}, "mutation_prompt": null}
{"id": "3e34faa2-2d33-4b95-9424-a1edffcf54db", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR *= self.adaptive_factor  # New: Adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2  # Changed: Fixed 2-layer periodicity \n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved HybridDE by integrating adaptive strategies and periodicity enforcement to enhance exploration and convergence.", "configspace": "", "generation": 4, "fitness": 0.9594824459649223, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.9637454734267393, 0.9659615965758631, 0.9487402678921644], "final_y": [0.1648561537231501, 0.16485649502413602, 0.16485604581892177]}, "mutation_prompt": null}
{"id": "f655ba53-e014-4b35-91be-2c84759e81d9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.92  # New: Slightly increased adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR *= self.adaptive_factor  # New: Adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2  # Changed: Fixed 2-layer periodicity \n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced adaptive control by increasing the adaptive factor slightly to better balance exploration and exploitation.", "configspace": "", "generation": 5, "fitness": 0.9185746391057362, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.027. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3e34faa2-2d33-4b95-9424-a1edffcf54db", "metadata": {"aucs": [0.9461070964070434, 0.8818419628092884, 0.927774858100877], "final_y": [0.16485614762201084, 0.1648564182418535, 0.16485671239294186]}, "mutation_prompt": null}
{"id": "969259d3-25cb-4403-bc3d-166554230081", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            F_dynamic = self.F / (1 + 0.1 * i / self.population_size)  # Changed: Dynamic F\n            mutant = np.clip(a + F_dynamic * (b - c), self.lb, self.ub)  # Changed: Use F_dynamic\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR *= self.adaptive_factor  # New: Adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 4  # Changed: Fixed 4-layer periodicity \n        for j in range(0, len(x), period):\n            x[j:j+period] = np.mean(x[j:j+period])  # Changed: Enforce periodic pattern for deeper blocks\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE by incorporating dynamic mutation rate and deeper periodic pattern enforcement for improved solution quality.", "configspace": "", "generation": 5, "fitness": 0.9545597231325255, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.955 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3e34faa2-2d33-4b95-9424-a1edffcf54db", "metadata": {"aucs": [0.9467041392768961, 0.957370407284917, 0.9596046228357631], "final_y": [0.16485710774911044, 0.16485584794624208, 0.16485598307308946]}, "mutation_prompt": null}
{"id": "be914107-088e-430b-8e0b-38c03f9f8b92", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.1  # Changed: More adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2  # Changed: Fixed 2-layer periodicity \n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        x[period:2*period] = x[:period]  # New: Extend periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE by refining CR adaptation and periodic pattern enforcement to boost convergence and robustness.", "configspace": "", "generation": 5, "fitness": 0.9655981093550846, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3e34faa2-2d33-4b95-9424-a1edffcf54db", "metadata": {"aucs": [0.9683579424178776, 0.9621519731215143, 0.966284412525862], "final_y": [0.16485600451564475, 0.16485671527058954, 0.16485599642311255]}, "mutation_prompt": null}
{"id": "ea7fd7af-1295-4a2f-ae7e-b6386217028b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = np.random.uniform(0.4, 0.9)  # Changed: Dynamic F\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR *= self.adaptive_factor  # New: Adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = np.random.randint(2, 5)  # Changed: Stochastic periodicity\n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE by dynamically adjusting differential weight and introducing stochastic periodicity to improve convergence.", "configspace": "", "generation": 5, "fitness": 0.95808265429573, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3e34faa2-2d33-4b95-9424-a1edffcf54db", "metadata": {"aucs": [0.9589414539364454, 0.9634268077048141, 0.9518797012459308], "final_y": [0.16485600367070996, 0.1648561271165253, 0.16485598662527023]}, "mutation_prompt": null}
{"id": "0669f664-5593-4f78-91bd-7b7cc4823005", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR *= self.adaptive_factor  # New: Adaptive CR update\n                self.F = 0.5 + 0.3 * np.random.rand()  # Modified: Adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2  # Changed: Fixed 2-layer periodicity \n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.2:  # Modified: Increased local search probability\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE by introducing adaptive mutation factor `F` and increased local search probability to balance exploration and exploitation effectively.", "configspace": "", "generation": 5, "fitness": 0.9587987702734617, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3e34faa2-2d33-4b95-9424-a1edffcf54db", "metadata": {"aucs": [0.9684588060856013, 0.963427174173916, 0.9445103305608678], "final_y": [0.16485614762201084, 0.16485632119504634, 0.1648567884092309]}, "mutation_prompt": null}
{"id": "5f096220-8956-4afa-bbf3-107d010c69fd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.7 * self.CR + 0.15  # Modified: More adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 4  # Modified: Dynamic 4-layer periodicity\n        x[:period] = np.mean(x[:period])  # Enforce periodic pattern\n        for j in range(period, len(x), period):  # New: Extend periodic pattern\n            x[j:j+period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Refined Enhanced HybridDE by incorporating frequency-based periodicity and improved adaptive control for CR to increase robustness and convergence efficiency.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('could not broadcast input array from shape (4,) into shape (2,)').", "error": "ValueError('could not broadcast input array from shape (4,) into shape (2,)')", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {}, "mutation_prompt": null}
{"id": "57267ce3-818c-4a89-b6dd-cd7651792066", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.1  # Changed: More adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2 + np.random.randint(0, self.dim // 10)  # Changed: Dynamically adjust periodic block size\n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        x[period:2*period] = x[:period]  # New: Extend periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhance periodicity by dynamically adjusting the periodic block size to adaptively match problem-specific patterns.", "configspace": "", "generation": 6, "fitness": 0.9652007802424688, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {"aucs": [0.9716531949274829, 0.953570806400539, 0.9703783393993844], "final_y": [0.16485602538314326, 0.16485582371553498, 0.16485599302595577]}, "mutation_prompt": null}
{"id": "1941b971-db59-497b-a82c-8793a98cec7b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.1  # Changed: More adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = np.random.randint(1, 4)  # Changed: Adaptive period length\n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        x[period:2*period] = x[:period]  # New: Extend periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Adaptive periodicity by varying period length within constraints for enhanced solution exploration.", "configspace": "", "generation": 6, "fitness": 0.9310482872745386, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {"aucs": [0.939078499615125, 0.9161677285539919, 0.9378986336544992], "final_y": [0.1648580425221836, 0.16485685252487225, 0.16486017818948184]}, "mutation_prompt": null}
{"id": "52657929-71c5-4c59-9e56-e12e9a86a834", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.85  # Changed: More aggressive adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.15  # Changed: More adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2  # Fixed 2-layer periodicity \n        x[:period] = np.mean(x[:period])  # Enforce periodic pattern\n        x[period:2*period] = x[:period]  # Extend periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved CR adaptation and periodicity enforcement to achieve better solution convergence and robustness.", "configspace": "", "generation": 6, "fitness": 0.9441231351578634, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.024. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {"aucs": [0.9716531949274829, 0.9484707642771545, 0.9122454462689529], "final_y": [0.16485602538314326, 0.16485602372451014, 0.16485623656904858]}, "mutation_prompt": null}
{"id": "2059179a-ebbf-4e33-ab3c-a959ed184fdb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            if fitness[i] > np.median(fitness):  # Changed: Improved mutant selection strategy\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.1  # Changed: More adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2  # Changed: Fixed 2-layer periodicity \n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        x[period:2*period] = x[:period]  # New: Extend periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Optimized DE step by improving mutant vector selection strategy for better convergence.", "configspace": "", "generation": 6, "fitness": 0.9580387770506528, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {"aucs": [0.9581214262410076, 0.9682674755966362, 0.9477274293143142], "final_y": [0.16485636194564823, 0.16485601381116444, 0.16485621918154514]}, "mutation_prompt": null}
{"id": "e544bb5d-1c7e-4e61-9201-d9d4c0205bd7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.85 * self.CR + 0.15  # Changed: More adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2  # Changed: Fixed 2-layer periodicity \n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        x[period:2*period] = x[:period]  # New: Extend periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Further refined HybridDE by enhancing CR adaptation and dynamic periodic pattern enforcement to improve convergence efficiency and robustness.", "configspace": "", "generation": 7, "fitness": 0.9526930146339655, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.026. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {"aucs": [0.9716531949274829, 0.9160488777246028, 0.9703769712498108], "final_y": [0.16485602538314326, 0.1648562877019627, 0.16485612891398027]}, "mutation_prompt": null}
{"id": "b4748bfa-ad98-4c4a-a0e8-42e49b3439e7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Changed: Increased Differential weight for exploration\n        self.CR = 0.9  # Changed: Adjusted crossover probability\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.85  # Tuned: Improved adaptive factor\n        self.periodicity = 2 + (dim // 10)  # New: Dynamic periodicity based on dimension\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.7 * self.CR + 0.15  # Changed: Enhanced adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = self.periodicity  # Changed: Use dynamic periodicity\n        for start in range(0, self.dim, period):\n            x[start:start+period] = np.mean(x[start:start+period])  # Changed: Dynamic periodic enforcement\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.2:  # Changed: Increase chance for local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Optimized HybridDE by enhancing mutation strategy, incorporating dynamic periodicity, and refining local search for improved performance.", "configspace": "", "generation": 7, "fitness": 0.963419274021852, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {"aucs": [0.9561386930861577, 0.9661150448048577, 0.9680040841745406], "final_y": [0.1648564846554531, 0.16485656522363845, 0.16485589109032217]}, "mutation_prompt": null}
{"id": "5ab052d3-e03b-4c82-93df-d4ddef65aacf", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.9 * self.F + 0.1  # New: Adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with adaptive F and CR for improved exploration and exploitation dynamics.", "configspace": "", "generation": 7, "fitness": 0.9685160036517152, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {"aucs": [0.9716531949274829, 0.9658906336602737, 0.9680041823673888], "final_y": [0.16485602538314326, 0.16485601381116444, 0.16485647955256844]}, "mutation_prompt": null}
{"id": "379b05ae-e686-431e-9515-f030631f5eb5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.95\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n        self.population_size = self.initial_population_size\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.7 * self.CR + 0.15  # More adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = max(2, np.random.randint(2, self.dim // 2))  # Adaptive periodicity\n        for i in range(0, self.dim, period):\n            x[i:i+period] = np.mean(x[i:i+period])\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def adapt_population_size(self):\n        self.population_size = max(self.initial_population_size // 2, int(self.population_size * 0.95))\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            self.adapt_population_size()  # Adaptive population size\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Incorporate adaptive population size and dynamic period enforcement to further enhance solution robustness and convergence speed.", "configspace": "", "generation": 7, "fitness": 0.9573111260259903, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.957 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {"aucs": [0.9595172789324651, 0.965646057524832, 0.9467700416206739], "final_y": [0.16485609485575226, 0.16485582371553498, 0.1648558152180455]}, "mutation_prompt": null}
{"id": "659fa0c8-5feb-4791-9d35-9a7f42cb014b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            F_dynamic = self.F + 0.3 * np.random.rand()  # Changed: Adaptive F\n            mutant = np.clip(a + F_dynamic * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.1  # Changed: More adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = np.random.randint(1, 3)  # Changed: Randomize period length\n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        x[period:2*period] = x[:period]  # New: Extend periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n        \n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with adaptive mutation scaling and dynamic periodic pattern length to optimize reflectivity in multilayer photonic structures.", "configspace": "", "generation": 7, "fitness": 0.9513766433821358, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.022. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {"aucs": [0.9674209711340659, 0.9658906336602737, 0.9208183253520676], "final_y": [0.1648565202577531, 0.16485601381116444, 0.1648567060072701]}, "mutation_prompt": null}
{"id": "7fb1ae2c-9bd2-49ee-8780-38b2617ef976", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.1  # Changed: Strategic CR update\n                self.F = 0.85 * self.F + 0.15  # Changed: Refined F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with strategic CR/F adjustments and refined periodicity constraints for superior optimization.", "configspace": "", "generation": 8, "fitness": 0.9356772819416818, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.936 with standard deviation 0.021. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5ab052d3-e03b-4c82-93df-d4ddef65aacf", "metadata": {"aucs": [0.9478332730382604, 0.9064406270179955, 0.9527579457687895], "final_y": [0.1648573218733782, 0.16485720455361186, 0.16485590102986125]}, "mutation_prompt": null}
{"id": "ddb7ea08-4ded-45e7-880f-6cd55a4ecad2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.9 * self.F + 0.1  # New: Adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:] = np.tile(x[:period], len(x[period:]) // period)  # Enhanced periodicity throughout\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "HybridDE with enhanced adaptive crossover and improved periodicity constraints for better solution quality.", "configspace": "", "generation": 8, "fitness": 0.9617913524580707, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5ab052d3-e03b-4c82-93df-d4ddef65aacf", "metadata": {"aucs": [0.9733288028458454, 0.963910516530611, 0.9481347379977559], "final_y": [0.1648562935033412, 0.16485616538362902, 0.16485830895053333]}, "mutation_prompt": null}
{"id": "495e6edf-ade7-4fca-9101-bc4e4f700b84", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  \n                self.F = 0.8 * self.F + 0.2  # Changed: Adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 5  # Changed: Refined periodicity constraints\n        for i in range(0, self.dim, period):\n            x[i:i+period] = np.mean(x[i:i+period])\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved HybridDE with refined periodic constraints and adaptive mutation to enhance convergence and exploration.", "configspace": "", "generation": 8, "fitness": 0.9642376075195802, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5ab052d3-e03b-4c82-93df-d4ddef65aacf", "metadata": {"aucs": [0.9677668370125412, 0.9553503588683909, 0.9695956266778085], "final_y": [0.16485773432591, 0.16485604337833715, 0.16485599302595577]}, "mutation_prompt": null}
{"id": "5722a44e-7bca-4949-9046-635896193cf5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.9 * self.F + 0.1  # New: Adaptive F update\n            else:\n                new_population[i] = self.apply_periodicity_constraints(population[i].copy())  # Modified line\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduce periodic component insertion during DE steps for enhanced periodicity exploitations.", "configspace": "", "generation": 8, "fitness": 0.9634567493068266, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5ab052d3-e03b-4c82-93df-d4ddef65aacf", "metadata": {"aucs": [0.9684866662350369, 0.9651146832706715, 0.9567688984147715], "final_y": [0.16485592932632231, 0.16485740075303512, 0.16485590102986125]}, "mutation_prompt": null}
{"id": "f727edab-931e-4c7f-b581-ed7144e4de1a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = self.adaptive_factor * self.F + 0.15  # Changed: Adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved Adaptive Factor for Differential Weight (F) to Enhance Exploration-Exploitation Balance.", "configspace": "", "generation": 8, "fitness": 0.9543184714378565, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5ab052d3-e03b-4c82-93df-d4ddef65aacf", "metadata": {"aucs": [0.9676560138444528, 0.9453219757776512, 0.9499774246914656], "final_y": [0.16485602538314326, 0.16485604337833715, 0.1648560206859465]}, "mutation_prompt": null}
{"id": "40f11264-50fc-4408-8a7b-e37a4e464402", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            chaotic_factor = 0.7 * (1 - (2 * np.random.rand() - 1)**3)  # New: Chaotic factor for mutation\n            mutant = np.clip(a + chaotic_factor * self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05\n                self.F = 0.9 * self.F + 0.1\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with adaptive mutation strategy that incorporates chaotic maps for improved exploration efficiency.", "configspace": "", "generation": 9, "fitness": 0.9734994759066057, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.973 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5ab052d3-e03b-4c82-93df-d4ddef65aacf", "metadata": {"aucs": [0.9725555727064755, 0.9648306020293129, 0.9831122529840287], "final_y": [0.16485589243507404, 0.16485610867335554, 0.16485612864506394]}, "mutation_prompt": null}
{"id": "a6b9b2c9-810b-4772-9ccd-33145cf12b36", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                # Updated: Adaptive CR and F updates for better exploration-exploitation balance\n                self.CR = 0.9 * self.CR + 0.1 * np.random.rand()  \n                self.F = 0.9 * self.F + 0.1 * np.random.rand()  \n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Refined HybridDE with enhanced local search using dynamic periodicity adjustment to improve convergence and solution quality.", "configspace": "", "generation": 9, "fitness": 0.974233281103932, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.974 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5ab052d3-e03b-4c82-93df-d4ddef65aacf", "metadata": {"aucs": [0.9684773977580603, 0.972846894307798, 0.9813755512459374], "final_y": [0.16485644240914976, 0.1648558260655162, 0.16485595419931676]}, "mutation_prompt": null}
{"id": "e5c965ba-a380-4781-90e0-417978bd7a71", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with minor adaptive tweak to balance exploration and exploitation dynamics.", "configspace": "", "generation": 9, "fitness": 0.9750897690159105, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.975 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5ab052d3-e03b-4c82-93df-d4ddef65aacf", "metadata": {"aucs": [0.9716531949274829, 0.9705038591362197, 0.9831122529840287], "final_y": [0.16485602538314326, 0.16485703969487475, 0.16485612864506394]}, "mutation_prompt": null}
{"id": "1ec87993-1ad1-4cdd-b4c8-2a4c6570471c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 5 * dim)  # Changed: Adaptive population size\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05\n                self.F = 0.9 * self.F + 0.1\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        for i in range(0, len(x), period):  # Changed: Improved periodic constraint application\n            x[i:i+period] = np.mean(x[i:i+period])\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with adaptive population size and improved periodicity constraints for better exploration-exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.9652706352915423, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5ab052d3-e03b-4c82-93df-d4ddef65aacf", "metadata": {"aucs": [0.9651534204898374, 0.9588463115638424, 0.9718121738209471], "final_y": [0.16485603093400403, 0.1648571074867754, 0.16485617758409854]}, "mutation_prompt": null}
{"id": "20e77054-3507-45ca-b0bc-faa2d01584a3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.9 * self.F + 0.1  # New: Adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 4  # Changed: Adjusted period to enhance solutions.\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with improved periodicity handling by adjusting period constraint logic for better interference exploitation.", "configspace": "", "generation": 9, "fitness": 0.9635795432309949, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5ab052d3-e03b-4c82-93df-d4ddef65aacf", "metadata": {"aucs": [0.9541885759082314, 0.9660306071162411, 0.9705194466685121], "final_y": [0.16485588621892, 0.16485645496747248, 0.16485623552146889]}, "mutation_prompt": null}
{"id": "9c242307-6c31-43ad-ac83-3e973d9ae2cc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            adaptive_F = self.F * np.random.uniform(0.5, 1.0)  # New: Dynamic mutation strategy\n            mutant = np.clip(a + adaptive_F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduced a dynamic mutation strategy in DE to enhance exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.9644809278511285, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9725554688034533, 0.95161709944174, 0.9692702153081924], "final_y": [0.16485601469965439, 0.1648575685748449, 0.1648566506459367]}, "mutation_prompt": null}
{"id": "5cf54bbf-a8d3-41c0-9043-c9c1598c8fb2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.3 + 0.5 * (1 - self.evaluations / self.budget)  # Adaptive mutation strategy\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05\n                self.F = 0.85 * self.F + 0.15\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduced adaptive mutation strategy in DE step to enhance exploration in early iterations and exploitation in later stages.", "configspace": "", "generation": 10, "fitness": 0.9600274477491588, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9716531949274829, 0.9515144221498691, 0.9569147261701241], "final_y": [0.16485602538314326, 0.16485601381116444, 0.16485599302595577]}, "mutation_prompt": null}
{"id": "0f2d0b23-fdbc-402e-8907-9f3fe2053275", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.1  # Changed: Adaptive CR update\n                self.F = 0.9 * self.F + 0.1  # Changed: Adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 4  # Changed: Improved periodic application\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with refined adaptive strategies and periodicity constraints to improve convergence.", "configspace": "", "generation": 10, "fitness": 0.9637207506901957, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9561938246588512, 0.9659395651092251, 0.9690288623025111], "final_y": [0.16485606191081703, 0.16485601381116444, 0.16485642765118924]}, "mutation_prompt": null}
{"id": "20df1201-e63b-4d56-9d8e-4db3fc61af9c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.9  # Adjusted to allow more exploration\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.85  # Adjusted adaptive factor\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial = self.apply_periodicity_constraints(trial)  # Enforce periodicity\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.1\n                self.F = 0.8 * self.F + 0.2\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2 + (self.evaluations % 3)  # Dynamically changing period\n        for i in range(0, len(x), period):\n            x[i:i+period] = np.mean(x[i:i+period])\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.15:  # Increased probability for local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with dynamic periodicity and multi-streaming to exploit constructive interference and diversity.", "configspace": "", "generation": 10, "fitness": 0.9493937999509526, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.949 with standard deviation 0.025. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9699925957061301, 0.9637014783903054, 0.9144873257564221], "final_y": [0.16485702517517253, 0.16485601381116444, 0.16485599302595577]}, "mutation_prompt": null}
{"id": "7eaad2c2-86b8-4a2c-8026-463844cfc4cd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(10, 10 * dim - int(dim * 0.1))  # Changed: Dynamic adjustment of population size\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05\n                self.F = 0.85 * self.F + 0.15\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Refined HybridDE with dynamic population size adjustment for improved exploration and convergence.", "configspace": "", "generation": 10, "fitness": 0.9529934118621094, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9718961296306401, 0.9424547408876798, 0.944629365068008], "final_y": [0.16485599854258537, 0.16485582371553498, 0.16485590102986125]}, "mutation_prompt": null}
{"id": "d20c11f3-1127-4a23-a2d6-f9030b18ffad", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            periodicity_freq = 0.1 + 0.05 * (self.evaluations / self.budget)  # Adjusted: Adaptive periodicity application rate\n            for i in range(self.population_size):\n                if np.random.rand() < periodicity_freq:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduced adaptive periodicity constraint frequency to enhance convergence by dynamically adjusting the constraint application rate.", "configspace": "", "generation": 11, "fitness": 0.9624575424670417, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.952941605527263, 0.9656453141840002, 0.9687857076898619], "final_y": [0.16485616100805223, 0.16485601381116444, 0.16485590102986125]}, "mutation_prompt": null}
{"id": "84059a56-47e8-485d-b257-896fdb719da4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.55  # Differential weight (adaptive) modified\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Refined adaptive parameters in HybridDE for improved convergence and exploration balance.", "configspace": "", "generation": 11, "fitness": 0.9529656920636168, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.020. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9684757965735444, 0.9663197325288903, 0.9241015470884156], "final_y": [0.1648566946524176, 0.16485666587186876, 0.16485641958080277]}, "mutation_prompt": null}
{"id": "2de2f2d7-7ba7-4ee7-834f-0839c7ff6c8b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05\n                self.F = 0.85 * self.F + 0.15\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 3  # Changed: Enhanced periodicity for better modular designs\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved HybridDE with enhanced periodicity constraint for better modular designs.", "configspace": "", "generation": 11, "fitness": 0.957110130863334, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.957 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9492145139619371, 0.9517422048491365, 0.9703736737789284], "final_y": [0.1648559822694794, 0.1648562877019627, 0.16485758450114296]}, "mutation_prompt": null}
{"id": "36acde30-b325-4fd7-8ac3-e967e15fb540", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.875 * self.F + 0.125  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Minor optimization of DE parameters to improve exploration-exploitation balance.", "configspace": "", "generation": 11, "fitness": 0.9516653653613277, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.952 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.953892653287195, 0.9513207805455165, 0.9497826622512722], "final_y": [0.16485601469965439, 0.16485605849670093, 0.1648560891649068]}, "mutation_prompt": null}
{"id": "c840c38f-237e-48ed-9449-951b31ae7cc7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.85 * self.CR + 0.10  # Changed: Adaptive CR update\n                self.F = 0.80 * self.F + 0.20  # Changed: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduced subtle diversity enhancements by modifying CR and F adaptation strategy in the DE step for improved exploration.", "configspace": "", "generation": 11, "fitness": 0.9519502826168688, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.952 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9530565305727913, 0.9616987775019022, 0.9410955397759129], "final_y": [0.16485638284169024, 0.16485605849670093, 0.16485647955256844]}, "mutation_prompt": null}
{"id": "228f6d9d-8801-41ee-9a3f-ff5d0e49ad30", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.92  # Changed: Adjusted adaptive factor for balancing\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05\n                self.F = 0.85 * self.F + 0.15\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Modified adaptive factor to enhance exploration-exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.9618559014863535, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9716532694871952, 0.966419957549535, 0.9474944774223302], "final_y": [0.16485587584160966, 0.16485601381116444, 0.16485647869257247]}, "mutation_prompt": null}
{"id": "9eebfc14-14aa-4536-ae1f-733a97920315", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)), options={'maxiter': 50})  # Changed: Limit iterations\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.2:  # Changed: Increased probability of applying periodicity\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "An adaptive and modular hybrid DE algorithm with enhanced periodicity enforcement and strategic local search.", "configspace": "", "generation": 12, "fitness": 0.9705674383121895, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.971 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9725554688034533, 0.9687276183297335, 0.9704192278033814], "final_y": [0.16485601469965439, 0.16485663512669002, 0.16485599528506578]}, "mutation_prompt": null}
{"id": "a40aa7af-1f75-4ed4-8690-529070ddd797", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            self.population_size = max(4, int(10 * self.dim * (1 - self.evaluations/self.budget)))  # Changed: Adaptive population size reduction\n            population, fitness = self.de_step(population[:self.population_size], fitness[:self.population_size])\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduce an adaptive population size reduction mechanism to enhance convergence speed in HybridDE.", "configspace": "", "generation": 12, "fitness": 0.9626723666031637, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9719382970248948, 0.9687294089230954, 0.947349393861501], "final_y": [0.16485601469965439, 0.1648571074867754, 0.16485704442735183]}, "mutation_prompt": null}
{"id": "bcf4012c-3fa6-41aa-8497-ef50ea60c447", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.85  # Modified: Adjusted adaptive factor\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.1  # Modified: Adjusted adaptive CR update\n                self.F = 0.8 * self.F + 0.2  # Modified: Further adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        modular_blocks = len(x) // period\n        for i in range(modular_blocks):  # Modified: Dynamic periodicity enforced\n            block = x[i*period:(i+1)*period]\n            mean_block = np.mean(block)\n            x[i*period:(i+1)*period] = mean_block\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with improved adaptive rate strategies and dynamic periodicity enforcement for better convergence and exploration.", "configspace": "", "generation": 12, "fitness": 0.9635241205513551, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9701116782646249, 0.9687300013849802, 0.9517306820044601], "final_y": [0.16485641515120864, 0.16485608470379987, 0.16485625350862843]}, "mutation_prompt": null}
{"id": "dde3d76f-cf44-409c-80b0-45224653ab1a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c) + np.random.normal(0, 0.1, self.dim), self.lb, self.ub)  # Changed: Added Gaussian noise to mutant\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        avg_value = np.mean(x[:period])  # Changed: Calculate average once\n        x[:period] = avg_value\n        x[period:2*period] = avg_value  # Changed: Improved periodicity implementation\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Refined HybridDE with adaptive mutation strategy and enhanced periodicity constraints to improve convergence and solution quality.", "configspace": "", "generation": 12, "fitness": 0.95585483446966, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.956 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.943643426338791, 0.9531844114885857, 0.9707366655816032], "final_y": [0.16485601674367534, 0.16485681223485982, 0.16485583089420952]}, "mutation_prompt": null}
{"id": "dc65434c-8970-44eb-94d7-501d85ed0109", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.2:  # Changed from 0.1 to 0.2\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced local search strategy by increasing the probability of periodicity constraint application to improve convergence.", "configspace": "", "generation": 13, "fitness": 0.9582492906125597, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.018. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9725554688034533, 0.9693734711958654, 0.9328189318383604], "final_y": [0.16485601469965439, 0.16485633833324254, 0.16485921457054709]}, "mutation_prompt": null}
{"id": "f5d7a36e-f174-49ca-bd33-3cd7db6c8ac6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        scaling_factor = (self.evaluations / self.budget)  # New: Dynamic scaling factor\n        x[:period] = np.mean(x[:period]) * scaling_factor\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduced a dynamic scaling factor in the periodicity constraint to enhance wave interference handling.", "configspace": "", "generation": 13, "fitness": 0.8704385489947878, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.116. And the mean value of best solutions found was 0.196 (0. is the best) with standard deviation 0.044.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.706387392626971, 0.965641349066831, 0.9392869052905612], "final_y": [0.25781321299626747, 0.16485597635498417, 0.16485599302595577]}, "mutation_prompt": null}
{"id": "c7d2b1d5-8ae7-461d-8085-1f819578e930", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.6  # Differential weight (updated)\n        self.CR = 0.85  # Crossover probability (updated)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.15  # Changed: Adaptive CR update\n                self.F = 0.75 * self.F + 0.25  # Changed: Adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2 + np.random.randint(0, 3)  # Changed: Randomized period\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.2:  # Changed: Increased exploration probability\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Refined HybridDE with enhanced adaptive strategies and periodicity enforcement to optimize black box functions more effectively.", "configspace": "", "generation": 13, "fitness": 0.9606841870839236, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9523763670783539, 0.9651388079699843, 0.9645373862034323], "final_y": [0.16485792754393036, 0.16485597635498417, 0.16485590102986125]}, "mutation_prompt": null}
{"id": "08378933-7b59-4e23-8e3e-2842331a34b1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.95\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.95 * self.CR + 0.025  # Adjusted adaptive CR update\n                self.F = 0.9 * self.F + 0.1  # Adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 5  # Increased periodicity constraint for stability\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with optimal periodicity and stability adjustments for improved convergence.", "configspace": "", "generation": 13, "fitness": 0.9618496803148928, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9669663163175526, 0.9592196261599487, 0.9593630984671773], "final_y": [0.1648563455327111, 0.16485601381116444, 0.16485611709338643]}, "mutation_prompt": null}
{"id": "8b971e01-59cf-42f9-879b-17cce37c1495", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.07  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.2  # Changed: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        x = self.apply_periodicity_constraints(x)  # Changed: Moved periodic constraints here\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved HybridDE with enhanced local search technique using periodic constraints to better exploit promising regions.", "configspace": "", "generation": 13, "fitness": 0.9492221120953963, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.949 with standard deviation 0.016. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.966853533264806, 0.9531587899458616, 0.9276540130755214], "final_y": [0.1648563006529834, 0.16485685643730785, 0.1648560206859465]}, "mutation_prompt": null}
{"id": "d8a56358-07db-4da9-94cb-fa44803750da", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with minor adaptive tweak to balance exploration and exploitation dynamics.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9716531949274829, 0.9705038591362197, 0.9831122529840287], "final_y": [0.16485602538314326, 0.16485703969487475, 0.16485612864506394]}, "mutation_prompt": null}
{"id": "319f7e08-da30-4249-8555-86a8d7c0401f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.85 * self.CR + 0.15  # Changed: Further fine-tuned adaptive CR update\n                self.F = 0.85 * self.F + 0.15\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Fine-tune crossover probability update for better convergence in Enhanced HybridDE.", "configspace": "", "generation": 14, "fitness": 0.9614920392240957, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.961 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9716531982816666, 0.9511374312276966, 0.9616854881629237], "final_y": [0.16485601674367534, 0.16485778993637534, 0.16485641958080277]}, "mutation_prompt": null}
{"id": "54ac7956-08ad-4abd-92ad-ab27877a3082", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.5 * (2 - np.sin(0.1 * self.evaluations))  # Changed: Chaotic-based adaptive F update\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Further enhance exploration by integrating a chaotic map-based mutation factor for differential evolution.", "configspace": "", "generation": 14, "fitness": 0.9454925803441318, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.945 with standard deviation 0.012. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9292057776257545, 0.9513519456917733, 0.9559200177148677], "final_y": [0.16485644240914976, 0.1648570166653346, 0.16485695660892696]}, "mutation_prompt": null}
{"id": "ef967490-f6b4-40aa-9c4b-4a5e1e005995", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.95\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial = self.apply_periodicity_constraints(trial)  # Apply periodicity in DE\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05\n                self.F = 0.85 * self.F + 0.15\n            else:\n                new_population[i] = population[i]\n        if np.random.rand() < 0.1:  # Restart population with periodicity\n            population, fitness = self.quasi_oppositional_initialization(self.func.bounds)\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.15:  # Increased chance for local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced Multi-strategy DE with Periodicity-Driven Population Restart and Adaptive Mutation Strategy.", "configspace": "", "generation": 14, "fitness": 0.9525258528599952, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.020. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9240572242391847, 0.9656412403674601, 0.9678790939733413], "final_y": [0.16485630560121245, 0.16485601381116444, 0.16485641958080277]}, "mutation_prompt": null}
{"id": "a9aa994c-8f5d-4fd5-8d44-1b3c9522fc5a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.7 * (1 - (self.evaluations / self.budget)) + 0.3  # Adaptive mutation scale\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduced adaptive mutation scale to enhance search efficiency while maintaining the original exploration-exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.9604511530962153, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9583805971039998, 0.9656413197980904, 0.957331542386556], "final_y": [0.1648573218733782, 0.16485582371553498, 0.16485590102986125]}, "mutation_prompt": null}
{"id": "58d90442-dfe2-4710-8bee-9e94293753b2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.1  # Adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        num_blocks = self.dim // period\n        for i in range(0, num_blocks * period, period):\n            x[i:i+period] = np.mean(x[i:i+period])  # Averaging improved periodicity\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with improved periodicity enforcement and local search integration to harness constructive interference more effectively.", "configspace": "", "generation": 15, "fitness": 0.9665221246330843, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.001. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9660450158797173, 0.9656412403674601, 0.9678801176520758], "final_y": [0.16485668520575725, 0.16485601381116444, 0.16485590102986125]}, "mutation_prompt": null}
{"id": "5f967292-8680-42e2-87d3-0ad237ce4b5d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.92 * self.CR + 0.04  # Modified: Improved adaptive CR update\n                self.F = 0.9 * self.F + 0.1  # Modified: Enhanced adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Minor enhancements to the adaptive update rules for exploration and exploitation balance.", "configspace": "", "generation": 15, "fitness": 0.9598884131182764, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9725554688034533, 0.9656412403674601, 0.9414685301839159], "final_y": [0.16485601469965439, 0.16485601381116444, 0.1648559898478522]}, "mutation_prompt": null}
{"id": "ec307009-e3f8-4b6d-b8c5-96674776da39", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05\n                self.F = 0.85 * self.F + 0.15\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = np.random.choice([2, 4])  # Changed: Dynamic periodicity adjustment\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1 * (1 + 0.1*np.sin(self.evaluations/self.budget * np.pi)):  # Changed: Adaptive local optimization frequency\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introducing dynamic adjustment of periodicity constraints and local optimization frequency to maintain solution diversity and improve convergence.  ", "configspace": "", "generation": 15, "fitness": 0.9595748961328091, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9716532052842566, 0.9419419863432921, 0.9651294967708787], "final_y": [0.16485602051681592, 0.16485602372451014, 0.16485628376895345]}, "mutation_prompt": null}
{"id": "75e58ebb-ec29-47ab-a683-5a1e76dc54e1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.8 * self.F + 0.2  # New: Enhanced adaptive bias towards exploration\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduce slight enhancement in the adaptive bias towards exploration in Differential Evolution step.", "configspace": "", "generation": 15, "fitness": 0.9596058817414881, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.015. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9716531949274829, 0.9383789998305846, 0.9687854504663965], "final_y": [0.16485602538314326, 0.16485601381116444, 0.16485590102986125]}, "mutation_prompt": null}
{"id": "d651e57e-5285-497a-8c00-f380858dac27", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]  # Store the global best individual\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c) + 0.1 * (best_individual - a), self.lb, self.ub)  # Introduce bias towards the best\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduce a slight mutation bias towards the global best in DE to enhance convergence speed.", "configspace": "", "generation": 15, "fitness": 0.9689652040160173, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9716532127405394, 0.9656467726297036, 0.9695956266778085], "final_y": [0.16485601469965439, 0.16485582371553498, 0.16485599302595577]}, "mutation_prompt": null}
{"id": "6820887e-282a-4b22-a4c7-ce3cfac3e301", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  \n                self.F = 0.85 * self.F + 0.1 * np.random.rand()  # Line 1: Improved adaptive F update with random scaling\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2 + np.random.randint(0, 2)  # Line 2: Introduced variability in periodicity\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Line 3: Retained as is\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with improved periodicity alignment and adaptive mutation scaling.", "configspace": "", "generation": 16, "fitness": 0.9467131968489625, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.947 with standard deviation 0.018. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9699051190962532, 0.9254934308897145, 0.94474104056092], "final_y": [0.16485602538314326, 0.16485720535740733, 0.1648560206859465]}, "mutation_prompt": null}
{"id": "384cc452-75c1-4a2a-9f9b-62e8d543ebd3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n                if fitness[i] < np.mean(fitness):  # New: Dynamic CR adjustment based on fitness\n                    self.CR = min(1.0, self.CR + 0.01)\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduced a dynamic adjustment to the crossover probability, CR, to enhance adaptability and convergence speed.", "configspace": "", "generation": 16, "fitness": 0.950792577883797, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.028. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9716531949274829, 0.9114548809209612, 0.969269657802947], "final_y": [0.16485602538314326, 0.16485638392150515, 0.16485746930130152]}, "mutation_prompt": null}
{"id": "4242ed71-be73-4278-8f3c-32bcf9c16a5d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n        self.pop_reduction_factor = 0.9  # New: Introduce population size reduction factor\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            self.population_size = int(self.population_size * self.pop_reduction_factor)  # New: Reduce population size dynamically\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Refined HybridDE with dynamic population size reduction for enhanced convergence speed and efficiency.", "configspace": "", "generation": 16, "fitness": 0.9409369709994299, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.026. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.971653218325385, 0.907239003125722, 0.9439186915471826], "final_y": [0.16485601674367534, 0.17787203807247376, 0.16485590102986125]}, "mutation_prompt": null}
{"id": "1f2852e6-8292-48b9-bb4a-baea65da87ef", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop + (ub - lb) * 0.1 * np.random.rand(self.population_size, self.dim)  # Changed: Enhanced exploration diversity\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Refined HybridDE by adjusting quasi-oppositional initialization to enhance exploration diversity.", "configspace": "", "generation": 16, "fitness": 0.9571518066301498, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.957 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9613652156627984, 0.9639026255813252, 0.9461875786463255], "final_y": [0.16485868437830853, 0.1648563511326373, 0.16485590102986125]}, "mutation_prompt": null}
{"id": "0348b77d-ca0f-48b0-8151-de3b710193e5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.95\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = np.random.uniform(0.4, 0.9)  # Changed: Dynamic mutation scaling\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05\n                self.F = 0.85 * self.F + 0.15\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = np.random.randint(2, 5)  # Changed: Randomized periodicity\n        for start in range(0, self.dim, period):\n            x[start:start + period] = np.mean(x[start:start + period])\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduce adaptive periodicity encouragement and dynamic mutation strategies for improved convergence in DE.", "configspace": "", "generation": 16, "fitness": 0.9544141917037107, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9637458991885965, 0.9563357535720244, 0.9431609223505114], "final_y": [0.1648568018240314, 0.16485600199636974, 0.16485590102986125]}, "mutation_prompt": null}
{"id": "085bb62c-9fca-472c-b4cc-48d44b561bb9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        for i in range(0, self.dim, period * 2):  # Changed: Dynamically enforce periodicity \n            x[i:i+period] = np.mean(x[i:i+period])\n            x[i+period:i+2*period] = x[i:i+period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved HybridDE with dynamic periodicity enforcement to enhance solution quality by exploiting periodic patterns. ", "configspace": "", "generation": 17, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('could not broadcast input array from shape (2,) into shape (0,)').", "error": "ValueError('could not broadcast input array from shape (2,) into shape (0,)')", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {}, "mutation_prompt": null}
{"id": "058c9ac4-7aab-4cbf-989c-4cdef6ebcdc8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.5 + 0.5 * (self.evaluations / self.budget)  # Dynamic mutation factor based on evaluations\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduce a dynamic mutation strategy that adjusts mutation factor based on current iteration versus the total budget to enhance exploration-exploitation balance.", "configspace": "", "generation": 17, "fitness": 0.9686502135074289, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9716531949274829, 0.966419957549535, 0.9678774880452689], "final_y": [0.16485602538314326, 0.16485601381116444, 0.16485694792560013]}, "mutation_prompt": null}
{"id": "66801d42-c3cd-44aa-990a-641b1a67967e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.85 * self.CR + 0.15  # Adjusted: Adaptive CR update\n                self.F = 0.8 * self.F + 0.2  # Adjusted: Adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 4  # Adjusted: Increased periodic block size\n        for i in range(0, len(x), period):\n            x[i:i+period] = np.mean(x[i:i+period])\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introducing a dynamic strategy to improve exploration and convergence by enhancing periodic constraints and adaptive parameters.", "configspace": "", "generation": 17, "fitness": 0.9501791104685601, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.950 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.944656691660953, 0.9529871649339738, 0.9528934748107534], "final_y": [0.16485647022563443, 0.16485582371553498, 0.1648572866668907]}, "mutation_prompt": null}
{"id": "78d408af-c93c-43d6-80ce-9a4d74d1dccf", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n            # New: Stagnation check and dynamic DE parameter adjustment\n            if np.ptp(fitness) < 1e-6: self.F, self.CR = 0.9, 0.8\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduced a check for stagnation and a dynamic adjustment of the DE parameters to enhance convergence speed and solution quality.", "configspace": "", "generation": 17, "fitness": 0.9603576945878558, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.960 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9616061661514229, 0.9664200615107927, 0.9530468561013519], "final_y": [0.16485657043735413, 0.16485597635498417, 0.1648560206859465]}, "mutation_prompt": null}
{"id": "c8d58cfb-fac3-4026-b1e6-75e67bed5ca1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.1  # Adaptive adjustment\n                self.F = 0.8 * self.F + 0.2  # Enhanced adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.15:  # Increased probability for local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with improved adaptive dynamics and hybrid strategy to boost convergence efficiency.", "configspace": "", "generation": 17, "fitness": 0.9537038842751405, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9513937243125739, 0.9532426041157886, 0.9564753243970591], "final_y": [0.1648560123779148, 0.16485616538362902, 0.1648566506459367]}, "mutation_prompt": null}
{"id": "fde4103b-ef09-4f3e-b108-b4a7e0af91ac", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.1  # Modified: More balanced adaptive CR update\n                self.F = 0.75 * self.F + 0.25  # Modified: Enhanced adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Refined Adaptive Differential Evolution by enhancing local exploration through modified CR and F adaptive rates.", "configspace": "", "generation": 18, "fitness": 0.9578119366605979, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9716531949274829, 0.9556328398888408, 0.9461497751654703], "final_y": [0.16485602538314326, 0.16485676964543983, 0.16485599302595577]}, "mutation_prompt": null}
{"id": "e2694ca2-242a-440c-a6ea-2e8a267b5551", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDEPlus:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.95\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n            if np.random.rand() < 0.1:\n                new_population[i] = self.diversity_enhancement(new_population[i], population)\n        return new_population, fitness\n\n    def diversity_enhancement(self, x, population):\n        return np.mean(population, axis=0)\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.15:  # Changed: higher chance for local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDEPlus", "description": "Adaptive HybridDE+ integrates a new diversity mechanism and enhanced local search for improved solution convergence.", "configspace": "", "generation": 18, "fitness": 0.9629646550306937, "feedback": "The algorithm HybridDEPlus got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.007. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9677728267478246, 0.9532411761067837, 0.9678799622374732], "final_y": [0.16485638284169024, 0.16485597635498417, 0.16485599302595577]}, "mutation_prompt": null}
{"id": "b2426e9a-3680-4c10-b2dc-84b3d77b57c2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.1  # Changed: More refined adaptive CR update\n                self.F = 0.8 * self.F + 0.2  # Changed: More refined adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        x_periodic = self.apply_periodicity_constraints(x)  # Changed: Apply periodic constraints before local optimization\n        res = minimize(self.func, x_periodic, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    population[i] = self.local_optimization(population[i])\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with periodicity-aware local tuning and refined adaptive strategy for improved convergence.", "configspace": "", "generation": 18, "fitness": 0.9543396100229834, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.012. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9691598292607193, 0.9395321305967388, 0.9543268702114921], "final_y": [0.16485677773374352, 0.16485616538362902, 0.16485641958080277]}, "mutation_prompt": null}
{"id": "10909fae-f4c1-4b1d-b25b-b0dfe0316de1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.1  # Changed: Adaptive CR update for better balance\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved adaptive adjustment of control parameters in DE for better convergence.", "configspace": "", "generation": 18, "fitness": 0.9662915092061777, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.004. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9716532116982096, 0.9656412403674601, 0.9615800755528634], "final_y": [0.16485601469965439, 0.16485601381116444, 0.16485667948448823]}, "mutation_prompt": null}
{"id": "b4af90e6-698e-4009-beb0-8f7b34100b8e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.75 * self.F + 0.25  # Updated: More aggressive adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with an improved adaptive tweak for more effective exploration-exploitation balance.", "configspace": "", "generation": 18, "fitness": 0.9578653927496159, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9461974598461796, 0.958614721697217, 0.968783996705451], "final_y": [0.16485815405361504, 0.16485582371553498, 0.1648560206859465]}, "mutation_prompt": null}
{"id": "cd6d2fc7-f29c-4baf-9c4f-63d5c5bef583", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.9 * self.F + 0.10  # Changed: Adjusted adaptive F update for better exploration/exploitation balance\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved the balance between exploration and exploitation by slightly adjusting the adaptive update for F.", "configspace": "", "generation": 19, "fitness": 0.9692851065236215, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9716531949274829, 0.9664514283518455, 0.9697506962915362], "final_y": [0.16485602538314326, 0.16485582371553498, 0.1648560333663226]}, "mutation_prompt": null}
{"id": "e76dd023-1517-4bce-b4c8-38a65164928b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]  # Changed: Apply periodicity over first two periods\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.15:  # Changed: Increased probability of local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with adaptive local search intensification and improved periodic constraint handling.", "configspace": "", "generation": 19, "fitness": 0.9666176542996235, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9716532075245646, 0.9594169404504188, 0.9687828149238871], "final_y": [0.16485601674367534, 0.16485616538362902, 0.1648559171708438]}, "mutation_prompt": null}
{"id": "8c921479-89fd-4c23-b6cc-f3fe6b2ef214", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2 + int(np.random.rand() * 2)  # Randomizes period size\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        if np.random.rand() < 0.5:  # Stochastic choice for local search\n            res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n            return res.x if res.success else x\n        return x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved HybridDE with dynamic periodicity adjustment and stochastic local search enhancements for better exploitation.", "configspace": "", "generation": 19, "fitness": 0.9491559993049004, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.949 with standard deviation 0.023. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9708782393199296, 0.9169629546174857, 0.959626803977286], "final_y": [0.16485598142596503, 0.16485669439307182, 0.1648560206859465]}, "mutation_prompt": null}
{"id": "4cedc5f5-ca31-4323-a880-8509e0167501", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n        self.memory = []\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05\n                self.F = 0.85 * self.F + 0.15\n                self.memory.append(fitness[i])  # Track historical improvements\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhance exploration by introducing historical memory for adaptive parameter tuning.", "configspace": "", "generation": 19, "fitness": 0.9543530976000838, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.016. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.966180042051319, 0.9656437310238055, 0.9312355197251271], "final_y": [0.16485723711649525, 0.16485604337833715, 0.164856160224788]}, "mutation_prompt": null}
{"id": "1f362dab-cdee-42ad-91b6-4bc7b68d8f30", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = (0.9 * self.CR + 0.05) * np.random.rand()  # Changed: stochastic CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Further refined the adaptive update of CR by adding a stochastic element, enhancing exploration.", "configspace": "", "generation": 19, "fitness": 0.9209372345585048, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.056. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.8419289655418825, 0.9656412403674601, 0.955241497766172], "final_y": [0.18187867507162325, 0.16485601381116444, 0.1648561171706744]}, "mutation_prompt": null}
{"id": "41e75208-5d64-46ec-8c0b-04da6e43ab2c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    perturbation = np.random.normal(0, 0.01, size=population[i].shape)  # Added: Periodicity-focused perturbation\n                    population[i] = self.local_optimization(x_periodic + perturbation)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduced a periodicity-focused perturbation to enhance the algorithm's ability to escape local minima.", "configspace": "", "generation": 20, "fitness": 0.9638467685922057, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9725541390836046, 0.9499545158333066, 0.9690316508597062], "final_y": [0.16485598194812034, 0.16485602372451014, 0.16485599302595577]}, "mutation_prompt": null}
{"id": "390ab722-6713-4341-953e-a0745f960a28", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduced an adaptive population size strategy to improve exploration and exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.9674344113165724, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.967 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9716531949274829, 0.9602763652433056, 0.9703736737789284], "final_y": [0.16485602538314326, 0.16485606325721835, 0.16485758450114296]}, "mutation_prompt": null}
{"id": "12fb6967-8193-4d7c-b214-8d11dd9d495e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05\n                self.F = 0.85 * self.F + 0.15\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = self.dim // 5  # Adaptive period based on dimension\n        for start in range(0, len(x), period):\n            x[start:start + period] = np.mean(x[start:start + period])\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if fitness[i] < np.mean(fitness) * 1.1:  # Trigger based on fitness\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduces adaptive periodicity and improved local optimization trigger to enhance convergence efficiency.", "configspace": "", "generation": 20, "fitness": 0.9577821246262662, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.013. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9642568784189796, 0.9400635065523008, 0.9690259889075182], "final_y": [0.16485603093400403, 0.16485616538362902, 0.16485695660892696]}, "mutation_prompt": null}
{"id": "6b54fb92-384d-4e6c-969d-65dee5402342", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.85 * self.CR + 0.1  # Changed: More aggressive adaptive CR update\n                self.F = 0.8 * self.F + 0.2  # Changed: More aggressive adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "The algorithm was refined by enhancing adaptation strategies and encouraging periodicity, improving the convergence dynamics.", "configspace": "", "generation": 20, "fitness": 0.962567502001986, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9708570084612235, 0.9576856992379938, 0.9591597983067406], "final_y": [0.16485677773374352, 0.16485666587186876, 0.16485584903728878]}, "mutation_prompt": null}
{"id": "a8dd395a-adec-4d47-bffc-aa392d0aec8c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.85 * self.F + 0.15  # New: Slightly adjusted adaptive F update\n            else:\n                new_population[i] = population[i]\n        # Dynamic population size adjustment\n        if self.evaluations / self.budget > 0.5:\n            self.population_size = max(5, int(0.9 * self.population_size))\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with adaptive exploration control through dynamic population size adjustment.", "configspace": "", "generation": 20, "fitness": 0.9644588919265126, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.009. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "e5c965ba-a380-4781-90e0-417978bd7a71", "metadata": {"aucs": [0.9716531949274829, 0.9513476458859889, 0.9703758349660659], "final_y": [0.16485602538314326, 0.16485604337833715, 0.16485590102986125]}, "mutation_prompt": null}
