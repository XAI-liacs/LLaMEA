{"id": "071fb07a-a747-4ae9-9576-ebf2fa50d2ca", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)  # adaptive population size\n        self.inertia_weight = 0.7\n        self.c1 = 1.5  # cognitive constant\n        self.c2 = 1.5  # social constant\n        self.F = 0.8  # DE mutation factor\n        self.CR = 0.9  # DE crossover probability\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # PSO velocity and position update\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] \n                                 + self.c1 * r1 * (personal_best[i] - pop[i]) \n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n                \n                # DE mutation and crossover\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), bounds[:, 0], bounds[:, 1])\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, pop[i])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n                \n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "HybridPSODE", "description": "A hybrid Particle Swarm Optimization with Adaptive Differential Evolution for dynamic and effective exploration and exploitation of the search space.", "configspace": "", "generation": 0, "fitness": 0.2788486903510231, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": null, "metadata": {"aucs": [0.2788486903510231]}, "mutation_prompt": null}
{"id": "8ade8545-8822-44e2-9c2e-b9ac43bdcfab", "solution": "import numpy as np\n\nclass AQEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.alpha = 0.1  # mutation factor\n        self.quantum_prob = 0.5  # initial quantum probability\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            # Quantum-inspired superposition\n            q_population = np.random.choice([0, 1], (self.population_size, self.dim), p=[1-self.quantum_prob, self.quantum_prob])\n            q_population = np.where(q_population == 1, pop, pop[::-1])\n            \n            # Mutation and selection\n            for i in range(self.population_size):\n                mutation_vector = np.random.uniform(-1, 1, self.dim) * self.alpha\n                trial = q_population[i] + mutation_vector\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_value\n                \n                # Adaptive mutation based on success\n                if eval_count % 10 == 0:\n                    self.alpha = min(0.5, self.alpha * 1.1) if trial_value < fitness[i] else max(0.05, self.alpha * 0.9)\n\n                if eval_count >= self.budget:\n                    break\n\n            # Update quantum probability adaptively\n            self.quantum_prob = min(0.9, self.quantum_prob + 0.01) if np.mean(fitness) < np.median(fitness) else max(0.1, self.quantum_prob - 0.01)\n        \n        best_index = np.argmin(fitness)\n        return pop[best_index]", "name": "AQEA", "description": "Adaptive Quantum-inspired Evolutionary Algorithm (AQEA) leveraging quantum superposition and adaptive mutation to enhance exploration and exploitation in high-dimensional spaces.", "configspace": "", "generation": 1, "fitness": 0.27593980714880306, "feedback": "The algorithm AQEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "071fb07a-a747-4ae9-9576-ebf2fa50d2ca", "metadata": {"aucs": [0.27593980714880306]}, "mutation_prompt": null}
{"id": "a05bd6f8-7f2b-4868-b6ed-6dbd6c17eb76", "solution": "import numpy as np\n\nclass QuantumEA:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.alpha = 0.1  # rotation angle for quantum gate\n\n    def initialize_population(self, bounds):\n        quantum_states = np.random.rand(self.population_size, self.dim, 2)  # amplitude for |0> and |1>\n        quantum_states /= np.linalg.norm(quantum_states, axis=2, keepdims=True)\n        return quantum_states, self.measure_population(quantum_states, bounds)\n\n    def measure_population(self, quantum_states, bounds):\n        binary_population = np.argmax(quantum_states, axis=2)\n        decimal_population = bounds[:, 0] + (bounds[:, 1] - bounds[:, 0]) * (binary_population / (2**self.dim - 1))\n        return decimal_population\n\n    def quantum_rotation(self, quantum_states, best_individual):\n        for i in range(self.population_size):\n            for j in range(self.dim):\n                if np.random.rand() < 0.5:\n                    if best_individual[j] == 0:\n                        quantum_states[i, j, 0], quantum_states[i, j, 1] = \\\n                            np.cos(self.alpha) * quantum_states[i, j, 0] - np.sin(self.alpha) * quantum_states[i, j, 1], \\\n                            np.sin(self.alpha) * quantum_states[i, j, 0] + np.cos(self.alpha) * quantum_states[i, j, 1]\n                    else:\n                        quantum_states[i, j, 0], quantum_states[i, j, 1] = \\\n                            np.cos(self.alpha) * quantum_states[i, j, 0] + np.sin(self.alpha) * quantum_states[i, j, 1], \\\n                            -np.sin(self.alpha) * quantum_states[i, j, 0] + np.cos(self.alpha) * quantum_states[i, j, 1]\n        return quantum_states\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        quantum_states, population = self.initialize_population(bounds)\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n        \n        best_index = np.argmin(fitness)\n        best_individual = population[best_index]\n        best_fitness = fitness[best_index]\n\n        while eval_count < self.budget:\n            quantum_states = self.quantum_rotation(quantum_states, best_individual)\n            population = self.measure_population(quantum_states, bounds)\n            \n            for i in range(self.population_size):\n                fitness[i] = func(population[i])\n                eval_count += 1\n                if fitness[i] < best_fitness:\n                    best_fitness = fitness[i]\n                    best_individual = population[i]\n                    \n                if eval_count >= self.budget:\n                    break\n\n        return best_individual", "name": "QuantumEA", "description": "Quantum-inspired Evolutionary Algorithm (QEA) leveraging superposition states and rotation gates to balance exploration and exploitation in optimizing photonic structures.", "configspace": "", "generation": 2, "fitness": 0.26669502325129235, "feedback": "The algorithm QuantumEA got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "071fb07a-a747-4ae9-9576-ebf2fa50d2ca", "metadata": {"aucs": [0.26669502325129235]}, "mutation_prompt": null}
{"id": "0b350fef-203b-4950-8ef4-c2b71fc08859", "solution": "import numpy as np\n\nclass CoevolutionaryHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.inertia_weight = 0.7\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n\n    def local_search(self, individual, func, bounds):\n        step_size = 0.05 * (bounds[:, 1] - bounds[:, 0])\n        best_local = individual\n        best_local_value = func(individual)\n        for _ in range(5):\n            candidate = individual + np.random.uniform(-step_size, step_size, self.dim)\n            candidate = np.clip(candidate, bounds[:, 0], bounds[:, 1])\n            candidate_value = func(candidate)\n            if candidate_value < best_local_value:\n                best_local = candidate\n                best_local_value = candidate_value\n        return best_local, best_local_value\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] \n                                 + self.c1 * r1 * (personal_best[i] - pop[i]) \n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), bounds[:, 0], bounds[:, 1])\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n            for i in range(self.population_size):\n                improved_individual, improved_value = self.local_search(pop[i], func, bounds)\n                if improved_value < personal_best_values[i]:\n                    personal_best[i] = improved_individual\n                    personal_best_values[i] = improved_value\n                    if improved_value < global_best_value:\n                        global_best = improved_individual\n                        global_best_value = improved_value\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "CoevolutionaryHybridPSODE", "description": "A Coevolutionary HybridPSODE that integrates a local search strategy to enhance fine-tuning and convergence in the optimization of complex search spaces.", "configspace": "", "generation": 3, "fitness": 0.27895087779702954, "feedback": "The algorithm CoevolutionaryHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "071fb07a-a747-4ae9-9576-ebf2fa50d2ca", "metadata": {"aucs": [0.27895087779702954]}, "mutation_prompt": null}
{"id": "4e991d90-cc06-419d-b021-c9b451775633", "solution": "import numpy as np\n\nclass SynergisticHybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.inertia_weight = 0.9  # Start with higher inertia for exploration\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.F = 0.8\n        self.CR = 0.9\n        self.local_search_steps = 10  # Increase local search intensity\n\n    def adaptive_local_search(self, individual, func, bounds, current_best):\n        step_size = 0.1 * (bounds[:, 1] - bounds[:, 0])\n        best_local = individual\n        best_local_value = func(individual)\n        for _ in range(self.local_search_steps):\n            candidate = individual + np.random.uniform(-step_size, step_size, self.dim)\n            candidate = np.clip(candidate, bounds[:, 0], bounds[:, 1])\n            candidate_value = func(candidate)\n            if candidate_value < best_local_value:\n                best_local = candidate\n                best_local_value = candidate_value\n                step_size *= 0.9  # Reduce step size for fine-tuning\n            else:\n                step_size *= 1.1  # Increase step size to escape local optima\n        return best_local, best_local_value\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] \n                                 + self.c1 * r1 * (personal_best[i] - pop[i]) \n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n                \n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), bounds[:, 0], bounds[:, 1])\n                crossover = np.random.rand(self.dim) < self.CR\n                trial = np.where(crossover, mutant, pop[i])\n\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n            for i in range(self.population_size):\n                improved_individual, improved_value = self.adaptive_local_search(pop[i], func, bounds, global_best_value)\n                if improved_value < personal_best_values[i]:\n                    personal_best[i] = improved_individual\n                    personal_best_values[i] = improved_value\n                    if improved_value < global_best_value:\n                        global_best = improved_individual\n                        global_best_value = improved_value\n\n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "SynergisticHybridPSODE", "description": "A Synergistic Hybrid Particle Swarm and Differential Evolution with Adaptive Local Search that dynamically adjusts search parameters to enhance exploration and exploitation balance for complex optimization tasks.", "configspace": "", "generation": 4, "fitness": 0.27881805736077536, "feedback": "The algorithm SynergisticHybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "0b350fef-203b-4950-8ef4-c2b71fc08859", "metadata": {"aucs": [0.27881805736077536]}, "mutation_prompt": null}
{"id": "83febe6a-9801-45a8-a0af-5fe4d89b8a18", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.inertia_weight = 0.5\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor = 0.3\n\n    def quantum_update(self, position, personal_best, global_best):\n        delta = np.random.rand(self.dim)\n        new_position = (position + personal_best) / 2 + self.quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumInspiredPSO", "description": "Quantum-Inspired Particle Swarm Optimization (QIPSO) leverages quantum superposition and entanglement principles to explore complex search spaces with enhanced diversity and convergence.", "configspace": "", "generation": 5, "fitness": 0.28858876813548695, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "0b350fef-203b-4950-8ef4-c2b71fc08859", "metadata": {"aucs": [0.28858876813548695]}, "mutation_prompt": null}
{"id": "1495e599-e4a1-4f2b-ac39-5d9875510172", "solution": "import numpy as np\n\nclass AdaptiveQuantumEvolutionStrategy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.mutation_rate = 0.1\n        self.quantum_factor = 0.4\n        self.sigma = 0.1\n\n    def quantum_mutation(self, position, global_best):\n        mutation = self.quantum_factor * (np.random.rand(self.dim) - 0.5) * 2\n        new_position = position + mutation * (global_best - position)\n        return new_position\n\n    def adaptive_mutation(self, position, func_val, best_val):\n        factor = np.exp(-(func_val - best_val) / (abs(best_val) + 1e-9))\n        noise = self.sigma * factor * np.random.randn(self.dim)\n        return position + noise\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        values = np.array([func(ind) for ind in pop])\n        \n        eval_count = self.population_size\n        global_best_index = np.argmin(values)\n        global_best = pop[global_best_index]\n        global_best_value = values[global_best_index]\n        \n        while eval_count < self.budget:\n            new_population = []\n            new_values = []\n            for i in range(self.population_size):\n                candidate = self.quantum_mutation(pop[i], global_best)\n                candidate = np.clip(candidate, bounds[:, 0], bounds[:, 1])\n\n                candidate_value = func(candidate)\n                eval_count += 1\n\n                if candidate_value < values[i]:\n                    pop[i] = candidate\n                    values[i] = candidate_value\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n\n                # Apply adaptive mutation\n                candidate = self.adaptive_mutation(pop[i], values[i], global_best_value)\n                candidate = np.clip(candidate, bounds[:, 0], bounds[:, 1])\n\n                candidate_value = func(candidate)\n                eval_count += 1\n\n                if candidate_value < values[i]:\n                    pop[i] = candidate\n                    values[i] = candidate_value\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n\n                new_population.append(pop[i])\n                new_values.append(values[i])\n\n                if eval_count >= self.budget:\n                    break\n\n            # Update population\n            pop = np.array(new_population)\n            values = np.array(new_values)\n        \n        return global_best", "name": "AdaptiveQuantumEvolutionStrategy", "description": "Adaptive Quantum Evolution Strategy (AQES) combines quantum-inspired exploration with adaptive mutation controls to efficiently navigate and exploit the search space.", "configspace": "", "generation": 6, "fitness": 0.2769002177929333, "feedback": "The algorithm AdaptiveQuantumEvolutionStrategy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "83febe6a-9801-45a8-a0af-5fe4d89b8a18", "metadata": {"aucs": [0.2769002177929333]}, "mutation_prompt": null}
{"id": "47c028d7-a0a9-4234-bb7d-f66973eddd52", "solution": "import numpy as np\n\nclass BioInspiredCooperativeBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(50, 5 * dim)\n        self.frequency_min = 0.0\n        self.frequency_max = 2.0\n        self.alpha = 0.9  # loudness coefficient\n        self.gamma = 0.9  # pulse rate coefficient\n        self.loudness = 1.0  # initial loudness\n        self.pulse_rate = 0.5  # initial pulse rate\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        fitness = np.array([func(ind) for ind in pop])\n        best_index = np.argmin(fitness)\n        global_best = pop[best_index]\n        global_best_value = fitness[best_index]\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                frequency = self.frequency_min + (self.frequency_max - self.frequency_min) * np.random.rand()\n                velocities[i] += (pop[i] - global_best) * frequency\n                trial = pop[i] + velocities[i]\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                if np.random.rand() > self.pulse_rate:\n                    # Exploitation phase: move globally towards the best known solution\n                    trial = global_best + 0.001 * np.random.randn(self.dim)\n\n                trial_value = func(trial)\n                eval_count += 1\n                if (trial_value < fitness[i]) and (np.random.rand() < self.loudness):\n                    pop[i] = trial\n                    fitness[i] = trial_value\n\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                # Update pulse rate and loudness\n                self.pulse_rate = self.pulse_rate * (1 - np.exp(-self.gamma * eval_count / self.budget))\n                self.loudness *= self.alpha\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "BioInspiredCooperativeBatAlgorithm", "description": "Bio-Inspired Cooperative Bat Algorithm (BICBA) synergizes echolocation and cooperative behavior of bats to efficiently navigate and exploit complex search spaces for global optima.", "configspace": "", "generation": 7, "fitness": 0.2688048467567212, "feedback": "The algorithm BioInspiredCooperativeBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "83febe6a-9801-45a8-a0af-5fe4d89b8a18", "metadata": {"aucs": [0.2688048467567212]}, "mutation_prompt": null}
{"id": "4ee0a021-0e36-439c-b4c5-4a76e9fb4bee", "solution": "import numpy as np\n\nclass AdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.inertia_weight = 0.9   # Start with a high inertia weight\n        self.inertia_min = 0.4      # Lower bound for inertia\n        self.inertia_decay = 0.99   # Decay factor for inertia\n        self.c1 = 1.5               # Cognitive component\n        self.c2 = 1.5               # Social component\n        self.c1_decay = 0.995       # Decay factor for cognitive component\n        self.c2_growth = 1.005      # Growth factor for social component\n        self.quantum_factor = 0.3\n\n    def quantum_update(self, position, personal_best, global_best):\n        delta = np.random.rand(self.dim)\n        new_position = (position + personal_best) / 2 + self.quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                \n                # Adaptive inertia weight and learning factors\n                self.inertia_weight = max(self.inertia_min, self.inertia_weight * self.inertia_decay)\n                self.c1 *= self.c1_decay\n                self.c2 *= self.c2_growth\n                \n                velocities[i] = (self.inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "AdaptiveQuantumPSO", "description": "Adaptive Quantum PSO (AQPSO) introduces adaptive inertia and learning factors for enhanced exploration-exploitation balance, improving convergence efficiency and solution quality.", "configspace": "", "generation": 8, "fitness": 0.2847726255790973, "feedback": "The algorithm AdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "83febe6a-9801-45a8-a0af-5fe4d89b8a18", "metadata": {"aucs": [0.2847726255790973]}, "mutation_prompt": null}
{"id": "3e63ec9d-16f4-453c-8cd2-fdd7ac5c68ed", "solution": "import numpy as np\n\nclass BioInspiredMemeticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.crossover_rate = 0.7\n        self.mutation_rate = 0.1\n        self.local_search_probability = 0.3\n        self.mutation_step_size = 0.05\n\n    def crossover(self, parent1, parent2):\n        if np.random.rand() < self.crossover_rate:\n            crossover_point = np.random.randint(1, self.dim)\n            child = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n            return child\n        return parent1\n\n    def mutate(self, individual, bounds):\n        if np.random.rand() < self.mutation_rate:\n            mutation_vector = np.random.normal(0, self.mutation_step_size, self.dim)\n            mutated_individual = individual + mutation_vector\n            return np.clip(mutated_individual, bounds[:, 0], bounds[:, 1])\n        return individual\n\n    def local_search(self, individual, func, bounds):\n        step_size = self.mutation_step_size * np.random.rand(self.dim)\n        candidate = individual + step_size\n        candidate = np.clip(candidate, bounds[:, 0], bounds[:, 1])\n        if func(candidate) < func(individual):\n            return candidate\n        return individual\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            new_population = []\n            for _ in range(self.population_size // 2):\n                parents_indices = np.random.choice(self.population_size, 2, replace=False)\n                parent1, parent2 = population[parents_indices]\n                \n                child1 = self.crossover(parent1, parent2)\n                child2 = self.crossover(parent2, parent1)\n                \n                child1 = self.mutate(child1, bounds)\n                child2 = self.mutate(child2, bounds)\n\n                if np.random.rand() < self.local_search_probability:\n                    child1 = self.local_search(child1, func, bounds)\n                    child2 = self.local_search(child2, func, bounds)\n\n                new_population.extend([child1, child2])\n\n            population = np.array(new_population)\n            fitness = np.array([func(ind) for ind in population])\n            eval_count += self.population_size\n\n            best_idx = np.argmin(fitness)\n            best_individual = population[best_idx]\n            best_value = fitness[best_idx]\n\n        return best_individual", "name": "BioInspiredMemeticAlgorithm", "description": "Bio-Inspired Memetic Algorithm with Adaptive Crossover and Mutation combines genetic operations with local search to enhance exploration and exploitation in dynamic search spaces.", "configspace": "", "generation": 9, "fitness": 0.2748713593062414, "feedback": "The algorithm BioInspiredMemeticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "83febe6a-9801-45a8-a0af-5fe4d89b8a18", "metadata": {"aucs": [0.2748713593062414]}, "mutation_prompt": null}
{"id": "15f1a603-7641-46f2-8869-74aa261f27d7", "solution": "import numpy as np\n\nclass AdaptiveDE_QTM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.base_pop_size = min(100, 10 * dim)\n        self.pop_size = self.base_pop_size\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.9\n        self.adaptive_threshold = 0.2\n\n    def quantum_tunneling(self, position, best):\n        delta = np.random.rand(self.dim)\n        factor = np.random.normal(0, 1, self.dim)\n        return position + factor * (best - position) * delta\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.pop_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        pop_values = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(pop_values)\n        best = pop[best_idx]\n        best_value = pop_values[best_idx]\n\n        eval_count = self.pop_size\n\n        while eval_count < self.budget:\n            new_pop = []\n            for i in range(self.pop_size):\n                indices = np.random.choice(self.pop_size, 3, replace=False)\n                a, b, c = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                \n                mutant = np.clip(a + self.mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant, pop[i])\n                \n                if np.random.rand() < self.adaptive_threshold:\n                    trial = self.quantum_tunneling(trial, best)\n                \n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_value = func(trial)\n                eval_count += 1\n\n                if trial_value < pop_values[i]:\n                    new_pop.append(trial)\n                    pop_values[i] = trial_value\n                    if trial_value < best_value:\n                        best = trial\n                        best_value = trial_value\n                else:\n                    new_pop.append(pop[i])\n\n                if eval_count >= self.budget:\n                    break\n            \n            pop = np.array(new_pop)\n            \n            # Adapt population size dynamically\n            if eval_count < self.budget * 0.5:\n                self.pop_size = int(self.base_pop_size * (1 + 0.2 * (eval_count / self.budget)))\n            elif eval_count < self.budget * 0.8:\n                self.pop_size = int(self.base_pop_size * (1 - 0.2 * (eval_count / self.budget)))\n\n        return best", "name": "AdaptiveDE_QTM", "description": "Adaptive Differential Evolution with Quantum-Tunneling Mutation (ADE-QTM) adapts population size and integrates quantum-inspired tunneling to escape local optima and enhance global search efficiency.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 102 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 102 is out of bounds for axis 0 with size 100')", "parent_id": "83febe6a-9801-45a8-a0af-5fe4d89b8a18", "metadata": {}, "mutation_prompt": null}
{"id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  # Adaptive quantum factor\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSO", "description": "Quantum-Enhanced Adaptive PSO (QEAPSO) dynamically adjusts quantum and inertia parameters for improved exploration and exploitation balance in high-dimensional spaces.", "configspace": "", "generation": 11, "fitness": 0.28956669165709803, "feedback": "The algorithm QuantumEnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "83febe6a-9801-45a8-a0af-5fe4d89b8a18", "metadata": {"aucs": [0.28956669165709803]}, "mutation_prompt": null}
{"id": "4834b325-1770-4704-bb41-faedf3898181", "solution": "import numpy as np\n\nclass HybridEvolutionaryDifferentialPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.diff_weight = 0.5  # Differential weight for mutation\n        self.crossover_prob = 0.7  # Crossover probability\n\n    def differential_mutation(self, pop, i):\n        indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n        a, b, c = pop[indices]\n        mutant = a + self.diff_weight * (b - c)\n        return mutant\n\n    def crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_prob\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                mutant = self.differential_mutation(pop, i)\n                mutant = np.clip(mutant, bounds[:, 0], bounds[:, 1])\n                trial = self.crossover(pop[i], mutant)\n                trial_value = func(trial)\n                eval_count += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "HybridEvolutionaryDifferentialPSO", "description": "Hybrid Evolutionary and Differential Particle Swarm Optimization (HEDPSO) integrates evolutionary strategies with differential updates for enhanced diversity and convergence in complex search spaces.", "configspace": "", "generation": 12, "fitness": 0.2789178325218531, "feedback": "The algorithm HybridEvolutionaryDifferentialPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2789178325218531]}, "mutation_prompt": null}
{"id": "07885646-72d9-4318-9d15-785946e90ba2", "solution": "import numpy as np\n\nclass QuantumSwarmHybridEnhancement:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.inertia_weight = 0.7\n        self.cognitive_coeff = 1.5\n        self.social_coeff = 1.5\n        self.quantum_tunneling_factor = 0.2\n        self.diversity_injection_prob = 0.1\n\n    def quantum_tunneling(self, position, global_best):\n        return position + self.quantum_tunneling_factor * np.random.randn(self.dim) * (global_best - position)\n\n    def diversity_injection(self, bounds):\n        return np.random.rand(self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i] +\n                                 self.cognitive_coeff * r1 * (personal_best[i] - pop[i]) +\n                                 self.social_coeff * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                if np.random.rand() < self.diversity_injection_prob:\n                    pop[i] = self.diversity_injection(bounds)\n\n                trial = self.quantum_tunneling(pop[i], global_best)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumSwarmHybridEnhancement", "description": "Quantum-Swarm Hybrid Enhancement (QSHE) integrates quantum tunneling and swarm intelligence with adaptive diversity injection to maintain exploration and convergence balance in multidimensional spaces.", "configspace": "", "generation": 13, "fitness": 0.28609406525674963, "feedback": "The algorithm QuantumSwarmHybridEnhancement got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28609406525674963]}, "mutation_prompt": null}
{"id": "439376f9-15ed-4623-a8a8-bff308fd9407", "solution": "import numpy as np\n\nclass QuantumInspiredDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.mutation_factor_initial = 0.8\n        self.mutation_factor_final = 0.5\n        self.crossover_rate = 0.9\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_mutation(self, target, donor, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = eval_count / self.budget\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        return donor + quantum_factor * (global_best - target) * delta\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        global_best = pop[np.argmin(fitness)]\n        global_best_value = fitness.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice([j for j in range(self.population_size) if j != i], 3, replace=False)\n                a, b, c = pop[indices]\n                lambda_factor = eval_count / self.budget\n                mutation_factor = self.mutation_factor_initial * (1 - lambda_factor) + self.mutation_factor_final * lambda_factor\n                \n                donor = np.clip(a + mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n\n                trial = np.array([donor[j] if np.random.rand() < self.crossover_rate else pop[i, j] for j in range(self.dim)])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumInspiredDifferentialEvolution", "description": "Quantum-Inspired Differential Evolution (QIDE) utilizes quantum-inspired operators to enhance Differential Evolution's exploration and exploitation balance, adapting to high-dimensional spaces dynamically.", "configspace": "", "generation": 14, "fitness": 0.2810801336454045, "feedback": "The algorithm QuantumInspiredDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2810801336454045]}, "mutation_prompt": null}
{"id": "1332ff67-7efb-4988-b92c-68b16f3bec8a", "solution": "import numpy as np\n\nclass DifferentialEvolutionQuantumLevy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.f = 0.8  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.alpha = 0.01  # Levy flight parameter\n\n    def levy_flight(self):\n        # Generating a step from a Levy distribution\n        u = np.random.normal(0, 1, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.abs(v) ** (1 / 3)\n        return self.alpha * step\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                idxs = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                # Apply a quantum-inspired Levy flight step\n                trial += self.levy_flight()\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "name": "DifferentialEvolutionQuantumLevy", "description": "Differential Evolution with Quantum-Inspired Levy Flight (DEQILF) combines differential mutation and crossover with quantum-inspired Levy flights for enhanced exploration and exploitation in complex landscapes.", "configspace": "", "generation": 15, "fitness": 0.2805495664343257, "feedback": "The algorithm DifferentialEvolutionQuantumLevy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2805495664343257]}, "mutation_prompt": null}
{"id": "e4ec83b8-0618-401e-9da1-ebcd4a3a3b60", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO_DPS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.dynamic_population_factor = 0.5\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  # Adaptive quantum factor\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n                             \n            adaptive_population_size = int(self.population_size * \n                                           (1 - self.dynamic_population_factor * eval_count / self.budget))\n\n            for i in range(adaptive_population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSO_DPS", "description": "Quantum-Enhanced Adaptive PSO with Dynamic Population Size (QEAPSO-DPS) improves convergence by dynamically adjusting the population size and enhancing exploration-exploitation balance using adaptive quantum parameters.", "configspace": "", "generation": 16, "fitness": 0.28893616997319194, "feedback": "The algorithm QuantumEnhancedAdaptivePSO_DPS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28893616997319194]}, "mutation_prompt": null}
{"id": "10ad91aa-4c31-4a60-ad12-709aff885ba5", "solution": "import numpy as np\n\nclass QuantumGeneticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.mutation_rate_initial = 0.1\n        self.mutation_rate_final = 0.001\n        self.quantum_factor_initial = 0.05\n        self.quantum_factor_final = 0.001\n\n    def quantum_mutation(self, individual, eval_count):\n        lambda_factor = eval_count / self.budget\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        mutation_vector = np.random.normal(0, quantum_factor, self.dim)\n        return individual + mutation_vector\n\n    def adaptive_mutation_rate(self, eval_count):\n        return self.mutation_rate_initial * (1 - eval_count / self.budget) + self.mutation_rate_final * (eval_count / self.budget)\n\n    def crossover(self, parent1, parent2):\n        mask = np.random.rand(self.dim) < 0.5\n        child = np.where(mask, parent1, parent2)\n        return child\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in population])\n        \n        eval_count = self.population_size\n        best_solution = population[np.argmin(fitness)]\n        best_fitness = fitness.min()\n\n        while eval_count < self.budget:\n            new_population = []\n            for _ in range(self.population_size // 2):\n                parents_indices = np.random.choice(self.population_size, 2, replace=False)\n                parent1, parent2 = population[parents_indices[0]], population[parents_indices[1]]\n                child1, child2 = self.crossover(parent1, parent2), self.crossover(parent2, parent1)\n                \n                mutation_rate = self.adaptive_mutation_rate(eval_count)\n                if np.random.rand() < mutation_rate:\n                    child1 = self.quantum_mutation(child1, eval_count)\n                if np.random.rand() < mutation_rate:\n                    child2 = self.quantum_mutation(child2, eval_count)\n\n                new_population.extend([child1, child2])\n            \n            new_population = np.array(new_population)\n            new_population = np.clip(new_population, bounds[:, 0], bounds[:, 1])\n\n            new_fitness = np.array([func(ind) for ind in new_population])\n            eval_count += self.population_size\n\n            combined_population = np.vstack((population, new_population))\n            combined_fitness = np.hstack((fitness, new_fitness))\n\n            best_indices = np.argsort(combined_fitness)[:self.population_size]\n            population = combined_population[best_indices]\n            fitness = combined_fitness[best_indices]\n\n            best_candidate_index = np.argmin(fitness)\n            if fitness[best_candidate_index] < best_fitness:\n                best_solution = population[best_candidate_index]\n                best_fitness = fitness[best_candidate_index]\n\n        return best_solution", "name": "QuantumGeneticAlgorithm", "description": "Quantum Genetic Algorithm (QGA) integrates quantum-inspired mechanisms into genetic algorithms, using quantum operators and adaptive mutation to enhance diversity and convergence.", "configspace": "", "generation": 17, "fitness": 0.28265182002441247, "feedback": "The algorithm QuantumGeneticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28265182002441247]}, "mutation_prompt": null}
{"id": "b28c66dc-209f-4117-ab4c-45d456de6d7f", "solution": "import numpy as np\nimport heapq\n\nclass QuantumEnhancedAdaptivePSOWithArchive:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.archive_size = min(5, dim)  # Size of elite archive\n\n    def quantum_update(self, position, personal_best, global_best, eval_count, archive):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  # Adaptive quantum factor\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        # Select a random elite from the archive\n        elite = archive[np.random.randint(len(archive))]\n        new_position = (position + personal_best) / 2 + quantum_factor * (elite - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        # Initialize elite archive\n        archive = [(val, personal_best[i]) for i, val in enumerate(personal_best_values)]\n        heapq.heapify(archive)\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count, [a[1] for a in archive])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n                \n                # Update elite archive\n                if len(archive) < self.archive_size:\n                    heapq.heappush(archive, (trial_value, trial))\n                else:\n                    heapq.heappushpop(archive, (trial_value, trial))\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSOWithArchive", "description": "Quantum-Enhanced Adaptive PSO with Elite Archive improves solution diversity and convergence by maintaining an archive of the best solutions to guide particles towards promising regions.", "configspace": "", "generation": 18, "fitness": 0.28426182786694254, "feedback": "The algorithm QuantumEnhancedAdaptivePSOWithArchive got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28426182786694254]}, "mutation_prompt": null}
{"id": "66869b2d-4cda-4964-9fe2-f177f936bc0b", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO_MSC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.num_swarms = 3  # Increase collaboration by using multiple swarms\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  # Adaptive quantum factor\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        # Initialize multiple swarms\n        swarms = [\n            np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n            for _ in range(self.num_swarms)\n        ]\n        velocities = [np.zeros_like(swarm) for swarm in swarms]\n        personal_bests = [swarm.copy() for swarm in swarms]\n        personal_best_values = [np.array([func(ind) for ind in swarm]) for swarm in swarms]\n        global_bests = [personal_bests[i][np.argmin(personal_best_values[i])] for i in range(self.num_swarms)]\n        global_best_values = [values.min() for values in personal_best_values]\n\n        eval_count = self.population_size * self.num_swarms\n\n        while eval_count < self.budget:\n            for swarm_idx in range(self.num_swarms):\n                inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                                 (1 - eval_count / self.budget) + self.final_inertia_weight\n                for i in range(self.population_size):\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    velocities[swarm_idx][i] = (inertia_weight * velocities[swarm_idx][i]\n                                                + self.c1 * r1 * (personal_bests[swarm_idx][i] - swarms[swarm_idx][i])\n                                                + self.c2 * r2 * (global_bests[swarm_idx] - swarms[swarm_idx][i]))\n                    swarms[swarm_idx][i] += velocities[swarm_idx][i]\n                    swarms[swarm_idx][i] = np.clip(swarms[swarm_idx][i], bounds[:, 0], bounds[:, 1])\n\n                    trial = self.quantum_update(swarms[swarm_idx][i], personal_bests[swarm_idx][i], global_bests[swarm_idx], eval_count)\n                    trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                    trial_value = func(trial)\n                    eval_count += 1\n                    if trial_value < personal_best_values[swarm_idx][i]:\n                        personal_bests[swarm_idx][i] = trial\n                        personal_best_values[swarm_idx][i] = trial_value\n                        if trial_value < global_best_values[swarm_idx]:\n                            global_bests[swarm_idx] = trial\n                            global_best_values[swarm_idx] = trial_value\n\n                    if eval_count >= self.budget:\n                        break\n\n            # Collaborate by sharing best solutions between swarms\n            overall_global_best_value = min(global_best_values)\n            for swarm_idx in range(self.num_swarms):\n                if global_best_values[swarm_idx] > overall_global_best_value:\n                    global_bests[swarm_idx] = global_bests[np.argmin(global_best_values)]\n                    global_best_values[swarm_idx] = overall_global_best_value\n\n        best_swarm_idx = np.argmin(global_best_values)\n        return global_bests[best_swarm_idx]", "name": "QuantumEnhancedAdaptivePSO_MSC", "description": "Quantum-Enhanced Adaptive PSO with Multi-Swarm Collaboration (QEAPSO-MSC) leverages multiple interacting swarms with adaptive quantum dynamics to enhance exploration and convergence in high-dimensional optimization problems.", "configspace": "", "generation": 19, "fitness": 0.28441361327888237, "feedback": "The algorithm QuantumEnhancedAdaptivePSO_MSC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28441361327888237]}, "mutation_prompt": null}
{"id": "4443d15d-e0fd-4e52-852e-c79a0e2d95c3", "solution": "import numpy as np\n\nclass HybridGeneticSimulatedAnnealing:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 5 * dim)\n        self.mutation_rate = 0.1\n        self.initial_temperature = 1000\n        self.final_temperature = 1\n        self.alpha = 0.99\n\n    def crossover(self, parent1, parent2):\n        mask = np.random.rand(self.dim) < 0.5\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def mutate(self, individual):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_values = np.random.randn(self.dim) * mutation_mask\n        return individual + mutation_values\n\n    def simulated_annealing(self, individual, func, temperature):\n        neighbor = self.mutate(individual)\n        delta_energy = func(neighbor) - func(individual)\n        if delta_energy < 0 or np.random.rand() < np.exp(-delta_energy / temperature):\n            return neighbor\n        return individual\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in population])\n        best_individual = population[np.argmin(fitness)]\n        best_fitness = fitness.min()\n\n        eval_count = self.population_size\n\n        temperature = self.initial_temperature\n        while eval_count < self.budget:\n            new_population = []\n            for _ in range(self.population_size // 2):\n                selected_indices = np.random.choice(self.population_size, 2, replace=False)\n                parent1, parent2 = population[selected_indices]\n                offspring1 = self.crossover(parent1, parent2)\n                offspring2 = self.crossover(parent2, parent1)\n\n                offspring1 = np.clip(offspring1, bounds[:, 0], bounds[:, 1])\n                offspring2 = np.clip(offspring2, bounds[:, 0], bounds[:, 1])\n\n                offspring1 = self.simulated_annealing(offspring1, func, temperature)\n                offspring2 = self.simulated_annealing(offspring2, func, temperature)\n\n                new_population.extend([offspring1, offspring2])\n\n                eval_count += 2\n                if eval_count >= self.budget:\n                    break\n\n            population = np.array(new_population)\n            fitness = np.array([func(ind) for ind in population])\n\n            current_best_index = np.argmin(fitness)\n            if fitness[current_best_index] < best_fitness:\n                best_individual = population[current_best_index]\n                best_fitness = fitness[current_best_index]\n\n            temperature *= self.alpha\n\n        return best_individual", "name": "HybridGeneticSimulatedAnnealing", "description": "Hybrid Genetic-Simulated Annealing (HGSA) synergistically combines genetic algorithm crossover with simulated annealing for enhanced global search capabilities in complex landscapes.", "configspace": "", "generation": 20, "fitness": 0.28164107641679204, "feedback": "The algorithm HybridGeneticSimulatedAnnealing got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28164107641679204]}, "mutation_prompt": null}
{"id": "70e7914e-ee80-4abd-bd29-04921b907d30", "solution": "import numpy as np\n\nclass QuantumGuidedEvolutionarySwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.8\n        self.final_inertia_weight = 0.3\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.mutation_probability = 0.1\n        self.quantum_factor_initial = 0.25\n        self.quantum_factor_final = 0.05\n\n    def quantum_guidance(self, position, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = position + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def mutate(self, individual):\n        mutation = np.random.rand(self.dim) < self.mutation_probability\n        changes = np.random.normal(0, 0.1, self.dim) * mutation\n        return individual + changes\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                # Quantum-guided trial\n                trial = self.quantum_guidance(pop[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                # Apply mutation\n                trial = self.mutate(trial)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumGuidedEvolutionarySwarmOptimization", "description": "Quantum-Guided Evolutionary Swarm Optimization (QGESO) integrates quantum-inspired guidance into evolutionary strategies to enhance convergence performance in complex and high-dimensional optimization landscapes.", "configspace": "", "generation": 21, "fitness": 0.2895063738704703, "feedback": "The algorithm QuantumGuidedEvolutionarySwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2895063738704703]}, "mutation_prompt": null}
{"id": "16bb9dcc-07f5-455b-a3cd-0d8417182ef3", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def get_neighborhood_best(self, pop, personal_best_values, i, neighborhood_size=5):\n        indices = np.random.choice(range(self.population_size), size=neighborhood_size, replace=False)\n        neighborhood_best_idx = indices[np.argmin(personal_best_values[indices])]\n        return pop[neighborhood_best_idx]\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                neighborhood_best = self.get_neighborhood_best(pop, personal_best_values, i)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (neighborhood_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSO_DN", "description": "Quantum-Enhanced Adaptive PSO with Dynamic Neighborhoods (QEAPSO-DN) integrates adaptive neighborhood structures with quantum updates to enhance convergence speed and solution quality in complex optimization landscapes.", "configspace": "", "generation": 22, "fitness": 0.2846156153553092, "feedback": "The algorithm QuantumEnhancedAdaptivePSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2846156153553092]}, "mutation_prompt": null}
{"id": "993b8aa4-17a3-4b68-903c-30db266d2a45", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.neighborhood_size = max(5, int(0.1 * self.population_size))\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                \n                # Dynamic neighborhood best selection\n                neighbors = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best_idx = neighbors[np.argmin(personal_best_values[neighbors])]\n                local_best = personal_best[local_best_idx]\n\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (local_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSO_DN", "description": "Quantum-Enhanced Adaptive PSO with Dynamic Neighborhood (QEAPSO-DN) introduces a dynamic neighborhood mechanism to foster diverse particle interactions, enhancing convergence in complex landscapes.", "configspace": "", "generation": 23, "fitness": 0.2871302538774766, "feedback": "The algorithm QuantumEnhancedAdaptivePSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2871302538774766]}, "mutation_prompt": null}
{"id": "7d6640c8-5b5c-4639-93e2-b215768e770f", "solution": "import numpy as np\n\nclass BioInspiredQuantumDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.quantum_factor_initial = 0.4\n        self.quantum_factor_final = 0.1\n\n    def quantum_mutation(self, target, donor, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  # Adaptive quantum factor\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        quantum_donor = donor + quantum_factor * (global_best - target) * delta\n        return quantum_donor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        global_best = pop[np.argmin(fitness)]\n        global_best_value = fitness.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = pop[indices[0]], pop[indices[1]], pop[indices[2]]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, bounds[:, 0], bounds[:, 1])\n\n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                trial = self.quantum_mutation(pop[i], trial, global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "BioInspiredQuantumDifferentialEvolution", "description": "Bio-Inspired Quantum Differential Evolution (BQDE) employs quantum-inspired principles and differential evolution to adaptively balance exploration and exploitation, enhancing convergence in complex, high-dimensional landscapes.", "configspace": "", "generation": 24, "fitness": 0.28135166862340744, "feedback": "The algorithm BioInspiredQuantumDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28135166862340744]}, "mutation_prompt": null}
{"id": "dbce895d-b8e4-4f3c-b8f2-7b2971f8403c", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSOWithLevyFlights:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def levy_flight(self, L):\n        u = np.random.normal(0, 1, self.dim) * np.power(L, -1.0 / 3.0)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / np.power(np.abs(v), 1 / 2)\n        return step\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n\n                if np.random.rand() < 0.1:  # Apply Levy flight with a probability of 10%\n                    positions_update = self.levy_flight(1.5)\n                    pop[i] += velocities[i] + positions_update\n                else:\n                    pop[i] += velocities[i]\n\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSOWithLevyFlights", "description": "Quantum-Enhanced Adaptive PSO with Lvy Flights (QEAPSO-LF) integrates Lvy flights to enhance global exploration and avoid local optima in high-dimensional spaces.", "configspace": "", "generation": 25, "fitness": 0.2880682976724789, "feedback": "The algorithm QuantumEnhancedAdaptivePSOWithLevyFlights got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2880682976724789]}, "mutation_prompt": null}
{"id": "661fa00a-9746-42df-bb76-7e2d7ece6ec1", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO_DynamicNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.neighborhood_size = max(2, self.population_size // 10)\n\n    def quantum_update(self, position, personal_best, local_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget) \n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (local_best - position) * delta\n        return new_position\n\n    def find_local_best(self, index, personal_best, personal_best_values):\n        neighborhood_indices = (np.arange(index - self.neighborhood_size, index + self.neighborhood_size + 1) \n                                % self.population_size)\n        local_best_index = neighborhood_indices[np.argmin(personal_best_values[neighborhood_indices])]\n        return personal_best[local_best_index]\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                local_best = self.find_local_best(i, personal_best, personal_best_values)\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], local_best, global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSO_DynamicNeighborhood", "description": "Quantum-Enhanced Adaptive PSO with Dynamic Neighborhood (QEAPSO-DN) enhances local convergence by incorporating a dynamic neighborhood strategy, leveraging neighboring solutions to adaptively refine exploration and exploitation.", "configspace": "", "generation": 26, "fitness": 0.28768645675776217, "feedback": "The algorithm QuantumEnhancedAdaptivePSO_DynamicNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28768645675776217]}, "mutation_prompt": null}
{"id": "8c5ccd8b-2d82-4637-976c-69bf26486b70", "solution": "import numpy as np\n\nclass MultiSwarmQuantumDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.num_swarms = 5\n        self.swarm_size = self.population_size // self.num_swarms\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.quantum_factor = 0.1\n\n    def quantum_update(self, position, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        new_position = position + self.quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        swarms = [np.random.rand(self.swarm_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n                  for _ in range(self.num_swarms)]\n        swarm_best = [swarm[np.argmin([func(ind) for ind in swarm])] for swarm in swarms]\n        global_best = min(swarm_best, key=lambda ind: func(ind))\n        eval_count = self.num_swarms * self.swarm_size\n\n        while eval_count < self.budget:\n            for swarm_idx, swarm in enumerate(swarms):\n                for i in range(self.swarm_size):\n                    if eval_count >= self.budget:\n                        break\n\n                    a, b, c = swarm[np.random.choice(self.swarm_size, 3, replace=False)]\n                    mutant = np.clip(a + self.F * (b - c), bounds[:, 0], bounds[:, 1])\n                    cross_points = np.random.rand(self.dim) < self.CR\n                    trial = np.where(cross_points, mutant, swarm[i])\n                    \n                    trial = self.quantum_update(trial, global_best, eval_count)\n                    trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                    trial_value = func(trial)\n                    eval_count += 1\n\n                    if trial_value < func(swarm[i]):\n                        swarm[i] = trial\n\n                swarm_best[swarm_idx] = min(swarm, key=lambda ind: func(ind))\n                if func(swarm_best[swarm_idx]) < func(global_best):\n                    global_best = swarm_best[swarm_idx]\n\n        return global_best", "name": "MultiSwarmQuantumDifferentialEvolution", "description": "Multi-Swarm Quantum Differential Evolution (MSQDE) utilizes multiple cooperative sub-swarms with quantum-inspired differential evolution for enhanced exploration and convergence.", "configspace": "", "generation": 27, "fitness": 0.2757001766772387, "feedback": "The algorithm MultiSwarmQuantumDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2757001766772387]}, "mutation_prompt": null}
{"id": "106a07f2-6e89-4f4c-8aa2-74dcd861a5c6", "solution": "import numpy as np\nfrom scipy.special import gamma\n\nclass QuantumPSOLevyFlight:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.beta = 1.5  # Lvy flight parameter\n\n    def levy_flight(self, size):\n        sigma_u = (gamma(1 + self.beta) * np.sin(np.pi * self.beta / 2) /\n                   (gamma((1 + self.beta) / 2) * self.beta * 2 ** ((self.beta - 1) / 2))) ** (1 / self.beta)\n        u = np.random.normal(0, sigma_u, size)\n        v = np.random.normal(0, 1, size)\n        step = u / (np.abs(v) ** (1 / self.beta))\n        return step\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                if np.random.rand() < 0.5:  # Apply Lvy flight occasionally\n                    levy_step = self.levy_flight(self.dim)\n                    pop[i] += levy_step\n                    pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumPSOLevyFlight", "description": "Quantum PSO with Lvy Flight (QPSO-LF) enhances exploration by integrating Lvy flight with adaptive quantum and inertia mechanisms for diversified search in complex spaces.", "configspace": "", "generation": 28, "fitness": 0.28766315312884494, "feedback": "The algorithm QuantumPSOLevyFlight got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28766315312884494]}, "mutation_prompt": null}
{"id": "8c13da2d-e59d-4386-9f73-dc874fe73494", "solution": "import numpy as np\n\nclass QuantumEnhancedWhaleOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.a_initial = 2.0\n        self.a_final = 0.1\n        self.b_initial = 1.5\n        self.b_final = 0.5\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_superposition(self, position, best_position, eval_count):\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        delta = np.random.rand(self.dim)\n        superposed_position = position + quantum_factor * (best_position - position) * delta\n        return superposed_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            a = self.a_initial * (1 - eval_count / self.budget) + self.a_final * (eval_count / self.budget)\n            b = self.b_initial * (1 - eval_count / self.budget) + self.b_final * (eval_count / self.budget)\n\n            for i in range(self.population_size):\n                r = np.random.rand()\n                A = 2 * a * r - a\n                C = 2 * r\n\n                if np.random.rand() < 0.5:\n                    D = np.abs(C * global_best - pop[i])\n                    pop[i] = global_best - A * D\n                else:\n                    l = np.random.uniform(-1, 1, size=self.dim)\n                    D_prime = np.abs(global_best - pop[i])\n                    pop[i] = D_prime * np.exp(b * l) * np.cos(2 * np.pi * l) + global_best\n\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_superposition(pop[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedWhaleOptimization", "description": "Quantum-Enhanced Whale Optimization Algorithm (QEWOA) uses quantum superposition states and adaptive encircling strategies to enhance exploration and exploitation in complex search spaces.", "configspace": "", "generation": 29, "fitness": 0.2849875657567241, "feedback": "The algorithm QuantumEnhancedWhaleOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2849875657567241]}, "mutation_prompt": null}
{"id": "cbac3f79-fd2e-4bf0-a60b-389e453a9c79", "solution": "import numpy as np\n\nclass AdaptiveMultiSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.num_swarms = 3\n        self.population_size = min(50, 5 * dim)\n        self.inertia_weight = 0.7\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.migration_rate = 0.1\n\n    def migrate_particles(self, swarms, global_best):\n        for swarm in swarms:\n            if np.random.rand() < self.migration_rate:\n                idx = np.random.randint(0, len(swarm['positions']))\n                swarm['positions'][idx] = global_best\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        swarms = []\n        for _ in range(self.num_swarms):\n            positions = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n            velocities = np.zeros_like(positions)\n            personal_best = positions.copy()\n            personal_best_values = np.array([func(ind) for ind in positions])\n            eval_count = self.population_size\n            swarms.append({'positions': positions, 'velocities': velocities, \n                           'personal_best': personal_best, 'personal_best_values': personal_best_values})\n\n        global_best = min(swarms, key=lambda swarm: swarm['personal_best_values'].min())['personal_best'].min(0)\n        global_best_value = min(swarm['personal_best_values'].min() for swarm in swarms)\n\n        eval_count = self.num_swarms * self.population_size\n\n        while eval_count < self.budget:\n            for swarm in swarms:\n                for i in range(self.population_size):\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    velocities = (self.inertia_weight * swarm['velocities'][i]\n                                  + self.c1 * r1 * (swarm['personal_best'][i] - swarm['positions'][i])\n                                  + self.c2 * r2 * (global_best - swarm['positions'][i]))\n                    swarm['positions'][i] += velocities\n                    swarm['positions'][i] = np.clip(swarm['positions'][i], bounds[:, 0], bounds[:, 1])\n\n                    value = func(swarm['positions'][i])\n                    eval_count += 1\n\n                    if value < swarm['personal_best_values'][i]:\n                        swarm['personal_best'][i] = swarm['positions'][i]\n                        swarm['personal_best_values'][i] = value\n                        if value < global_best_value:\n                            global_best = swarm['positions'][i]\n                            global_best_value = value\n\n                    if eval_count >= self.budget:\n                        break\n\n            self.migrate_particles(swarms, global_best)\n\n        return global_best", "name": "AdaptiveMultiSwarmPSO", "description": "Adaptive Multi-Swarm Particle Swarm Optimization (AMPSO) utilizes multiple interacting swarms with adaptive communication strategies for enhanced global exploration and local exploitation.", "configspace": "", "generation": 30, "fitness": 0.2821337994607359, "feedback": "The algorithm AdaptiveMultiSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2821337994607359]}, "mutation_prompt": null}
{"id": "e285d3c0-0049-4dbc-86c9-6de837f98241", "solution": "import numpy as np\n\nclass HybridQuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.levy_factor = 0.001\n\n    def levy_flight(self):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v) ** (1 / beta)\n        return step\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  \n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                levy_step = self.levy_flight()\n                trial += self.levy_factor * levy_step\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "HybridQuantumInspiredPSO", "description": "Hybrid Quantum-Inspired PSO with Lvy Flights (HQIPSO) integrates quantum updates with Lvy flight exploration to enhance global search capabilities and convergence speed.", "configspace": "", "generation": 31, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {}, "mutation_prompt": null}
{"id": "8be0e425-02ba-47f4-826a-a11d4b833606", "solution": "import numpy as np\n\nclass DifferentialEvolutionAdaptivePerturbation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.mutation_factor_initial = 0.8\n        self.mutation_factor_final = 0.2\n        self.crossover_probability = 0.9\n\n    def adaptive_mutation_factor(self, eval_count):\n        lambda_factor = eval_count / self.budget\n        return self.mutation_factor_initial * (1 - lambda_factor) + self.mutation_factor_final * lambda_factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Select three random, distinct indices\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutation_factor = self.adaptive_mutation_factor(eval_count)\n\n                # Differential mutation\n                mutant_vector = np.clip(a + mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                \n                # Crossover\n                crossover_mask = np.random.rand(self.dim) < self.crossover_probability\n                if not np.any(crossover_mask):\n                    crossover_mask[np.random.randint(0, self.dim)] = True  # ensure at least one crossover\n                trial_vector = np.where(crossover_mask, mutant_vector, pop[i])\n                \n                # Selection\n                trial_fitness = func(trial_vector)\n                eval_count += 1\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial_vector\n                    fitness[i] = trial_fitness\n                \n                if eval_count >= self.budget:\n                    break\n\n        best_index = np.argmin(fitness)\n        return pop[best_index]", "name": "DifferentialEvolutionAdaptivePerturbation", "description": "Differential Evolution with Adaptive Perturbation (DEAP) dynamically adjusts mutation strategies using an adaptive perturbation control mechanism to balance exploration and exploitation in complex search spaces.", "configspace": "", "generation": 32, "fitness": 0.2813462030067688, "feedback": "The algorithm DifferentialEvolutionAdaptivePerturbation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2813462030067688]}, "mutation_prompt": null}
{"id": "2f898c57-652b-4bbe-939e-8c8149c097b6", "solution": "import numpy as np\n\nclass QuantumInspiredFireflyAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.alpha = 0.5  # Randomness reduction parameter\n        self.beta0 = 1.0  # Initial attractiveness\n        self.gamma = 1.0  # Light absorption coefficient\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_attraction(self, firefly_i, firefly_j, brightness_i, brightness_j, eval_count):\n        distance = np.linalg.norm(firefly_i - firefly_j)\n        beta = self.beta0 * np.exp(-self.gamma * distance ** 2)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        move = beta * (firefly_j - firefly_i) + quantum_factor * np.random.uniform(-1, 1, self.dim)\n        return firefly_i + move\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        fireflies = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        brightness = np.array([func(firefly) for firefly in fireflies])\n        \n        eval_count = self.population_size\n        global_best_index = np.argmin(brightness)\n        global_best = fireflies[global_best_index]\n        global_best_value = brightness[global_best_index]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                for j in range(self.population_size):\n                    if brightness[j] < brightness[i]:\n                        new_position = self.quantum_attraction(fireflies[i], fireflies[j], brightness[i], brightness[j], eval_count)\n                        new_position = np.clip(new_position, bounds[:, 0], bounds[:, 1])\n                        new_value = func(new_position)\n                        eval_count += 1\n                        if new_value < brightness[i]:\n                            fireflies[i] = new_position\n                            brightness[i] = new_value\n                            if new_value < global_best_value:\n                                global_best = new_position\n                                global_best_value = new_value\n\n                        if eval_count >= self.budget:\n                            break\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumInspiredFireflyAlgorithm", "description": "Quantum-Inspired Firefly Algorithm (QIFA) leverages quantum superposition to enhance the attraction mechanism, dynamically balancing exploration and exploitation.", "configspace": "", "generation": 33, "fitness": 0.2748713593062414, "feedback": "The algorithm QuantumInspiredFireflyAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2748713593062414]}, "mutation_prompt": null}
{"id": "bd41c444-103f-4bca-a72e-97df063be5bf", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSOWithDiversityControl:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.diversity_threshold = 1e-3  # Diversity threshold for reinitialization\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def measure_diversity(self, population):\n        centroid = np.mean(population, axis=0)\n        diversity = np.mean(np.linalg.norm(population - centroid, axis=1))\n        return diversity\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n            # Check diversity and reinitialize if necessary\n            diversity = self.measure_diversity(pop)\n            if diversity < self.diversity_threshold:\n                pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n                velocities = np.zeros_like(pop)  # Reset velocities to maintain diversity\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSOWithDiversityControl", "description": "Quantum-Enhanced Adaptive PSO with Diversity Control (QEDCPSO) integrates a diversity preservation mechanism to maintain exploration capabilities and prevent premature convergence for complex optimization landscapes.", "configspace": "", "generation": 34, "fitness": 0.28956669165709803, "feedback": "The algorithm QuantumEnhancedAdaptivePSOWithDiversityControl got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28956669165709803]}, "mutation_prompt": null}
{"id": "57dbf2b2-a816-4812-ba6d-a8ca3a5646fa", "solution": "import numpy as np\n\nclass DifferentialEvolutionACM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_crossover_rate = 0.9\n        self.final_crossover_rate = 0.5\n        self.initial_mutation_factor = 0.8\n        self.final_mutation_factor = 0.5\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            crossover_rate = (self.initial_crossover_rate - self.final_crossover_rate) * \\\n                             (1 - eval_count / self.budget) + self.final_crossover_rate\n            mutation_factor = (self.initial_mutation_factor - self.final_mutation_factor) * \\\n                              (1 - eval_count / self.budget) + self.final_mutation_factor\n\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n\n                trial_vector = np.where(np.random.rand(self.dim) < crossover_rate, mutant_vector, pop[i])\n                trial_value = func(trial_vector)\n                eval_count += 1\n\n                if trial_value < fitness[i]:\n                    pop[i] = trial_vector\n                    fitness[i] = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        best_index = np.argmin(fitness)\n        return pop[best_index]", "name": "DifferentialEvolutionACM", "description": "Differential Evolution with Adaptive Crossover and Mutation (DE-ACM) leverages adaptive strategies for crossover and mutation rates to enhance convergence in optimizing complex photonic structures.", "configspace": "", "generation": 35, "fitness": 0.2781716470029395, "feedback": "The algorithm DifferentialEvolutionACM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2781716470029395]}, "mutation_prompt": null}
{"id": "3a138bfc-9c9e-40d6-aeb1-2b15e0d5dfd9", "solution": "import numpy as np\n\nclass GeneticQuantumHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.hmcr = 0.9  # Harmony Memory Consideration Rate\n        self.par = 0.3   # Pitch Adjustment Rate\n        self.quantum_factor_initial = 0.2\n        self.quantum_factor_final = 0.05\n        self.mutation_rate = 0.1\n\n    def quantum_harmony_update(self, harmony, global_best, eval_count):\n        lambda_factor = eval_count / self.budget\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        delta = np.random.rand(self.dim)\n        new_harmony = harmony + quantum_factor * (global_best - harmony) * delta\n        return new_harmony\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        global_best = pop[np.argmin(fitness)]\n        global_best_value = fitness.min()\n\n        while eval_count < self.budget:\n            new_pop = []\n            for _ in range(self.population_size):\n                if np.random.rand() < self.hmcr:\n                    harmony_idx = np.random.choice(self.population_size)\n                    new_harmony = pop[harmony_idx].copy()\n                    if np.random.rand() < self.par:\n                        new_harmony += np.random.normal(0, 0.1, self.dim)\n                else:\n                    new_harmony = np.random.rand(self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n                \n                new_harmony = self.quantum_harmony_update(new_harmony, global_best, eval_count)\n                new_harmony = np.clip(new_harmony, bounds[:, 0], bounds[:, 1])\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    new_harmony = np.clip(new_harmony + mutation, bounds[:, 0], bounds[:, 1])\n\n                new_pop.append(new_harmony)\n\n            new_fitness = np.array([func(ind) for ind in new_pop])\n            eval_count += self.population_size\n\n            pop = np.array(new_pop)\n            fitness = new_fitness\n            if new_fitness.min() < global_best_value:\n                global_best = new_pop[np.argmin(new_fitness)]\n                global_best_value = new_fitness.min()\n\n        return global_best", "name": "GeneticQuantumHarmonySearch", "description": "Genetic Quantum Harmony Search (GQHS) combines genetic algorithms, quantum-inspired mechanisms, and harmony search principles for enhanced diversity and convergence speed in complex optimization landscapes.", "configspace": "", "generation": 36, "fitness": 0.27710638886762595, "feedback": "The algorithm GeneticQuantumHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.27710638886762595]}, "mutation_prompt": null}
{"id": "322eebd4-b528-4e30-a6fb-e4a54fc32da6", "solution": "import numpy as np\n\nclass SelfAdaptiveSimulatedAnnealingPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_temp = 1.0\n        self.final_temp = 0.01\n        self.c1 = 2.0\n        self.c2 = 2.0\n\n    def simulated_annealing_update(self, position, temperature):\n        perturbation = np.random.normal(0, temperature, self.dim)\n        return position + perturbation\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            temperature = self.initial_temp * ((self.budget - eval_count) / self.budget) + \\\n                          self.final_temp * (eval_count / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.simulated_annealing_update(pop[i], temperature)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "SelfAdaptiveSimulatedAnnealingPSO", "description": "Self-Adaptive Simulated Annealing Particle Swarm Optimization (SASAPSO) integrates simulated annealing into PSO to dynamically adjust exploration and exploitation balance based on temperature-driven convergence.", "configspace": "", "generation": 37, "fitness": 0.27978205907223364, "feedback": "The algorithm SelfAdaptiveSimulatedAnnealingPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.27978205907223364]}, "mutation_prompt": null}
{"id": "9c5255ca-91d4-4d15-8fd3-9b7dce0703c3", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO_DDM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.mutation_probability = 0.1\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  # Adaptive quantum factor\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def diversity_mutation(self, position, bounds):\n        if np.random.rand() < self.mutation_probability:\n            mutation = np.random.normal(0, 0.1, self.dim)\n            mutated_position = position + mutation * (bounds[:, 1] - bounds[:, 0])\n            return np.clip(mutated_position, bounds[:, 0], bounds[:, 1])\n        return position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = self.diversity_mutation(trial, bounds)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSO_DDM", "description": "Quantum-Enhanced Adaptive PSO with Diversity-Driven Mutation (QEAPSO-DDM) incorporates diversity-driven mutation to prevent premature convergence and enhance exploration.", "configspace": "", "generation": 38, "fitness": 0.2885833844472515, "feedback": "The algorithm QuantumEnhancedAdaptivePSO_DDM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2885833844472515]}, "mutation_prompt": null}
{"id": "873223ec-4590-477a-93ee-ef8c48bd3efe", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO_DP:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.final_population_size = min(100, self.initial_population_size)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  # Adaptive quantum factor\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population_size = self.initial_population_size\n        pop = np.random.rand(population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = population_size\n\n        while eval_count < self.budget:\n            lambda_factor = (eval_count / self.budget)\n            population_size = int(self.initial_population_size * (1 - lambda_factor) + self.final_population_size * lambda_factor)\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * (1 - lambda_factor) + self.final_inertia_weight\n\n            for i in range(population_size):\n                if i >= len(pop):\n                    new_particle = np.random.rand(self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n                    new_velocity = np.zeros(self.dim)\n                    pop = np.vstack((pop, new_particle))\n                    velocities = np.vstack((velocities, new_velocity))\n                    personal_best = np.vstack((personal_best, new_particle))\n                    personal_best_values = np.append(personal_best_values, func(new_particle))\n                    eval_count += 1\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSO_DP", "description": "Quantum-Enhanced Adaptive PSO with Dynamic Population (QEAPSO-DP) introduces a dynamically adjusting population size to enhance exploration-exploitation balance and improve convergence in high-dimensional optimization tasks.", "configspace": "", "generation": 39, "fitness": 0.28956669165709803, "feedback": "The algorithm QuantumEnhancedAdaptivePSO_DP got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28956669165709803]}, "mutation_prompt": null}
{"id": "5c61e56b-c257-4abe-bc50-0c9144e972af", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.f_scale_initial = 0.9\n        self.f_scale_final = 0.5\n        self.cr_initial = 0.9\n        self.cr_final = 0.4\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_mutation(self, target, candidates, eval_count):\n        indices = np.random.choice(len(candidates), 3, replace=False)\n        a, b, c = candidates[indices]\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        \n        mutant = a + quantum_factor * (b - c)\n        return mutant\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        population = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in population])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            f_scale = self.f_scale_initial * (1 - eval_count / self.budget) + self.f_scale_final * (eval_count / self.budget)\n            cr = self.cr_initial * (1 - eval_count / self.budget) + self.cr_final * (eval_count / self.budget)\n\n            new_population = np.empty_like(population)\n            for i in range(self.population_size):\n                mutant = self.quantum_mutation(population[i], population, eval_count)\n                crossover = np.random.rand(self.dim) < cr\n                trial = np.where(crossover, mutant, population[i])\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    new_population[i] = trial\n                    fitness[i] = trial_fitness\n                else:\n                    new_population[i] = population[i]\n\n                if eval_count >= self.budget:\n                    break\n\n            population = new_population\n            best_idx = np.argmin(fitness)\n            best_solution = population[best_idx]\n\n        return best_solution", "name": "QuantumEnhancedAdaptiveDE", "description": "Quantum-Enhanced Adaptive Differential Evolution (QEAD) utilizes quantum-inspired mutation and adaptive parameter control for effective exploration and exploitation in complex search spaces.", "configspace": "", "generation": 40, "fitness": 0.28009728893827623, "feedback": "The algorithm QuantumEnhancedAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28009728893827623]}, "mutation_prompt": null}
{"id": "c5605041-1bd2-4e6e-a523-6fbb946b57a9", "solution": "import numpy as np\n\nclass QuantumInspiredDynamicTopologyPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def adaptive_topology(self, positions, eval_count):\n        # Dynamically change the topology for better exploration and exploitation\n        if eval_count < self.budget / 3:\n            # Use a global best topology in early stages for exploration\n            return np.mean(positions, axis=0)\n        else:\n            # Switch to local best topology for exploitation in later stages\n            return np.median(positions, axis=0)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                local_best = self.adaptive_topology(pop, eval_count)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (local_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumInspiredDynamicTopologyPSO", "description": "Quantum-Inspired PSO with Dynamic Topology (QIDT-PSO) combines quantum behavior and adaptive topological structures to enhance exploration and exploitation in complex, high-dimensional search spaces.", "configspace": "", "generation": 41, "fitness": 0.2825283357138868, "feedback": "The algorithm QuantumInspiredDynamicTopologyPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2825283357138868]}, "mutation_prompt": null}
{"id": "b3648f8b-b073-41f8-81ac-755276ca9b49", "solution": "import numpy as np\n\nclass QuantumInspiredDynamicNeighborhoodPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.neighborhood_size = max(3, int(self.population_size / 10))  # Dynamic neighborhood size\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  # Adaptive quantum factor\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def dynamic_neighborhood(self, idx, personal_best_values):\n        sorted_indices = np.argsort(personal_best_values)\n        closest_indices = sorted_indices[:self.neighborhood_size]\n        if idx in closest_indices:\n            return closest_indices\n        return closest_indices[:-1] + [idx]\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n            for i in range(self.population_size):\n                neighborhood = self.dynamic_neighborhood(i, personal_best_values)\n                local_best = personal_best[neighborhood[np.argmin(personal_best_values[neighborhood])]]\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (local_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], local_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumInspiredDynamicNeighborhoodPSO", "description": "Quantum-Inspired Dynamic Neighborhood PSO (QIDN-PSO) enhances exploration and exploitation by dynamically adjusting particle neighborhoods and employing quantum-inspired updates for balancing convergence toward global optima.", "configspace": "", "generation": 42, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 100 is out of bounds for axis 0 with size 100').", "error": "IndexError('index 100 is out of bounds for axis 0 with size 100')", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {}, "mutation_prompt": null}
{"id": "b2a88c0f-7913-41d1-8917-749beb6a7799", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.neighborhood_size = max(2, int(0.1 * self.population_size))\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = eval_count / self.budget  # Adaptive quantum factor\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                # Dynamic neighborhood influence\n                neighbors = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_values[neighbors])]]\n\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (local_best - pop[i])\n                                 + self.c2 * r3 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSO_DN", "description": "Quantum-Enhanced Adaptive PSO with Dynamic Neighborhood (QEAPSO-DN) introduces a dynamic neighborhood structure that adapts the influence of neighboring particles, enhancing diversity and convergence in complex landscapes.", "configspace": "", "generation": 43, "fitness": 0.28648194277876926, "feedback": "The algorithm QuantumEnhancedAdaptivePSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28648194277876926]}, "mutation_prompt": null}
{"id": "3404a5ce-39d6-4960-84df-e0c018205cfc", "solution": "import numpy as np\n\nclass QuantumEnhancedDynamicNeighborhoodPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.neighborhood_size = max(2, dim // 10)  # Dynamic neighborhood size\n\n    def quantum_update(self, position, personal_best, local_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  # Adaptive quantum factor\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (local_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                local_best_index = np.argpartition(personal_best_values, self.neighborhood_size)[:self.neighborhood_size]\n                local_best = personal_best[local_best_index[np.argmin(personal_best_values[local_best_index])]]\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (local_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], local_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedDynamicNeighborhoodPSO", "description": "Quantum-Enhanced Dynamic Neighborhood PSO (QEDN-PSO) improves exploration and exploitation by dynamically adjusting quantum factors and utilizing local neighborhood information for better convergence.", "configspace": "", "generation": 44, "fitness": 0.28956669165709803, "feedback": "The algorithm QuantumEnhancedDynamicNeighborhoodPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28956669165709803]}, "mutation_prompt": null}
{"id": "61204772-df82-4d0f-8bef-1f6d872dc996", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.neighborhood_size = max(5, self.population_size // 10)\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = eval_count / self.budget\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def dynamic_neighborhood_best(self, pop, personal_best_values):\n        neighbors = np.random.choice(self.population_size, (self.population_size, self.neighborhood_size), replace=False)\n        neighborhood_best = np.array([personal_best_values[neighbors[i]].argmin() for i in range(self.population_size)])\n        return pop[neighborhood_best]\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            neighborhood_best = self.dynamic_neighborhood_best(personal_best, personal_best_values)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (neighborhood_best[i] - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSO_DN", "description": "Quantum-Enhanced Adaptive PSO with Dynamic Neighborhood (QEAPSO-DN) enhances convergence by integrating dynamic neighborhood topology to balance local and global searches alongside quantum updates.", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {}, "mutation_prompt": null}
{"id": "8aecb5b7-098c-49ae-a2ce-80fe0cf48969", "solution": "import numpy as np\n\nclass QuantumInspiredDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.mutation_factor_initial = 0.8\n        self.mutation_factor_final = 0.3\n        self.crossover_rate = 0.9\n\n    def quantum_superposition(self, parent1, parent2, global_best, eval_count):\n        lambda_factor = (eval_count / self.budget)\n        mutation_factor = self.mutation_factor_initial * (1 - lambda_factor) + self.mutation_factor_final * lambda_factor\n        weight = np.random.uniform(0, 1, self.dim)\n        trial_vector = weight * parent1 + (1 - weight) * parent2 + mutation_factor * (global_best - parent1)\n        return trial_vector\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness_values = np.array([func(ind) for ind in pop])\n        global_best = pop[np.argmin(fitness_values)]\n        global_best_value = fitness_values.min()\n        \n        eval_count = self.population_size\n        \n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                r1, r2 = indices[0], indices[1]\n                \n                trial_vector = self.quantum_superposition(pop[r1], pop[r2], global_best, eval_count)\n                trial_vector = np.clip(trial_vector, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial_vector)\n                eval_count += 1\n                \n                if trial_value < fitness_values[i]:\n                    pop[i] = trial_vector\n                    fitness_values[i] = trial_value\n                    \n                    if trial_value < global_best_value:\n                        global_best = trial_vector\n                        global_best_value = trial_value\n                \n                if eval_count >= self.budget:\n                    break\n        \n        return global_best", "name": "QuantumInspiredDifferentialEvolution", "description": "Quantum-Inspired Differential Evolution (QIDE) leverages quantum superposition principles with differential evolution mutations to enhance convergence and diversity handling in complex optimization landscapes.", "configspace": "", "generation": 46, "fitness": 0.28839480445128796, "feedback": "The algorithm QuantumInspiredDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28839480445128796]}, "mutation_prompt": null}
{"id": "0ef754c5-45b8-475e-8dbc-ab6febbaf6fa", "solution": "import numpy as np\n\nclass QuantumInspiredDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.mutation_factor = 0.5\n        self.crossover_prob = 0.7\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_interference(self, position, eval_count):\n        quantum_factor = self.quantum_factor_initial * (1 - eval_count / self.budget) + self.quantum_factor_final * (eval_count / self.budget)\n        interference_pattern = np.sin(np.pi * position + np.random.rand(self.dim)) * quantum_factor\n        return interference_pattern\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = x0 + self.mutation_factor * (x1 - x2)\n                mutant = np.clip(mutant, bounds[:, 0], bounds[:, 1])\n\n                crossover = np.random.rand(self.dim) < self.crossover_prob\n                trial = np.where(crossover, mutant, pop[i])\n\n                quantum_adjustment = self.quantum_interference(trial, eval_count)\n                trial = np.clip(trial + quantum_adjustment, bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(trial)\n                eval_count += 1\n\n                if trial_value < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        best_index = np.argmin(fitness)\n        return pop[best_index]", "name": "QuantumInspiredDifferentialEvolution", "description": "Quantum-Inspired Differential Evolution (QIDE) incorporates quantum interference mechanisms and adaptive differential mutation strategies to enhance convergence speed and solution diversity in complex search spaces.", "configspace": "", "generation": 47, "fitness": 0.27923321303575444, "feedback": "The algorithm QuantumInspiredDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.27923321303575444]}, "mutation_prompt": null}
{"id": "c176f303-d55d-4000-9ada-7755129aa27e", "solution": "import numpy as np\n\nclass EnhancedParticleSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.temperature_initial = 1.0\n        self.temperature_final = 0.01\n\n    def adaptive_mutation(self, position, eval_count):\n        temperature = self.temperature_initial * (1 - eval_count / self.budget) + self.temperature_final * (eval_count / self.budget)\n        mutation_strength = np.exp(-temperature)\n        mutation_vector = mutation_strength * np.random.randn(self.dim)\n        return position + mutation_vector\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                mutated_position = self.adaptive_mutation(pop[i], eval_count)\n                mutated_position = np.clip(mutated_position, bounds[:, 0], bounds[:, 1])\n                \n                mutated_value = func(mutated_position)\n                eval_count += 1\n                if mutated_value < personal_best_values[i]:\n                    personal_best[i] = mutated_position\n                    personal_best_values[i] = mutated_value\n                    if mutated_value < global_best_value:\n                        global_best = mutated_position\n                        global_best_value = mutated_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "EnhancedParticleSwarmOptimization", "description": "Enhanced Particle Swarm Optimization (EPSO) integrates an adaptive mutation based on simulated annealing to refine exploration and exploitation phases dynamically.", "configspace": "", "generation": 48, "fitness": 0.28465420621934356, "feedback": "The algorithm EnhancedParticleSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28465420621934356]}, "mutation_prompt": null}
{"id": "cb1073ad-71b2-4330-89e3-ce875e53c147", "solution": "import numpy as np\n\nclass EnhancedQuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1_initial = 2.0\n        self.c2_initial = 2.0\n        self.c1_final = 0.5\n        self.c2_final = 2.5\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_update(self, position, personal_best, global_best, eval_count, success_rate):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  # Adaptive quantum factor\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        social_scaling = 1 + success_rate\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta * social_scaling\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n        success_count = 0\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n                             \n            success_rate = success_count / eval_count if eval_count > 0 else 0\n            \n            c1 = self.c1_initial * (1 - success_rate) + self.c1_final * success_rate\n            c2 = self.c2_initial * (1 - success_rate) + self.c2_final * success_rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + c1 * r1 * (personal_best[i] - pop[i])\n                                 + c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count, success_rate)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    success_count += 1\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "EnhancedQuantumInspiredPSO", "description": "Enhanced Quantum-Inspired PSO (EQIPSO) introduces adaptive social and cognitive scaling based on success rate to refine balance between exploration and exploitation dynamically.", "configspace": "", "generation": 49, "fitness": 0.289516822398559, "feedback": "The algorithm EnhancedQuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.289516822398559]}, "mutation_prompt": null}
{"id": "adee4a25-2577-47de-b43d-b83ad696e963", "solution": "import numpy as np\n\nclass ChaosDrivenAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.mutation_factor = 0.5\n        self.crossover_rate = 0.9\n        self.beta = 0.05  # Chaotic parameter\n\n    def chaotic_sequence(self, size):\n        # Generate a chaotic sequence using the logistic map for diversity\n        x = np.random.rand()\n        sequence = []\n        for _ in range(size):\n            x = 4 * x * (1 - x)\n            sequence.append(x)\n        return np.array(sequence)\n\n    def adapt_parameters(self, eval_count):\n        # Adapt mutation and crossover rates\n        lambda_factor = eval_count / self.budget\n        self.mutation_factor = 0.5 * (1 + lambda_factor)\n        self.crossover_rate = 0.9 * (1 - lambda_factor)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        best_idx = np.argmin([func(ind) for ind in pop])\n        best = pop[best_idx]\n\n        eval_count = self.population_size\n        chaotic_sequence = self.chaotic_sequence(self.population_size * self.dim).reshape(self.population_size, self.dim)\n\n        while eval_count < self.budget:\n            self.adapt_parameters(eval_count)\n            new_pop = np.empty_like(pop)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = pop[indices]\n\n                mutant = x1 + self.mutation_factor * (x2 - x3)\n                mutant = np.clip(mutant, bounds[:, 0], bounds[:, 1])\n                \n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                \n                trial = np.where(cross_points, mutant, pop[i])\n                trial = np.clip(trial + self.beta * chaotic_sequence[i], bounds[:, 0], bounds[:, 1])\n                \n                if func(trial) < func(pop[i]):\n                    new_pop[i] = trial\n                    if func(trial) < func(best):\n                        best = trial\n                else:\n                    new_pop[i] = pop[i]\n                \n                eval_count += 1\n                if eval_count >= self.budget:\n                    break\n\n            pop = new_pop\n\n        return best", "name": "ChaosDrivenAdaptiveDE", "description": "Chaos-Driven Adaptive Differential Evolution (CADE) leverages chaotic sequences and adaptive control of mutation and crossover strategies to enhance exploration and convergence in high-dimensional optimization tasks.", "configspace": "", "generation": 50, "fitness": 0.27785802156728223, "feedback": "The algorithm ChaosDrivenAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.27785802156728223]}, "mutation_prompt": null}
{"id": "77ba6972-b3f3-4669-a6cb-085e0d5eecc2", "solution": "import numpy as np\n\nclass DifferentialEvolutionACM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_crossover_rate = 0.9\n        self.final_crossover_rate = 0.3\n        self.initial_mutation_factor = 0.8\n        self.final_mutation_factor = 0.4\n\n    def adapt_parameters(self, diversity, eval_count):\n        lambda_factor = eval_count / self.budget\n        crossover_rate = (self.initial_crossover_rate - self.final_crossover_rate) * (1 - lambda_factor) + self.final_crossover_rate\n        mutation_factor = (self.initial_mutation_factor - self.final_mutation_factor) * (1 - diversity) + self.final_mutation_factor\n        return crossover_rate, mutation_factor\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(pop, axis=0) / (bounds[:, 1] - bounds[:, 0]))\n            crossover_rate, mutation_factor = self.adapt_parameters(diversity, eval_count)\n\n            for i in range(self.population_size):\n                candidates = list(range(self.population_size))\n                candidates.remove(i)\n                a, b, c = pop[np.random.choice(candidates, 3, replace=False)]\n                mutant = np.clip(a + mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                \n                trial = np.copy(pop[i])\n                jrand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < crossover_rate or j == jrand:\n                        trial[j] = mutant[j]\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n                \n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "name": "DifferentialEvolutionACM", "description": "Differential Evolution with Adaptive Crossover and Mutation (DEACM) dynamically adjusts crossover and mutation rates based on population diversity for effective exploration and exploitation.", "configspace": "", "generation": 51, "fitness": 0.278632253887537, "feedback": "The algorithm DifferentialEvolutionACM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.278632253887537]}, "mutation_prompt": null}
{"id": "27f40419-a2fc-4fba-bad5-7f69fb8c178e", "solution": "import numpy as np\n\nclass QuantumInspiredDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_perturbation(self, vector, best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        perturbed_vector = vector + quantum_factor * (best - vector) * delta\n        return perturbed_vector\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best_vector = pop[best_idx]\n        best_fitness = fitness[best_idx]\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = pop[indices]\n                mutant = x1 + self.mutation_factor * (x2 - x3)\n                mutant = np.clip(mutant, bounds[:, 0], bounds[:, 1])\n\n                cross_points = np.random.rand(self.dim) < self.crossover_rate\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n\n                trial = np.where(cross_points, mutant, pop[i])\n                trial = self.quantum_perturbation(trial, best_vector, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_vector = trial\n                        best_fitness = trial_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n        return best_vector", "name": "QuantumInspiredDifferentialEvolution", "description": "Quantum-Inspired Differential Evolution (QIDE) employs quantum-inspired perturbations to enhance the exploration capabilities of Differential Evolution, especially in complex high-dimensional search spaces.", "configspace": "", "generation": 52, "fitness": 0.27770493715300804, "feedback": "The algorithm QuantumInspiredDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.27770493715300804]}, "mutation_prompt": null}
{"id": "a54767f0-967b-45d3-913f-30500686b86a", "solution": "import numpy as np\n\nclass QuantumWalkInspiredDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.scale_factor = 0.5\n        self.crossover_prob = 0.7\n\n    def quantum_walk(self, position, global_best, step_size):\n        # Quantum walk inspired transition\n        q_step = np.random.normal(0, step_size, size=self.dim)\n        new_position = position + q_step * (global_best - position)\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        global_best = pop[np.argmin(fitness)]\n        global_best_value = fitness.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Mutate using Differential Evolution strategy\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = pop[indices]\n                mutant = np.clip(a + self.scale_factor * (b - c), bounds[:, 0], bounds[:, 1])\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.crossover_prob\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Quantum walk update\n                trial = self.quantum_walk(trial, global_best, step_size=0.1)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumWalkInspiredDifferentialEvolution", "description": "Quantum-Walk-Inspired Differential Evolution (QWIDE) utilizes quantum walk principles for state transition to enhance exploration in differential evolution strategies within high-dimensional search spaces.", "configspace": "", "generation": 53, "fitness": 0.2798025422656458, "feedback": "The algorithm QuantumWalkInspiredDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2798025422656458]}, "mutation_prompt": null}
{"id": "a4c06b39-7ce1-4703-ac84-ebafc93c4bc3", "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass QuantumEnhancedAdaptivePSO_DynamicClustering:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.num_clusters = max(2, dim // 10)\n\n    def quantum_update(self, position, personal_best, cluster_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (cluster_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            kmeans = KMeans(n_clusters=self.num_clusters)\n            cluster_labels = kmeans.fit_predict(pop)\n            \n            cluster_bests = []\n            for cluster in range(self.num_clusters):\n                cluster_indices = np.where(cluster_labels == cluster)[0]\n                cluster_best_idx = cluster_indices[np.argmin(personal_best_values[cluster_indices])]\n                cluster_bests.append(personal_best[cluster_best_idx])\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cluster_best = cluster_bests[cluster_labels[i]]\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (cluster_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], cluster_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSO_DynamicClustering", "description": "Quantum-Enhanced Adaptive PSO with Dynamic Subpopulation Clustering (QEAPSO-D) integrates a dynamic subpopulation clustering mechanism to enhance local exploration and exploitation balance, adapting the search strategy based on the optimization landscape.", "configspace": "", "generation": 54, "fitness": 0.28498935157811645, "feedback": "The algorithm QuantumEnhancedAdaptivePSO_DynamicClustering got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28498935157811645]}, "mutation_prompt": null}
{"id": "14c6cdb3-1a0e-44fc-abbe-4d113032b3ee", "solution": "import numpy as np\n\nclass QuantumEnhancedDualSwarmPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.split_ratio = 0.5  # Ratio to split the dual swarms\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n        split_index = int(self.population_size * self.split_ratio)\n        swarm_a = np.arange(split_index)\n        swarm_b = np.arange(split_index, self.population_size)\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for swarm, global_best_current in zip([swarm_a, swarm_b], [global_best, global_best]):\n                for i in swarm:\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    velocities[i] = (inertia_weight * velocities[i]\n                                     + self.c1 * r1 * (personal_best[i] - pop[i])\n                                     + self.c2 * r2 * (global_best_current - pop[i]))\n                    pop[i] += velocities[i]\n                    pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                    trial = self.quantum_update(pop[i], personal_best[i], global_best_current, eval_count)\n                    trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                    trial_value = func(trial)\n                    eval_count += 1\n                    if trial_value < personal_best_values[i]:\n                        personal_best[i] = trial\n                        personal_best_values[i] = trial_value\n                        if trial_value < global_best_value:\n                            global_best = trial\n                            global_best_value = trial_value\n\n                    if eval_count >= self.budget:\n                        break\n\n        return global_best", "name": "QuantumEnhancedDualSwarmPSO", "description": "Quantum-Enhanced Dual-Swarm PSO (QEDS-PSO) integrates dual-swarm dynamics and adaptive parameter tuning to enhance exploration and convergence in diverse optimization landscapes.", "configspace": "", "generation": 55, "fitness": 0.2862200267553574, "feedback": "The algorithm QuantumEnhancedDualSwarmPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2862200267553574]}, "mutation_prompt": null}
{"id": "30f8e03a-f938-4a61-b37b-0677fa8a0bb8", "solution": "import numpy as np\n\nclass QuantumInspiredDifferentialPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.differential_weight = 0.5\n        self.crossover_prob = 0.9\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def differential_mutation(self, pop, best_idx):\n        indices = np.random.choice(self.population_size, 3, replace=False)\n        indices = indices[indices != best_idx]\n        a, b, c = pop[indices]\n        mutant = a + self.differential_weight * (b - c)\n        return mutant\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                if np.random.rand() < self.crossover_prob:\n                    mutant = self.differential_mutation(pop, i)\n                    trial = np.where(np.random.rand(self.dim) < self.crossover_prob, mutant, pop[i])\n                else:\n                    trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                \n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumInspiredDifferentialPSO", "description": "Quantum-Inspired Differential Particle Swarm Optimization (QIDPSO) combines adaptive differential evolution with quantum-inspired updates for enhanced exploration and convergence in complex optimization landscapes.", "configspace": "", "generation": 56, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('not enough values to unpack (expected 3, got 2)').", "error": "ValueError('not enough values to unpack (expected 3, got 2)')", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {}, "mutation_prompt": null}
{"id": "7f722299-3c51-4ff7-acf5-e71560759302", "solution": "import numpy as np\n\nclass QuantumTurbochargedPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.turbulence_chance = 0.1\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        if np.random.rand() < self.turbulence_chance:\n            new_position += np.random.normal(0, 0.1, self.dim)\n        return new_position\n\n    def dynamic_leader_selection(self, personal_best, personal_best_values):\n        indices = np.argsort(personal_best_values)[:max(1, self.population_size // 10)]\n        return personal_best[np.random.choice(indices)]\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                dynamic_leader = self.dynamic_leader_selection(personal_best, personal_best_values)\n                trial = self.quantum_update(pop[i], personal_best[i], dynamic_leader, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumTurbochargedPSO", "description": "Quantum Turbocharged PSO (QTPSO) incorporates adaptive quantum behavior with dynamic leader selection and turbulence factors to enhance exploration and exploitation in diverse landscapes.", "configspace": "", "generation": 57, "fitness": 0.28734416175703603, "feedback": "The algorithm QuantumTurbochargedPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28734416175703603]}, "mutation_prompt": null}
{"id": "17f685bd-1c25-458e-8c2a-0b4130a9a52d", "solution": "import numpy as np\n\nclass QuantumSwarmDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.quantum_factor_initial = 0.4\n        self.quantum_factor_final = 0.1\n        self.F = 0.8  # Differential weight\n        self.CR = 0.9  # Crossover probability\n\n    def quantum_update(self, position, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = eval_count / self.budget\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = position + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def differential_evolution(self, pop, bounds):\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), bounds[:, 0], bounds[:, 1])\n            crossover = np.random.rand(self.dim) < self.CR\n            trial = np.where(crossover, mutant, pop[i])\n            pop[i] = trial\n        return pop\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        global_best = pop[np.argmin(fitness)]\n        global_best_value = fitness.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            pop = self.differential_evolution(pop, bounds)\n            for i in range(self.population_size):\n                trial = self.quantum_update(pop[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumSwarmDifferentialEvolution", "description": "Quantum-Swarm Differential Evolution (QSDE) combines quantum-inspired position updates with differential evolution to enhance exploration and convergence in complex optimization landscapes.", "configspace": "", "generation": 58, "fitness": 0.2785546634415582, "feedback": "The algorithm QuantumSwarmDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2785546634415582]}, "mutation_prompt": null}
{"id": "51ffe3cb-9272-4186-9b06-5e6a34117b06", "solution": "import numpy as np\n\nclass QuantumEnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.f = 0.5  # Differential weight\n        self.cr = 0.9  # Crossover probability\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_perturbation(self, target, best, trial, eval_count):\n        lambda_factor = eval_count / self.budget\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        delta = np.random.rand(self.dim)\n        new_trial = trial + quantum_factor * (best - target) * delta\n        return new_trial\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = list(range(self.population_size))\n                indices.remove(i)\n                a, b, c = np.random.choice(indices, 3, replace=False)\n                mutant = pop[a] + self.f * (pop[b] - pop[c])\n                mutant = np.clip(mutant, bounds[:, 0], bounds[:, 1])\n                \n                cross_points = np.random.rand(self.dim) < self.cr\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n                \n                trial = self.quantum_perturbation(pop[i], best, trial, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return best", "name": "QuantumEnhancedDifferentialEvolution", "description": "Quantum-Enhanced Differential Evolution (QEDE) incorporates adaptive quantum perturbations into the differential mutation process for enhanced global optimization performance.", "configspace": "", "generation": 59, "fitness": 0.28142202042861897, "feedback": "The algorithm QuantumEnhancedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28142202042861897]}, "mutation_prompt": null}
{"id": "ce3bab58-74a7-4c15-870c-5fd1c2abd0a1", "solution": "import numpy as np\n\nclass MultiSwarmQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.swarm_count = min(10, max(2, dim // 10))\n        self.population_size_per_swarm = min(50, 5 * dim)\n        self.total_population_size = self.swarm_count * self.population_size_per_swarm\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  # Adaptive quantum factor\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        swarms = [np.random.rand(self.population_size_per_swarm, self.dim) * \n                  (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0] for _ in range(self.swarm_count)]\n        velocities = [np.zeros_like(swarm) for swarm in swarms]\n        personal_bests = [swarm.copy() for swarm in swarms]\n        personal_best_values = [np.array([func(ind) for ind in swarm]) for swarm in swarms]\n        \n        all_personal_best_values = np.concatenate(personal_best_values)\n        global_best = np.concatenate(personal_bests)[np.argmin(all_personal_best_values)]\n        global_best_value = all_personal_best_values.min()\n        \n        eval_count = self.total_population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for swarm_idx in range(self.swarm_count):\n                for i in range(self.population_size_per_swarm):\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    velocities[swarm_idx][i] = (inertia_weight * velocities[swarm_idx][i]\n                                                + self.c1 * r1 * (personal_bests[swarm_idx][i] - swarms[swarm_idx][i])\n                                                + self.c2 * r2 * (global_best - swarms[swarm_idx][i]))\n                    swarms[swarm_idx][i] += velocities[swarm_idx][i]\n                    swarms[swarm_idx][i] = np.clip(swarms[swarm_idx][i], bounds[:, 0], bounds[:, 1])\n\n                    trial = self.quantum_update(swarms[swarm_idx][i], personal_bests[swarm_idx][i], global_best, eval_count)\n                    trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                    \n                    trial_value = func(trial)\n                    eval_count += 1\n                    if trial_value < personal_best_values[swarm_idx][i]:\n                        personal_bests[swarm_idx][i] = trial\n                        personal_best_values[swarm_idx][i] = trial_value\n                        if trial_value < global_best_value:\n                            global_best = trial\n                            global_best_value = trial_value\n\n                    if eval_count >= self.budget:\n                        break\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "MultiSwarmQuantumPSO", "description": "Multi-Swarm Quantum PSO (MS-QPSO) enhances exploration by employing multiple swarms that communicate via a shared global best, dynamically adjusting quantum factors and inertia for diverse search space exploration.", "configspace": "", "generation": 60, "fitness": 0.28956669165709803, "feedback": "The algorithm MultiSwarmQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28956669165709803]}, "mutation_prompt": null}
{"id": "b77a722c-6514-4e2e-8be1-89d04d2fdad6", "solution": "import numpy as np\n\nclass EnhancedQuantumAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.neighborhood_size = 5  # Size of the local neighborhood\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  # Adaptive quantum factor\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n            # Adaptive population resizing\n            self.population_size = max(5, int(self.population_size * (1 - eval_count / self.budget)))\n            neighborhood_best = []\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                # Neighborhood search\n                neighbors = personal_best[np.random.choice(range(self.population_size), self.neighborhood_size, replace=False)]\n                local_best = neighbors[np.argmin([func(nb) for nb in neighbors])]\n                neighborhood_best.append(local_best)\n\n                trial = self.quantum_update(pop[i], personal_best[i], local_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "EnhancedQuantumAdaptivePSO", "description": "Enhanced Quantum-Enhanced Adaptive PSO (E-QEAPSO) introduces an adaptive neighborhood search mechanism and dynamic population resizing to balance exploration and exploitation effectively.", "configspace": "", "generation": 61, "fitness": 0.2817403302485919, "feedback": "The algorithm EnhancedQuantumAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2817403302485919]}, "mutation_prompt": null}
{"id": "520ac6e7-db86-4360-8232-0fdff4421b2f", "solution": "import numpy as np\n\nclass AdaptiveQuantumGeneticAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.crossover_rate_initial = 0.9\n        self.crossover_rate_final = 0.4\n        self.quantum_mutation_rate = 0.1\n\n    def quantum_mutation(self, individual, global_best, eval_count):\n        lambda_factor = (eval_count / self.budget)  # Adaptive factor\n        mutation_vector = np.random.rand(self.dim)\n        new_individual = individual + self.quantum_mutation_rate * lambda_factor * (global_best - individual) * mutation_vector\n        return new_individual\n\n    def crossover(self, parent1, parent2, eval_count):\n        lambda_factor = (eval_count / self.budget)\n        crossover_rate = self.crossover_rate_initial * (1 - lambda_factor) + self.crossover_rate_final * lambda_factor\n        mask = np.random.rand(self.dim) < crossover_rate\n        offspring = np.where(mask, parent1, parent2)\n        return offspring\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness_values = np.array([func(ind) for ind in pop])\n        global_best = pop[np.argmin(fitness_values)]\n        global_best_value = fitness_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            new_population = []\n            for _ in range(self.population_size // 2):\n                parents = np.random.choice(self.population_size, 2, replace=False, p=None)\n                parent1, parent2 = pop[parents[0]], pop[parents[1]]\n                \n                offspring1 = self.crossover(parent1, parent2, eval_count)\n                offspring2 = self.crossover(parent2, parent1, eval_count)\n                \n                offspring1 = self.quantum_mutation(offspring1, global_best, eval_count)\n                offspring2 = self.quantum_mutation(offspring2, global_best, eval_count)\n                \n                offspring1 = np.clip(offspring1, bounds[:, 0], bounds[:, 1])\n                offspring2 = np.clip(offspring2, bounds[:, 0], bounds[:, 1])\n                \n                new_population.extend([offspring1, offspring2])\n\n            new_population = np.array(new_population)\n            new_fitness_values = np.array([func(ind) for ind in new_population])\n            eval_count += self.population_size\n            \n            # Combine and select the best individuals\n            combined_pop = np.vstack((pop, new_population))\n            combined_fitness = np.concatenate((fitness_values, new_fitness_values))\n            \n            best_indices = np.argpartition(combined_fitness, self.population_size)[:self.population_size]\n            pop = combined_pop[best_indices]\n            fitness_values = combined_fitness[best_indices]\n            \n            current_best_value = fitness_values.min()\n            if current_best_value < global_best_value:\n                global_best_value = current_best_value\n                global_best = pop[np.argmin(fitness_values)]\n\n        return global_best", "name": "AdaptiveQuantumGeneticAlgorithm", "description": "Adaptive Quantum Genetic Algorithm (AQGA) integrates quantum-inspired mutation with adaptive crossover rates to enhance exploration and exploitation in complex multi-dimensional search spaces.", "configspace": "", "generation": 62, "fitness": 0.28343431197207536, "feedback": "The algorithm AdaptiveQuantumGeneticAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28343431197207536]}, "mutation_prompt": null}
{"id": "58771600-6218-41a6-8c6c-1e2d5eacaf3a", "solution": "import numpy as np\n\nclass QuantumInspiredGrasshopperOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.r_max = 1.0\n        self.r_min = 0.00001\n        self.quantum_factor_initial = 0.5\n        self.quantum_factor_final = 0.1\n\n    def quantum_position_update(self, position, best_position, eval_count):\n        r = self.r_max - (self.r_max - self.r_min) * (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - eval_count / self.budget) + self.quantum_factor_final * (eval_count / self.budget)\n        noise = np.random.rand(self.dim)\n        new_position = position + quantum_factor * r * (best_position - position) * noise\n        return new_position\n\n    def grasshopper_movement(self, position, population, eval_count):\n        s = np.zeros(self.dim)\n        r = self.r_max - (self.r_max - self.r_min) * (eval_count / self.budget)\n        for j in range(self.population_size):\n            if not np.array_equal(position, population[j]):\n                dist = np.linalg.norm(position - population[j])\n                s += ((population[j] - position) / (dist + np.finfo(float).eps)) * np.exp(-dist / r)\n        return s\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        best_position = pop[np.argmin(fitness)]\n        best_value = fitness.min()\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                s_i = self.grasshopper_movement(pop[i], pop, eval_count)\n                quantum_position = self.quantum_position_update(pop[i], best_position, eval_count)\n                candidate_position = pop[i] + s_i + quantum_position\n                candidate_position = np.clip(candidate_position, bounds[:, 0], bounds[:, 1])\n                \n                candidate_value = func(candidate_position)\n                eval_count += 1\n                if candidate_value < fitness[i]:\n                    pop[i] = candidate_position\n                    fitness[i] = candidate_value\n                    if candidate_value < best_value:\n                        best_position = candidate_position\n                        best_value = candidate_value\n                \n                if eval_count >= self.budget:\n                    break\n\n        return best_position", "name": "QuantumInspiredGrasshopperOptimization", "description": "Quantum-Inspired Grasshopper Optimization (QIGO) leverages quantum positions and adaptive grasshopper movement to enhance exploration and exploitation in complex search spaces.", "configspace": "", "generation": 63, "fitness": 0.2748713593062414, "feedback": "The algorithm QuantumInspiredGrasshopperOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2748713593062414]}, "mutation_prompt": null}
{"id": "80b4c2be-ba6e-4403-ae98-40511ec2f10f", "solution": "import numpy as np\n\nclass AdaptiveQuantumLevyFlight:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def levy_flight(self, cur_pos):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2**((beta - 1) / 2)))**(1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / np.abs(v)**(1/beta)\n        return cur_pos + step\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                levy_trial = np.clip(self.levy_flight(pop[i]), bounds[:, 0], bounds[:, 1])\n\n                if np.random.rand() < 0.5:\n                    final_trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                else:\n                    final_trial = levy_trial\n\n                trial_value = func(final_trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = final_trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = final_trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "AdaptiveQuantumLevyFlight", "description": "Adaptive Quantum Levy Flight (AQLF) combines adaptive quantum walks and Levy flights to enhance global exploration and local exploitation in dynamic optimization landscapes.", "configspace": "", "generation": 64, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {}, "mutation_prompt": null}
{"id": "10e65374-7525-4ffc-b69d-bbe12cd95a6e", "solution": "import numpy as np\n\nclass QuantumEnhancedPSO_DSP:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.partition_limit = 5  # Number of partitions for dynamic strategy\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            partitions = min(self.partition_limit, self.population_size // 10)\n            partition_size = self.population_size // partitions\n\n            for part in range(partitions):\n                start, end = part * partition_size, min((part + 1) * partition_size, self.population_size)\n                subpop = pop[start:end]\n                sub_velocities = velocities[start:end]\n                sub_personal_best = personal_best[start:end]\n                sub_personal_best_values = personal_best_values[start:end]\n\n                for i in range(start, end):\n                    r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                    velocities[i] = (inertia_weight * velocities[i]\n                                     + self.c1 * r1 * (personal_best[i] - pop[i])\n                                     + self.c2 * r2 * (global_best - pop[i]))\n                    pop[i] += velocities[i]\n                    pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                    trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                    trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                    trial_value = func(trial)\n                    eval_count += 1\n                    if trial_value < personal_best_values[i]:\n                        personal_best[i] = trial\n                        personal_best_values[i] = trial_value\n                        if trial_value < global_best_value:\n                            global_best = trial\n                            global_best_value = trial_value\n\n                    if eval_count >= self.budget:\n                        break\n                pop[start:end] = subpop\n                velocities[start:end] = sub_velocities\n                personal_best[start:end] = sub_personal_best\n                personal_best_values[start:end] = sub_personal_best_values\n\n        return global_best", "name": "QuantumEnhancedPSO_DSP", "description": "Quantum-Enhanced PSO with Dynamic Subpopulation Partitioning (QEPSO-DSP) integrates quantum-enhanced search with dynamic subpopulation partitioning to better balance global and local searches in high-dimensional optimization problems.", "configspace": "", "generation": 65, "fitness": 0.28956669165709803, "feedback": "The algorithm QuantumEnhancedPSO_DSP got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28956669165709803]}, "mutation_prompt": null}
{"id": "d0bb9e20-9f37-4c9a-a693-be4d5a47419b", "solution": "import numpy as np\n\nclass BioInspiredEnvironmentalAdaptation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_step_size = 0.05\n        self.final_step_size = 0.01\n        self.local_weight_initial = 0.7\n        self.local_weight_final = 0.3\n        self.global_weight_initial = 0.3\n        self.global_weight_final = 0.7\n\n    def environment_update(self, position, local_best, global_best, eval_count):\n        alpha = eval_count / self.budget\n        step_size = (self.initial_step_size * (1 - alpha) + self.final_step_size * alpha)\n        local_weight = (self.local_weight_initial * (1 - alpha) + self.local_weight_final * alpha)\n        global_weight = (self.global_weight_initial * alpha + self.global_weight_final * (1 - alpha))\n        \n        disturbance = np.random.normal(0, step_size, self.dim)\n        new_position = (1 - local_weight - global_weight) * position + \\\n                       local_weight * local_best + \\\n                       global_weight * global_best + disturbance\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        local_best = pop.copy()\n        local_best_values = np.array([func(ind) for ind in pop])\n        global_best = local_best[np.argmin(local_best_values)]\n        global_best_value = local_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                candidate = self.environment_update(pop[i], local_best[i], global_best, eval_count)\n                candidate = np.clip(candidate, bounds[:, 0], bounds[:, 1])\n                \n                candidate_value = func(candidate)\n                eval_count += 1\n                if candidate_value < local_best_values[i]:\n                    local_best[i] = candidate\n                    local_best_values[i] = candidate_value\n                    if candidate_value < global_best_value:\n                        global_best = candidate\n                        global_best_value = candidate_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "BioInspiredEnvironmentalAdaptation", "description": "Bio-Inspired Environmental Adaptation (BIEA) leverages environmental signals to adaptively modify local and global search dynamics for enhanced convergence in black box optimization.", "configspace": "", "generation": 66, "fitness": 0.28784623587478364, "feedback": "The algorithm BioInspiredEnvironmentalAdaptation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28784623587478364]}, "mutation_prompt": null}
{"id": "5e370da5-8bdd-4c94-ae01-9b36069315aa", "solution": "import numpy as np\n\nclass DifferentialEvolutionAdaptivePopulation:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.population_size = self.initial_population_size\n        self.F = 0.5  # Mutation factor\n        self.CR = 0.9  # Crossover probability\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), bounds[:, 0], bounds[:, 1])\n                \n                trial = np.where(np.random.rand(self.dim) < self.CR, mutant, pop[i])\n                trial_value = func(trial)\n                eval_count += 1\n\n                if trial_value < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n            # Adapt population size based on convergence and diversity\n            if eval_count < self.budget:\n                fitness_std = np.std(fitness)\n                if fitness_std < 1e-5:  # Convergence detected\n                    self.population_size = min(self.initial_population_size, self.population_size + 1)\n                else:  # Increase exploration\n                    self.population_size = max(4, self.population_size - 1)\n\n                # Adjust current population size if necessary\n                if len(pop) != self.population_size:\n                    pop = np.resize(pop, (self.population_size, self.dim))\n                    fitness = np.resize(fitness, self.population_size)\n                    if len(pop) > self.population_size:\n                        excess = len(pop) - self.population_size\n                        pop = np.delete(pop, np.random.choice(len(pop), excess, replace=False), axis=0)\n                        fitness = np.delete(fitness, np.random.choice(len(fitness), excess, replace=False))\n\n        best_idx = np.argmin(fitness)\n        return pop[best_idx]", "name": "DifferentialEvolutionAdaptivePopulation", "description": "Differential Evolution with Autonomously Adapting Population Size (DEAPS) scales population based on convergence speed and diversity to balance exploration and exploitation.", "configspace": "", "generation": 67, "fitness": 0.28254441661756713, "feedback": "The algorithm DifferentialEvolutionAdaptivePopulation got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28254441661756713]}, "mutation_prompt": null}
{"id": "3de9684f-97ab-433a-9ea1-3db722d58126", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO_FLI:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.local_search_prob = 0.1\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  # Adaptive quantum factor\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def local_search(self, position, bounds, func):\n        local_radius = 0.1 * (bounds[:, 1] - bounds[:, 0])\n        perturbation = np.random.uniform(-local_radius, local_radius)\n        new_position = position + perturbation\n        new_position = np.clip(new_position, bounds[:, 0], bounds[:, 1])\n        return new_position, func(new_position)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                # Local search intensification\n                if np.random.rand() < self.local_search_prob:\n                    local_trial, local_trial_value = self.local_search(trial, bounds, func)\n                    eval_count += 1\n                    if local_trial_value < trial_value:\n                        trial = local_trial\n                        trial_value = local_trial_value\n                        if trial_value < personal_best_values[i]:\n                            personal_best[i] = trial\n                            personal_best_values[i] = trial_value\n                            if trial_value < global_best_value:\n                                global_best = trial\n                                global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSO_FLI", "description": "Quantum-Enhanced Adaptive PSO with Focused Local Intensification (QEAPSO-FLI) introduces a secondary local search mechanism to intensify search near promising areas, enhancing convergence speed and precision.", "configspace": "", "generation": 68, "fitness": 0.28718943601947444, "feedback": "The algorithm QuantumEnhancedAdaptivePSO_FLI got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28718943601947444]}, "mutation_prompt": null}
{"id": "11b7eb10-9411-44f0-8981-2958362da3d2", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1_initial = 2.5\n        self.c1_final = 0.5\n        self.c2_initial = 0.5\n        self.c2_final = 2.5\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - personal_best) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n            c1 = self.c1_initial * (1 - eval_count / self.budget) + self.c1_final * (eval_count / self.budget)\n            c2 = self.c2_initial * (1 - eval_count / self.budget) + self.c2_final * (eval_count / self.budget)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + c1 * r1 * (personal_best[i] - pop[i])\n                                 + c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSO", "description": "Quantum-Enhanced Adaptive PSO (QEAPSO) with Dynamic Learning Factors enhances particle diversity and adaptability through time-varying cognitive and social coefficients and an improved quantum update mechanism.", "configspace": "", "generation": 69, "fitness": 0.286677747364409, "feedback": "The algorithm QuantumEnhancedAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.286677747364409]}, "mutation_prompt": null}
{"id": "b5009ce2-73cb-4740-bdd9-c7b828823a2d", "solution": "import numpy as np\n\nclass AdaptiveQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.neighborhood_size = max(3, self.population_size // 10)\n\n    def quantum_update(self, position, personal_best, neighborhood_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (neighborhood_best - position) * delta\n        return new_position\n\n    def select_neighborhood_best(self, personal_best_values, personal_best, index):\n        start = max(0, index - self.neighborhood_size // 2)\n        end = min(self.population_size, start + self.neighborhood_size)\n        neighborhood = personal_best[start:end]\n        neighborhood_values = personal_best_values[start:end]\n        local_best_index = np.argmin(neighborhood_values)\n        return neighborhood[local_best_index]\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                neighborhood_best = self.select_neighborhood_best(personal_best_values, personal_best, i)\n                trial = self.quantum_update(pop[i], personal_best[i], neighborhood_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "AdaptiveQuantumPSO", "description": "Adaptive Quantum Particle Swarm Optimization (AQPSO) integrates a dynamic neighborhood strategy with quantum-enhanced particle updates to improve robustness and convergence in photonic structure optimization.", "configspace": "", "generation": 70, "fitness": 0.2869792762644333, "feedback": "The algorithm AdaptiveQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2869792762644333]}, "mutation_prompt": null}
{"id": "6c49a633-a9cd-4856-b547-49c77a53c312", "solution": "import numpy as np\n\nclass QuantumInspiredDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_perturbation(self, vector, best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = eval_count / self.budget  # Adaptive quantum factor\n        quantum_factor = (self.quantum_factor_initial * (1 - lambda_factor) \n                          + self.quantum_factor_final * lambda_factor)\n        perturbation = quantum_factor * (best - vector) * delta\n        return vector + perturbation\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                # Mutation\n                idxs = np.random.choice(self.population_size, 3, replace=False)\n                x1, x2, x3 = pop[idxs]\n                mutant = x1 + self.F * (x2 - x3)\n                mutant = np.clip(mutant, bounds[:, 0], bounds[:, 1])\n\n                # Crossover\n                cross_points = np.random.rand(self.dim) < self.CR\n                if not np.any(cross_points):\n                    cross_points[np.random.randint(0, self.dim)] = True\n                trial = np.where(cross_points, mutant, pop[i])\n\n                # Quantum perturbation\n                trial = self.quantum_perturbation(trial, pop[np.argmin(fitness)], eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                # Selection\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n        return pop[np.argmin(fitness)]", "name": "QuantumInspiredDifferentialEvolution", "description": "Quantum-Inspired Differential Evolution (QIDE) synergizes quantum-inspired mechanisms with differential evolution for robust exploration and exploitation in complex search spaces.", "configspace": "", "generation": 71, "fitness": 0.28013688787995306, "feedback": "The algorithm QuantumInspiredDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28013688787995306]}, "mutation_prompt": null}
{"id": "ba0199ec-461b-4aeb-9c6b-7c9117a94709", "solution": "import numpy as np\n\nclass HybridQuantumDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.quantum_factor = 0.2\n        self.F = 0.5  # Differential weight factor\n        self.CR = 0.9  # Crossover probability\n\n    def quantum_update(self, position, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_influence = self.quantum_factor * (1 - lambda_factor)\n        new_position = position + quantum_influence * (global_best - position) * delta\n        return new_position\n\n    def differential_mutation(self, pop, idx, bounds):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.F * (b - c), bounds[:, 0], bounds[:, 1])\n        return mutant\n\n    def differential_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.CR\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        global_best = pop[np.argmin(fitness)]\n        global_best_value = fitness.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                mutant = self.differential_mutation(pop, i, bounds)\n                trial = self.differential_crossover(pop[i], mutant)\n                trial = self.quantum_update(trial, global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(trial)\n                eval_count += 1\n\n                if trial_value < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "HybridQuantumDifferentialEvolution", "description": "Hybrid Quantum and Differential Evolution (HQDE) synergizes quantum-inspired exploration and differential evolution strategies for robust global optimization in complex landscapes.", "configspace": "", "generation": 72, "fitness": 0.28216810925748104, "feedback": "The algorithm HybridQuantumDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28216810925748104]}, "mutation_prompt": null}
{"id": "f1edde44-517f-43ff-b75f-2b81e3c99bfa", "solution": "import numpy as np\n\nclass HybridQuantumCuckooSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.pa = 0.25  # Discovery rate of alien eggs/solutions\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def levy_flight(self, L):\n        beta = 1.5\n        sigma = (np.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1/beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1/beta)\n        return L * step\n\n    def quantum_update(self, position, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  # Adaptive quantum factor\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = position + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        global_best = pop[np.argmin(fitness)]\n        global_best_value = fitness.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                new_solution = pop[i] + self.levy_flight(0.01)\n                new_solution = np.clip(new_solution, bounds[:, 0], bounds[:, 1])\n                new_fitness = func(new_solution)\n                eval_count += 1\n                \n                if new_fitness < fitness[i]:\n                    pop[i] = new_solution\n                    fitness[i] = new_fitness\n                    if new_fitness < global_best_value:\n                        global_best = new_solution\n                        global_best_value = new_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n            # Quantum-inspired update\n            for i in range(self.population_size):\n                if np.random.rand() < self.pa:\n                    quantum_solution = self.quantum_update(pop[i], global_best, eval_count)\n                    quantum_solution = np.clip(quantum_solution, bounds[:, 0], bounds[:, 1])\n                    quantum_fitness = func(quantum_solution)\n                    eval_count += 1\n\n                    if quantum_fitness < fitness[i]:\n                        pop[i] = quantum_solution\n                        fitness[i] = quantum_fitness\n                        if quantum_fitness < global_best_value:\n                            global_best = quantum_solution\n                            global_best_value = quantum_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "HybridQuantumCuckooSearch", "description": "Hybrid Quantum-Cuckoo Search (HQCS) combines quantum-inspired superposition with the Levy flight mechanism of Cuckoo Search for enhanced exploration capabilities.", "configspace": "", "generation": 73, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {}, "mutation_prompt": null}
{"id": "97be8e27-52b4-4451-9c3c-e4178df8a564", "solution": "import numpy as np\n\nclass SwarmEnhancedQuantumPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.c3 = 1.5  # New coefficient for neighborhood influence\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.neighborhood_size = max(3, int(0.1 * self.population_size))  # Neighborhood size\n\n    def quantum_update(self, position, personal_best, neighborhood_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (neighborhood_best - position) * delta\n        return new_position\n\n    def update_neighborhood_best(self, pop, personal_best_values):\n        neighborhood_best = np.zeros_like(pop)\n        for i in range(self.population_size):\n            indices = np.arange(max(0, i-self.neighborhood_size//2), min(self.population_size, i+self.neighborhood_size//2))\n            neighborhood_best[i] = pop[indices[np.argmin(personal_best_values[indices])]]\n        return neighborhood_best\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            neighborhood_best = self.update_neighborhood_best(personal_best, personal_best_values)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.rand(self.dim), np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i])\n                                 + self.c3 * r3 * (neighborhood_best[i] - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], neighborhood_best[i], eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "SwarmEnhancedQuantumPSO", "description": "Swarm-Enhanced Quantum PSO (SEQPSO) integrates adaptive neighborhood topology and hybrid quantum updates to enhance convergence speed and solution quality in high-dimensional optimization.", "configspace": "", "generation": 74, "fitness": 0.2868356072185574, "feedback": "The algorithm SwarmEnhancedQuantumPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2868356072185574]}, "mutation_prompt": null}
{"id": "c6106d0c-c26e-4ddb-a197-b0e76e0541dd", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSOWithDynamicNeighborhoods:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.neighborhood_size = 5\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def select_dynamic_neighborhood(self, personal_best_values):\n        indices = np.argsort(personal_best_values)\n        neighborhood = indices[:self.neighborhood_size]\n        return neighborhood\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                neighborhood = self.select_dynamic_neighborhood(personal_best_values)\n                local_best_index = neighborhood[np.argmin(personal_best_values[neighborhood])]\n                local_best = personal_best[local_best_index]\n                \n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (local_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSOWithDynamicNeighborhoods", "description": "Quantum-Enhanced Adaptive PSO with Dynamic Neighborhoods (QEAPSO-DN) introduces dynamic neighborhood topology for enhanced diversity and convergence speed, improving search efficiency in complex landscapes.", "configspace": "", "generation": 75, "fitness": 0.28956669165709803, "feedback": "The algorithm QuantumEnhancedAdaptivePSOWithDynamicNeighborhoods got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28956669165709803]}, "mutation_prompt": null}
{"id": "6108fce3-d6ed-4cb0-a2e4-669c9fc06610", "solution": "import numpy as np\n\nclass QuantumInspiredAdaptivePSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.diversity_threshold = 1e-5\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            diversity = np.mean(np.std(pop, axis=0))\n            if diversity < self.diversity_threshold:\n                # Reinitialize a part of the population if diversity is too low\n                reinit_indices = np.random.choice(self.population_size, self.population_size // 5, replace=False)\n                pop[reinit_indices] = np.random.rand(len(reinit_indices), self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumInspiredAdaptivePSO", "description": "Quantum-Inspired Adaptive PSO with Diversity Preservation (QIAPSO-DP) integrates quantum computing principles and diversity-preserving strategies to maintain robust exploration and exploitation across complex landscapes.", "configspace": "", "generation": 76, "fitness": 0.28956669165709803, "feedback": "The algorithm QuantumInspiredAdaptivePSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28956669165709803]}, "mutation_prompt": null}
{"id": "ca7b3eaf-5dfc-41b2-86e9-e6eba1e7ebc4", "solution": "import numpy as np\n\nclass HybridQuantumEnhancedPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.mutation_rate = 0.1\n        self.mutation_decay = 0.99\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  \n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def adaptive_mutation(self, position, bounds, eval_count):\n        mutation_strength = (self.mutation_rate * (1 - eval_count / self.budget)) ** self.mutation_decay\n        mutation_vector = mutation_strength * np.random.normal(0, 1, self.dim) * (bounds[:, 1] - bounds[:, 0])\n        return position + mutation_vector\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                # Apply adaptive mutation\n                mutated_position = self.adaptive_mutation(pop[i], bounds, eval_count)\n                mutated_position = np.clip(mutated_position, bounds[:, 0], bounds[:, 1])\n                mutated_value = func(mutated_position)\n                eval_count += 1\n                if mutated_value < personal_best_values[i]:\n                    personal_best[i] = mutated_position\n                    personal_best_values[i] = mutated_value\n                    if mutated_value < global_best_value:\n                        global_best = mutated_position\n                        global_best_value = mutated_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "HybridQuantumEnhancedPSO", "description": "Hybrid Quantum-Enhanced PSO with Adaptive Mutation integrates quantum updates and adaptive mutation to enhance exploration and exploitation dynamically, improving convergence in complex high-dimensional optimization tasks.", "configspace": "", "generation": 77, "fitness": 0.2866999009584106, "feedback": "The algorithm HybridQuantumEnhancedPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2866999009584106]}, "mutation_prompt": null}
{"id": "5bd13371-d78d-4d38-827f-0eb16ac73993", "solution": "import numpy as np\n\nclass SelfAdaptiveDifferentialTabuSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.tabu_size = int(self.population_size / 5)\n        self.mutation_factor = 0.5\n        self.recombination_rate = 0.7\n\n    def mutate(self, population, idx):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = np.random.choice(indices, 3, replace=False)\n        mutant = population[a] + self.mutation_factor * (population[b] - population[c])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover = np.random.rand(self.dim) < self.recombination_rate\n        trial = np.where(crossover, mutant, target)\n        return trial\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        tabu_list = []\n        best_solution = None\n        best_value = float('inf')\n        \n        eval_count = 0\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                mutant = self.mutate(pop, i)\n                mutant = np.clip(mutant, bounds[:, 0], bounds[:, 1])\n                trial = self.crossover(pop[i], mutant)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                \n                if len(tabu_list) >= self.tabu_size:\n                    tabu_list.pop(0)\n                \n                if trial_value < best_value and not any(np.allclose(trial, tabu) for tabu in tabu_list):\n                    best_solution = trial\n                    best_value = trial_value\n                    tabu_list.append(trial)\n                \n                if trial_value < func(pop[i]):\n                    pop[i] = trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return best_solution", "name": "SelfAdaptiveDifferentialTabuSearch", "description": "Self-Adaptive Differential Tabu Search (SADTS) combines adaptive differential mutation with tabu search to enhance exploration while avoiding local optima in complex landscapes.", "configspace": "", "generation": 78, "fitness": 0.2784684401582338, "feedback": "The algorithm SelfAdaptiveDifferentialTabuSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2784684401582338]}, "mutation_prompt": null}
{"id": "6adfa0c3-647e-4392-9116-96596c5e137d", "solution": "import numpy as np\n\nclass AdaptiveQuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = min(100, 10 * dim)\n        self.population_size = self.initial_population_size\n        self.inertia_weight = 0.7\n        self.c1 = 2.05\n        self.c2 = 2.05\n        self.quantum_factor = 0.3\n        self.epsilon = 1e-8  # small constant to avoid division by zero\n\n    def quantum_jump(self, position, personal_best, global_best, convergence):\n        delta = np.random.rand(self.dim)\n        adaptive_qf = self.quantum_factor * (1 - convergence)\n        new_position = position + adaptive_qf * (personal_best - position) * delta + adaptive_qf * (global_best - position) * (1 - delta)\n        return new_position\n\n    def adjust_population(self, eval_count):\n        # Reduce population size as evaluations progress to focus on exploitation\n        new_population_size = max(10, self.initial_population_size * (1 - eval_count / self.budget))\n        self.population_size = int(new_population_size)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) * 0.1\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            self.adjust_population(eval_count)\n            convergence = 1 - eval_count / self.budget\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_jump(pop[i], personal_best[i], global_best, convergence)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "AdaptiveQuantumInspiredPSO", "description": "Adaptive Quantum-Inspired PSO with Dynamic Population Control (AQIPSO-DPC) optimizes exploration and exploitation through dynamic population resizing and quantum-inspired particle jumps based on convergence behavior.", "configspace": "", "generation": 79, "fitness": 0.2846895281596178, "feedback": "The algorithm AdaptiveQuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2846895281596178]}, "mutation_prompt": null}
{"id": "f5ec4cf7-8aa6-44fa-86b8-fdcff97dab61", "solution": "import numpy as np\n\nclass GradientInformedQuantumSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.gradient_factor = 0.5\n\n    def quantum_gradient_update(self, position, personal_best, global_best, gradient, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  # Adaptive quantum factor\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        new_position -= self.gradient_factor * gradient  # Incorporating gradient descent\n        return new_position\n\n    def estimate_gradient(self, func, position, epsilon=1e-8):\n        gradient = np.zeros(self.dim)\n        for i in range(self.dim):\n            delta = np.zeros(self.dim)\n            delta[i] = epsilon\n            grad = (func(position + delta) - func(position - delta)) / (2 * epsilon)\n            gradient[i] = grad\n        return gradient\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                gradient = self.estimate_gradient(func, pop[i])\n                trial = self.quantum_gradient_update(pop[i], personal_best[i], global_best, gradient, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "GradientInformedQuantumSwarmOptimizer", "description": "Gradient-Informed Quantum-Swarm Optimizer (GIQSO) integrates gradient information with quantum-enhanced swarm dynamics to improve convergence rates on high-dimensional optimization problems.", "configspace": "", "generation": 80, "fitness": 0.2821388983837225, "feedback": "The algorithm GradientInformedQuantumSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2821388983837225]}, "mutation_prompt": null}
{"id": "4ed9c4ba-d360-4501-a3cf-f12facf147b1", "solution": "import numpy as np\n\nclass AdaptiveQuantumDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.mutation_factor_initial = 0.8\n        self.mutation_factor_final = 0.5\n        self.crossover_rate = 0.9\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_perturbation(self, ind, best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = eval_count / self.budget\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_ind = ind + quantum_factor * (best - ind) * delta\n        return new_ind\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        pop_values = np.array([func(ind) for ind in pop])\n        best = pop[np.argmin(pop_values)]\n        best_value = pop_values.min()\n        \n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            mutation_factor = self.mutation_factor_initial * (1 - eval_count / self.budget) + self.mutation_factor_final * (eval_count / self.budget)\n\n            for i in range(self.population_size):\n                indices = np.random.choice(np.delete(np.arange(self.population_size), i), 3, replace=False)\n                a, b, c = pop[indices]\n\n                mutant = np.clip(a + mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n                trial = np.array([mutant[j] if np.random.rand() < self.crossover_rate else pop[i][j] for j in range(self.dim)])\n                \n                trial_quantum = self.quantum_perturbation(trial, best, eval_count)\n                trial_quantum = np.clip(trial_quantum, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial_quantum)\n                eval_count += 1\n\n                if trial_value < pop_values[i]:\n                    pop[i] = trial_quantum\n                    pop_values[i] = trial_value\n                    if trial_value < best_value:\n                        best = trial_quantum\n                        best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return best", "name": "AdaptiveQuantumDifferentialEvolution", "description": "Adaptive Quantum Differential Evolution (AQDE) combines quantum-inspired perturbations with differential evolution to enhance diversity and convergence speed in complex optimization landscapes.", "configspace": "", "generation": 81, "fitness": 0.27947002596099646, "feedback": "The algorithm AdaptiveQuantumDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.27947002596099646]}, "mutation_prompt": null}
{"id": "4e159796-8995-4519-bd09-4cf92332d03e", "solution": "import numpy as np\n\nclass QuantumLevyFlightPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.inertia_weight = 0.7\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.alpha = 0.5  # Levy flight scaling factor\n\n    def levy_flight(self, scale):\n        u = np.random.normal(0, 1, self.dim)\n        v = np.random.normal(0, 1, self.dim)\n        step = u / (abs(v) ** (1 / self.alpha))\n        return scale * step\n\n    def quantum_update(self, position, personal_best, global_best):\n        delta = np.random.rand(self.dim)\n        new_position = (position + personal_best) / 2 + 0.1 * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (self.inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                if np.random.rand() < 0.3:  # Introduce Levy flights occasionally\n                    pop[i] += self.levy_flight(0.01 * (bounds[:, 1] - bounds[:, 0]))\n\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumLevyFlightPSO", "description": "Quantum-Levy Flight PSO (QLF-PSO) integrates Levy flights with quantum-inspired particle swarm dynamics to enhance exploration capabilities in diverse search spaces.", "configspace": "", "generation": 82, "fitness": 0.28605613620543746, "feedback": "The algorithm QuantumLevyFlightPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28605613620543746]}, "mutation_prompt": null}
{"id": "f997befd-0ef9-445c-a582-4183eb5c8838", "solution": "import numpy as np\n\nclass QuantumInspiredDifferentialPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.differential_weight = 0.8\n        self.crossover_prob = 0.9\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def differential_mutation(self, pop, idx, bounds):\n        indices = [i for i in range(self.population_size) if i != idx]\n        a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n        mutant = np.clip(a + self.differential_weight * (b - c), bounds[:, 0], bounds[:, 1])\n        return mutant\n\n    def crossover(self, target, mutant):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_prob\n        offspring = np.where(crossover_mask, mutant, target)\n        return offspring\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                # Perform differential mutation and crossover\n                mutant = self.differential_mutation(pop, i, bounds)\n                offspring = self.crossover(pop[i], mutant)\n                offspring = np.clip(offspring, bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(offspring)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = offspring\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = offspring\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumInspiredDifferentialPSO", "description": "Quantum-Inspired Differential PSO (QIDPSO) integrates quantum probability amplitudes with differential evolution strategies for enhanced exploration-exploitation trade-offs in global optimization.", "configspace": "", "generation": 83, "fitness": 0.27694481543747285, "feedback": "The algorithm QuantumInspiredDifferentialPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.27694481543747285]}, "mutation_prompt": null}
{"id": "f7608cd9-8d1f-4dac-9b78-9421a5e45c8c", "solution": "import numpy as np\n\nclass QuantumEnhancedDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_quantum_factor = 0.3\n        self.final_quantum_factor = 0.1\n        self.f = 0.5    # Differential evolution control parameter\n        self.cr = 0.9   # Crossover probability\n\n    def quantum_update(self, target, mutant, eval_count):\n        lambda_factor = eval_count / self.budget\n        quantum_factor = self.initial_quantum_factor * (1 - lambda_factor) + self.final_quantum_factor * lambda_factor\n        delta = np.random.rand(self.dim)\n        new_position = target + quantum_factor * (mutant - target) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n        best_idx = np.argmin(fitness)\n        best = pop[best_idx]\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                x0, x1, x2 = pop[indices]\n                mutant = np.clip(x0 + self.f * (x1 - x2), bounds[:, 0], bounds[:, 1])\n\n                crossover = np.random.rand(self.dim) < self.cr\n                trial = np.where(crossover, mutant, pop[i])\n                trial = self.quantum_update(trial, pop[i], eval_count)\n\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                trial_fitness = func(trial)\n                eval_count += 1\n\n                if trial_fitness < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < fitness[best_idx]:\n                        best_idx = i\n                        best = trial\n\n                if eval_count >= self.budget:\n                    break\n\n        return best", "name": "QuantumEnhancedDifferentialEvolution", "description": "Quantum-Enhanced Differential Evolution (QEDE) combines differential evolution with adaptive quantum updates to enhance exploration and exploitation dynamics, optimizing performance in high-dimensional spaces.", "configspace": "", "generation": 84, "fitness": 0.28064152851883206, "feedback": "The algorithm QuantumEnhancedDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28064152851883206]}, "mutation_prompt": null}
{"id": "69931d5f-d53f-4b2d-b6db-900b852814d9", "solution": "import numpy as np\n\nclass QuantumParticleSwarmDynamicNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_update(self, position, personal_best, neighborhood_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (neighborhood_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        \n        eval_count = self.population_size\n\n        def get_neighborhood_best(index):\n            neighbors_indices = [(index - 1) % self.population_size, index, (index + 1) % self.population_size]\n            neighbor_values = personal_best_values[neighbors_indices]\n            best_neighbor_index = neighbors_indices[np.argmin(neighbor_values)]\n            return personal_best[best_neighbor_index]\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                neighborhood_best = get_neighborhood_best(i)\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (neighborhood_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], neighborhood_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        global_best_index = np.argmin(personal_best_values)\n        return personal_best[global_best_index]", "name": "QuantumParticleSwarmDynamicNeighborhood", "description": "Quantum-Particle Swarm with Dynamic Neighborhoods (QPS-DN) leverages adaptive neighborhood topologies and quantum-inspired position updates to balance exploration and exploitation effectively.", "configspace": "", "generation": 85, "fitness": 0.2820194970214933, "feedback": "The algorithm QuantumParticleSwarmDynamicNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2820194970214933]}, "mutation_prompt": null}
{"id": "556f3725-0797-4e2c-b550-b361dddf1e5b", "solution": "import numpy as np\n\nclass QuantumGuidedDynamicHarmonySearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.harmony_memory_consideration_rate = 0.9\n        self.pitch_adjustment_rate = 0.3\n        self.bandwidth = 0.05\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_adjustment(self, vector, global_best, eval_count):\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        delta = np.random.rand(self.dim)\n        new_vector = vector + quantum_factor * (global_best - vector) * delta\n        return new_vector\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        harmony_memory = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        harmony_values = np.array([func(harmony) for harmony in harmony_memory])\n        global_best = harmony_memory[np.argmin(harmony_values)]\n        global_best_value = harmony_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            new_harmony = np.empty(self.dim)\n            for i in range(self.dim):\n                if np.random.rand() < self.harmony_memory_consideration_rate:\n                    selected_harmony = harmony_memory[np.random.randint(self.population_size)]\n                    new_harmony[i] = selected_harmony[i]\n                    if np.random.rand() < self.pitch_adjustment_rate:\n                        new_harmony[i] += self.bandwidth * np.random.uniform(-1, 1)\n                else:\n                    new_harmony[i] = np.random.uniform(bounds[i, 0], bounds[i, 1])\n\n            new_harmony = np.clip(new_harmony, bounds[:, 0], bounds[:, 1])\n            new_harmony = self.quantum_adjustment(new_harmony, global_best, eval_count)\n            new_harmony = np.clip(new_harmony, bounds[:, 0], bounds[:, 1])\n\n            new_harmony_value = func(new_harmony)\n            eval_count += 1\n\n            if new_harmony_value < global_best_value:\n                global_best = new_harmony\n                global_best_value = new_harmony_value\n\n            worst_index = np.argmax(harmony_values)\n            if new_harmony_value < harmony_values[worst_index]:\n                harmony_memory[worst_index] = new_harmony\n                harmony_values[worst_index] = new_harmony_value\n\n            if eval_count >= self.budget:\n                break\n\n        return global_best", "name": "QuantumGuidedDynamicHarmonySearch", "description": "Quantum-Guided Dynamic Harmony Search (QGDHS) combines harmony search with quantum-inspired dynamics for enhanced exploration and exploitation in complex optimization landscapes.", "configspace": "", "generation": 86, "fitness": 0.2860624755796124, "feedback": "The algorithm QuantumGuidedDynamicHarmonySearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2860624755796124]}, "mutation_prompt": null}
{"id": "6413d94f-a45e-403c-b4d1-10aa6b24509a", "solution": "import numpy as np\n\nclass BioInspiredDispersiveSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.dispersal_factor_initial = 0.5\n        self.dispersal_factor_final = 0.1\n\n    def dispersive_update(self, position, global_best, eval_count):\n        dispersal_factor = self.dispersal_factor_initial * (1 - (eval_count / self.budget)) + self.dispersal_factor_final * (eval_count / self.budget)\n        random_direction = np.random.uniform(-1, 1, self.dim)\n        dispersive_position = position + dispersal_factor * random_direction\n        return dispersive_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                dispersive_trial = self.dispersive_update(pop[i], global_best, eval_count)\n                dispersive_trial = np.clip(dispersive_trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(dispersive_trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = dispersive_trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = dispersive_trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "BioInspiredDispersiveSwarmOptimization", "description": "Bio-Inspired Dispersive Swarm Optimization (BIDSO) utilizes a dispersive mechanism to enhance diversity, maintaining exploration in multi-modal landscapes for balanced search efficiency.", "configspace": "", "generation": 87, "fitness": 0.2794480464622069, "feedback": "The algorithm BioInspiredDispersiveSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2794480464622069]}, "mutation_prompt": null}
{"id": "e3fa10dc-2f4f-4694-bf36-f56e1ccbcca7", "solution": "import numpy as np\n\nclass QuantumStochasticPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.stochastic_factor = 0.1\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.05\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        adaptive_quantum = (np.mean(np.abs(position - global_best)) / np.max(np.abs(personal_best - global_best)))\n        new_position = (position + personal_best) / 2 + quantum_factor * adaptive_quantum * (global_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                stochastic_velocity = self.stochastic_factor * (np.random.rand(self.dim) - 0.5)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i])\n                                 + stochastic_velocity)\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumStochasticPSO", "description": "Quantum-Stochastic PSO (QS-PSO) incorporates stochastic velocity adaptation and feedback-based quantum factors to enhance convergence robustness and efficiency.", "configspace": "", "generation": 88, "fitness": 0.28676039175453416, "feedback": "The algorithm QuantumStochasticPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28676039175453416]}, "mutation_prompt": null}
{"id": "a4980716-0db8-413c-a5d0-233678138e9e", "solution": "import numpy as np\n\nclass QuantumEnhancedBatAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.fmin = 0\n        self.fmax = 2\n        self.initial_loudness = 1.0\n        self.final_loudness = 0.1\n        self.initial_pulse_rate = 0.5\n        self.final_pulse_rate = 0.1\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n\n    def quantum_update(self, position, best_position, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = position + quantum_factor * (best_position - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        bats = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(bats)\n        loudness = np.ones(self.population_size) * self.initial_loudness\n        pulse_rate = np.ones(self.population_size) * self.initial_pulse_rate\n\n        fitness = np.array([func(ind) for ind in bats])\n        best_bat = bats[np.argmin(fitness)]\n        best_fitness = fitness.min()\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            for i in range(self.population_size):\n                beta = np.random.rand()\n                frequency = self.fmin + (self.fmax - self.fmin) * beta\n                velocities[i] = velocities[i] + (bats[i] - best_bat) * frequency\n                candidate_bat = bats[i] + velocities[i]\n                candidate_bat = np.clip(candidate_bat, bounds[:, 0], bounds[:, 1])\n\n                if np.random.rand() > pulse_rate[i]:\n                    candidate_bat = self.quantum_update(candidate_bat, best_bat, eval_count)\n                    candidate_bat = np.clip(candidate_bat, bounds[:, 0], bounds[:, 1])\n\n                candidate_fitness = func(candidate_bat)\n                eval_count += 1\n\n                if candidate_fitness <= fitness[i] and np.random.rand() < loudness[i]:\n                    bats[i] = candidate_bat\n                    fitness[i] = candidate_fitness\n                    loudness[i] = max(self.final_loudness, loudness[i] * 0.9)\n                    pulse_rate[i] = min(self.final_pulse_rate, pulse_rate[i] * 1.1)\n\n                    if candidate_fitness < best_fitness:\n                        best_bat = candidate_bat\n                        best_fitness = candidate_fitness\n\n                if eval_count >= self.budget:\n                    break\n\n        return best_bat", "name": "QuantumEnhancedBatAlgorithm", "description": "Quantum-Enhanced Bat Algorithm (QEBA) introduces quantum behavior and dynamic loudness and pulse rate adaptation to balance exploration and exploitation effectively in high-dimensional spaces.", "configspace": "", "generation": 89, "fitness": 0.2748713593062414, "feedback": "The algorithm QuantumEnhancedBatAlgorithm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2748713593062414]}, "mutation_prompt": null}
{"id": "4eab87a7-0a7c-4378-a47e-fb0f5a90e3c9", "solution": "import numpy as np\n\nclass QuantumInspiredDynamicPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.elite_archive_size = max(5, dim // 2)\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def dynamic_bound_adjustment(self, bounds, global_best):\n        adjustment_factor = 0.1\n        new_bounds = np.copy(bounds)\n        range_width = bounds[:, 1] - bounds[:, 0]\n        new_bounds[:, 0] = global_best - adjustment_factor * range_width\n        new_bounds[:, 1] = global_best + adjustment_factor * range_width\n        return new_bounds\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n        elite_archive = []\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(trial)\n                eval_count += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n            if eval_count % (self.population_size * 2) == 0:\n                elite_archive = sorted(elite_archive + [(global_best_value, global_best)],\n                                       key=lambda x: x[0])[:self.elite_archive_size]\n                if len(elite_archive) > 0:\n                    bounds = self.dynamic_bound_adjustment(bounds, elite_archive[0][1])\n\n        return global_best", "name": "QuantumInspiredDynamicPSO", "description": "Quantum-Inspired Dynamic Particle Swarm Optimization (QIDPSO) introduces dynamic boundary adaptation and elite archival to enhance convergence and robustness in photonic structure optimization.", "configspace": "", "generation": 90, "fitness": 0.28636648409247634, "feedback": "The algorithm QuantumInspiredDynamicPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28636648409247634]}, "mutation_prompt": null}
{"id": "2c9f6a33-cfa7-46a4-a190-527fd17a64fd", "solution": "import numpy as np\n\nclass QuantumInspiredGravitationalWaveOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_gravitation = 0.9\n        self.final_gravitation = 0.4\n        self.quantum_tunneling_prob = 0.2\n\n    def quantum_tunnel(self, position, global_best, eval_count):\n        lambda_factor = (eval_count / self.budget)\n        scale = (1 - lambda_factor) * self.initial_gravitation + lambda_factor * self.final_gravitation\n        if np.random.rand() < self.quantum_tunneling_prob:\n            perturbation = np.random.randn(self.dim) * scale\n            return position + perturbation\n        return position\n\n    def gravitational_wave_propagate(self, pop, global_best, gravitation):\n        for i in range(self.population_size):\n            r = np.random.rand(self.dim)\n            pop[i] += gravitation * r * (global_best - pop[i])\n            pop[i] = np.clip(pop[i], self.bounds[:, 0], self.bounds[:, 1])\n\n    def __call__(self, func):\n        self.bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (self.bounds[:, 1] - self.bounds[:, 0]) + self.bounds[:, 0]\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            gravitation = (self.initial_gravitation - self.final_gravitation) * \\\n                          (1 - eval_count / self.budget) + self.final_gravitation\n\n            self.gravitational_wave_propagate(pop, global_best, gravitation)\n\n            for i in range(self.population_size):\n                trial = self.quantum_tunnel(pop[i], global_best, eval_count)\n                trial = np.clip(trial, self.bounds[:, 0], self.bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumInspiredGravitationalWaveOptimization", "description": "Quantum-Inspired Gravitational Wave Optimization (QIGWO) integrates quantum tunneling with gravitational wave propagation to enhance diversity and convergence in the search space.", "configspace": "", "generation": 91, "fitness": 0.28819111060660896, "feedback": "The algorithm QuantumInspiredGravitationalWaveOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28819111060660896]}, "mutation_prompt": null}
{"id": "feb19108-aba6-4bda-b833-e4172d893c62", "solution": "import numpy as np\n\nclass QuantumAssistedDynamicSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.diversity_threshold = 0.1\n\n    def quantum_update(self, position, personal_best, global_best, eval_count, strategy='adaptive'):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        if strategy == 'adaptive':\n            quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        else:  # fixed strategy for diversity\n            quantum_factor = self.quantum_factor_initial * 0.5\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def calculate_diversity(self, population):\n        return np.std(population, axis=0).mean()\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial_strategy = 'adaptive'\n                if self.calculate_diversity(pop) < self.diversity_threshold:\n                    trial_strategy = 'diversity'\n                    \n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count, strategy=trial_strategy)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumAssistedDynamicSwarmOptimization", "description": "Quantum-Assisted Dynamic Swarm Optimization (QADSO) introduces a diversity preservation mechanism and a dual quantum update strategy for better convergence and diversity balance in complex optimization landscapes.", "configspace": "", "generation": 92, "fitness": 0.28956669165709803, "feedback": "The algorithm QuantumAssistedDynamicSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28956669165709803]}, "mutation_prompt": null}
{"id": "77e6796c-0a95-460d-a7e5-f01bde04d148", "solution": "import numpy as np\n\nclass QuantumEnhancedDifferentialPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.de_mutation_factor = 0.8\n        self.de_crossover_rate = 0.9\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  # Adaptive quantum factor\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def differential_evolution(self, pop, bounds):\n        for i in range(self.population_size):\n            candidates = np.random.choice(self.population_size, 3, replace=False)\n            a, b, c = pop[candidates]\n            mutant = np.clip(a + self.de_mutation_factor * (b - c), bounds[:, 0], bounds[:, 1])\n            cross_points = np.random.rand(self.dim) < self.de_crossover_rate\n            trial = np.where(cross_points, mutant, pop[i])\n            trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n            yield trial\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i, trial in enumerate(self.differential_evolution(pop, bounds)):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedDifferentialPSO", "description": "Quantum-Enhanced Differential PSO (QEDPSO) integrates differential evolution strategies into quantum-enhanced PSO for diversified exploration and robust convergence.", "configspace": "", "generation": 93, "fitness": 0.28231232489015334, "feedback": "The algorithm QuantumEnhancedDifferentialPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28231232489015334]}, "mutation_prompt": null}
{"id": "52f87185-7dea-4aee-acd6-d14f3a5df396", "solution": "import numpy as np\n\nclass QuantumCognitiveSwarmOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.cognitive_factor = 1.5  # Cognitive factor for individual learning\n\n    def quantum_cognitive_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.uniform(-1, 1, self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        cognitive_component = self.cognitive_factor * (personal_best - position) * np.random.rand(self.dim)\n        new_position = position + quantum_factor * (global_best - position) * delta + cognitive_component\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_cognitive_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumCognitiveSwarmOptimization", "description": "Quantum-Cognitive Swarm Optimization (QCSO) integrates quantum-inspired cognitive components with individual learning to enhance diversity and convergence speed in complex optimization landscapes.", "configspace": "", "generation": 94, "fitness": 0.28334930823547855, "feedback": "The algorithm QuantumCognitiveSwarmOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28334930823547855]}, "mutation_prompt": null}
{"id": "99e25d32-efaf-489b-a935-2595ec75660c", "solution": "import numpy as np\n\nclass DynamicDifferentialEvolution:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.1\n        self.CR_max = 0.9\n\n    def adapt_parameters(self, diversity):\n        F = self.F_min + (self.F_max - self.F_min) * (1 - diversity)\n        CR = self.CR_min + (self.CR_max - self.CR_min) * diversity\n        return F, CR\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        fitness = np.array([func(ind) for ind in pop])\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            diversity = np.mean(np.std(pop, axis=0) / (bounds[:, 1] - bounds[:, 0]))\n            F, CR = self.adapt_parameters(diversity)\n\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, bounds[:, 0], bounds[:, 1])\n\n                trial = np.copy(pop[i])\n                j_rand = np.random.randint(self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == j_rand:\n                        trial[j] = mutant[j]\n\n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < fitness[i]:\n                    pop[i] = trial\n                    fitness[i] = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        best_index = np.argmin(fitness)\n        return pop[best_index]", "name": "DynamicDifferentialEvolution", "description": "Dynamic Differential Evolution (DynDE) employs adaptive mutation and crossover rates based on population diversity to efficiently explore and exploit complex search spaces.", "configspace": "", "generation": 95, "fitness": 0.2788829368183091, "feedback": "The algorithm DynamicDifferentialEvolution got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2788829368183091]}, "mutation_prompt": null}
{"id": "5c33ef62-cce0-4853-89be-681fb6a2503d", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO_DN:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.neighborhood_size = max(2, self.population_size // 10)\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def update_neighborhood_best(self, pop, personal_best_values):\n        neighborhood_best = np.zeros_like(pop)\n        for i in range(self.population_size):\n            neighbors_idx = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n            best_neighbor_idx = neighbors_idx[np.argmin(personal_best_values[neighbors_idx])]\n            neighborhood_best[i] = pop[best_neighbor_idx]\n        return neighborhood_best\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            neighborhood_best = self.update_neighborhood_best(pop, personal_best_values)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (neighborhood_best[i] - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSO_DN", "description": "Quantum-Enhanced Adaptive PSO with Dynamic Neighborhood (QEAPSO-DN) improves convergence by incorporating a dynamic neighborhood structure, promoting diverse exploration and exploitation balance.", "configspace": "", "generation": 96, "fitness": 0.2835626096399809, "feedback": "The algorithm QuantumEnhancedAdaptivePSO_DN got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2835626096399809]}, "mutation_prompt": null}
{"id": "5bf4dff4-585c-4cee-82b8-3a792ed1413a", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSOWithDiversityControl:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.diversity_threshold = 0.05  # Threshold for diversity control\n\n    def quantum_update(self, position, personal_best, global_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)  # Adaptive quantum factor\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (global_best - position) * delta\n        return new_position\n\n    def calculate_diversity(self, population):\n        return np.mean(np.std(population, axis=0))\n\n    def reinject_diversity(self, population, bounds):\n        for i in range(self.population_size):\n            if np.random.rand() < 0.1:  # Reinject diversity with 10% probability\n                population[i] = np.random.rand(self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n            \n            # Check and maintain diversity\n            diversity = self.calculate_diversity(pop)\n            if diversity < self.diversity_threshold:\n                self.reinject_diversity(pop, bounds)\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSOWithDiversityControl", "description": "The Quantum-Enhanced Adaptive PSO with Diversity Control (QEAPSO-DC) introduces a diversity mechanism to prevent premature convergence by reinjecting diversity when the population stagnates, ensuring a more robust exploration of the solution space.", "configspace": "", "generation": 97, "fitness": 0.28956669165709803, "feedback": "The algorithm QuantumEnhancedAdaptivePSOWithDiversityControl got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28956669165709803]}, "mutation_prompt": null}
{"id": "0f0892ee-1b33-441b-b2ec-d499ae3f3be8", "solution": "import numpy as np\n\nclass QuantumInspiredPSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.archive_size = self.population_size // 2\n\n    def quantum_leap(self, position, local_best, global_best, eval_count):\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        leap_vector = np.random.rand(self.dim)\n        new_position = (position + local_best) / 2 + quantum_factor * (global_best - position) * leap_vector\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        archive = personal_best[np.argsort(personal_best_values)[:self.archive_size]]\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             np.exp(-5 * eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (global_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_leap(pop[i], personal_best[i], global_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n            archive = np.vstack((archive, personal_best[np.argsort(personal_best_values)[:self.archive_size]]))\n            archive = archive[np.argsort([func(a) for a in archive])[:self.archive_size]]\n\n            if eval_count >= self.budget:\n                break\n\n        return global_best", "name": "QuantumInspiredPSO", "description": "Quantum-Inspired Particle Swarm Optimization (QIPSO) incorporates adaptive memory and non-linear inertia reduction to enhance diversity and convergence in complex search spaces.", "configspace": "", "generation": 98, "fitness": 0.28736311992738717, "feedback": "The algorithm QuantumInspiredPSO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.28736311992738717]}, "mutation_prompt": null}
{"id": "c95f8167-c280-4403-a934-0eb305c4e7c5", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptivePSO_DynamicNeighborhood:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = min(100, 10 * dim)\n        self.initial_inertia_weight = 0.9\n        self.final_inertia_weight = 0.4\n        self.c1 = 2.0\n        self.c2 = 2.0\n        self.quantum_factor_initial = 0.3\n        self.quantum_factor_final = 0.1\n        self.neighborhood_size = max(2, self.population_size // 10)\n\n    def quantum_update(self, position, personal_best, local_best, eval_count):\n        delta = np.random.rand(self.dim)\n        lambda_factor = (eval_count / self.budget)\n        quantum_factor = self.quantum_factor_initial * (1 - lambda_factor) + self.quantum_factor_final * lambda_factor\n        new_position = (position + personal_best) / 2 + quantum_factor * (local_best - position) * delta\n        return new_position\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        pop = np.random.rand(self.population_size, self.dim) * (bounds[:, 1] - bounds[:, 0]) + bounds[:, 0]\n        velocities = np.zeros_like(pop)\n        personal_best = pop.copy()\n        personal_best_values = np.array([func(ind) for ind in pop])\n        global_best = personal_best[np.argmin(personal_best_values)]\n        global_best_value = personal_best_values.min()\n\n        eval_count = self.population_size\n\n        while eval_count < self.budget:\n            inertia_weight = (self.initial_inertia_weight - self.final_inertia_weight) * \\\n                             (1 - eval_count / self.budget) + self.final_inertia_weight\n\n            for i in range(self.population_size):\n                # Define neighborhood and find local best\n                neighborhood_indices = np.random.choice(self.population_size, self.neighborhood_size, replace=False)\n                local_best = personal_best[neighborhood_indices[np.argmin(personal_best_values[neighborhood_indices])]]\n\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                velocities[i] = (inertia_weight * velocities[i]\n                                 + self.c1 * r1 * (personal_best[i] - pop[i])\n                                 + self.c2 * r2 * (local_best - pop[i]))\n                pop[i] += velocities[i]\n                pop[i] = np.clip(pop[i], bounds[:, 0], bounds[:, 1])\n\n                trial = self.quantum_update(pop[i], personal_best[i], local_best, eval_count)\n                trial = np.clip(trial, bounds[:, 0], bounds[:, 1])\n                \n                trial_value = func(trial)\n                eval_count += 1\n                if trial_value < personal_best_values[i]:\n                    personal_best[i] = trial\n                    personal_best_values[i] = trial_value\n                    if trial_value < global_best_value:\n                        global_best = trial\n                        global_best_value = trial_value\n\n                if eval_count >= self.budget:\n                    break\n\n        return global_best", "name": "QuantumEnhancedAdaptivePSO_DynamicNeighborhood", "description": "Quantum-Enhanced Adaptive PSO with Dynamic Neighborhood (QEAPSO-DN) improves convergence by dynamically adjusting quantum, inertia parameters, and using a dynamic neighborhood topology to enhance information sharing among particles.", "configspace": "", "generation": 99, "fitness": 0.2864162232953248, "feedback": "The algorithm QuantumEnhancedAdaptivePSO_DynamicNeighborhood got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.00.", "error": "", "parent_id": "dc42eee7-bbf8-4920-8dc5-a36e9ca981fb", "metadata": {"aucs": [0.2864162232953248]}, "mutation_prompt": null}
