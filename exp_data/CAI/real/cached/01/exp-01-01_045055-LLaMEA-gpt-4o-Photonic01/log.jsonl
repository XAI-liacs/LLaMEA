{"id": "b4f7daa0-943f-40d7-bd0c-9ea7e4b0b025", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.7\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n        \n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "An adaptive swarm-based algorithm inspired by social dynamics and perturbation to efficiently explore multimodal landscapes under budget constraints.", "configspace": "", "generation": 0, "fitness": 0.27559213686468403, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": null, "metadata": {"aucs": [0.27770572177812425, 0.27345472545061467, 0.27561596336531324]}, "mutation_prompt": null}
{"id": "b97b6a16-17eb-4c33-94f0-51022fb00b2e", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.7\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Dynamic coefficients\n                cognitive_coeff = 1.5 + 0.5 * np.sin(evaluations/100)\n                social_coeff = 1.5 + 0.5 * np.cos(evaluations/100)\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "A modified adaptive swarm-based algorithm with dynamic social and cognitive coefficients to enhance exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.27687700302763124, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "b4f7daa0-943f-40d7-bd0c-9ea7e4b0b025", "metadata": {"aucs": [0.2775201038404075, 0.2770679987838123, 0.276042906458674]}, "mutation_prompt": null}
{"id": "39bdb0cd-7e33-4862-83a9-d855492fef40", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Dynamic coefficients\n                cognitive_coeff = 1.5 + 0.5 * np.sin(evaluations/100)\n                social_coeff = 1.5 + 0.5 * np.cos(evaluations/100)\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)**2\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduced a nonlinear inertia weight decay and stochastic velocity clamping to enhance convergence and prevent premature convergence.", "configspace": "", "generation": 2, "fitness": 0.27760859880912375, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "b97b6a16-17eb-4c33-94f0-51022fb00b2e", "metadata": {"aucs": [0.27755063150070824, 0.2776868601432809, 0.27758830478338203]}, "mutation_prompt": null}
{"id": "fc391cc1-da01-48f9-83c1-aa69e59d2d6d", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n        stuck_threshold = 10  # New: Stagnation threshold\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        stagnation_counter = 0  # New: Counter for stagnation detection\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Dynamic coefficients\n                cognitive_coeff = 1.5 + 0.5 * np.sin(evaluations/100)\n                social_coeff = 1.5 + 0.5 * np.cos(evaluations/100)\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)**2\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n                        stagnation_counter = 0  # New: Reset stagnation counter\n                    else:\n                        stagnation_counter += 1  # New: Increment on no global improvement\n                    \n                if stagnation_counter >= stuck_threshold:  # New: Restart mechanism\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n                    stagnation_counter = 0\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced swarm diversity and exploration through adaptive particle restarting triggered by stagnation detection.", "configspace": "", "generation": 3, "fitness": 0.2775827179442872, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "39bdb0cd-7e33-4862-83a9-d855492fef40", "metadata": {"aucs": [0.277482704152228, 0.2776818961424633, 0.2775835535381703]}, "mutation_prompt": null}
{"id": "fd289886-5097-4b85-a40e-6f25a531c74b", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = max(10, int(self.budget / 100))\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Dynamic coefficients\n                cognitive_coeff = 1.5 + 0.5 * np.sin(evaluations/100)\n                social_coeff = 1.5 + 0.5 * np.cos(evaluations/100)\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)**2\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "AdaptiveSwarmOptimizer refines exploration by introducing dynamic particle count adjustment based on convergence trends.", "configspace": "", "generation": 4, "fitness": 0.2764055291328672, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "39bdb0cd-7e33-4862-83a9-d855492fef40", "metadata": {"aucs": [0.27680178153603363, 0.27621534056937624, 0.2761994652931917]}, "mutation_prompt": null}
{"id": "f1d01b9d-d882-4c58-9698-f23b0c294273", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 20 + (10 * (self.budget // 1000))\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Dynamic coefficients\n                cognitive_coeff = 1.5 + 0.5 * np.sin(evaluations/100)\n                social_coeff = 1.5 + 0.5 * np.cos(evaluations/100)\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)**2\n                # Adjust social-cognitive ratio\n                if evaluations > self.budget * 0.5:\n                    cognitive_coeff, social_coeff = 2.0, 1.0\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced convergence by dynamically adjusting the particle count and employing a nonlinear dynamic social-cognitive coefficient ratio.", "configspace": "", "generation": 5, "fitness": 0.2764086918016368, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "39bdb0cd-7e33-4862-83a9-d855492fef40", "metadata": {"aucs": [0.2763130345527819, 0.276314590831772, 0.27659845002035655]}, "mutation_prompt": null}
{"id": "a04c1ae2-ac7b-468c-b289-2b9fa73a9eee", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30  # Initial number of particles\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n        \n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            if evaluations % 100 == 0:  # Adjust the number of particles periodically\n                n_particles = min(n_particles + 1, 50)\n                new_particles = np.random.uniform(lb, ub, (1, self.dim))\n                particles = np.vstack((particles, new_particles))\n                velocities = np.vstack((velocities, np.random.uniform(-1, 1, (1, self.dim))))\n                pbest_positions = np.vstack((pbest_positions, new_particles))\n                pbest_scores = np.append(pbest_scores, func(new_particles[0]))\n                evaluations += 1\n            \n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_coeff = 1.5 + 0.5 * np.sin(evaluations/100)\n                social_coeff = 1.5 + 0.5 * np.cos(evaluations/100)\n                inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)**2\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced exploration by dynamically adjusting the number of particles and incorporating LÃ©vy flight for escaping local optima.", "configspace": "", "generation": 6, "fitness": 0.27750815011322416, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "39bdb0cd-7e33-4862-83a9-d855492fef40", "metadata": {"aucs": [0.2774378361933205, 0.27748764345654886, 0.2775989706898031]}, "mutation_prompt": null}
{"id": "32015125-ea74-42c4-a6e7-48d1c2be45ca", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)**2\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced AdaptiveSwarmOptimizer by incorporating adaptive learning coefficients based on particle performance to improve exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.2777689000154232, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "39bdb0cd-7e33-4862-83a9-d855492fef40", "metadata": {"aucs": [0.27778357587178937, 0.2776399435759822, 0.27788318059849804]}, "mutation_prompt": null}
{"id": "7c2083e4-5309-4b16-ad72-848411053864", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        prev_gbest_score = gbest_score\n        \n        while evaluations < self.budget:\n            # Adjust number of particles based on convergence\n            if evaluations % 50 == 0 and evaluations > n_particles:\n                if np.abs(prev_gbest_score - gbest_score) < 1e-5:\n                    n_particles = min(n_particles + 5, 50)  # Dynamically increase particles\n                else:\n                    n_particles = max(n_particles - 5, 10)  # Reduce particles if converging\n                prev_gbest_score = gbest_score\n\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)**2\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a dynamic particle number adjustment strategy based on convergence speed to enhance exploration and exploitation in AdaptiveSwarmOptimizer.", "configspace": "", "generation": 8, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 30 is out of bounds for axis 0 with size 30').", "error": "IndexError('index 30 is out of bounds for axis 0 with size 30')", "parent_id": "32015125-ea74-42c4-a6e7-48d1c2be45ca", "metadata": {}, "mutation_prompt": null}
{"id": "c5ff3ee1-f867-43b7-a95b-c7c556fc44f8", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            if evaluations % 50 == 0:  # Dynamic adjustment of particles\n                n_particles = 20 + int(10 * (1 - (evaluations / self.budget)**0.5))\n\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)**2\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Incorporate a dynamic particle count strategy to enhance exploration and exploitation, adjusting the number of particles based on current performance to improve global and local search capabilities.", "configspace": "", "generation": 9, "fitness": 0.27768010473626276, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "32015125-ea74-42c4-a6e7-48d1c2be45ca", "metadata": {"aucs": [0.2777296024919239, 0.27766990845180284, 0.2776408032650616]}, "mutation_prompt": null}
{"id": "75cb873c-0eec-4420-9545-fe4c3fa4e68a", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        # Dynamic particle count adjustment\n        n_particles = max(15, min(50, self.dim * 2))\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-0.5, 0.5, (n_particles, self.dim))  # Improved velocity range\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)**2\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced AdaptiveSwarmOptimizer by introducing dynamic particle count adjustment and improved velocity handling for diverse exploration.", "configspace": "", "generation": 10, "fitness": 0.2777672419837372, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "32015125-ea74-42c4-a6e7-48d1c2be45ca", "metadata": {"aucs": [0.2777775099653904, 0.27792047854357127, 0.27760373744224986]}, "mutation_prompt": null}
{"id": "2b328157-d972-41b4-96a8-391bc90877d2", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n\n        evaluations = n_particles\n\n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)**2\n                # Update velocity using neighborhood-based exploration\n                neighbors = np.random.choice(n_particles, 3, replace=False)\n                local_best = np.min([pbest_scores[n] for n in neighbors])\n                if local_best < pbest_scores[i]:\n                    velocities[i] = (0.5 * velocities[i] +\n                                     0.5 * r1 * (pbest_positions[np.argmin([pbest_scores[n] for n in neighbors])] - particles[i]))\n                else:\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                     social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n\n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Improved AdaptiveSwarmOptimizer by integrating a dynamic neighborhood-based exploration mechanism to enhance convergence. ", "configspace": "", "generation": 11, "fitness": 0.2770389347877645, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "32015125-ea74-42c4-a6e7-48d1c2be45ca", "metadata": {"aucs": [0.2757768439283864, 0.27758682285355196, 0.2777531375813551]}, "mutation_prompt": null}
{"id": "4c051918-cdbe-4a35-9319-8514fd462083", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = min(30, int(np.sqrt(self.dim) * 10))  # Dynamic particle count\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * (evaluations / self.budget)**2\n                # Update velocity\n                local_best_position = pbest_positions[np.random.choice(n_particles)]  # Neighborhood influence\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (0.5 * (gbest_position + local_best_position) - particles[i]))  # Combined influence\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Incorporate neighborhood best particle influence and dynamic particle count to improve convergence and diversity.", "configspace": "", "generation": 12, "fitness": 0.27765972606436945, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "32015125-ea74-42c4-a6e7-48d1c2be45ca", "metadata": {"aucs": [0.27775505608236084, 0.27749355719517976, 0.2777305649155677]}, "mutation_prompt": null}
{"id": "597e887d-21ef-46b9-8877-8f654259710f", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce nonlinear dynamic inertia and velocity adaptation to improve convergence speed and solution quality.", "configspace": "", "generation": 13, "fitness": 0.27787700795118403, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "32015125-ea74-42c4-a6e7-48d1c2be45ca", "metadata": {"aucs": [0.2778764968901334, 0.2778292099095263, 0.27792531705389234]}, "mutation_prompt": null}
{"id": "9d779122-8b41-4970-98f8-892f9980724e", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            # Adaptive population size\n            n_particles = max(10, int(30 - 20 * (evaluations / self.budget)))\n            particles = particles[:n_particles]\n            velocities = velocities[:n_particles]\n            pbest_positions = pbest_positions[:n_particles]\n            pbest_scores = pbest_scores[:n_particles]\n\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive population size to balance exploration and exploitation dynamically.", "configspace": "", "generation": 14, "fitness": 0.27768901381517186, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "597e887d-21ef-46b9-8877-8f654259710f", "metadata": {"aucs": [0.27783922905937963, 0.27782079754442424, 0.2774070148417117]}, "mutation_prompt": null}
{"id": "8427fa66-0981-4c87-a275-f4b0c6e9eae9", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            diversity_factor = np.std(pbest_scores) / np.mean(pbest_scores)\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Update velocity with quadratic deflection\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 diversity_factor * np.square(velocities[i]))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce quadratic trajectory deflection and adaptive particle diversity control to enhance exploration and exploitation balance.", "configspace": "", "generation": 15, "fitness": 0.2474029163503562, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.00.", "error": "", "parent_id": "597e887d-21ef-46b9-8877-8f654259710f", "metadata": {"aucs": [0.24661556803048357, 0.24792526077726218, 0.24766792024332285]}, "mutation_prompt": null}
{"id": "7f2dce60-9ab3-43bb-ae8d-d1db876bcfba", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            # Calculate diversity as standard deviation of particles\n            diversity = np.std(particles, axis=0).mean()\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight based on diversity\n                inertia_weight = 0.7 + 0.2 * np.tanh(diversity)\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a selective inertia adjustment strategy based on particle diversity to enhance exploration and exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.27759419411512054, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "597e887d-21ef-46b9-8877-8f654259710f", "metadata": {"aucs": [0.2776673857366001, 0.27728811570851764, 0.2778270809002439]}, "mutation_prompt": null}
{"id": "9101a6b0-adbf-4c3e-b4db-c0e2ff03416e", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                \n                # Update inertia weight using a chaotic map\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                \n                # Update velocity with a simple chaotic map\n                chaotic_factor = np.sin(3.8 * r1)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * chaotic_factor * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance the exploration-exploitation balance by dynamically adjusting the swarm size and implementing chaotic maps in velocity updates.", "configspace": "", "generation": 17, "fitness": 0.2774976126385721, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "597e887d-21ef-46b9-8877-8f654259710f", "metadata": {"aucs": [0.277563819347312, 0.27759047702215, 0.27733854154625426]}, "mutation_prompt": null}
{"id": "b94382ed-a14d-4f9c-bb76-df33ec458d04", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n\n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n                        # Local search around the global best\n                        perturbation = np.random.normal(0, (ub-lb) * 0.02, self.dim)\n                        candidate = np.clip(gbest_position + perturbation, lb, ub)\n                        candidate_score = func(candidate)\n                        evaluations += 1\n                        if candidate_score < gbest_score:\n                            gbest_position = candidate\n                            gbest_score = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance convergence by introducing a local search phase for elitist particles.", "configspace": "", "generation": 18, "fitness": 0.2778402674026558, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "597e887d-21ef-46b9-8877-8f654259710f", "metadata": {"aucs": [0.27783130635153963, 0.2778494979763201, 0.2778399978801078]}, "mutation_prompt": null}
{"id": "b31bfc19-5c3f-47f1-85e8-235d286bce65", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n            \n            # Random re-initialization step\n            if evaluations % (self.budget // 10) == 0:\n                particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance global exploration by introducing a random re-initialization step for particle positions.", "configspace": "", "generation": 19, "fitness": 0.2778770079257293, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "597e887d-21ef-46b9-8877-8f654259710f", "metadata": {"aucs": [0.27787649686930227, 0.27782920985509685, 0.27792531705278867]}, "mutation_prompt": null}
{"id": "4188f5b3-0628-4307-a42e-1b2a770af8fe", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - (gbest_score / np.max(pbest_scores))  # Changed line\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance convergence by dynamically adjusting social coefficient based on current best score.", "configspace": "", "generation": 20, "fitness": 0.27775328823614037, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "597e887d-21ef-46b9-8877-8f654259710f", "metadata": {"aucs": [0.27773569521627417, 0.2778682718302463, 0.2776558976619006]}, "mutation_prompt": null}
{"id": "e8fb73d3-66d0-4179-a0e6-34ee10c849df", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            fitness_variance = np.var(pbest_scores)\n            neighborhood_size = max(1, int(n_particles * 0.1 + fitness_variance * 10))  # Change 1\n            local_bests = np.zeros((n_particles, self.dim))\n\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on fitness variance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.5 - (pbest_scores[i] / gbest_score))  # Change 2\n                else:\n                    cognitive_coeff = 1.5 + 0.2 * np.log1p(fitness_variance)  # Change 3\n                social_coeff = 2.5 - cognitive_coeff  # Change 4\n\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance the swarm's exploration by introducing a dynamic neighborhood and adaptive learning factors based on fitness variance.", "configspace": "", "generation": 21, "fitness": 0.27770479849924967, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "597e887d-21ef-46b9-8877-8f654259710f", "metadata": {"aucs": [0.27784951150817216, 0.2777838819172619, 0.27748100207231496]}, "mutation_prompt": null}
{"id": "a96be2cb-179f-4f30-97a0-707a9139ec78", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * (1 - evaluations/self.budget) * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * (evaluations/self.budget) * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance convergence by incorporating dynamic learning rates based on progress towards the global best.", "configspace": "", "generation": 22, "fitness": 0.27169919583508306, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "597e887d-21ef-46b9-8877-8f654259710f", "metadata": {"aucs": [0.27270988584043254, 0.27212529253624684, 0.2702624091285698]}, "mutation_prompt": null}
{"id": "52d303db-26f5-405c-92b6-1bf4737fda28", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        stagnation_counter = 0\n        stagnation_threshold = 100\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n                        stagnation_counter = 0\n                else:\n                    stagnation_counter += 1  # Increment stagnation counter\n\n                if evaluations >= self.budget:\n                    break\n                \n            # Adaptive random restart mechanism\n            if stagnation_counter > stagnation_threshold:\n                gbest_position = np.random.uniform(lb, ub, self.dim)\n                stagnation_counter = 0  # Reset stagnation counter\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance convergence by introducing a diversity-driven escape mechanism and adaptive random restart when stagnation is detected.", "configspace": "", "generation": 23, "fitness": 0.27693609537041547, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "597e887d-21ef-46b9-8877-8f654259710f", "metadata": {"aucs": [0.27719740102559776, 0.27603330692088024, 0.27757757816476847]}, "mutation_prompt": null}
{"id": "32b92d4e-efc8-4597-bf2d-3395c7f60a52", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.2, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.4\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight\n                inertia_weight = 0.8 - 0.6 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Update velocity\n                if np.random.rand() < 0.5:\n                    velocities[i] = (inertia_weight * velocities[i] +\n                                     cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                     social_coeff * r2 * (gbest_position - particles[i]))\n                else:\n                    velocities[i] = inertia_weight * velocities[i] + 0.5 * np.random.rand(self.dim)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a multi-modal search strategy with dynamic swarm behavior to improve global exploration and solution robustness.", "configspace": "", "generation": 24, "fitness": 0.27769418707701415, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "597e887d-21ef-46b9-8877-8f654259710f", "metadata": {"aucs": [0.27771052402564356, 0.2776321061817606, 0.27773993102363836]}, "mutation_prompt": null}
{"id": "42e7a74f-4659-4961-aa34-62ccad2eb509", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                \n                # Adaptive coefficients based on performance\n                cognitive_coeff = max(1.0, 2.5 - (pbest_scores[i] / (gbest_score + 1e-9)))\n                social_coeff = 2.5 - cognitive_coeff\n                \n                # Update inertia weight with sinusoidal adaptation\n                inertia_weight = 0.7 + 0.3 * np.cos((evaluations / self.budget) * np.pi)\n                \n                # Neighborhood-based cooperation\n                neighbors = np.random.choice(n_particles, 5, replace=False)\n                neighbor_best = pbest_positions[neighbors[np.argmin(pbest_scores[neighbors])]]\n                \n                # Update velocity with neighbor influence\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (neighbor_best - particles[i]))\n                \n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                \n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance dynamic adaptation by incorporating a convergence-based perturbation strategy and a neighborhood-based cooperation mechanism for improved exploration and exploitation balance.", "configspace": "", "generation": 25, "fitness": 0.27762857829464743, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "597e887d-21ef-46b9-8877-8f654259710f", "metadata": {"aucs": [0.2775477435579077, 0.2777415240892873, 0.27759646723674736]}, "mutation_prompt": null}
{"id": "97b0f788-2904-4662-b99a-d39e924598bc", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization using chaotic maps\n        particles = lb + (ub - lb) * np.tan(np.random.uniform(-np.pi/2, np.pi/2, (n_particles, self.dim)))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            for i in range(n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight with enhanced adjustment\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2) + 0.1 * np.sin(evaluations)\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce chaotic maps for particle initialization and adaptive inertia adjustment to enhance exploration and exploitation balance.", "configspace": "", "generation": 26, "fitness": 0.24689618860484808, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.01.", "error": "", "parent_id": "597e887d-21ef-46b9-8877-8f654259710f", "metadata": {"aucs": [0.24220062325641112, 0.24083436630843535, 0.25765357624969776]}, "mutation_prompt": null}
{"id": "5d1eea7a-a4fe-4541-b164-d9b6a649e523", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            # Dynamically adjust the number of particles based on evaluations\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a dynamic swarm size that adapts based on current evaluations to maintain exploration and exploitation balance.", "configspace": "", "generation": 27, "fitness": 0.2778782143227892, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "597e887d-21ef-46b9-8877-8f654259710f", "metadata": {"aucs": [0.27788043813460617, 0.27783161265280265, 0.2779225921809588]}, "mutation_prompt": null}
{"id": "99ef5ffe-5e29-4e68-8508-d6175abe87e2", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            # Dynamically adjust the number of particles based on evaluations\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight based on velocity magnitude\n                inertia_weight = 0.9 - 0.5 * np.linalg.norm(velocities[i]) / np.linalg.norm(ub-lb)\n                # Update velocity with a random walk component\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.uniform(-1, 1, self.dim))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Improve exploration by introducing a random walk component and adaptive inertia weight based on velocity magnitude.", "configspace": "", "generation": 28, "fitness": 0.277738455224783, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "5d1eea7a-a4fe-4541-b164-d9b6a649e523", "metadata": {"aucs": [0.27773362758285236, 0.27758381747930794, 0.27789792061218876]}, "mutation_prompt": null}
{"id": "8e3e5fd3-bdad-4a19-ae96-44be50c78de1", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            # Dynamically adjust the number of particles based on evaluations\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * np.cos((evaluations / self.budget) * np.pi / 2)  # Changed to cosine for non-linear decay\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a non-linear inertia weight decay for improved convergence speed.", "configspace": "", "generation": 29, "fitness": 0.2759551595063478, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "5d1eea7a-a4fe-4541-b164-d9b6a649e523", "metadata": {"aucs": [0.2759653839106688, 0.2764908595140152, 0.27540923509435944]}, "mutation_prompt": null}
{"id": "de7106e3-c0f6-4e22-8b9d-038cc1e1c2aa", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            # Dynamically adjust the number of particles based on evaluations\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                \n                # Update velocity with adaptive scaling\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i])) * (1 + np.random.uniform(-0.1, 0.1))\n                \n                # Stochastic velocity clamping with enhanced diversity\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.2, abs(ub-lb) * 0.2)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive velocity scaling and enhanced diversity preservation to optimize the exploration-exploitation trade-off.", "configspace": "", "generation": 30, "fitness": 0.27764505481122176, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "5d1eea7a-a4fe-4541-b164-d9b6a649e523", "metadata": {"aucs": [0.27798049961727245, 0.2773807117886359, 0.2775739530277569]}, "mutation_prompt": null}
{"id": "5c725753-3cf0-4d98-833e-504f8bdcb48f", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            # Dynamically adjust the number of particles based on evaluations\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                # Mutation for enhanced diversity\n                if np.random.rand() < 0.1: \n                    particles[i] += np.random.normal(0, 0.1, self.dim)\n\n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced swarm diversity by introducing mutation to improve exploration.", "configspace": "", "generation": 31, "fitness": 0.27775787172565064, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "5d1eea7a-a4fe-4541-b164-d9b6a649e523", "metadata": {"aucs": [0.27769359931427084, 0.2778716304567086, 0.27770838540597254]}, "mutation_prompt": null}
{"id": "74a4c78a-57ab-4632-a732-a7e8ba3e85eb", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            # Dynamically adjust the number of particles based on evaluations\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score) + 0.1 * np.cos(evaluations))  # changed line\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance exploitation by introducing a nonlinear component to adaptively update the cognitive coefficient.", "configspace": "", "generation": 32, "fitness": 0.2778782143227892, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "5d1eea7a-a4fe-4541-b164-d9b6a649e523", "metadata": {"aucs": [0.27788043813460617, 0.27783161265280265, 0.2779225921809588]}, "mutation_prompt": null}
{"id": "085969fd-dbfb-4330-8aab-e0829e914db4", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            # Dynamically adjust the number of particles based on evaluations\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n\n                # Update inertia weight with cosine annealing\n                inertia_weight = 0.4 + 0.5 * (1 + np.cos((evaluations / self.budget) * np.pi))\n\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Implement an adaptive inertia weight strategy using a cosine annealing schedule to enhance exploration-exploitation trade-off.", "configspace": "", "generation": 33, "fitness": 0.2745749897735049, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "5d1eea7a-a4fe-4541-b164-d9b6a649e523", "metadata": {"aucs": [0.2728450828443707, 0.27547138352810197, 0.2754085029480421]}, "mutation_prompt": null}
{"id": "ac4e07bc-8b15-4c03-8f7b-bba18eebabcf", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n        temperature = 1.0  # Added line for temperature initialization\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            # Dynamically adjust the number of particles based on evaluations\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight with cooling schedule\n                inertia_weight = 0.9 - (0.5 * (1 - np.exp(-0.05 * evaluations)))  # Modified line\n                # Update velocity\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a temperature-based cooling schedule for inertia weight to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 34, "fitness": 0.27545465911511285, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "5d1eea7a-a4fe-4541-b164-d9b6a649e523", "metadata": {"aucs": [0.27552091957594227, 0.27608240149713303, 0.2747606562722633]}, "mutation_prompt": null}
{"id": "26b73cdf-0d1a-4d48-a45f-1a1363540900", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            # Dynamically adjust the number of particles based on evaluations\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Nonlinear acceleration\n                velocities[i] *= (1.0 + np.tanh((gbest_score - pbest_scores[i]) / gbest_score))\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a nonlinear acceleration mechanism for particles to enhance convergence speed without compromising exploration.", "configspace": "", "generation": 35, "fitness": 0.27787877640073694, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "5d1eea7a-a4fe-4541-b164-d9b6a649e523", "metadata": {"aucs": [0.2779172832805714, 0.2778690624771508, 0.2778499834444885]}, "mutation_prompt": null}
{"id": "abb97ece-0604-436d-92e2-0f1251ae45eb", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            decay_factor = (self.budget - evaluations) / self.budget  # Line changed\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                velocities[i] *= (1.0 + np.tanh((gbest_score - pbest_scores[i]) / gbest_score))\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], -decay_factor * abs(ub-lb) * 0.1, decay_factor * abs(ub-lb) * 0.1)  # Line changed\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a decay factor for velocity clamping to enhance exploration exploitation balance over time.", "configspace": "", "generation": 36, "fitness": 0.27784233064184555, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "26b73cdf-0d1a-4d48-a45f-1a1363540900", "metadata": {"aucs": [0.2778850134582581, 0.2778419283736252, 0.2778000500936533]}, "mutation_prompt": null}
{"id": "292ebe51-de2d-4c5e-9812-b6a406b76114", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Nonlinear acceleration and neighbor effect\n                neighbor_effect = np.mean(pbest_scores) / (gbest_score + 1e-9)\n                velocities[i] *= (1.0 + np.tanh(neighbor_effect))\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance swarm diversity dynamically by adjusting particle velocities based on neighborhood performance to improve global exploration.", "configspace": "", "generation": 37, "fitness": 0.2741502816269838, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "26b73cdf-0d1a-4d48-a45f-1a1363540900", "metadata": {"aucs": [0.2734684649447773, 0.27457787796860456, 0.2744045019675696]}, "mutation_prompt": null}
{"id": "c33ed798-e190-437f-9c77-60164614fc91", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            # Dynamically adjust the number of particles based on evaluations\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Nonlinear acceleration\n                velocities[i] *= (1.0 + np.tanh((gbest_score - pbest_scores[i]) / gbest_score))\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Introduce diversity mechanism\n                if np.random.rand() < 0.1: \n                    velocities[i] += 0.5 * (np.random.uniform(lb, ub, self.dim) - particles[i])\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a particle diversity mechanism to maintain exploration during optimization.", "configspace": "", "generation": 38, "fitness": 0.27754909707944014, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "26b73cdf-0d1a-4d48-a45f-1a1363540900", "metadata": {"aucs": [0.2773531132381529, 0.27779973154343984, 0.2774944464567276]}, "mutation_prompt": null}
{"id": "fb7531b1-5259-4d9d-b0e4-3b17c2f6bdac", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            # Dynamically adjust the number of particles based on evaluations\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                # Adaptive coefficients based on performance\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Nonlinear acceleration with adaptive factor\n                diversity = np.mean(np.std(particles, axis=0))\n                velocities[i] *= (1.0 + np.tanh((gbest_score - pbest_scores[i]) / gbest_score) + diversity * 0.01)\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce an adaptive learning factor based on swarm diversity to enhance exploration and convergence.", "configspace": "", "generation": 39, "fitness": 0.27758523056375034, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "26b73cdf-0d1a-4d48-a45f-1a1363540900", "metadata": {"aucs": [0.2775388674879973, 0.27758043070732696, 0.2776363934959267]}, "mutation_prompt": null}
{"id": "77fa624d-0fc7-4c3a-bc3d-b25a03f8d373", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            # Dynamically adjust the number of particles based on evaluations\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            diversity = np.mean(np.std(particles, axis=0))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                cognitive_coeff = 1.5 + 0.5 * (diversity / (np.std(pbest_scores) + 1e-9))\n                social_coeff = 2.0 - cognitive_coeff\n                # Update inertia weight\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Nonlinear acceleration\n                velocities[i] *= (1.0 + np.tanh((gbest_score - pbest_scores[i]) / gbest_score))\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                # Stochastic velocity clamping\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                # Update position\n                particles[i] += velocities[i]\n                # Enforce bounds\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance swarm adaptability by introducing dynamic social and cognitive coefficients based on particle diversity.", "configspace": "", "generation": 40, "fitness": 0.25061843293434105, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.01.", "error": "", "parent_id": "26b73cdf-0d1a-4d48-a45f-1a1363540900", "metadata": {"aucs": [0.26092325946691486, 0.2414228615610432, 0.2495091777750651]}, "mutation_prompt": null}
{"id": "e5ac0dcf-63ed-4153-bd76-73fa61fabeb9", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive particle initialization and hybrid velocity update rules to improve exploration-exploitation balance.", "configspace": "", "generation": 41, "fitness": 0.2779048212717082, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "26b73cdf-0d1a-4d48-a45f-1a1363540900", "metadata": {"aucs": [0.2779005031729903, 0.27796916684284, 0.2778447937992943]}, "mutation_prompt": null}
{"id": "08db96eb-4ddc-4318-83e7-ac31e9c51faf", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff\n                improvement_rate = (gbest_score - pbest_scores[i]) / max(1e-10, abs(gbest_score))\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2) * improvement_rate\n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance exploration by dynamically adjusting inertia and cognitive factors based on fitness improvement rates.", "configspace": "", "generation": 42, "fitness": 0.2776322619691575, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e5ac0dcf-63ed-4153-bd76-73fa61fabeb9", "metadata": {"aucs": [0.27736136786185517, 0.2777932892566205, 0.27774212878899684]}, "mutation_prompt": null}
{"id": "b126d1a9-b731-4732-96e2-e34abdb5535c", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                social_coeff = 2.0 - cognitive_coeff * (np.std(pbest_scores) / (np.abs(gbest_score) + 1e-9))\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2)\n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance convergence by introducing dynamic social coefficient adjustment based on performance variability.", "configspace": "", "generation": 43, "fitness": 0.2778218643357159, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e5ac0dcf-63ed-4153-bd76-73fa61fabeb9", "metadata": {"aucs": [0.2778125556229888, 0.27785799061527783, 0.277795046768881]}, "mutation_prompt": null}
{"id": "ad25baf7-0860-4037-b346-772954eb533f", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with damping\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2) * (1 - i / n_particles)\n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Refine adaptive strategy by introducing a dynamic social coefficient and adaptive particle damping for improved convergence.", "configspace": "", "generation": 44, "fitness": 0.2779751869506852, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e5ac0dcf-63ed-4153-bd76-73fa61fabeb9", "metadata": {"aucs": [0.2779993484030636, 0.2779990734906357, 0.2779271389583563]}, "mutation_prompt": null}
{"id": "53336441-daa4-495e-b20e-f5240d1e0ef7", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        elite_particle = gbest_position  # Added elite particle memory\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with damping\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2) * (1 - i / n_particles)\n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                # Adaptive boundary scaling\n                if evaluations % 10 == 0:\n                    lb, ub = lb * 0.99, ub * 1.01\n\n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n                        elite_particle = gbest_position  # Update elite particle\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce elite particle memory and adaptive boundary scaling to enhance convergence reliability.", "configspace": "", "generation": 45, "fitness": 0.2776280265164324, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "ad25baf7-0860-4037-b346-772954eb533f", "metadata": {"aucs": [0.27732597965126227, 0.27772164569140956, 0.2778364542066254]}, "mutation_prompt": null}
{"id": "1d6b966a-3d74-44d4-b17d-4f64013f9613", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with exponential decay\n                inertia_weight = 0.9 * np.exp(-0.5 * evaluations / self.budget) # changed line 1\n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] + # changed line 2\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance the inertia weight adaptation by introducing an exponential decay factor for refined convergence speed.", "configspace": "", "generation": 46, "fitness": 0.2779575690711626, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "ad25baf7-0860-4037-b346-772954eb533f", "metadata": {"aucs": [0.2779994401131729, 0.2779688688862879, 0.2779043982140269]}, "mutation_prompt": null}
{"id": "2a4638a1-9deb-470d-ad4c-b814ed5661bd", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Adjusted social coefficient based on particle index and global best factor\n                social_coeff = 2.0 - cognitive_coeff + 0.7 * (i / n_particles) * (gbest_score / np.mean(pbest_scores))\n                \n                # Non-linear inertia damping\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) ** 1.5 * np.pi / 2) * (1 - i / n_particles)\n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance convergence by introducing non-linear inertia damping and an adaptive particle influence factor.", "configspace": "", "generation": 47, "fitness": 0.27783757952643545, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "ad25baf7-0860-4037-b346-772954eb533f", "metadata": {"aucs": [0.27784389665166553, 0.2778190840998602, 0.27784975782778065]}, "mutation_prompt": null}
{"id": "c5120734-fe77-48f3-bf92-3d9d877ab7c7", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with damping\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2) * (1 - i / n_particles)\n                \n                # Hybrid velocity update with modified random perturbation\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.05 * np.random.normal(0, 1, self.dim))  # Changed from 0.1 to 0.05\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduced diversity control by adjusting the random perturbation impact in velocity updates to enhance exploration.", "configspace": "", "generation": 48, "fitness": 0.2779119284560545, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "ad25baf7-0860-4037-b346-772954eb533f", "metadata": {"aucs": [0.2778736909600432, 0.27798593780004643, 0.27787615660807385]}, "mutation_prompt": null}
{"id": "7331844d-0454-4e83-933b-9956d8acea6d", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Increased dynamic social coefficient impact\n                social_coeff = 2.5 - cognitive_coeff + 0.7 * (i / n_particles)\n                \n                # Random inertia adjustment\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2) * ((1 - i / n_particles) + np.random.uniform(-0.1, 0.1))\n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance adaptive strategy by introducing a random inertia adjustment and increasing dynamic social coefficient impact for enhanced exploration and convergence.", "configspace": "", "generation": 49, "fitness": 0.27791287700740114, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "ad25baf7-0860-4037-b346-772954eb533f", "metadata": {"aucs": [0.27801107047940354, 0.2778262120621564, 0.2779013484806435]}, "mutation_prompt": null}
{"id": "d13c82f3-c2bd-4dc4-badf-3110372519a7", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with damping\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2) * (1 - i / n_particles)\n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                \n                # Random restart mechanism\n                if np.random.rand() < 0.005:\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n                    current_score = func(particles[i])\n                    evaluations += 1\n\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a random restart mechanism to diversify search when stuck in local optima.", "configspace": "", "generation": 50, "fitness": 0.27790441793587034, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "ad25baf7-0860-4037-b346-772954eb533f", "metadata": {"aucs": [0.27784588577773306, 0.27794926888046934, 0.2779180991494087]}, "mutation_prompt": null}
{"id": "79599b2f-66c1-44e2-b175-0a7212cf01f7", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n        temp_initial = 1.0  # Initial temperature for annealing\n        temp_final = 0.1    # Final temperature\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            temp = temp_final + (temp_initial - temp_final) * (1 - evaluations / self.budget)\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles) * temp\n                \n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2) * (1 - i / n_particles)\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a simulated annealing-inspired temperature coefficient to influence social attraction, enhancing exploration and convergence.", "configspace": "", "generation": 51, "fitness": 0.27795875126660285, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "ad25baf7-0860-4037-b346-772954eb533f", "metadata": {"aucs": [0.2779900460974636, 0.27799016330528703, 0.27789604439705795]}, "mutation_prompt": null}
{"id": "c9b7b267-8a9e-497e-897f-f26f11902c88", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with damping\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2) * (1 - i / n_particles)\n                \n                # Hybrid velocity update with adaptive learning rate\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * np.random.uniform(0.8, 1.2))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce an adaptive learning rate and dynamic neighborhood search to enhance local and global exploration.", "configspace": "", "generation": 52, "fitness": 0.2779226509735254, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "ad25baf7-0860-4037-b346-772954eb533f", "metadata": {"aucs": [0.2779397386441016, 0.277941025196484, 0.27788718907999066]}, "mutation_prompt": null}
{"id": "9d658a9a-bb4e-4e4d-b128-3c6982e11b94", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2) * (1 - i / n_particles)\n                \n                # Hybrid velocity update with nonlinear scaling\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                \n                velocity_scale_factor = np.tanh(evaluations/self.budget)  # Nonlinear scaling based on evaluations\n                velocities[i] *= velocity_scale_factor\n                \n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                # Re-evaluate particles periodically\n                if evaluations % (self.budget // 10) == 0:\n                    current_score = pbest_scores[i]  # Skip re-evaluation\n                else:\n                    current_score = func(particles[i])\n                \n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance exploration-exploitation balance by introducing nonlinear velocity scaling and adaptive particle re-evaluation.", "configspace": "", "generation": 53, "fitness": 0.2730705440997216, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "ad25baf7-0860-4037-b346-772954eb533f", "metadata": {"aucs": [0.2726147996027809, 0.27475115048283394, 0.2718456822135499]}, "mutation_prompt": null}
{"id": "b5f03c15-14e0-4103-8285-81c457665eab", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with damping\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2) * (1 - i / n_particles)\n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                # Local search enhancement\n                if evaluations < self.budget and np.random.rand() < 0.1: \n                    perturbation = 0.01 * np.random.normal(0, 1, self.dim)\n                    candidate_position = gbest_position + perturbation\n                    candidate_position = np.clip(candidate_position, lb, ub)\n                    candidate_score = func(candidate_position)\n                    evaluations += 1\n                    if candidate_score < gbest_score:\n                        gbest_position = candidate_position\n                        gbest_score = candidate_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce local search enhancement with random perturbation to explore the immediate vicinity of the best-known position.", "configspace": "", "generation": 54, "fitness": 0.2779461223554654, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "ad25baf7-0860-4037-b346-772954eb533f", "metadata": {"aucs": [0.27802543672785174, 0.2779318871516332, 0.2778810431869113]}, "mutation_prompt": null}
{"id": "85d97bb3-8aa1-4f0a-8d2b-af9c5eae8fa9", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    # Changed cognitive coefficient to use a nonlinear function\n                    cognitive_coeff = max(1.0, 2.0 - np.tanh(pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with damping\n                inertia_weight = 0.9 - 0.5 * np.sin((evaluations / self.budget) * np.pi / 2) * (1 - i / n_particles)\n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a nonlinear dynamic cognitive coefficient for enhanced adaptability during the optimization process.", "configspace": "", "generation": 55, "fitness": 0.2779751869506852, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "ad25baf7-0860-4037-b346-772954eb533f", "metadata": {"aucs": [0.2779993484030636, 0.2779990734906357, 0.2779271389583563]}, "mutation_prompt": null}
{"id": "be628258-eb98-47a9-82b7-f6391791899e", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with a cosine schedule\n                inertia_weight = 0.9 - 0.4 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2  \n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a dynamic inertia weight strategy using cosine schedule to enhance exploration and exploitation balance.", "configspace": "", "generation": 56, "fitness": 0.27809056165634, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "ad25baf7-0860-4037-b346-772954eb533f", "metadata": {"aucs": [0.27811752265040346, 0.27805450588886405, 0.27809965642975243]}, "mutation_prompt": null}
{"id": "4a7a114f-3fca-4922-a3b9-7cc5521706d0", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 - 0.4 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2  \n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                velocities[i] = np.clip(velocities[i], -abs(gbest_position - particles[i]) * 0.1, abs(gbest_position - particles[i]) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive velocity clamping based on current global best position to refine balance between exploration and exploitation.", "configspace": "", "generation": 57, "fitness": 0.2741071228472866, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "be628258-eb98-47a9-82b7-f6391791899e", "metadata": {"aucs": [0.27243213384680864, 0.2764154669407428, 0.27347376775430843]}, "mutation_prompt": null}
{"id": "dc6044b5-c13b-4063-801c-ed76bbc9d7e0", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with a cosine schedule\n                inertia_weight = 0.9 - 0.4 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2  \n                \n                # Hybrid velocity update with adaptive mutation\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                mutation = np.random.normal(0, (1 - evaluations / self.budget) * 0.1, self.dim)  # Adaptive mutation\n                particles[i] += velocities[i] + mutation\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive mutation to enhance diversity and avoid local optima.", "configspace": "", "generation": 58, "fitness": 0.27808548098745167, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "be628258-eb98-47a9-82b7-f6391791899e", "metadata": {"aucs": [0.2781640748288402, 0.27810978775598094, 0.27798258037753387]}, "mutation_prompt": null}
{"id": "e16a4643-9f4c-403b-b008-5bfff16294c9", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Refined initialization to be more centered\n        particles = np.random.uniform(lb + 0.2 * (ub - lb), ub - 0.2 * (ub - lb), (n_particles, self.dim))\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n\n        evaluations = n_particles\n\n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                \n                # Apply decay to cognitive coefficient\n                cognitive_coeff = 1.5 * (1 - evaluations / self.budget) + 0.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 - 0.4 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2  \n\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n\n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance the algorithm by adding a decay factor for the cognitive coefficient and refining initialization toward the center of the search space.", "configspace": "", "generation": 59, "fitness": 0.27782693008343995, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "be628258-eb98-47a9-82b7-f6391791899e", "metadata": {"aucs": [0.2774830626305709, 0.2781456603918644, 0.2778520672278846]}, "mutation_prompt": null}
{"id": "37c89317-aaa0-4d99-8cc9-7a021af2b8bc", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        restart_threshold = 0.05  # New line: restart mechanism threshold\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with a cosine schedule\n                inertia_weight = 0.9 - 0.4 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2  \n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                    # New line: Random restart mechanism\n                    if np.random.rand() < restart_threshold and evaluations + n_particles < self.budget:\n                        particles = np.random.uniform(lb, ub, (n_particles, self.dim))\n                        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n                        pbest_positions = np.copy(particles)\n                        pbest_scores = np.array([func(p) for p in particles])\n                        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n                        gbest_score = np.min(pbest_scores)\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a random restart mechanism to escape local optima and enhance global exploration.", "configspace": "", "generation": 60, "fitness": 0.27297186575505544, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.00.", "error": "", "parent_id": "be628258-eb98-47a9-82b7-f6391791899e", "metadata": {"aucs": [0.27281629712882494, 0.27209136145829793, 0.2740079386780434]}, "mutation_prompt": null}
{"id": "c53dfff6-6437-4dcb-97c6-a635c9004252", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        stagnation_counter = 0\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with a cosine schedule\n                inertia_weight = 0.9 - 0.4 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2  \n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n                        stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if stagnation_counter > 50:  # Restart mechanism\n                    particles[i] = np.random.uniform(lb, ub, self.dim)\n                    stagnation_counter = 0\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance exploration by introducing a particle restart mechanism when stagnation is detected.", "configspace": "", "generation": 61, "fitness": 0.2780904353349005, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "be628258-eb98-47a9-82b7-f6391791899e", "metadata": {"aucs": [0.27811746660483927, 0.27805438355082757, 0.2780994558490347]}, "mutation_prompt": null}
{"id": "e2adecdb-d40a-4399-824e-3c7305ded2df", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with a cosine schedule\n                inertia_weight = 0.9 - 0.4 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2  \n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) + 0.05 * np.sin(evaluations))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced particle velocity update with sinusoidal perturbation for better exploration.", "configspace": "", "generation": 62, "fitness": 0.2780920175147212, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "be628258-eb98-47a9-82b7-f6391791899e", "metadata": {"aucs": [0.2781193168933441, 0.2780552823118392, 0.2781014533389802]}, "mutation_prompt": null}
{"id": "2118b6c5-91c5-4292-86fc-e9f489cf0d7b", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 - 0.4 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2  \n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) + \n                                 0.05 * np.sin(evaluations))\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * (0.05 + 0.05 * (evaluations / self.budget)), abs(ub-lb) * (0.05 + 0.05 * (evaluations / self.budget)))  # Dynamic mutation scaling\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce dynamic mutation scaling based on budget usage to enhance particle diversity in later stages.", "configspace": "", "generation": 63, "fitness": 0.2779987606701905, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e2adecdb-d40a-4399-824e-3c7305ded2df", "metadata": {"aucs": [0.27805844741727037, 0.27796530411351195, 0.2779725304797892]}, "mutation_prompt": null}
{"id": "2a99ac79-0ce7-4d06-bf7d-de6fd47458e4", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with a cosine schedule\n                inertia_weight = 0.9 - 0.4 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2  \n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * np.random.uniform(-1, 1, self.dim))  # Changed line\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.1, abs(ub-lb) * 0.1)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive noise in velocity updates to enhance exploration and convergence.", "configspace": "", "generation": 64, "fitness": 0.27806260263663757, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e2adecdb-d40a-4399-824e-3c7305ded2df", "metadata": {"aucs": [0.2780837554630877, 0.2780966362889322, 0.2780074161578927]}, "mutation_prompt": null}
{"id": "dee2ff0a-6e3e-47a0-95f3-ca9e4a8ca4ff", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with a cosine schedule\n                inertia_weight = 0.9 - 0.4 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2  \n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) + 0.05 * np.sin(evaluations))\n                # Adaptive velocity clipping based on function evaluation proportion\n                velocity_clamp_factor = 0.1 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduced adaptive velocity clipping based on the function evaluation proportion to enhance exploration.", "configspace": "", "generation": 65, "fitness": 0.2780937485942459, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e2adecdb-d40a-4399-824e-3c7305ded2df", "metadata": {"aucs": [0.2781216159872101, 0.2780564927372138, 0.2781031370583138]}, "mutation_prompt": null}
{"id": "2dd80004-e88a-4f3f-b90f-cc7fffafb423", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with a nonlinear decay\n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**2) - 0.4 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2  \n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) + 0.05 * np.sin(evaluations))\n                # Adaptive velocity clipping based on function evaluation proportion\n                velocity_clamp_factor = 0.1 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduced nonlinear inertia weight decay for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 66, "fitness": 0.2780938265561134, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "dee2ff0a-6e3e-47a0-95f3-ca9e4a8ca4ff", "metadata": {"aucs": [0.27812169889410376, 0.27805650730251286, 0.2781032734717237]}, "mutation_prompt": null}
{"id": "93dde9a7-e8b5-4616-bb86-6dc70abade2e", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with a nonlinear decay\n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**2) - 0.4 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + 0.05 * np.sin(evaluations))\n                # Adaptive velocity clipping based on function evaluation proportion\n                velocity_clamp_factor = 0.1 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced inertia weight decay and velocity update with adaptive learning rate for improved exploration.", "configspace": "", "generation": 67, "fitness": 0.27809384015715555, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "2dd80004-e88a-4f3f-b90f-cc7fffafb423", "metadata": {"aucs": [0.2781217028331877, 0.27805666854798505, 0.2781031490902939]}, "mutation_prompt": null}
{"id": "fc3a5428-25df-4fb6-abef-d10c0cd2395f", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(10, n_particles - int((evaluations / self.budget) * n_particles / 3))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with a nonlinear decay\n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**2) - 0.4 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + 0.05 * np.sin(evaluations))\n                # Adaptive velocity clipping based on function evaluation proportion\n                velocity_clamp_factor = 0.1 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduced dynamic inertia weight oscillation and additive noise for enhanced exploration and convergence.", "configspace": "", "generation": 68, "fitness": 0.27809384015715555, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "93dde9a7-e8b5-4616-bb86-6dc70abade2e", "metadata": {"aucs": [0.2781217028331877, 0.27805666854798505, 0.2781031490902939]}, "mutation_prompt": null}
{"id": "c6d38f48-4b3b-4c8e-bb36-3eaf1cd95b42", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget) * n_particles / 2))  # Changed line\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Added dynamic social coefficient based on particle index\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Adjusted inertia weight with a nonlinear decay\n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**2) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2  # Changed line\n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + 0.05 * np.sin(evaluations))\n                # Adaptive velocity clipping based on function evaluation proportion\n                velocity_clamp_factor = 0.1 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Incorporate a dynamic particle count reduction strategy and adaptive inertia weight tuning for improved convergence.", "configspace": "", "generation": 69, "fitness": 0.2780956612490482, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "93dde9a7-e8b5-4616-bb86-6dc70abade2e", "metadata": {"aucs": [0.2781194113301786, 0.27806025571162685, 0.2781073167053393]}, "mutation_prompt": null}
{"id": "710e5c26-0cc4-40d4-aed6-90904043925f", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget) * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score)) * (1 - evaluations/self.budget)  # Changed line\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**1.5) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2  # Changed line\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + 0.05 * np.sin(evaluations))\n                velocity_clamp_factor = 0.1 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance exploration-exploitation balance by introducing a decay factor to cognitive coefficient and adjusting inertia weight decay.", "configspace": "", "generation": 70, "fitness": 0.2780927986364635, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "c6d38f48-4b3b-4c8e-bb36-3eaf1cd95b42", "metadata": {"aucs": [0.27811889543351576, 0.27805399272426434, 0.27810550775161047]}, "mutation_prompt": null}
{"id": "efaf4c4d-aaf1-41f5-95af-667f5afa0a03", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget) * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                # Added dynamic particle acceleration update\n                acceleration_factor = 0.5 + 1.5 * (evaluations / self.budget)  # Changed line\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**2) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 acceleration_factor * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + 0.05 * np.sin(evaluations))  # Changed line\n                \n                velocity_clamp_factor = 0.1 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce dynamic particle acceleration rate proportional to evaluation progress and enhance adaptive social coefficient adjustment.", "configspace": "", "generation": 71, "fitness": 0.2780511022950109, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "c6d38f48-4b3b-4c8e-bb36-3eaf1cd95b42", "metadata": {"aucs": [0.2780691845714396, 0.27802783221636973, 0.27805629009722344]}, "mutation_prompt": null}
{"id": "16f9dd4b-df95-48fd-a200-2e5ee74a6797", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        # Initialization with adaptive strategy\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            # Changed line: Introduce sigmoid-based adaptive particle reduction\n            dynamic_n_particles = int(n_particles / (1 + np.exp(5 * (evaluations / self.budget - 0.5))))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                # Changed line: Sigmoid-based adaptive inertia weight\n                inertia_weight = 0.9 * (1 - 1 / (1 + np.exp(-10 * (evaluations / self.budget - 0.5))))\n                \n                # Hybrid velocity update\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + 0.05 * np.sin(evaluations))\n                # Adaptive velocity clipping based on function evaluation proportion\n                velocity_clamp_factor = 0.1 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Optimize convergence by introducing a sigmoid-based adaptive strategy for inertia weight and particle shrinking, creating smoother transitions.", "configspace": "", "generation": 72, "fitness": 0.27789167967070355, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "c6d38f48-4b3b-4c8e-bb36-3eaf1cd95b42", "metadata": {"aucs": [0.2778757562860754, 0.2779197379004513, 0.27787954482558397]}, "mutation_prompt": null}
{"id": "e1ca0954-dddc-4430-989b-87a77e1d8181", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))  # Changed line\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**2) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + 0.05 * np.sin(evaluations))\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)  # Changed line\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a non-linear dynamic particle count reduction and adaptive coefficient tuning for improved exploration-exploitation balance.", "configspace": "", "generation": 73, "fitness": 0.2781052811445765, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "c6d38f48-4b3b-4c8e-bb36-3eaf1cd95b42", "metadata": {"aucs": [0.2781187320863052, 0.27811006591201537, 0.27808704543540885]}, "mutation_prompt": null}
{"id": "8d176cb7-05d6-41b7-9999-037c3b63e810", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**2) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + 0.05 * np.sin(evaluations))\n                velocity_clamp_factor = 0.1 * (1 - evaluations / self.budget) + 0.05 * np.var(pbest_scores)  # Changed line\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance convergence by dynamically adjusting inertia and swarm size using cosine modulation and objective variance.", "configspace": "", "generation": 74, "fitness": 0.27809257485390587, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e1ca0954-dddc-4430-989b-87a77e1d8181", "metadata": {"aucs": [0.27811737616929977, 0.27806444372816863, 0.27809590466424927]}, "mutation_prompt": null}
{"id": "931b6754-0a17-45fc-91e9-a1053ef3fc35", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**2) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.05 * np.random.uniform(-1, 1, self.dim) * (np.random.rand() < 0.1))  # Changed line\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce stochastic disturbance in velocity updates to enhance escape from local optima.", "configspace": "", "generation": 75, "fitness": 0.27809862372141947, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e1ca0954-dddc-4430-989b-87a77e1d8181", "metadata": {"aucs": [0.27808187442858157, 0.27813865579709296, 0.2780753409385839]}, "mutation_prompt": null}
{"id": "de8cc962-366e-47d5-827d-b3a0e71c949c", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n\n        evaluations = n_particles\n        \n        def levy_flight(Lambda):\n            sigma = (np.math.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2) /\n                     (np.math.gamma((1 + Lambda) / 2) * Lambda * 2**((Lambda - 1) / 2)))**(1 / Lambda)\n            u = np.random.normal(0, sigma, size=self.dim)\n            v = np.random.normal(0, 1, size=self.dim)\n            step = u / abs(v)**(1 / Lambda)\n            return step\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, int(n_particles * (1 - 0.5 * np.tanh((evaluations / self.budget) * np.pi))))  # Changed line\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.2\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.4 * np.tanh(i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - np.tanh((evaluations / self.budget) * np.pi))  # Changed line\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]))\n                \n                levy_step = levy_flight(1.5) * 0.01  # Introduced line\n                velocities[i] += levy_step * (1 - evaluations/self.budget)  # Changed line\n                \n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * 0.15, abs(ub-lb) * 0.15)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Integrate LÃ©vy flight and adaptive dynamic coefficients to enhance global and local search balance.", "configspace": "", "generation": 76, "fitness": 0.27798796798766207, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e1ca0954-dddc-4430-989b-87a77e1d8181", "metadata": {"aucs": [0.2780792840104064, 0.27805791781040845, 0.2778267021421714]}, "mutation_prompt": null}
{"id": "8e00a0f4-375d-4710-8c85-40ede3bed4ae", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.9 + 0.05 * (ub - lb)  # Changed line\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**2) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + 0.05 * np.sin(evaluations) +\n                                 0.03 * np.random.uniform(-1, 1, self.dim))  # Changed line\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance the velocity update rule with a stochastic exploration component and refine particle initialization for increased diversity.", "configspace": "", "generation": 77, "fitness": 0.27804124111512263, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e1ca0954-dddc-4430-989b-87a77e1d8181", "metadata": {"aucs": [0.27802369065164667, 0.27807432309309865, 0.27802570960062256]}, "mutation_prompt": null}
{"id": "a2e89858-48d5-45fe-845a-d6fb296414df", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**2) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))  # Changed line\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + 0.05 * np.sin(evaluations))\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a dynamic inertia weight adjustment to enhance the algorithm's ability to balance exploration and exploitation over time.", "configspace": "", "generation": 78, "fitness": 0.27810569164587556, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "e1ca0954-dddc-4430-989b-87a77e1d8181", "metadata": {"aucs": [0.2781207957189843, 0.278109211919105, 0.27808706729953747]}, "mutation_prompt": null}
{"id": "71d798e7-dcae-4e63-a167-1d38feb1e2f3", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**2) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))  # Modified line\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a dynamic adaptive mutation intensity to enhance exploration capabilities as the budget depletes.", "configspace": "", "generation": 79, "fitness": 0.2781360982348707, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "a2e89858-48d5-45fe-845a-d6fb296414df", "metadata": {"aucs": [0.27814701120821816, 0.2781600675390973, 0.27810121595729653]}, "mutation_prompt": null}
{"id": "0f056ae5-ac88-49a1-894f-86229eb53ea4", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**2) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                decay_factor = 1 - evaluations / (2 * self.budget)  # New line\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) + \n                                 0.05 * np.sin(evaluations) * decay_factor +  # Modified line\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))  # Modified line\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Revamped velocity update rule to incorporate a decay factor for improved convergence.", "configspace": "", "generation": 80, "fitness": 0.27810572648943727, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "71d798e7-dcae-4e63-a167-1d38feb1e2f3", "metadata": {"aucs": [0.2781208338400877, 0.2781092634460398, 0.27808708218218436]}, "mutation_prompt": null}
{"id": "f50af36b-d7d8-4f17-9fe9-37ea300586a5", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 1.5 + 0.5 * np.sin(evaluations / self.budget * np.pi)  # Modified line\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**2) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) +\n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a time-varying dynamic inertia weight and social coefficient to balance exploration and exploitation.", "configspace": "", "generation": 81, "fitness": 0.27812201930151464, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "71d798e7-dcae-4e63-a167-1d38feb1e2f3", "metadata": {"aucs": [0.27814696180360066, 0.2781301374477452, 0.27808895865319805]}, "mutation_prompt": null}
{"id": "ef51cec2-4b1f-4c1e-9da0-cbda0c6921f5", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                # Introduce adaptive oscillation to social coefficient\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles) * np.sin(evaluations / self.budget * np.pi)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**2) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))  # Modified line\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive social coefficient oscillation to enhance convergence towards the global best position.", "configspace": "", "generation": 82, "fitness": 0.27807088365107163, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "71d798e7-dcae-4e63-a167-1d38feb1e2f3", "metadata": {"aucs": [0.2780920710927012, 0.2781128492159157, 0.27800773064459805]}, "mutation_prompt": null}
{"id": "4680c3d2-c13a-4b2e-8dfd-3770e2dcd314", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**2) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))\n                velocity_correction = 0.05 * np.sin(pbest_scores[i])  # Modified line\n                velocities[i] = np.clip(velocities[i] + velocity_correction, -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a dynamic velocity correction factor based on particle performance to enhance convergence stability.", "configspace": "", "generation": 83, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'velocity_clamp_factor' is not defined\").", "error": "NameError(\"name 'velocity_clamp_factor' is not defined\")", "parent_id": "71d798e7-dcae-4e63-a167-1d38feb1e2f3", "metadata": {}, "mutation_prompt": null}
{"id": "f2620ca0-84b8-4ac9-ab9e-b60a95b04d39", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**2) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * (0.7 + 0.3 * np.sin(np.pi * evaluations / self.budget)) * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))  # Modified line\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce time-varying cognitive and social coefficients to balance exploration and exploitation over iterations.", "configspace": "", "generation": 84, "fitness": 0.27813616465862934, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "71d798e7-dcae-4e63-a167-1d38feb1e2f3", "metadata": {"aucs": [0.2781466676521991, 0.2781594288906013, 0.2781023974330876]}, "mutation_prompt": null}
{"id": "74a6cd61-6198-4a12-ad76-ab2e9c439381", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**1.5) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2  # Modified line\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * (0.7 + 0.3 * np.sin(np.pi * evaluations / self.budget)) * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Incorporate a dynamically decreasing inertia weight factor to enhance convergence speed while maintaining diversity.", "configspace": "", "generation": 85, "fitness": 0.2781366294369682, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "f2620ca0-84b8-4ac9-ab9e-b60a95b04d39", "metadata": {"aucs": [0.2781476920927165, 0.27816008996217234, 0.27810210625601584]}, "mutation_prompt": null}
{"id": "6c94a671-0cfd-4c9a-b1bb-6446628979e0", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.7  # Changed line\n                \n                social_coeff = 2.05 - cognitive_coeff + 0.5 * (i / n_particles)  # Changed line\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**1.5) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * (0.7 + 0.3 * np.sin(np.pi * evaluations / self.budget)) * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhanced swarm adaptation by introducing adaptive cognitive and social coefficients based on particle performance.", "configspace": "", "generation": 86, "fitness": 0.27810103905098854, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "74a6cd61-6198-4a12-ad76-ab2e9c439381", "metadata": {"aucs": [0.27813974431699173, 0.2781130469931715, 0.2780503258428024]}, "mutation_prompt": null}
{"id": "d30166c6-bc5b-43ed-959b-53810ec5ad50", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**1.5) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * (0.7 + 0.3 * np.sin(np.pi * evaluations / self.budget)) * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))\n                if evaluations % (self.budget // 10) == 0:  # New line\n                    velocities[i] += 0.1 * np.random.normal(0, 1, self.dim)  # New line\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance swarm diversity by introducing periodic random perturbations to escape local optima.", "configspace": "", "generation": 87, "fitness": 0.2781366226503619, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "74a6cd61-6198-4a12-ad76-ab2e9c439381", "metadata": {"aucs": [0.27814771331702537, 0.27816005585750725, 0.278102098776553]}, "mutation_prompt": null}
{"id": "802c2b8a-313a-473e-8e55-892505784e67", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = 1.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)  # Modified line\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 1.7 + 0.3 * np.cos(np.pi * evaluations / self.budget)  # Modified line\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**1.5) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * (0.7 + 0.3 * np.sin(np.pi * evaluations / self.budget)) * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))\n                \n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive acceleration coefficients to enhance exploration and exploitation balance dynamically.", "configspace": "", "generation": 88, "fitness": 0.2780383672150473, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "74a6cd61-6198-4a12-ad76-ab2e9c439381", "metadata": {"aucs": [0.27806228748035366, 0.27806118204152774, 0.2779916321232605]}, "mutation_prompt": null}
{"id": "2d91a6ff-c2b1-472b-848e-665c599ef58a", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5 * (1 + 0.1 * np.sin(evaluations / self.budget * np.pi))  # Adjusted line\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles) * (0.9 + 0.1 * np.cos(evaluations / self.budget * np.pi))  # Adjusted line\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**1.5) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * (0.7 + 0.3 * np.sin(np.pi * evaluations / self.budget)) * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance adaptive swarm optimizer by refining velocity update with adaptive cognitive and social coefficients for improved convergence.", "configspace": "", "generation": 89, "fitness": 0.2781322061642742, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "74a6cd61-6198-4a12-ad76-ab2e9c439381", "metadata": {"aucs": [0.2781484494340901, 0.27815911530095005, 0.27808905375778237]}, "mutation_prompt": null}
{"id": "4bbf7c22-139e-4742-a512-80349a25d8a3", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**1.5) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2  # Modified line\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                chaotic_factor = 0.5 * np.sin(4 * np.pi * (evaluations / self.budget))  # New line \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 chaotic_factor * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))  # Modified line\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance exploration by integrating a chaotic sequence in velocity updates for improved diversity and convergence.", "configspace": "", "generation": 90, "fitness": 0.27813265222294487, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "74a6cd61-6198-4a12-ad76-ab2e9c439381", "metadata": {"aucs": [0.2781357590907574, 0.2781582609424531, 0.27810393663562405]}, "mutation_prompt": null}
{"id": "948fbace-264a-4f20-9cb8-fdf32af50cb0", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**1.8 * n_particles / 2))  # Modified line\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**1.5) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.12 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) +  # Modified line\n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * (0.7 + 0.3 * np.sin(np.pi * evaluations / self.budget)) * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Improved convergence by dynamically adjusting the number of particles and enhancing local search.", "configspace": "", "generation": 91, "fitness": 0.2781159493731848, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "74a6cd61-6198-4a12-ad76-ab2e9c439381", "metadata": {"aucs": [0.2781484998296354, 0.2781591393143814, 0.2780402089755376]}, "mutation_prompt": null}
{"id": "20bb9539-3707-4e7b-8442-0da73431efba", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**1.5) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * (0.7 + 0.3 * np.sin(np.pi * evaluations / self.budget)) * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                improvement_rate = (pbest_scores[i] - current_score) / (1 + abs(current_score))\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Improve exploration by introducing a dynamic acceleration coefficient adjustment based on particle improvement rates.", "configspace": "", "generation": 92, "fitness": 0.2781366294369682, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "74a6cd61-6198-4a12-ad76-ab2e9c439381", "metadata": {"aucs": [0.2781476920927165, 0.27816008996217234, 0.27810210625601584]}, "mutation_prompt": null}
{"id": "6288a001-9a84-4092-beb6-3b6e1a1940d7", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**1.5) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * (0.7 + 0.3 * np.sin(np.pi * evaluations / self.budget)) * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))\n                \n                velocities[i] *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))  # Modified line\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive velocity scaling to improve convergence by refining the balance between exploration and exploitation.", "configspace": "", "generation": 93, "fitness": 0.27813680174982597, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "74a6cd61-6198-4a12-ad76-ab2e9c439381", "metadata": {"aucs": [0.2781475960560581, 0.27816010449832407, 0.2781027046950957]}, "mutation_prompt": null}
{"id": "47a7c8e2-64a0-4aba-ac5e-c7b7f368b2b5", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                \n                # Modified line 1\n                fitness_improvement = (pbest_scores[i] - gbest_score) / (1 + abs(gbest_score))\n                # Modified line 2\n                cognitive_coeff = max(1.0, 2.0 - np.tanh(fitness_improvement))\n                # Modified line 3\n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**1.5) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * (0.7 + 0.3 * np.sin(np.pi * evaluations / self.budget)) * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))\n                \n                velocities[i] *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce dynamic cognitive and social coefficients adjustment based on fitness improvement to enhance convergence efficiency.", "configspace": "", "generation": 94, "fitness": 0.2780041724693088, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "6288a001-9a84-4092-beb6-3b6e1a1940d7", "metadata": {"aucs": [0.2779200692814946, 0.2780242725806391, 0.27806817554579266]}, "mutation_prompt": null}
{"id": "99b1ad90-0177-440d-95fd-df2dee65a182", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**1.5) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * (0.7 + 0.3 * np.sin(np.pi * evaluations / self.budget)) * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))\n                \n                velocities[i] *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi)) \n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i] + np.random.uniform(-0.01, 0.01, self.dim), -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)  # Modified line\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance convergence by dynamically adjusting the cognitive and social coefficients based on particle performance and incorporating a random perturbation.", "configspace": "", "generation": 95, "fitness": 0.278094653639741, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "6288a001-9a84-4092-beb6-3b6e1a1940d7", "metadata": {"aucs": [0.27806300412940244, 0.27812650328810007, 0.27809445350172046]}, "mutation_prompt": null}
{"id": "b2b036d8-963e-4ece-8cdf-f3fd79b0c853", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**1.5) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * (0.7 + 0.3 * np.sin(np.pi * evaluations / self.budget)) * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))\n                \n                velocities[i] *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a dynamic cognitive coefficient adjustment for faster convergence by altering the initialization of cognitive coefficients.", "configspace": "", "generation": 96, "fitness": 0.27813680174982597, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "6288a001-9a84-4092-beb6-3b6e1a1940d7", "metadata": {"aucs": [0.2781475960560581, 0.27816010449832407, 0.2781027046950957]}, "mutation_prompt": null}
{"id": "ed6a6fb4-3ac8-4126-bc13-72aaf613e5c4", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**1.5) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * (0.7 + 0.3 * np.sin(np.pi * evaluations / self.budget)) * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))\n                \n                velocities[i] *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget + 0.05 * np.sin(i))  # Modified line\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Enhance exploration through dynamic particle acceleration based on budget utilization and particle performance.", "configspace": "", "generation": 97, "fitness": 0.2781225871127349, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "6288a001-9a84-4092-beb6-3b6e1a1940d7", "metadata": {"aucs": [0.27814054843324143, 0.278145556286422, 0.27808165661854134]}, "mutation_prompt": null}
{"id": "47f966c9-ed61-4506-81a2-cca7e5643725", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**1.5) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                # Line modified for modulation factor\n                modulation_factor = 0.1 * np.sin((evaluations / self.budget) * np.pi * 2)\n\n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 modulation_factor * np.random.normal(0, 1, self.dim) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * (0.7 + 0.3 * np.sin(np.pi * evaluations / self.budget)) * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))\n                \n                velocities[i] *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce a time-varying dynamic modulation factor to enhance swarm diversity and prevent premature convergence.", "configspace": "", "generation": 98, "fitness": 0.27809059026477806, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "6288a001-9a84-4092-beb6-3b6e1a1940d7", "metadata": {"aucs": [0.27812410580013713, 0.278068073415479, 0.2780795915787181]}, "mutation_prompt": null}
{"id": "5b38f5c3-56f7-4650-96bb-018bbedda0dd", "solution": "import numpy as np\n\nclass AdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        n_particles = 30\n        inertia_weight = 0.9\n        cognitive_coeff = 1.5\n        social_coeff = 1.5\n\n        particles = np.random.uniform(lb, ub, (n_particles, self.dim)) * 0.8 + 0.1 * (ub - lb)\n        velocities = np.random.uniform(-1, 1, (n_particles, self.dim))\n        pbest_positions = np.copy(particles)\n        pbest_scores = np.array([func(p) for p in particles])\n        gbest_position = pbest_positions[np.argmin(pbest_scores)]\n        gbest_score = np.min(pbest_scores)\n        \n        evaluations = n_particles\n        \n        while evaluations < self.budget:\n            dynamic_n_particles = max(8, n_particles - int((evaluations / self.budget)**2 * n_particles / 2))\n            for i in range(dynamic_n_particles):\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                if pbest_scores[i] < gbest_score:\n                    cognitive_coeff = max(1.0, 2.0 - (pbest_scores[i] / gbest_score))\n                else:\n                    cognitive_coeff = 1.5\n                \n                social_coeff = 2.0 - cognitive_coeff + 0.5 * (i / n_particles)\n                \n                inertia_weight = 0.9 * (1 - (evaluations / self.budget)**1.5) - 0.3 * (1 + np.cos((evaluations / self.budget) * np.pi)) / 2\n                inertia_weight *= (0.5 + 0.5 * np.cos(evaluations / self.budget * np.pi))\n                \n                velocities[i] = (inertia_weight * velocities[i] +\n                                 cognitive_coeff * r1 * (pbest_positions[i] - particles[i]) +\n                                 social_coeff * r2 * (gbest_position - particles[i]) +\n                                 0.1 * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget) + \n                                 0.05 * np.sin(evaluations) +\n                                 0.1 * (0.7 + 0.3 * np.sin(np.pi * evaluations / self.budget)) * np.random.normal(0, 1, self.dim) * (1 - evaluations/self.budget))\n                \n                velocities[i] *= (0.4 + 0.6 * np.cos(evaluations / self.budget * np.pi))  # Modified line\n                velocity_clamp_factor = 0.15 * (1 - evaluations / self.budget)\n                velocities[i] = np.clip(velocities[i], -abs(ub-lb) * velocity_clamp_factor, abs(ub-lb) * velocity_clamp_factor)\n                particles[i] += velocities[i]\n                particles[i] = np.clip(particles[i], lb, ub)\n                \n                current_score = func(particles[i])\n                evaluations += 1\n                if current_score < pbest_scores[i]:\n                    pbest_positions[i] = particles[i]\n                    pbest_scores[i] = current_score\n                    if current_score < gbest_score:\n                        gbest_position = particles[i]\n                        gbest_score = current_score\n\n                if evaluations >= self.budget:\n                    break\n\n        return gbest_position, gbest_score", "name": "AdaptiveSwarmOptimizer", "description": "Introduce adaptive velocity reduction using trigonometric functions to enhance convergence stability near the optimum.", "configspace": "", "generation": 99, "fitness": 0.2781368383064479, "feedback": "The algorithm AdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.00.", "error": "", "parent_id": "6288a001-9a84-4092-beb6-3b6e1a1940d7", "metadata": {"aucs": [0.2781477176253727, 0.27816007065433346, 0.27810272663963764]}, "mutation_prompt": null}
