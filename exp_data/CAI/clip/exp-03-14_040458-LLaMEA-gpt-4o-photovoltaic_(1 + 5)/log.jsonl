{"id": "04197700-74c7-48b7-a4b0-b2db93e9307d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "c4792745-0a61-4e59-9fa8-89c0b13f4ce8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Dynamic adjustment of velocity based on solution's performance\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) *\n                                    (1 - (f_value - global_best_value)/(ub-lb).max()))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces dynamic velocity adjustment based on the solution's performance to improve convergence speed and accuracy. ", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: UnboundLocalError(\"local variable 'f_value' referenced before assignment\").", "error": "UnboundLocalError(\"local variable 'f_value' referenced before assignment\")", "parent_id": "04197700-74c7-48b7-a4b0-b2db93e9307d", "metadata": {}, "mutation_prompt": null}
{"id": "1e5aa8e3-821d-49ab-9967-1f1b80e3cd6a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                # Apply adaptive mutation for exploration\n                if np.random.rand() < adaptive_factor:\n                    swarm[i] += np.random.normal(0, 0.1 * (ub - lb), size=self.dim)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced ASGD with adaptive mutation for improved exploration.", "configspace": "", "generation": 1, "fitness": 0.817428469534549, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.817 with standard deviation 0.034. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "04197700-74c7-48b7-a4b0-b2db93e9307d", "metadata": {"aucs": [0.8421718969360092, 0.76890311738062, 0.8412103942870173], "final_y": [0.13587473423270857, 0.1702433386818767, 0.1431931876488628]}, "mutation_prompt": null}
{"id": "2608f9bd-6442-4daf-af4b-4f22b6d42bc8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        velocity_momentum = 0.9  # Introduce momentum for velocity updates\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (velocity_momentum * self.velocity[i] +\n                                    inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces momentum to velocity updates for improved convergence stability and speed in exploring and exploiting the search space.", "configspace": "", "generation": 1, "fitness": 0.7829193901037774, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.009. And the mean value of best solutions found was 0.164 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "04197700-74c7-48b7-a4b0-b2db93e9307d", "metadata": {"aucs": [0.7763213210062687, 0.7762606199917056, 0.7961762293133581], "final_y": [0.16605840729024635, 0.16729882281766173, 0.15913530059500247]}, "mutation_prompt": null}
{"id": "857c092b-f63b-493f-8200-19dc853ba016", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Adjusted line for dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces dynamic social coefficient adjustment for improved convergence speed and solution quality.", "configspace": "", "generation": 1, "fitness": 0.7716754668577837, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.772 with standard deviation 0.009. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "04197700-74c7-48b7-a4b0-b2db93e9307d", "metadata": {"aucs": [0.7844056639948751, 0.76890311738062, 0.7617176191978559], "final_y": [0.13599490088050936, 0.1702433386818767, 0.17267260947850327]}, "mutation_prompt": null}
{"id": "f60f658a-139f-4de6-b085-bef2bea4a840", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Incorporate differential mutation\n                a, b = np.random.choice(self.population_size, 2, replace=False)\n                differential_mutation = 0.5 * (personal_best[a] - personal_best[b])\n                swarm[i] += self.velocity[i] + differential_mutation\n\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD) integrates differential mutation for increased diversity and convergence speed.", "configspace": "", "generation": 1, "fitness": 0.8091990436701675, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.014. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "04197700-74c7-48b7-a4b0-b2db93e9307d", "metadata": {"aucs": [0.8014283909175954, 0.7970906777680888, 0.8290780623248182], "final_y": [0.1411480179757877, 0.15933357882466703, 0.14755707481383595]}, "mutation_prompt": null}
{"id": "c2bbd17a-af26-41a0-b637-671733fbb666", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            # Dynamic population resizing\n            self.population_size = max(5, int((10 + 2 * int(np.sqrt(dim))) * adaptive_factor))\n            swarm = swarm[:self.population_size]\n            self.velocity = self.velocity[:self.population_size]\n            personal_best = personal_best[:self.population_size]\n            personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces a dynamic population resizing strategy to improve exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'dim' is not defined\").", "error": "NameError(\"name 'dim' is not defined\")", "parent_id": "04197700-74c7-48b7-a4b0-b2db93e9307d", "metadata": {}, "mutation_prompt": null}
{"id": "e2426ea0-f437-4bf4-932a-bcb9bf47fd6e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            diversity_control = np.std(swarm, axis=0).mean()\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + diversity_control)\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces diversity control and dynamic adaptation of cognitive coefficients to improve exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.8312026324386919, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.831 with standard deviation 0.023. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "04197700-74c7-48b7-a4b0-b2db93e9307d", "metadata": {"aucs": [0.8076667071408087, 0.8618081197712556, 0.8241330704040115], "final_y": [0.15454834812086005, 0.13044506354804697, 0.1278950947632106]}, "mutation_prompt": null}
{"id": "02c27472-09e2-49d4-93c9-3b94407bd2bc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Changed line\n\n            for i in range(self.population_size):\n                local_influence = np.mean(swarm, axis=0)  # Changed line\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Changed line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * r3 * (local_influence - swarm[i]))  # Changed line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces local swarm influence and dynamic parameter adjustment to improve exploration and convergence in the search space.", "configspace": "", "generation": 2, "fitness": 0.8341304089290595, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.834 with standard deviation 0.011. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "04197700-74c7-48b7-a4b0-b2db93e9307d", "metadata": {"aucs": [0.8179672012786459, 0.8421198571566478, 0.842304168351885], "final_y": [0.13804833347036805, 0.1272794171793893, 0.12224775010294886]}, "mutation_prompt": null}
{"id": "8c73c096-d9f7-4201-bc92-07205f03a5bd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (adaptive_factor + 0.5)  # Modified line 1\n            social_coeff = 1.5 * (adaptive_factor + 0.5)    # Modified line 2\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces dynamic social and cognitive coefficients to improve convergence and diversity.", "configspace": "", "generation": 2, "fitness": 0.8235943862332341, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.024. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "04197700-74c7-48b7-a4b0-b2db93e9307d", "metadata": {"aucs": [0.790213211738493, 0.8464973893486468, 0.834072557612562], "final_y": [0.14221021099031572, 0.12587293181330672, 0.14020862731368644]}, "mutation_prompt": null}
{"id": "d79420b6-41ab-4dea-8b78-a57df06ae743", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances ASGD by adjusting the social coefficient dynamically based on the current best's improvement rate to balance exploration and exploitation.", "configspace": "", "generation": 2, "fitness": 0.858977501177463, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.016. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "04197700-74c7-48b7-a4b0-b2db93e9307d", "metadata": {"aucs": [0.8578941758714862, 0.8394647555847938, 0.8795735720761088], "final_y": [0.12116174094504395, 0.12065285927561897, 0.12476807550729918]}, "mutation_prompt": null}
{"id": "c9f47b78-2382-47e5-bf2d-c90016accc6e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Modified line\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances ASGD by utilizing an adaptive inertia weight that decreases more aggressively to strengthen exploration at early stages and exploitation in later stages.", "configspace": "", "generation": 3, "fitness": 0.8417616523983528, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.054. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "d79420b6-41ab-4dea-8b78-a57df06ae743", "metadata": {"aucs": [0.8981903468974165, 0.8580047248989833, 0.7690898853986587], "final_y": [0.12184648692851452, 0.12588938514578574, 0.16198839777022322]}, "mutation_prompt": null}
{"id": "f3b3547f-329a-4aa0-9c34-9648b61e85b6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introducing adaptive mutation\n                mutation_strength = 0.1 * (1 - evaluations / self.budget)\n                swarm[i] += mutation_strength * np.random.normal(size=self.dim)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refines ASGD by integrating an adaptive mutation based on the budget consumption to enhance solution diversity and convergence speed.", "configspace": "", "generation": 3, "fitness": 0.8543680022987958, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.018. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "d79420b6-41ab-4dea-8b78-a57df06ae743", "metadata": {"aucs": [0.8458093898567646, 0.8793788890087588, 0.8379157280308642], "final_y": [0.13537095420712875, 0.12467972707663655, 0.13746972894068377]}, "mutation_prompt": null}
{"id": "0f662ae0-fa7d-4850-a9b5-bc34403273e7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * (adaptive_factor ** 2)  # Changed line\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a non-linear scaling for inertia weight to enhance convergence speed in ASGD.", "configspace": "", "generation": 3, "fitness": 0.843355771808057, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.843 with standard deviation 0.008. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "d79420b6-41ab-4dea-8b78-a57df06ae743", "metadata": {"aucs": [0.8329559824639852, 0.8526392758824424, 0.8444720570777438], "final_y": [0.1250245239974903, 0.1335231765870476, 0.13446649548027356]}, "mutation_prompt": null}
{"id": "732ab975-61df-4f2c-bf7d-bbc50231f368", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n        momentum = 0.9\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                adaptive_velocity_scale = 0.5 + 0.5 * improvement_rate\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += momentum * (adaptive_velocity_scale * self.velocity[i])\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces adaptive velocity scaling and a momentum term to enhance convergence speed and stability in ASGD.", "configspace": "", "generation": 3, "fitness": 0.8498695120773632, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.006. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "d79420b6-41ab-4dea-8b78-a57df06ae743", "metadata": {"aucs": [0.8431915619694488, 0.8480985286879402, 0.8583184455747003], "final_y": [0.1205969964600806, 0.12393788882726531, 0.13320902322016137]}, "mutation_prompt": null}
{"id": "15d5028a-e0b6-4259-9cbd-b4394eadaa10", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = None\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        evaluations = 0\n        population_size = self.initial_population_size\n\n        while evaluations < self.budget:\n            # Dynamically adjust population size\n            population_size = self.initial_population_size + int(0.1 * self.initial_population_size * (evaluations / self.budget))\n            if self.velocity is None or self.velocity.shape[0] != population_size:\n                self.velocity = np.zeros((population_size, self.dim))\n            swarm = np.random.uniform(lb, ub, (population_size, self.dim))\n            personal_best = swarm.copy()\n            personal_best_value = np.array([func(x) for x in swarm])\n            global_best = personal_best[np.argmin(personal_best_value)]\n            global_best_value = np.min(personal_best_value)\n\n            previous_best_value = global_best_value\n\n            for i in range(population_size):\n                adaptive_factor = 1 - evaluations / self.budget\n                inertia_weight = 0.7 + 0.3 * adaptive_factor\n                cognitive_coeff = 1.5 * adaptive_factor\n                improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n                social_coeff = 1.5 * (1 + improvement_rate)\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic population size adjustment based on evaluation progress to enhance exploration and convergence balance.", "configspace": "", "generation": 3, "fitness": 0.8214000753159421, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.018. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "d79420b6-41ab-4dea-8b78-a57df06ae743", "metadata": {"aucs": [0.7955539869545145, 0.8349769692050673, 0.8336692697882445], "final_y": [0.15853670064682812, 0.13011778582002897, 0.12802714414355687]}, "mutation_prompt": null}
{"id": "570718d2-f387-4b38-b3be-1a438d5afe54", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            convergence_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            inertia_weight = 0.8 - 0.2 * convergence_rate  # Adjusted line\n            adaptive_factor = 1 - evaluations / self.budget\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improves ASGD by introducing a dynamic inertia weight based on convergence rate for better exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.850412310126174, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.014. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "d79420b6-41ab-4dea-8b78-a57df06ae743", "metadata": {"aucs": [0.8490273149157517, 0.8333880438153026, 0.8688215716474679], "final_y": [0.1266830515433386, 0.12961524715590422, 0.11827495308628078]}, "mutation_prompt": null}
{"id": "0c7cba6d-ea63-4074-a072-f1918604a30a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * adaptive_factor  # Changed from 0.7 + 0.3\n            cognitive_coeff = 2.0 * adaptive_factor        # Changed from 1.5\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances ASGD by dynamically adjusting inertia weight and social coefficient based on the improvement rate to optimize exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.838628553753261, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.038. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "d79420b6-41ab-4dea-8b78-a57df06ae743", "metadata": {"aucs": [0.8886817736159034, 0.8304323296529419, 0.7967715579909378], "final_y": [0.11201141822879823, 0.12700305315473026, 0.14677550264016448]}, "mutation_prompt": null}
{"id": "1b7d5b8b-cdeb-4e3d-afc2-625e44bb3134", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            # Adjust population size based on remaining budget\n            dynamic_population_size = max(5, int(self.population_size * adaptive_factor))\n            for i in range(dynamic_population_size):  # Only iterate over the dynamic population size\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces an adaptive population size mechanism in ASGD to dynamically adjust the exploration-exploitation balance based on remaining budget.", "configspace": "", "generation": 4, "fitness": 0.8480552550327619, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.027. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "d79420b6-41ab-4dea-8b78-a57df06ae743", "metadata": {"aucs": [0.813525955999143, 0.8520618374442691, 0.8785779716548733], "final_y": [0.13791693163982655, 0.13109555259359695, 0.12246480125130144]}, "mutation_prompt": null}
{"id": "6da0bc0b-e191-4c36-b207-9a2ea609d7a7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget)**2  # Nonlinear decay\n            inertia_weight = 0.9 + 0.2 * adaptive_factor  # Modified inertia bounds\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Add diversity-preserving mechanism\n                if np.random.rand() < 0.1:\n                    self.velocity[i] += np.random.uniform(-0.1, 0.1, self.dim)\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a nonlinear decay function for inertia and adds a diversity-preserving mechanism to improve exploration.", "configspace": "", "generation": 4, "fitness": 0.8459212979073824, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.027. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "d79420b6-41ab-4dea-8b78-a57df06ae743", "metadata": {"aucs": [0.8144027219264458, 0.8441156584738403, 0.8792455133218606], "final_y": [0.1453702040106024, 0.1302820926547238, 0.12317158261384187]}, "mutation_prompt": null}
{"id": "eac8568c-f69f-464a-af34-587ef87a9529", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            # Dynamic population size adjustment\n            self.population_size = int(10 + 2 * np.sqrt(self.dim) * adaptive_factor)\n            self.velocity = np.resize(self.velocity, (self.population_size, self.dim))\n            swarm = np.resize(swarm, (self.population_size, self.dim))\n            personal_best = np.resize(personal_best, (self.population_size, self.dim))\n            personal_best_value = np.resize(personal_best_value, self.population_size)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n\n                # Adaptive velocity clamping\n                velocity_clamp = np.max(np.abs(self.velocity[i])) * adaptive_factor\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "AdaptiveSwarmGradientDescent refined by introducing a dynamic population size adjustment and adaptive velocity clamping to enhance convergence speed and solution quality.", "configspace": "", "generation": 4, "fitness": 0.8568018228047439, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.018. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "d79420b6-41ab-4dea-8b78-a57df06ae743", "metadata": {"aucs": [0.8744465099367766, 0.832213535242712, 0.863745423234743], "final_y": [0.11188605166865528, 0.13435334365033036, 0.12386733389710858]}, "mutation_prompt": null}
{"id": "a88af8d1-7590-4a3e-a20a-7e8e6e2dc0c6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= 0.95  # Velocity damping factor\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a velocity damping factor to dynamically reduce velocity magnitude, enhancing convergence stability and precision.", "configspace": "", "generation": 5, "fitness": 0.8620013413067834, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.035. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "d79420b6-41ab-4dea-8b78-a57df06ae743", "metadata": {"aucs": [0.908632481950973, 0.8233881813618635, 0.8539833606075133], "final_y": [0.11642466964181442, 0.13220802196424675, 0.12573529837233488]}, "mutation_prompt": null}
{"id": "7d066f87-bdee-4e11-9cca-12a21040a75a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * evaluations / self.budget  # Changed line for time-varying inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a time-varying inertia weight to improve exploration initially and exploitation later.", "configspace": "", "generation": 5, "fitness": 0.8413389397827064, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.011. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "d79420b6-41ab-4dea-8b78-a57df06ae743", "metadata": {"aucs": [0.8538487383417859, 0.8427144994706863, 0.827453581535647], "final_y": [0.1303685696128969, 0.13145553920129305, 0.14021028672233515]}, "mutation_prompt": null}
{"id": "32bce717-ab7a-4d30-a9b2-5226f46f6b6e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocity_scaling = 1 + improvement_rate  # Introduced dynamic velocity scaling\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * velocity_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic velocity scaling factor based on current best's improvement rate to enhance balance between exploration and exploitation.", "configspace": "", "generation": 5, "fitness": 0.8302760494156697, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.020. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "d79420b6-41ab-4dea-8b78-a57df06ae743", "metadata": {"aucs": [0.8052558989566365, 0.8320441765059097, 0.8535280727844627], "final_y": [0.1361614790104776, 0.13248199096407276, 0.12549540736736342]}, "mutation_prompt": null}
{"id": "eb61f0b4-2672-4b84-8153-681404a9cea6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce a mutation step with a small probability\n                if np.random.rand() < 0.05:\n                    mutation_factor = np.random.uniform(-0.1, 0.1, self.dim)\n                    swarm[i] += mutation_factor * (ub - lb)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a mutation step to enhance diversity by occasionally perturbing particles toward random points in the search space.", "configspace": "", "generation": 5, "fitness": 0.8376254314802725, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.021. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "d79420b6-41ab-4dea-8b78-a57df06ae743", "metadata": {"aucs": [0.8659843170105623, 0.8156699556779324, 0.8312220217523225], "final_y": [0.12703554756159519, 0.14734469487082502, 0.13304690556163645]}, "mutation_prompt": null}
{"id": "ec3673ce-0478-4c88-b826-53a565eb8fb8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) + np.random.random(self.dim) * 0.01)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a dynamic random factor to enhance exploration and prevent premature convergence.", "configspace": "", "generation": 5, "fitness": 0.843764783922993, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.029. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "d79420b6-41ab-4dea-8b78-a57df06ae743", "metadata": {"aucs": [0.8038932867122928, 0.8704730964998865, 0.8569279685567996], "final_y": [0.13797563828293125, 0.1226144932920391, 0.1263835021047084]}, "mutation_prompt": null}
{"id": "2814ce4f-e679-43bb-af05-b094ea862eed", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= 0.95 + 0.05 * improvement_rate  # Adaptive velocity damping factor\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces an adaptive velocity damping factor based on the improvement rate to enhance convergence precision and stability.", "configspace": "", "generation": 6, "fitness": 0.7981146924098086, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.798 with standard deviation 0.042. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "a88af8d1-7590-4a3e-a20a-7e8e6e2dc0c6", "metadata": {"aucs": [0.855264491807796, 0.7846681370963292, 0.7544114483253006], "final_y": [0.12918358138972375, 0.16398169665737194, 0.1756035658658459]}, "mutation_prompt": null}
{"id": "b5bfe676-0a7b-4cf0-9674-5ca2ede13a76", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            diversity = np.mean(np.std(swarm, axis=0))  # Calculate swarm diversity\n            cognitive_coeff = 1.5 * adaptive_factor * (1 + diversity)  # Dynamic adjustment\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= 0.95  # Velocity damping factor\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporates a dynamic adjustment of cognitive coefficient based on swarm diversity to improve exploration capabilities.", "configspace": "", "generation": 6, "fitness": 0.8154807900441924, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.011. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "a88af8d1-7590-4a3e-a20a-7e8e6e2dc0c6", "metadata": {"aucs": [0.7999110458406709, 0.8272309958695805, 0.819300328422326], "final_y": [0.15765953043015624, 0.14825141681702392, 0.15040784474295144]}, "mutation_prompt": null}
{"id": "9b85d46e-1c3d-4af1-b80e-40f0353bd518", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= (0.95 + 0.05 * improvement_rate)  # Adjusted velocity damping factor\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances the balance between exploration and exploitation by dynamically adjusting the velocity damping factor based on the improvement rate.", "configspace": "", "generation": 6, "fitness": 0.8059311638247252, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.035. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "a88af8d1-7590-4a3e-a20a-7e8e6e2dc0c6", "metadata": {"aucs": [0.8555691900187152, 0.7781073652844646, 0.7841169361709956], "final_y": [0.12457058940695642, 0.16657524820522118, 0.16315897802128276]}, "mutation_prompt": null}
{"id": "2ae2af3f-9119-4e39-a9b0-8cf06f554c36", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            diversity = np.mean(np.std(swarm, axis=0))  # Calculate swarm diversity\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor + 0.1 * diversity  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= 0.95\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances convergence by introducing a dynamic inertia adaptation mechanism that responds to the swarm's diversity.", "configspace": "", "generation": 6, "fitness": 0.8076849008510562, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.043. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "a88af8d1-7590-4a3e-a20a-7e8e6e2dc0c6", "metadata": {"aucs": [0.785497749745792, 0.7693748645317908, 0.8681820882755856], "final_y": [0.1628172087233144, 0.16568242748543627, 0.1344822665205817]}, "mutation_prompt": null}
{"id": "89c9f44d-e27c-44ff-bb32-7685dd01e474", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate * np.random.rand()) # Changed to add stochastic factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= 0.95  # Velocity damping factor\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporates a dynamic social coefficient for improved swarm attraction based on stochastic volatility.", "configspace": "", "generation": 6, "fitness": 0.7983057791617391, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.798 with standard deviation 0.016. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "a88af8d1-7590-4a3e-a20a-7e8e6e2dc0c6", "metadata": {"aucs": [0.8119252263835665, 0.8072538345502133, 0.7757382765514373], "final_y": [0.13850195971028112, 0.1555191639595167, 0.16710453159955319]}, "mutation_prompt": null}
{"id": "f8c6ec16-5847-47c2-8b78-d7cb1db500a6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate + adaptive_factor * 0.5)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= 0.95  # Velocity damping factor\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances convergence by dynamically adjusting the social coefficient based on improvement rate and current evaluations.", "configspace": "", "generation": 7, "fitness": 0.7688849084032786, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.769 with standard deviation 0.020. And the mean value of best solutions found was 0.167 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "a88af8d1-7590-4a3e-a20a-7e8e6e2dc0c6", "metadata": {"aucs": [0.7935463092511217, 0.76890311738062, 0.744205298578094], "final_y": [0.1521777246682131, 0.1702433386818767, 0.17994546382471666]}, "mutation_prompt": null}
{"id": "a333e4a4-2fb3-459d-b645-6e372797dbe8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                convergence_speed = np.abs((previous_best_value - global_best_value) / (previous_best_value + 1e-9))\n                damping_factor = 0.9 + 0.05 * (1 - convergence_speed)  # Adaptive damping factor\n                self.velocity[i] *= damping_factor\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces an adaptive velocity damping factor based on convergence speed to enhance performance stability and precision.", "configspace": "", "generation": 7, "fitness": 0.8198943383267214, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.010. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "a88af8d1-7590-4a3e-a20a-7e8e6e2dc0c6", "metadata": {"aucs": [0.8325862981091762, 0.807298262715866, 0.819798454155122], "final_y": [0.1286570616869661, 0.15542764562911848, 0.15068716696475737]}, "mutation_prompt": null}
{"id": "b0303ded-832b-47b4-9873-d90198a1a286", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n\n            # Calculate diversity of the swarm\n            diversity = np.mean(np.var(swarm, axis=0))\n            # Update cognitive coefficient based on diversity\n            cognitive_coeff = 1.5 * (1 + diversity) * adaptive_factor\n\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= 0.95  # Velocity damping factor\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporates an adaptive cognitive coefficient based on the diversity of the swarm to enhance exploration.", "configspace": "", "generation": 7, "fitness": 0.7916344631875827, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.035. And the mean value of best solutions found was 0.162 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "a88af8d1-7590-4a3e-a20a-7e8e6e2dc0c6", "metadata": {"aucs": [0.7521198873175785, 0.837978498894356, 0.7848050033508134], "final_y": [0.17642755813396804, 0.14453668985765344, 0.16360371899070436]}, "mutation_prompt": null}
{"id": "a1378cf1-07c5-4f59-88c6-5ebbe3393f67", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= 0.95 + 0.05 * improvement_rate  # Adaptive velocity damping factor\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces adaptive velocity damping based on the improvement rate to enhance convergence precision.", "configspace": "", "generation": 7, "fitness": 0.7999133842195216, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.025. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "a88af8d1-7590-4a3e-a20a-7e8e6e2dc0c6", "metadata": {"aucs": [0.8333478727292053, 0.7923925409539643, 0.7739997389753955], "final_y": [0.1340143782548361, 0.1609452645057471, 0.1672587307785297]}, "mutation_prompt": null}
{"id": "bce4f46e-82c7-4210-9df6-31000ad3beec", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Change made here for dynamic inertia adjustment\n            cognitive_coeff = 1.5 * adaptive_factor\n            improvement_rate = (previous_best_value - global_best_value) / previous_best_value if previous_best_value != 0 else 0\n            social_coeff = 1.5 * (1 + improvement_rate)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= 0.95  # Velocity damping factor\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    previous_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a dynamic inertia weight adjustment based on performance to enhance convergence via better exploration-exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.8196256194953353, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.820 with standard deviation 0.052. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "a88af8d1-7590-4a3e-a20a-7e8e6e2dc0c6", "metadata": {"aucs": [0.8904007306635111, 0.76890311738062, 0.7995730104418748], "final_y": [0.12331482636767177, 0.1702433386818767, 0.15776979936266655]}, "mutation_prompt": null}
