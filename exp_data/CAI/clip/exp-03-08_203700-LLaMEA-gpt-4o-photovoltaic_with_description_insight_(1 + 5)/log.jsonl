{"id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Multi-layer Adaptive Hybrid Optimization (MAHO) which combines differential evolution for exploration and adaptive local search for refinement, gradually increasing the problem complexity to manage computational cost while preserving solution robustness.", "configspace": "", "generation": 0, "fitness": 0.8014255414589018, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.007. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7919761021631633, 0.8046118976365253, 0.8076886245770165], "final_y": [0.15461080224244594, 0.13118175845832658, 0.13459700502320449]}, "mutation_prompt": null}
{"id": "4c147630-09da-492d-9a6d-0eb6ef10145a", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.5  # Increased local search probability\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced Multi-layer Adaptive Hybrid Optimization (MAHO+) with increased local search probability to improve refinement.", "configspace": "", "generation": 1, "fitness": 0.799447738105476, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.018. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.7840989331232361, 0.8253038805003883, 0.7889404006928036], "final_y": [0.1534251768710897, 0.14236211058626758, 0.14415371141768285]}, "mutation_prompt": null}
{"id": "feaff8c6-25e1-4e1c-95b2-bdc0052c80a8", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        dynamic_crossover_prob = self.crossover_prob + 0.1 * (1 - self.evaluations / self.budget)  # Adjusted line\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < dynamic_crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.normal(0, self.robustness_factor, x.shape)  # Adjusted line\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced Multi-layer Adaptive Hybrid Optimization (MAHO) with dynamic crossover probability adjustment and improved local search perturbation for better exploration-exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.7696333712916008, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.770 with standard deviation 0.008. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.7578387426380185, 0.7773100177218168, 0.7737513535149669], "final_y": [0.15421959410785135, 0.15321754010683486, 0.1553035667094056]}, "mutation_prompt": null}
{"id": "fcf154fb-d8e8-45d5-bfbb-f9d2d7ab9a72", "solution": "import numpy as np\n\nclass E_MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5\n        self.robustness_factor = 0.05\n        self.evaluations = 0\n        self.adaptive_rate = 0.9  # New: Adaptive mutation rate\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # New: Adaptive mutation factor\n            adaptive_mutation = self.mutation_factor * (1 - self.evaluations / self.budget)\n            mutant = np.clip(a + adaptive_mutation * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            # New: Adjust layer increment strategy\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment // 2)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "E_MAHO", "description": "Enhanced Multi-layer Adaptive Hybrid Optimization (E-MAHO) introduces adaptive mutation and dynamic layer adjustments, improving robustness and convergence in high-dimensional noisy problems.", "configspace": "", "generation": 1, "fitness": 0.7870249995325017, "feedback": "The algorithm E_MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.787 with standard deviation 0.018. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.76633160018563, 0.8100875669384802, 0.7846558314733949], "final_y": [0.14490552372951104, 0.1409444555205086, 0.1363966478872859]}, "mutation_prompt": null}
{"id": "e213de8c-7d28-4909-bb6d-b0ae52ebc9fa", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, int(dim * 2.5))  # Increased population size for better exploration\n        self.mutation_factor = 0.9  # Increased mutation factor for broader search\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced Multi-layer Adaptive Hybrid Optimization (Enhanced MAHO) with increased mutation factor and adaptive population size for improved exploration and solution robustness.", "configspace": "", "generation": 1, "fitness": 0.7966661027119325, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.033. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.8227835814377651, 0.8171101637208417, 0.7501045629771909], "final_y": [0.13737376978956373, 0.1447084233347674, 0.16248284688966397]}, "mutation_prompt": null}
{"id": "7827061e-e733-4b1c-9593-d66571e6b394", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptively adjust mutation factor based on budget usage\n            adaptive_mutation = self.mutation_factor * (1 - self.evaluations / self.budget)\n            mutant = np.clip(a + adaptive_mutation * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO with adaptive mutation factors for improved exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.7901256198426828, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.009. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.7791862134523967, 0.7899635772944218, 0.80122706878123], "final_y": [0.15522129028708564, 0.15283840369850332, 0.13996555297520363]}, "mutation_prompt": null}
{"id": "b30188f4-6011-40f4-ae5a-1ca9d250631e", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            adaptive_mutation_factor = self.mutation_factor * (1 - (self.evaluations / self.budget))\n            adaptive_crossover_prob = self.crossover_prob + (0.3 * (self.evaluations / self.budget))\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < adaptive_crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO with adaptive mutation and crossover strategies to improve exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.7997274627240444, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.014. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.8049144758017377, 0.813571955041513, 0.7806959573288828], "final_y": [0.13388623560009383, 0.14612193683222774, 0.1333484999587351]}, "mutation_prompt": null}
{"id": "b8410d26-d1f2-4e06-a108-4e9533b80e1d", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.85  # Fine-tuned mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Improved Multi-layer Adaptive Hybrid Optimization (MAHO) by fine-tuning the mutation factor.", "configspace": "", "generation": 2, "fitness": 0.7879095195927096, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.788 with standard deviation 0.012. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.805378000656074, 0.7780281704457821, 0.7803223876762727], "final_y": [0.13483361111700676, 0.14439661730229603, 0.1473768720760017]}, "mutation_prompt": null}
{"id": "b95e33b9-4a65-45fd-8a72-d633f008d2ac", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced Multi-layer Adaptive Hybrid Optimization (MAHO+) introduces a scaled mutation factor for better diversity and a dynamic local search probability to improve convergence.", "configspace": "", "generation": 2, "fitness": 0.8027004770627206, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.025. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.80751595806686, 0.7695050944484424, 0.8310803786728596], "final_y": [0.1454622841796348, 0.15568794211095083, 0.1380137264010518]}, "mutation_prompt": null}
{"id": "36ebb24a-7a5e-4e7f-b50c-e4468c9a1657", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.9  # Adjusted mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 3  # Reduced increment for finer control\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Refined Multi-layer Adaptive Hybrid Optimization (RMAHO) enhances robustness by adjusting layer increment strategies and incorporating adaptive mutation factors for more efficient exploration.", "configspace": "", "generation": 2, "fitness": 0.793774958605128, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.794 with standard deviation 0.001. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.794054038660319, 0.7928129523793591, 0.7944578847757062], "final_y": [0.14839366180958014, 0.13966651144481168, 0.1479906963938763]}, "mutation_prompt": null}
{"id": "f8ec2a6b-0671-4edf-bb71-94c93ef83642", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.8\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            adaptive_mutation_factor = self.mutation_factor + np.random.uniform(-0.1, 0.1)  # Adaptive mutation\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        if np.random.rand() < self.local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            layer_perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if layer_perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO with adaptive mutation factor and layer-specific local search to improve exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.7720486692843224, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.772 with standard deviation 0.011. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "334d1ce4-3946-4f58-ab86-9a0736a7b0f7", "metadata": {"aucs": [0.7857895314263594, 0.7594981538172785, 0.7708583226093293], "final_y": [0.15237374825459737, 0.1547931057431139, 0.15470515725882983]}, "mutation_prompt": null}
{"id": "c65e5574-62f8-47f3-912b-ea06dbc90038", "solution": "import numpy as np\n\nclass EMaho:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5\n        self.robustness_factor = 0.05\n        self.evaluations = 0\n        self.base_mutation_factor = 0.5\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = self.base_mutation_factor + 0.2 * np.random.rand()  # Adaptive mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and np.random.rand() < 0.3:  # Stochastic layer addition\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "EMaho", "description": "Enhanced MAHO (E-MAHO) introduces adaptive mutation factor and stochastic layer addition for improved exploration and convergence.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (15,) (10,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (15,) (10,) (10,) ')", "parent_id": "b95e33b9-4a65-45fd-8a72-d633f008d2ac", "metadata": {}, "mutation_prompt": null}
{"id": "d4212672-476e-4def-9f06-e9f852c59902", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO+ with adaptive crossover probability scaling to improve solution space exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8193930118499623, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.819 with standard deviation 0.015. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b95e33b9-4a65-45fd-8a72-d633f008d2ac", "metadata": {"aucs": [0.8377828116504928, 0.8010202926038, 0.8193759312955937], "final_y": [0.1358836509393062, 0.14572098167736958, 0.13040846147118623]}, "mutation_prompt": null}
{"id": "07384bad-0671-4be9-b05c-1ed0dc1907ea", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.3 * (self.evaluations / self.budget)  # Fine-tuned dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "MAHO++ optimizes layer adaptation by fine-tuning the dynamic local search probability for enhanced convergence.", "configspace": "", "generation": 3, "fitness": 0.8155229985633078, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.016. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b95e33b9-4a65-45fd-8a72-d633f008d2ac", "metadata": {"aucs": [0.8371260790640094, 0.7986369688115884, 0.8108059478143257], "final_y": [0.14482560097484054, 0.14019495648456604, 0.13470643242366132]}, "mutation_prompt": null}
{"id": "f3de2de9-1631-4b65-8da5-38a5f45cab1f", "solution": "import numpy as np\n\nclass IMAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.7 + 0.3 * np.random.rand()  # Adjusted mutation factor\n        self.crossover_prob = 0.6  # Adjusted for adaptivity\n        self.local_search_prob = 0.3\n        self.layers_increment = 5\n        self.robustness_factor = 0.05\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def layered_learning(self, pop, func):\n        fitness = np.array([func(ind) for ind in pop])\n        fitness_variance = np.var(fitness)\n        if fitness_variance > 0.01:  # Threshold for variance-based learning\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n        return pop\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            pop = self.layered_learning(pop, func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "IMAHO", "description": "Improved Multi-objective Adaptive Hybrid Optimization (IMAHO) adjusts mutation and crossover adaptively based on fitness variance and introduces layered learning for better convergence.", "configspace": "", "generation": 3, "fitness": 0.8115557680161757, "feedback": "The algorithm IMAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.027. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "b95e33b9-4a65-45fd-8a72-d633f008d2ac", "metadata": {"aucs": [0.774375046439123, 0.8396995525520968, 0.820592705057307], "final_y": [0.1552765303152288, 0.1233836973040815, 0.13071478117801216]}, "mutation_prompt": null}
{"id": "c5d1fe70-8d46-4eac-8636-44032aef94d0", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adapt mutation factor based on progress for exploration-exploitation balance\n            mutation_factor = self.mutation_factor * (0.5 + 0.5 * (self.evaluations / self.budget))\n            mutant = np.clip(a + mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "MAHO++ improves convergence by adapting the mutation factor based on iteration progress for better exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.812339023951795, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.024. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b95e33b9-4a65-45fd-8a72-d633f008d2ac", "metadata": {"aucs": [0.8209256839517725, 0.8364340015868834, 0.7796573863167294], "final_y": [0.13099497860581077, 0.12666535085060748, 0.1373497411064638]}, "mutation_prompt": null}
{"id": "e0f157f7-7c74-4e88-9d24-a52e7e3788db", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 3  # Increment layers gradually, reduced for frequent adaptation\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.3 + 0.4 * np.random.rand()  # More adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.3:  # Earlier dimensional increment\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Synergistic MAHO+ with adaptive exploration-exploitation balance and interleaved layer adaptation for enhanced convergence.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (13,) (10,) (10,) ').", "error": "ValueError('operands could not be broadcast together with shapes (13,) (10,) (10,) ')", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {}, "mutation_prompt": null}
{"id": "d2ebfee6-dcd6-4212-9626-0a694822e576", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.4 + 0.3 * np.random.rand()  # Adaptive mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        # Dynamic adjustment of local search probability based on evaluations\n        dynamic_local_search_prob = self.local_search_prob + 0.3 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO++ with adaptive mutation and dynamic local search scaling to improve balance and solution quality.", "configspace": "", "generation": 4, "fitness": 0.7820957481038967, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.024. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.8157853619460335, 0.7706165811067228, 0.7598853012589337], "final_y": [0.14087179800967065, 0.15321972304336362, 0.16271313012678168]}, "mutation_prompt": null}
{"id": "2cf7e3fd-c43d-42f4-81fd-21fd62ae3b4e", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.1 * (self.evaluations / self.budget)  # Adjusted factor\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO+ with adaptive local search probability scaling for better exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.7850913736934731, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.010. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7792648790463674, 0.7993233739000963, 0.7766858681339559], "final_y": [0.15251255570967726, 0.14344567592818236, 0.15739484364977152]}, "mutation_prompt": null}
{"id": "77bf84ec-12d7-4344-be3e-d71b9e77a442", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.3 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Slightly increase the dynamic local search probability to enhance local refinement while preserving the exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.7864038545444195, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.786 with standard deviation 0.030. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.8126181454585135, 0.8016503438775675, 0.7449430742971772], "final_y": [0.1443395805129548, 0.14373334124937187, 0.1672247281252699]}, "mutation_prompt": null}
{"id": "c6158575-5237-45f5-85b3-546a3de2c5f7", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n        self.adaptive_mutation = 0.5  # Adaptive mutation initial value\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.adaptive_mutation = 0.4 + 0.3 * (1 - self.evaluations / self.budget)  # Dynamic adaptation\n            mutant = np.clip(a + self.adaptive_mutation * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.6 + 0.1 * np.random.rand()  # Slightly modified adaptive crossover\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_search_width = self.robustness_factor * (1 - self.evaluations / self.budget)  # Adaptive perturbation\n        dynamic_local_search_prob = self.local_search_prob + 0.3 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-dynamic_search_width, dynamic_search_width, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Hybrid MAHO+ leveraging dynamic adaptive mutation and diversified local search strategies for enhanced exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.8066916045304472, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.014. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.809789145457823, 0.8215711534856175, 0.7887145146479011], "final_y": [0.14962888623647308, 0.1390385426695081, 0.14756404230592768]}, "mutation_prompt": null}
{"id": "6ae5fe37-2f5a-427a-8897-bcb100dcad32", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.3 + 0.4 * (self.evaluations / self.budget)  # Dynamic mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "MAHO+ with dynamically adaptive crossover and mutation factors to enhance exploration-exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.7961980718671172, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.038. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.8471286505400267, 0.7868164117234825, 0.7546491533378425], "final_y": [0.13234451077506637, 0.14860320988464049, 0.15471254918142552]}, "mutation_prompt": null}
{"id": "03d04825-ae74-4f42-982d-fc609509bbec", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            decaying_mutation_factor = self.mutation_factor * (1 - self.evaluations / self.budget)  # Decaying mutation factor\n            mutant = np.clip(a + decaying_mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Introduce a decaying mutation factor to enhance convergence stability and performance.", "configspace": "", "generation": 5, "fitness": 0.7794327152490018, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.779 with standard deviation 0.029. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7908892303343698, 0.8078404241945325, 0.7395684912181033], "final_y": [0.1486160646776602, 0.14179889767915876, 0.14812738476946785]}, "mutation_prompt": null}
{"id": "335e9fe5-e524-404e-aad4-06dbec69cb99", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.6 + 0.3 * np.random.rand()  # Adjusted mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.35  # Increased local search probability\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "MAHO++ with enhanced mutation and exploration for improved convergence and performance.", "configspace": "", "generation": 5, "fitness": 0.7811716470323334, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.781 with standard deviation 0.012. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7932576506165497, 0.7643079177722609, 0.7859493727081894], "final_y": [0.14263667506925282, 0.14524247410590785, 0.15480787332265256]}, "mutation_prompt": null}
{"id": "b41a654e-ed65-4c21-9f4b-08aa54edef77", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation_range = self.robustness_factor * (1 - self.evaluations / self.budget)  # Adjust perturbation based on budget usage\n            perturbation = np.random.uniform(-perturbation_range, perturbation_range, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "MAHO+ improvement by optimizing local search perturbation range based on budget utilization for enhanced solution refinement.", "configspace": "", "generation": 5, "fitness": 0.7829974997562456, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.038. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.8184268385400557, 0.7305056934665083, 0.8000599672621727], "final_y": [0.13958458485963632, 0.1650505997468511, 0.14890202614065762]}, "mutation_prompt": null}
{"id": "c0a60bef-454a-4d08-aabe-a53ac0ad547a", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 3)  # Increased initial population size\n        self.base_mutation_factor = 0.5\n        self.mutation_factor = self.base_mutation_factor + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        dynamic_pop_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))  # Dynamic population scaling\n        for i in range(dynamic_pop_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(dynamic_pop_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = self.base_mutation_factor + 0.2 * np.random.rand()  # Adaptive mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(len(pop)):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO++ with dynamic population scaling and adaptive mutation for improved exploration-exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.7776131129923084, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.778 with standard deviation 0.018. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7615226066912204, 0.8031413572786781, 0.7681753750070266], "final_y": [0.1478206926634852, 0.14084628800158483, 0.14352199722697545]}, "mutation_prompt": null}
{"id": "f88d9304-24f5-402a-9183-1ca025211347", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.4 + 0.5 * np.random.rand()  # Adaptive mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            if self.evaluations / self.budget > 0.3:\n                self.population_size = min(50, self.population_size + 1)  # Gradually increase population size\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO++ with adaptive population size and mutation factor for improved exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {}, "mutation_prompt": null}
{"id": "ee910d1d-0838-4bd6-8580-7fb6fa7430c6", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            # Adaptive robustness scaling based on evaluations\n            self.robustness_factor = 0.05 + 0.1 * (self.evaluations / self.budget)  \n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Improved MAHO+ by incorporating adaptive robustness scaling to enhance robustness and exploration in high-dimensional spaces.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {}, "mutation_prompt": null}
{"id": "c88e6ed7-8dd1-485e-876c-c9c87979eb28", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + int(self.layers_increment * (self.evaluations / self.budget)))  # Dynamic layer increment\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "MAHO++ now includes dynamic adjustment of layer increment to adapt complexity growth during the optimization process.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {}, "mutation_prompt": null}
{"id": "4470a5d3-f2d7-4ccc-8af0-5b9791dc075a", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5 \n        self.robustness_factor = 0.05\n        self.evaluations = 0\n        self.learning_rate = 0.01  # Learning rate for gradient-based local search\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand() \n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            gradient = (func(x + perturbation) - func(x)) / perturbation\n            x_perturbed = np.clip(x - self.learning_rate * gradient, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Hybridized MAHO+ with gradient-based local search and adaptive parameter control to improve convergence and solution quality.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {}, "mutation_prompt": null}
{"id": "5d6e39c0-bec7-457a-a43a-cae87aed1601", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.4 + 0.2 * np.random.rand()  # Adaptive mutation factor adjustment\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO+ with adaptive mutation factor adjustment to improve solution space exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {}, "mutation_prompt": null}
{"id": "e8cc0f83-e35c-4bd5-9604-e48514084687", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            if self.evaluations > self.budget / 2:  # Increase perturbation after half budget\n                perturbation *= 2\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "MAHO++ by elevating perturbation impact for local search refinement beyond mid-budget.", "configspace": "", "generation": 7, "fitness": 0.7883443759262878, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.788 with standard deviation 0.017. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7681363239907186, 0.7871241985719941, 0.8097726052161507], "final_y": [0.1432350621728693, 0.14510041184958422, 0.13896961779139905]}, "mutation_prompt": null}
{"id": "93862ce2-cf36-4948-b3f8-9cc1daf3d28a", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Adaptive mutation factor scaling\n            self.mutation_factor = 0.4 + 0.3 * np.random.rand()\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO+ with adaptive mutation factor scaling for improved exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.7873891181117282, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.787 with standard deviation 0.013. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7732199703180187, 0.8041246914553603, 0.7848226925618057], "final_y": [0.15680081745277819, 0.14070658172714623, 0.13610033427591572]}, "mutation_prompt": null}
{"id": "12b47c76-459a-4a4a-9fcd-6d1061100d61", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial) + np.random.normal(0, 0.01)  # Adding noise to reflect realistic conditions\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Refined adaptive crossover strategy with noise-adjusted selection to improve solution quality under noisy conditions.", "configspace": "", "generation": 7, "fitness": 0.7904721689681667, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.004. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7855257489490222, 0.7917038809676948, 0.7941868769877831], "final_y": [0.14721520043778702, 0.14288708435118458, 0.13919942570195543]}, "mutation_prompt": null}
{"id": "8a8c02f5-0238-4654-ac5f-bf63335f86f4", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.4 + 0.4 * (self.evaluations / self.budget)  # Dynamic mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.6 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Improved adaptive crossover and dynamic mutation factor for enhanced exploration-exploitation balance in MAHO+.", "configspace": "", "generation": 7, "fitness": 0.7956142765600482, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.796 with standard deviation 0.018. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.8202063697091175, 0.7756729033130056, 0.7909635566580213], "final_y": [0.1317084544622127, 0.15300247431604386, 0.14850846019627528]}, "mutation_prompt": null}
{"id": "4f9736e7-98e7-4e86-9674-b7034d4478a3", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 3  # Dynamic layer increment\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutation_rate = 0.4 + 0.1 * (1 - self.evaluations / self.budget)  # Adaptive mutation scaling\n            mutant = np.clip(a + mutation_rate * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhanced MAHO+ with dynamic layer increment and adaptive mutation for improved exploration and refinement balance.", "configspace": "", "generation": 7, "fitness": 0.7898065864019627, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.007. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7797038226357523, 0.7949687660634905, 0.7947471705066451], "final_y": [0.1558089128682526, 0.1330233822473229, 0.13905119572218383]}, "mutation_prompt": null}
{"id": "bcdff5fd-31ce-42af-aa0e-792e0b9335b6", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.6 + 0.2 * np.random.rand()  # Adjusted mutation factor scaling\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Improved MAHO+ by refining the mutation factor scaling for better exploration-exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8012135229886992, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.801 with standard deviation 0.013. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.8190625973798433, 0.7952736381472881, 0.789304333438966], "final_y": [0.14409111430160992, 0.1270027532731598, 0.1378881214751615]}, "mutation_prompt": null}
{"id": "d4601135-4153-46e8-9d6d-252a1a862301", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05 \n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            # Dynamic mutation factor based on convergence\n            dynamic_mutation_factor = self.mutation_factor * (1 - self.evaluations / self.budget)\n            mutant = np.clip(a + dynamic_mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)\n        if np.random.rand() < dynamic_local_search_prob:\n            # Layer-wise adaptive perturbation\n            perturbation = np.random.uniform(-self.robustness_factor / np.sqrt(self.dim), \n                                             self.robustness_factor / np.sqrt(self.dim), x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Enhance MAHO+ by integrating adaptive layer-wise perturbation and convergence-focused dynamic mutation.", "configspace": "", "generation": 8, "fitness": 0.798730515289432, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.015. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7803415910358388, 0.7988742508721083, 0.8169757039603488], "final_y": [0.15245288198679485, 0.12923601732566303, 0.12180579344723319]}, "mutation_prompt": null}
{"id": "094d63c1-a773-4dd0-aea7-2fc78581363a", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            self.mutation_factor = 0.3 + 0.4 * (self.evaluations / self.budget)  # Dynamic mutation factor\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        self.population_size = min(self.population_size, int(self.budget / self.dim))  # Adaptive population size\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Improved MAHO+ with dynamic mutation factor and adaptive population size for better exploration and exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.7864970579980671, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.786 with standard deviation 0.052. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.816586050748549, 0.8295533196289043, 0.7133518036167483], "final_y": [0.13208248961978075, 0.12875872885781803, 0.18102684689897497]}, "mutation_prompt": null}
{"id": "9bd8a903-4f75-4de8-af8c-c5dd186c7718", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            adaptive_mutation_factor = self.mutation_factor * (0.9 + 0.1 * np.random.rand())  # Adaptive mutation factor\n            mutant = np.clip(a + adaptive_mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.2 * (self.evaluations / self.budget)  # Dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            self.population_size = min(max(5, int(self.dimension_factor() * self.dim)), self.population_size)  # Adaptive population size\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]\n\n    def dimension_factor(self):\n        return 0.75 + 0.25 * (self.evaluations / self.budget)  # Scaling function for population size", "name": "MAHO", "description": "Improved MAHO+ with weighted mutation factor and adaptive population size adjustment for better exploration and exploitation.", "configspace": "", "generation": 8, "fitness": 0.8056365427618913, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.806 with standard deviation 0.039. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.858788804077669, 0.7676987509037313, 0.7904220733042738], "final_y": [0.1289088808454547, 0.1439274151719815, 0.14146005078368606]}, "mutation_prompt": null}
{"id": "40efc2bc-9d2e-4879-935f-394486ca0283", "solution": "import numpy as np\n\nclass MAHO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(5, dim * 2)\n        self.mutation_factor = 0.5 + 0.3 * np.random.rand()  # Scaled mutation factor\n        self.crossover_prob = 0.7\n        self.local_search_prob = 0.3\n        self.layers_increment = 5  # Increment layers gradually\n        self.robustness_factor = 0.05  # Small perturbation factor\n        self.evaluations = 0\n\n    def differential_evolution(self, pop, func):\n        next_pop = []\n        for i in range(self.population_size):\n            if self.evaluations >= self.budget:\n                break\n            indices = list(range(self.population_size))\n            indices.remove(i)\n            a, b, c = pop[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.mutation_factor * (b - c), func.bounds.lb, func.bounds.ub)\n            self.crossover_prob = 0.5 + 0.2 * np.random.rand()  # Adaptive crossover probability scaling\n            cross_points = np.random.rand(self.dim) < self.crossover_prob\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_cost = func(trial)\n            self.evaluations += 1\n            if trial_cost < func(pop[i]):\n                next_pop.append(trial)\n            else:\n                next_pop.append(pop[i])\n        return np.array(next_pop)\n\n    def local_search(self, x, func):\n        dynamic_local_search_prob = self.local_search_prob + 0.3 * (self.evaluations / self.budget) ** 2  # Enhanced dynamic local search probability\n        if np.random.rand() < dynamic_local_search_prob:\n            perturbation = np.random.uniform(-self.robustness_factor, self.robustness_factor, x.shape)\n            x_perturbed = np.clip(x + perturbation, func.bounds.lb, func.bounds.ub)\n            perturbed_cost = func(x_perturbed)\n            self.evaluations += 1\n            if perturbed_cost < func(x):\n                return x_perturbed\n        return x\n\n    def __call__(self, func):\n        pop = np.random.uniform(func.bounds.lb, func.bounds.ub, (self.population_size, self.dim))\n        while self.evaluations < self.budget:\n            pop = self.differential_evolution(pop, func)\n            for i in range(self.population_size):\n                if self.evaluations >= self.budget:\n                    break\n                pop[i] = self.local_search(pop[i], func)\n            if self.dim < 32 and self.evaluations / self.budget > 0.5:\n                self.dim = min(32, self.dim + self.layers_increment)\n        best_idx = np.argmin([func(ind) for ind in pop])\n        return pop[best_idx]", "name": "MAHO", "description": "Improved dynamic tuning of local search probability to enhance convergence during late optimization stages.", "configspace": "", "generation": 8, "fitness": 0.7790802702218543, "feedback": "The algorithm MAHO got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.779 with standard deviation 0.025. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "d4212672-476e-4def-9f06-e9f852c59902", "metadata": {"aucs": [0.7636282885360628, 0.8147037183009592, 0.7589088038285409], "final_y": [0.15077034456885396, 0.12543922295792242, 0.15287614727586052]}, "mutation_prompt": null}
