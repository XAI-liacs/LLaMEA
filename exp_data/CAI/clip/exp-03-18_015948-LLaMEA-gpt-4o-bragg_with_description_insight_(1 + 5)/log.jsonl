{"id": "acd9b743-7c6f-4c7d-9242-5dce6acbc8da", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]\n\n# Usage of this class would involve creating an instance with a budget and dimensionality, \n# and then calling it with the function to be optimized.", "name": "HybridDE", "description": "A hybrid Differential Evolution algorithm enhanced with Quasi-Oppositional learning and periodicity constraints, combined with local BFGS optimization for fine-tuning.", "configspace": "", "generation": 0, "fitness": 0.9168291241873066, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.045. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": null, "metadata": {"aucs": [0.9608267181775404, 0.9347702977347986, 0.8548903566495809], "final_y": [0.16485629721472783, 0.1648566010583914, 0.2004451527650314]}, "mutation_prompt": null}
{"id": "394b2385-e361-4dbc-9dc1-4314ac82b316", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            F_dynamic = self.F + 0.1 * np.random.rand()  # Dynamic F\n            mutant = np.clip(a + F_dynamic * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        method = 'L-BFGS-B' if np.random.rand() > 0.5 else 'TNC'  # Diversified local search\n        res = minimize(self.func, x, method=method, bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with dynamic parameter tuning and diversified local search strategies for improved convergence and exploitative efficiency.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('`x0` violates bound constraints.').", "error": "ValueError('`x0` violates bound constraints.')", "parent_id": "acd9b743-7c6f-4c7d-9242-5dce6acbc8da", "metadata": {}, "mutation_prompt": null}
{"id": "81a75920-ad13-412e-9d00-245eea10b892", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]\n\n# Usage of this class would involve creating an instance with a budget and dimensionality, \n# and then calling it with the function to be optimized.", "name": "HybridDE", "description": "Enhanced HybridDE by adjusting crossover probability for improved exploration-exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.925444574656317, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.046. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "acd9b743-7c6f-4c7d-9242-5dce6acbc8da", "metadata": {"aucs": [0.9608265290293865, 0.8607520865476423, 0.9547551083919223], "final_y": [0.1648568120720293, 0.20044561257493576, 0.16485615500419037]}, "mutation_prompt": null}
{"id": "36a0680a-3bf0-4e2d-854a-087d32513386", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x = np.tile(x[:period], self.dim // period)  # Ensure full replication\n        return x\n\n    def local_optimization(self, x):\n        if np.random.rand() < 0.2:  # Adjusted probability\n            res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n            return res.x if res.success else x\n        return x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with improved periodic pattern application and selective local optimization.", "configspace": "", "generation": 1, "fitness": 0.9002775369006609, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.041. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "acd9b743-7c6f-4c7d-9242-5dce6acbc8da", "metadata": {"aucs": [0.9559306175049186, 0.8594236628069559, 0.8854783303901084], "final_y": [0.16485622814187484, 0.18813073690422855, 0.1818843309747039]}, "mutation_prompt": null}
{"id": "3f632166-89d5-4277-a1b3-bb02ac27b159", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.4 + 0.3 * np.random.rand()  # Adaptive F\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            self.CR = 0.8 + 0.2 * np.random.rand()  # Adaptive CR\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "An improved HybridDE algorithm with adaptive Differential weight and crossover probability for enhanced exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.880429234234334, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.028. And the mean value of best solutions found was 0.188 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "acd9b743-7c6f-4c7d-9242-5dce6acbc8da", "metadata": {"aucs": [0.8961155712472076, 0.8409735061034865, 0.9041986253523073], "final_y": [0.18187832609588306, 0.20044678943551242, 0.18188377320867566]}, "mutation_prompt": null}
{"id": "99e826b1-b55e-4824-897b-3e6671b8ee3c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = np.random.choice(range(self.population_size), 3, replace=False)\n            a, b, c = population[idxs]  # Modify this line to select random individuals\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved the selection of individuals for DE mutation to enhance diversity and exploration capability.", "configspace": "", "generation": 1, "fitness": 0.8672210306755433, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.026. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "acd9b743-7c6f-4c7d-9242-5dce6acbc8da", "metadata": {"aucs": [0.9035496025539506, 0.8468325949786677, 0.8512808944940117], "final_y": [0.18187834609944697, 0.1881318466940749, 0.18813377433440315]}, "mutation_prompt": null}
{"id": "d439a279-11d4-4c3b-82e8-09b8259bc377", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.3  # Differential weight (reduced for better fine-tuning)\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhance hybrid exploration-exploitation by reducing differential weight for better fine-tuning.", "configspace": "", "generation": 2, "fitness": 0.9151170403910012, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.067. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.9608265290293865, 0.9634983556407362, 0.8210262365028811], "final_y": [0.1648568120720293, 0.16485656290281558, 0.1818843309747039]}, "mutation_prompt": null}
{"id": "1505eaff-f3e0-40f2-9c2e-dce3850f3921", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            self.CR = 0.9 + 0.1 * (self.evaluations / self.budget)  # Adaptive CR\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < (0.05 + 0.05 * (1 - fitness[i]/max(fitness))):  # Dynamic frequency\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduced adaptive crossover probability and dynamic local optimization frequency in HybridDE for enhanced performance.", "configspace": "", "generation": 2, "fitness": 0.8823247672952016, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.033. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.863078613459181, 0.9290949165702167, 0.8548007718562072], "final_y": [0.18187950887489912, 0.1648566010583914, 0.2004450301152726]}, "mutation_prompt": null}
{"id": "8fa643d0-b3bf-4b0e-9870-9ecc29964e0d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            adapted_F = 0.4 + 0.1 * np.random.rand()  # Adaptive differential weight\n            mutant = np.clip(a + adapted_F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE by incorporating adaptive differential weight for improved convergence speed and precision.", "configspace": "", "generation": 2, "fitness": 0.8871226923702139, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.013. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.8889293812866808, 0.8707188270490158, 0.9017198687749455], "final_y": [0.18187908472922565, 0.18187971045709161, 0.16485615500419037]}, "mutation_prompt": null}
{"id": "680a94ee-14c5-43e0-beea-f9ccd4756f47", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def dynamic_mutation(self, population, i):\n        idxs = [idx for idx in range(self.population_size) if idx != i]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        return np.clip(a + self.F * (b - c), self.lb, self.ub)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            mutant = self.dynamic_mutation(population, i)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)\n        repetitions = self.dim // period\n        x[:period] = np.repeat(np.mean(x[:period]), period)\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1: \n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved HybridDE by introducing adaptive mutation strategies and enhancing periodicity constraints.", "configspace": "", "generation": 2, "fitness": 0.9148370166252976, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.032. And the mean value of best solutions found was 0.173 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.9580166102213953, 0.9041700467092451, 0.8823243929452526], "final_y": [0.1648605080497576, 0.16485791396692184, 0.18813377433440315]}, "mutation_prompt": null}
{"id": "e48ac7e3-ff61-40a9-9c79-3987526423e6", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.15:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Refined HybridDE by adjusting local optimization probability to improve local search accuracy.", "configspace": "", "generation": 2, "fitness": 0.901909628079185, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.045. And the mean value of best solutions found was 0.179 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.9373503042948572, 0.8380409003282145, 0.9303376796144831], "final_y": [0.16485851521328132, 0.20725467842384904, 0.16485615500419037]}, "mutation_prompt": null}
{"id": "44b04491-eff5-4a74-9ad2-af8e4615d33c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Initial differential weight\n        self.CR = 0.95  # Crossover probability (unchanged)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.5 + np.random.rand() * 0.3  # Adaptive differential weight\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period\n        pattern = np.tile(x[:period], self.dim // period)\n        x[:len(pattern)] = pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with adaptive differential weight and periodicity-based local search for improved performance.", "configspace": "", "generation": 3, "fitness": 0.8886211921921392, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.025. And the mean value of best solutions found was 0.177 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.906421255021853, 0.9061486262493954, 0.8532936953051694], "final_y": [0.16485646396897013, 0.1648566010583914, 0.20044557117307593]}, "mutation_prompt": null}
{"id": "47a04412-6ff8-4ec6-9b7a-e1bb888ea6f9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.9  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Slightly reduce the crossover probability in HybridDE for better exploration capabilities.", "configspace": "", "generation": 3, "fitness": 0.8556832897016343, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.028. And the mean value of best solutions found was 0.197 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.8432121515956537, 0.8296166187139522, 0.8942210987952971], "final_y": [0.20725523120693268, 0.20044699469129656, 0.18187939951712428]}, "mutation_prompt": null}
{"id": "150442c0-8083-492f-abc2-56163e6627b5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.4 + 0.1 * np.random.rand()  # Adaptive mutation strategy (changed line)\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved HybridDE by integrating adaptive mutation strategies to enhance search adaptability without increasing code length.", "configspace": "", "generation": 3, "fitness": 0.8642304790053528, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.028. And the mean value of best solutions found was 0.185 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.8906005464835173, 0.8762555771746441, 0.8258353133578971], "final_y": [0.1818785424609325, 0.16485791396692184, 0.2072565648364656]}, "mutation_prompt": null}
{"id": "0df25355-1c6a-4cba-90ed-11271a9a696e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.85  # Crossover probability (reduced for better genetic diversity)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved exploration in HybridDE by reducing crossover probability to increase genetic diversity.", "configspace": "", "generation": 3, "fitness": 0.8745727043680174, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.021. And the mean value of best solutions found was 0.178 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.8652943063495946, 0.9033765032101788, 0.8550473035442786], "final_y": [0.18187878472236674, 0.16485791396692184, 0.18813377433440315]}, "mutation_prompt": null}
{"id": "b4be5f27-6519-482b-b2b9-9dac0f7721e1", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        best_idx = np.argmin(fitness)  # Elitism: track the best solution\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.5 + 0.3 * np.random.rand()  # Adaptive mutation factor\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        new_population[0] = population[best_idx]  # Retain the best individual\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with adaptive mutation and elitism to balance exploration and exploitation while leveraging periodicity.", "configspace": "", "generation": 3, "fitness": 0.8690248646987279, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.027. And the mean value of best solutions found was 0.182 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.8911416235528871, 0.8854157969874277, 0.8305171735558692], "final_y": [0.16485623343029143, 0.18188004870843022, 0.20044569388494426]}, "mutation_prompt": null}
{"id": "d811f7da-3a9b-4861-a004-bb55bdf2496f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = np.random.uniform(0.3, 0.9)  # Adaptive differential weight\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduced adaptive differential weight in HybridDE for improved exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.9463651069800018, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.946 with standard deviation 0.018. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.9418160652037058, 0.9264758162296349, 0.9708034395066645], "final_y": [0.16485790130074462, 0.1648566010583914, 0.16485641635669301]}, "mutation_prompt": null}
{"id": "697d4320-6090-4b6f-a8de-10f5688d7837", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x[:period] = x[:period] * (self.dim // period)  # Repeat pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            if np.random.rand() < 0.1:  # Occasionally reinitialize population\n                population, fitness = self.quasi_oppositional_initialization(func.bounds)\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhancing exploration by applying quasi-oppositional initialization multiple times within the optimization process.", "configspace": "", "generation": 4, "fitness": 0.9426442913419137, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.943 with standard deviation 0.035. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.8928660777519419, 0.9659615965758631, 0.9691051996979362], "final_y": [0.1648625468803926, 0.16485649502413602, 0.16485619143696528]}, "mutation_prompt": null}
{"id": "42675df6-c414-4630-bc98-cf081d5bbf17", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = 0.5 + 0.3 * np.random.rand()  # Adaptive mutation factor\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2) \n        x[:period] = x[:period] * (self.dim // period) \n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.15:  # Increased local optimization frequency\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE by integrating adaptive mutation factor and increased local search frequency for improved convergence speed and solution quality.", "configspace": "", "generation": 4, "fitness": 0.9410255874476233, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.941 with standard deviation 0.038. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.8869927853860224, 0.9659615965758631, 0.9701223803809843], "final_y": [0.18187902113597298, 0.16485649502413602, 0.16485601471948885]}, "mutation_prompt": null}
{"id": "41d6adec-cf0f-48e3-a17d-803fa9b8cecc", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adjusted for better exploration)\n        self.lb = None\n        self.ub = None\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            F_adaptive = np.random.uniform(0.4, 0.9)  # Adaptive differential weight\n            mutant = np.clip(a + F_adaptive * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = int(self.dim / 2)  # Assume a 2-layer period \n        x_transformed = x[:period].repeat(self.dim // period)  # Improved periodicity application\n        return x_transformed\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:  # Occasionally apply local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved HybridDE by introducing adaptive differential weight (F) and periodic constraint adjustments for better solution convergence.", "configspace": "", "generation": 4, "fitness": 0.9494533890329633, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.949 with standard deviation 0.026. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.9122763820134582, 0.9659619167145106, 0.9701218683709214], "final_y": [0.16485749974743746, 0.1648561271165253, 0.16485619143696528]}, "mutation_prompt": null}
{"id": "3e34faa2-2d33-4b95-9424-a1edffcf54db", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR *= self.adaptive_factor  # New: Adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2  # Changed: Fixed 2-layer periodicity \n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved HybridDE by integrating adaptive strategies and periodicity enforcement to enhance exploration and convergence.", "configspace": "", "generation": 4, "fitness": 0.9594824459649223, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "81a75920-ad13-412e-9d00-245eea10b892", "metadata": {"aucs": [0.9637454734267393, 0.9659615965758631, 0.9487402678921644], "final_y": [0.1648561537231501, 0.16485649502413602, 0.16485604581892177]}, "mutation_prompt": null}
{"id": "f655ba53-e014-4b35-91be-2c84759e81d9", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.92  # New: Slightly increased adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR *= self.adaptive_factor  # New: Adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2  # Changed: Fixed 2-layer periodicity \n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced adaptive control by increasing the adaptive factor slightly to better balance exploration and exploitation.", "configspace": "", "generation": 5, "fitness": 0.9185746391057362, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.027. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3e34faa2-2d33-4b95-9424-a1edffcf54db", "metadata": {"aucs": [0.9461070964070434, 0.8818419628092884, 0.927774858100877], "final_y": [0.16485614762201084, 0.1648564182418535, 0.16485671239294186]}, "mutation_prompt": null}
{"id": "969259d3-25cb-4403-bc3d-166554230081", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            F_dynamic = self.F / (1 + 0.1 * i / self.population_size)  # Changed: Dynamic F\n            mutant = np.clip(a + F_dynamic * (b - c), self.lb, self.ub)  # Changed: Use F_dynamic\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR *= self.adaptive_factor  # New: Adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 4  # Changed: Fixed 4-layer periodicity \n        for j in range(0, len(x), period):\n            x[j:j+period] = np.mean(x[j:j+period])  # Changed: Enforce periodic pattern for deeper blocks\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE by incorporating dynamic mutation rate and deeper periodic pattern enforcement for improved solution quality.", "configspace": "", "generation": 5, "fitness": 0.9545597231325255, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.955 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3e34faa2-2d33-4b95-9424-a1edffcf54db", "metadata": {"aucs": [0.9467041392768961, 0.957370407284917, 0.9596046228357631], "final_y": [0.16485710774911044, 0.16485584794624208, 0.16485598307308946]}, "mutation_prompt": null}
{"id": "be914107-088e-430b-8e0b-38c03f9f8b92", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.1  # Changed: More adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2  # Changed: Fixed 2-layer periodicity \n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        x[period:2*period] = x[:period]  # New: Extend periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE by refining CR adaptation and periodic pattern enforcement to boost convergence and robustness.", "configspace": "", "generation": 5, "fitness": 0.9655981093550846, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.966 with standard deviation 0.003. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3e34faa2-2d33-4b95-9424-a1edffcf54db", "metadata": {"aucs": [0.9683579424178776, 0.9621519731215143, 0.966284412525862], "final_y": [0.16485600451564475, 0.16485671527058954, 0.16485599642311255]}, "mutation_prompt": null}
{"id": "ea7fd7af-1295-4a2f-ae7e-b6386217028b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            self.F = np.random.uniform(0.4, 0.9)  # Changed: Dynamic F\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR *= self.adaptive_factor  # New: Adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = np.random.randint(2, 5)  # Changed: Stochastic periodicity\n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE by dynamically adjusting differential weight and introducing stochastic periodicity to improve convergence.", "configspace": "", "generation": 5, "fitness": 0.95808265429573, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3e34faa2-2d33-4b95-9424-a1edffcf54db", "metadata": {"aucs": [0.9589414539364454, 0.9634268077048141, 0.9518797012459308], "final_y": [0.16485600367070996, 0.1648561271165253, 0.16485598662527023]}, "mutation_prompt": null}
{"id": "0669f664-5593-4f78-91bd-7b7cc4823005", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR *= self.adaptive_factor  # New: Adaptive CR update\n                self.F = 0.5 + 0.3 * np.random.rand()  # Modified: Adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2  # Changed: Fixed 2-layer periodicity \n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.2:  # Modified: Increased local search probability\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE by introducing adaptive mutation factor `F` and increased local search probability to balance exploration and exploitation effectively.", "configspace": "", "generation": 5, "fitness": 0.9587987702734617, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.959 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3e34faa2-2d33-4b95-9424-a1edffcf54db", "metadata": {"aucs": [0.9684588060856013, 0.963427174173916, 0.9445103305608678], "final_y": [0.16485614762201084, 0.16485632119504634, 0.1648567884092309]}, "mutation_prompt": null}
{"id": "5f096220-8956-4afa-bbf3-107d010c69fd", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.7 * self.CR + 0.15  # Modified: More adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 4  # Modified: Dynamic 4-layer periodicity\n        x[:period] = np.mean(x[:period])  # Enforce periodic pattern\n        for j in range(period, len(x), period):  # New: Extend periodic pattern\n            x[j:j+period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Refined Enhanced HybridDE by incorporating frequency-based periodicity and improved adaptive control for CR to increase robustness and convergence efficiency.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('could not broadcast input array from shape (4,) into shape (2,)').", "error": "ValueError('could not broadcast input array from shape (4,) into shape (2,)')", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {}, "mutation_prompt": null}
{"id": "57267ce3-818c-4a89-b6dd-cd7651792066", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.1  # Changed: More adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2 + np.random.randint(0, self.dim // 10)  # Changed: Dynamically adjust periodic block size\n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        x[period:2*period] = x[:period]  # New: Extend periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhance periodicity by dynamically adjusting the periodic block size to adaptively match problem-specific patterns.", "configspace": "", "generation": 6, "fitness": 0.9652007802424688, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.965 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {"aucs": [0.9716531949274829, 0.953570806400539, 0.9703783393993844], "final_y": [0.16485602538314326, 0.16485582371553498, 0.16485599302595577]}, "mutation_prompt": null}
{"id": "1941b971-db59-497b-a82c-8793a98cec7b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.1  # Changed: More adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = np.random.randint(1, 4)  # Changed: Adaptive period length\n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        x[period:2*period] = x[:period]  # New: Extend periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Adaptive periodicity by varying period length within constraints for enhanced solution exploration.", "configspace": "", "generation": 6, "fitness": 0.9310482872745386, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.011. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {"aucs": [0.939078499615125, 0.9161677285539919, 0.9378986336544992], "final_y": [0.1648580425221836, 0.16485685252487225, 0.16486017818948184]}, "mutation_prompt": null}
{"id": "52657929-71c5-4c59-9e56-e12e9a86a834", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.85  # Changed: More aggressive adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.15  # Changed: More adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2  # Fixed 2-layer periodicity \n        x[:period] = np.mean(x[:period])  # Enforce periodic pattern\n        x[period:2*period] = x[:period]  # Extend periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved CR adaptation and periodicity enforcement to achieve better solution convergence and robustness.", "configspace": "", "generation": 6, "fitness": 0.9441231351578634, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.944 with standard deviation 0.024. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {"aucs": [0.9716531949274829, 0.9484707642771545, 0.9122454462689529], "final_y": [0.16485602538314326, 0.16485602372451014, 0.16485623656904858]}, "mutation_prompt": null}
{"id": "2059179a-ebbf-4e33-ab3c-a959ed184fdb", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            if fitness[i] > np.median(fitness):  # Changed: Improved mutant selection strategy\n                a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n                mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.1  # Changed: More adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2  # Changed: Fixed 2-layer periodicity \n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        x[period:2*period] = x[:period]  # New: Extend periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Optimized DE step by improving mutant vector selection strategy for better convergence.", "configspace": "", "generation": 6, "fitness": 0.9580387770506528, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.958 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {"aucs": [0.9581214262410076, 0.9682674755966362, 0.9477274293143142], "final_y": [0.16485636194564823, 0.16485601381116444, 0.16485621918154514]}, "mutation_prompt": null}
{"id": "e544bb5d-1c7e-4e61-9201-d9d4c0205bd7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.85 * self.CR + 0.15  # Changed: More adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2  # Changed: Fixed 2-layer periodicity \n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        x[period:2*period] = x[:period]  # New: Extend periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Further refined HybridDE by enhancing CR adaptation and dynamic periodic pattern enforcement to improve convergence efficiency and robustness.", "configspace": "", "generation": 7, "fitness": 0.9526930146339655, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.953 with standard deviation 0.026. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {"aucs": [0.9716531949274829, 0.9160488777246028, 0.9703769712498108], "final_y": [0.16485602538314326, 0.1648562877019627, 0.16485612891398027]}, "mutation_prompt": null}
{"id": "b4748bfa-ad98-4c4a-a0e8-42e49b3439e7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.8  # Changed: Increased Differential weight for exploration\n        self.CR = 0.9  # Changed: Adjusted crossover probability\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.85  # Tuned: Improved adaptive factor\n        self.periodicity = 2 + (dim // 10)  # New: Dynamic periodicity based on dimension\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.7 * self.CR + 0.15  # Changed: Enhanced adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = self.periodicity  # Changed: Use dynamic periodicity\n        for start in range(0, self.dim, period):\n            x[start:start+period] = np.mean(x[start:start+period])  # Changed: Dynamic periodic enforcement\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.2:  # Changed: Increase chance for local optimization\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Optimized HybridDE by enhancing mutation strategy, incorporating dynamic periodicity, and refining local search for improved performance.", "configspace": "", "generation": 7, "fitness": 0.963419274021852, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {"aucs": [0.9561386930861577, 0.9661150448048577, 0.9680040841745406], "final_y": [0.1648564846554531, 0.16485656522363845, 0.16485589109032217]}, "mutation_prompt": null}
{"id": "5ab052d3-e03b-4c82-93df-d4ddef65aacf", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.9 * self.F + 0.1  # New: Adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with adaptive F and CR for improved exploration and exploitation dynamics.", "configspace": "", "generation": 7, "fitness": 0.9685160036517152, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.969 with standard deviation 0.002. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {"aucs": [0.9716531949274829, 0.9658906336602737, 0.9680041823673888], "final_y": [0.16485602538314326, 0.16485601381116444, 0.16485647955256844]}, "mutation_prompt": null}
{"id": "379b05ae-e686-431e-9515-f030631f5eb5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 * dim\n        self.F = 0.5\n        self.CR = 0.95\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n        self.population_size = self.initial_population_size\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.7 * self.CR + 0.15  # More adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = max(2, np.random.randint(2, self.dim // 2))  # Adaptive periodicity\n        for i in range(0, self.dim, period):\n            x[i:i+period] = np.mean(x[i:i+period])\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def adapt_population_size(self):\n        self.population_size = max(self.initial_population_size // 2, int(self.population_size * 0.95))\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            self.adapt_population_size()  # Adaptive population size\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Incorporate adaptive population size and dynamic period enforcement to further enhance solution robustness and convergence speed.", "configspace": "", "generation": 7, "fitness": 0.9573111260259903, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.957 with standard deviation 0.008. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {"aucs": [0.9595172789324651, 0.965646057524832, 0.9467700416206739], "final_y": [0.16485609485575226, 0.16485582371553498, 0.1648558152180455]}, "mutation_prompt": null}
{"id": "659fa0c8-5feb-4791-9d35-9a7f42cb014b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9  # New: Adaptive factor for CR\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n    \n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            F_dynamic = self.F + 0.3 * np.random.rand()  # Changed: Adaptive F\n            mutant = np.clip(a + F_dynamic * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.1  # Changed: More adaptive CR update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = np.random.randint(1, 3)  # Changed: Randomize period length\n        x[:period] = np.mean(x[:period])  # New: Enforce periodic pattern\n        x[period:2*period] = x[:period]  # New: Extend periodic pattern\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n        \n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with adaptive mutation scaling and dynamic periodic pattern length to optimize reflectivity in multilayer photonic structures.", "configspace": "", "generation": 7, "fitness": 0.9513766433821358, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.951 with standard deviation 0.022. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "be914107-088e-430b-8e0b-38c03f9f8b92", "metadata": {"aucs": [0.9674209711340659, 0.9658906336602737, 0.9208183253520676], "final_y": [0.1648565202577531, 0.16485601381116444, 0.1648567060072701]}, "mutation_prompt": null}
{"id": "7fb1ae2c-9bd2-49ee-8780-38b2617ef976", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.8 * self.CR + 0.1  # Changed: Strategic CR update\n                self.F = 0.85 * self.F + 0.15  # Changed: Refined F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Enhanced HybridDE with strategic CR/F adjustments and refined periodicity constraints for superior optimization.", "configspace": "", "generation": 8, "fitness": 0.9356772819416818, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.936 with standard deviation 0.021. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5ab052d3-e03b-4c82-93df-d4ddef65aacf", "metadata": {"aucs": [0.9478332730382604, 0.9064406270179955, 0.9527579457687895], "final_y": [0.1648573218733782, 0.16485720455361186, 0.16485590102986125]}, "mutation_prompt": null}
{"id": "ddb7ea08-4ded-45e7-880f-6cd55a4ecad2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.9 * self.F + 0.1  # New: Adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:] = np.tile(x[:period], len(x[period:]) // period)  # Enhanced periodicity throughout\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "HybridDE with enhanced adaptive crossover and improved periodicity constraints for better solution quality.", "configspace": "", "generation": 8, "fitness": 0.9617913524580707, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.962 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5ab052d3-e03b-4c82-93df-d4ddef65aacf", "metadata": {"aucs": [0.9733288028458454, 0.963910516530611, 0.9481347379977559], "final_y": [0.1648562935033412, 0.16485616538362902, 0.16485830895053333]}, "mutation_prompt": null}
{"id": "495e6edf-ade7-4fca-9101-bc4e4f700b84", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  \n                self.F = 0.8 * self.F + 0.2  # Changed: Adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 5  # Changed: Refined periodicity constraints\n        for i in range(0, self.dim, period):\n            x[i:i+period] = np.mean(x[i:i+period])\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved HybridDE with refined periodic constraints and adaptive mutation to enhance convergence and exploration.", "configspace": "", "generation": 8, "fitness": 0.9642376075195802, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.964 with standard deviation 0.006. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5ab052d3-e03b-4c82-93df-d4ddef65aacf", "metadata": {"aucs": [0.9677668370125412, 0.9553503588683909, 0.9695956266778085], "final_y": [0.16485773432591, 0.16485604337833715, 0.16485599302595577]}, "mutation_prompt": null}
{"id": "5722a44e-7bca-4949-9046-635896193cf5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = 0.9 * self.F + 0.1  # New: Adaptive F update\n            else:\n                new_population[i] = self.apply_periodicity_constraints(population[i].copy())  # Modified line\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Introduce periodic component insertion during DE steps for enhanced periodicity exploitations.", "configspace": "", "generation": 8, "fitness": 0.9634567493068266, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.963 with standard deviation 0.005. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5ab052d3-e03b-4c82-93df-d4ddef65aacf", "metadata": {"aucs": [0.9684866662350369, 0.9651146832706715, 0.9567688984147715], "final_y": [0.16485592932632231, 0.16485740075303512, 0.16485590102986125]}, "mutation_prompt": null}
{"id": "f727edab-931e-4c7f-b581-ed7144e4de1a", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 * dim\n        self.F = 0.5  # Differential weight (adaptive)\n        self.CR = 0.95  # Crossover probability (adaptive)\n        self.lb = None\n        self.ub = None\n        self.adaptive_factor = 0.9\n\n    def quasi_oppositional_initialization(self, bounds):\n        lb, ub = bounds.lb, bounds.ub\n        pop = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        opposite_pop = lb + ub - pop\n        combined_pop = np.vstack((pop, opposite_pop))\n        fitness = np.array([self.evaluate(ind) for ind in combined_pop])\n        indices = fitness.argsort()[:self.population_size]\n        return combined_pop[indices], fitness[indices]\n\n    def evaluate(self, x):\n        if hasattr(self, 'evaluations') and self.evaluations >= self.budget:\n            return np.inf\n        self.evaluations += 1\n        return self.func(x)\n\n    def de_step(self, population, fitness):\n        new_population = np.zeros_like(population)\n        for i in range(self.population_size):\n            idxs = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + self.F * (b - c), self.lb, self.ub)\n            cross_points = np.random.rand(self.dim) < self.CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, self.dim)] = True\n            trial = np.where(cross_points, mutant, population[i])\n            trial_fitness = self.evaluate(trial)\n            if trial_fitness < fitness[i]:\n                new_population[i] = trial\n                fitness[i] = trial_fitness\n                self.CR = 0.9 * self.CR + 0.05  # Changed: Adaptive CR update\n                self.F = self.adaptive_factor * self.F + 0.15  # Changed: Adaptive F update\n            else:\n                new_population[i] = population[i]\n        return new_population, fitness\n\n    def apply_periodicity_constraints(self, x):\n        period = 2\n        x[:period] = np.mean(x[:period])\n        x[period:2*period] = x[:period]\n        return x\n\n    def local_optimization(self, x):\n        res = minimize(self.func, x, method='L-BFGS-B', bounds=list(zip(self.lb, self.ub)))\n        return res.x if res.success else x\n\n    def __call__(self, func):\n        self.func = func\n        self.lb, self.ub = func.bounds.lb, func.bounds.ub\n        self.evaluations = 0\n        population, fitness = self.quasi_oppositional_initialization(func.bounds)\n        \n        while self.evaluations < self.budget:\n            population, fitness = self.de_step(population, fitness)\n            for i in range(self.population_size):\n                if np.random.rand() < 0.1:\n                    x_periodic = self.apply_periodicity_constraints(population[i].copy())\n                    population[i] = self.local_optimization(x_periodic)\n                    fitness[i] = self.evaluate(population[i])\n\n        best_idx = np.argmin(fitness)\n        return population[best_idx]", "name": "HybridDE", "description": "Improved Adaptive Factor for Differential Weight (F) to Enhance Exploration-Exploitation Balance.", "configspace": "", "generation": 8, "fitness": 0.9543184714378565, "feedback": "The algorithm HybridDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.954 with standard deviation 0.010. And the mean value of best solutions found was 0.165 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "5ab052d3-e03b-4c82-93df-d4ddef65aacf", "metadata": {"aucs": [0.9676560138444528, 0.9453219757776512, 0.9499774246914656], "final_y": [0.16485602538314326, 0.16485604337833715, 0.1648560206859465]}, "mutation_prompt": null}
