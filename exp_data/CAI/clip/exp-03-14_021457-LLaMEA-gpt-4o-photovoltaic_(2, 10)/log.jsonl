{"id": "ab1bf53d-9d5f-4364-9538-03edff631733", "solution": "import numpy as np\n\nclass QuantumInspiredEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.best_solution = None\n        self.best_value = float('inf')\n        \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def evaluate_population(self, func, population):\n        values = np.array([func(ind) for ind in population])\n        return values\n    \n    def superposition(self, population):\n        mean = np.mean(population, axis=0)\n        std_dev = np.std(population, axis=0)\n        return np.random.normal(mean, std_dev, (self.population_size, self.dim))\n    \n    def update_best(self, population, values):\n        min_idx = np.argmin(values)\n        if values[min_idx] < self.best_value:\n            self.best_value = values[min_idx]\n            self.best_solution = population[min_idx]\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            values = self.evaluate_population(func, population)\n            self.update_best(population, values)\n            if evaluations + self.population_size > self.budget:\n                break\n            population = self.superposition(population)\n            population = np.clip(population, lb, ub)\n            evaluations += self.population_size\n        \n        return self.best_solution, self.best_value", "name": "QuantumInspiredEvolutionaryOptimizer", "description": "A novel metaheuristic algorithm called \"Quantum-Inspired Evolutionary Optimization\" that incorporates principles of quantum computing such as superposition and entanglement to explore the search space more efficiently.", "configspace": "", "generation": 0, "fitness": 0.765644532125847, "feedback": "The algorithm QuantumInspiredEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.766 with standard deviation 0.017. And the mean value of best solutions found was 0.170 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7437288559720264, 0.7855275180527245, 0.7676772223527902], "final_y": [0.17840012540388295, 0.16359539081792596, 0.1693275179722089]}, "mutation_prompt": null}
{"id": "39133867-8680-4756-a478-bd1e6fb197b8", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic algorithm combining Differential Evolution and Local Search to explore and exploit the search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8190816341213933, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.819 with standard deviation 0.008. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8293466225796007, 0.8106521131436816, 0.8172461666408981], "final_y": [0.1324942892895089, 0.15176587426756039, 0.1465085382827419]}, "mutation_prompt": null}
{"id": "3e2aa064-a0bd-40c7-8a5a-6b103660379c", "solution": "import numpy as np\n\nclass QuantumInspiredEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.best_solution = None\n        self.best_value = float('inf')\n        \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def evaluate_population(self, func, population):\n        values = np.array([func(ind) for ind in population])\n        return values\n    \n    def superposition(self, population):\n        mean = np.mean(population, axis=0)\n        std_dev = np.std(population, axis=0)\n        return np.random.normal(mean, std_dev, (self.population_size, self.dim))\n    \n    def update_best(self, population, values):\n        min_idx = np.argmin(values)\n        if values[min_idx] < self.best_value:\n            self.best_value = values[min_idx]\n            self.best_solution = population[min_idx]\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            values = self.evaluate_population(func, population)\n            self.update_best(population, values)\n            if evaluations + self.population_size > self.budget:\n                break\n            population = self.superposition(population)\n            population = np.clip(population, lb, ub)\n            evaluations += self.population_size\n            self.population_size = max(5, int(self.population_size * 0.9))  # Adaptive adjustment\n\n        return self.best_solution, self.best_value", "name": "QuantumInspiredEvolutionaryOptimizer", "description": "Enhanced Quantum-Inspired Evolutionary Optimization with adaptive population size based on performance.  ", "configspace": "", "generation": 1, "fitness": 0.7340237270189728, "feedback": "The algorithm QuantumInspiredEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.734 with standard deviation 0.025. And the mean value of best solutions found was 0.185 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "ab1bf53d-9d5f-4364-9538-03edff631733", "metadata": {"aucs": [0.7139975465065167, 0.76890311738062, 0.7191705171697818], "final_y": [0.19250048396369146, 0.1702433386818767, 0.19103396660959382]}, "mutation_prompt": null}
{"id": "9d4a2245-3379-4b19-b0a6-4a9dae1c4466", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Update crossover probability based on fitness improvement\n                CR = 0.5 + 0.4 * (best_fitness - fitness[i]) / abs(best_fitness) if best_fitness != 0 else 0.9\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced HybridMetaheuristic incorporating adaptive crossover probability to improve exploration and exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.7917704477238448, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.003. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "39133867-8680-4756-a478-bd1e6fb197b8", "metadata": {"aucs": [0.7934923452582328, 0.7878494493635668, 0.7939695485497346], "final_y": [0.15551311460784212, 0.14535587357814217, 0.1464222670265526]}, "mutation_prompt": null}
{"id": "9a743dfa-3529-4801-a362-c607e66c64b9", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Dynamic adjustment of parameters\n            F = 0.5 + 0.5 * (1 - func_evals / self.budget)  # Adjust F linearly\n            CR = 0.9 - 0.4 * (func_evals / self.budget)  # Adjust CR linearly\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic that dynamically adjusts Differential Evolution parameters based on the search progress to improve convergence speed and accuracy.", "configspace": "", "generation": 1, "fitness": 0.7981722533801153, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.798 with standard deviation 0.007. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "39133867-8680-4756-a478-bd1e6fb197b8", "metadata": {"aucs": [0.8027426941392506, 0.7886083576657797, 0.8031657083353156], "final_y": [0.14737152700413514, 0.1476801085671079, 0.14986381895910839]}, "mutation_prompt": null}
{"id": "37114660-7a42-46c8-8eb8-945b7010fa14", "solution": "import numpy as np\n\nclass QuantumInspiredEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = max(2, budget // (5 * dim))\n        self.best_solution = None\n        self.best_value = float('inf')\n        \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def evaluate_population(self, func, population):\n        values = np.array([func(ind) for ind in population])\n        return values\n    \n    def superposition(self, population):\n        mean = np.mean(population, axis=0)\n        std_dev = np.std(population, axis=0)\n        return np.random.normal(mean, std_dev, (self.population_size, self.dim))\n    \n    def update_best(self, population, values):\n        min_idx = np.argmin(values)\n        if values[min_idx] < self.best_value:\n            self.best_value = values[min_idx]\n            self.best_solution = population[min_idx]\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            values = self.evaluate_population(func, population)\n            self.update_best(population, values)\n            if evaluations + self.population_size > self.budget:\n                break\n            population = self.superposition(population)\n            population = np.clip(population, lb, ub)\n            evaluations += self.population_size\n        \n        return self.best_solution, self.best_value", "name": "QuantumInspiredEvolutionaryOptimizer", "description": "Improved Quantum-Inspired Evolutionary Optimization by incorporating adaptive population size for enhanced exploration and exploitation.", "configspace": "", "generation": 1, "fitness": 0.7538200382891099, "feedback": "The algorithm QuantumInspiredEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.754 with standard deviation 0.025. And the mean value of best solutions found was 0.175 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "ab1bf53d-9d5f-4364-9538-03edff631733", "metadata": {"aucs": [0.7733864803169282, 0.76890311738062, 0.7191705171697818], "final_y": [0.16421308631871512, 0.1702433386818767, 0.19103396660959382]}, "mutation_prompt": null}
{"id": "11fef91f-1be8-4210-8298-50950cf06cc8", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n            \n            F = 0.3 + 0.7 * np.exp(-0.1 * func_evals / self.budget)  # Dynamic adjustment of F\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhancing the exploration of the search space by adjusting the mutation factor dynamically based on the improvement rate of the best solution over time.", "configspace": "", "generation": 1, "fitness": 0.8032000862718315, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.005. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "39133867-8680-4756-a478-bd1e6fb197b8", "metadata": {"aucs": [0.8105040236711678, 0.8008292225426138, 0.7982670126017131], "final_y": [0.14849790838838783, 0.12937273560101448, 0.13111232612377421]}, "mutation_prompt": null}
{"id": "98fec3a9-7817-4f24-8169-05eb0239e6d0", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive crossover probability\n                CR = 0.8 + 0.2 * np.random.rand()\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.05, self.dim)  # Reduced perturbation\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced Hybrid Metaheuristic with Adaptive Parameters and Gaussian Perturbation for Local Search Refinement.", "configspace": "", "generation": 1, "fitness": 0.8081711011203807, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.012. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "39133867-8680-4756-a478-bd1e6fb197b8", "metadata": {"aucs": [0.8039681339741651, 0.7959276522937231, 0.8246175170932538], "final_y": [0.13807281215671374, 0.15636533437652722, 0.14570214026505923]}, "mutation_prompt": null}
{"id": "29bead09-55f9-4387-9ab7-e9345f613a57", "solution": "import numpy as np\n\nclass AdaptiveHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            for i in range(population_size):\n                # Adaptive mutation factor\n                adapt_factor = (self.budget - func_evals) / self.budget\n                adapt_F = F + adapt_factor * 0.3\n                \n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + adapt_F * (b - c), lb, ub)\n\n                # Adaptive crossover probability\n                adapt_CR = CR - adapt_factor * 0.3\n                crossover = np.random.rand(self.dim) < adapt_CR\n                # Crossover: Create a trial vector\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "AdaptiveHybridMetaheuristic", "description": "The \"Adaptive Hybrid Metaheuristic\" enhances exploration and exploitation by introducing adaptive parameters for mutation and crossover based on current search progress.", "configspace": "", "generation": 1, "fitness": 0.8020971053892803, "feedback": "The algorithm AdaptiveHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.002. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "39133867-8680-4756-a478-bd1e6fb197b8", "metadata": {"aucs": [0.8025472739244508, 0.7996807197984943, 0.8040633224448956], "final_y": [0.1355618147578016, 0.13845199158483779, 0.14639320074372386]}, "mutation_prompt": null}
{"id": "6e676240-94c0-4e6e-bd33-ad1f21bebec5", "solution": "import numpy as np\n\nclass QuantumInspiredEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.best_solution = None\n        self.best_value = float('inf')\n        \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def evaluate_population(self, func, population):\n        values = np.array([func(ind) for ind in population])\n        return values\n    \n    def superposition(self, population):\n        mean = np.mean(population, axis=0)\n        std_dev = np.std(population, axis=0)\n        return np.random.normal(mean, std_dev, (self.population_size, self.dim))\n    \n    def update_best(self, population, values):\n        min_idx = np.argmin(values)\n        if values[min_idx] < self.best_value:\n            self.best_value = values[min_idx]\n            self.best_solution = population[min_idx]\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            values = self.evaluate_population(func, population)\n            self.update_best(population, values)\n            if evaluations + self.population_size > self.budget:\n                break\n            population = self.superposition(population)\n            population = np.clip(population, lb, ub)\n            evaluations += self.population_size\n            self.population_size = max(5, self.population_size - 1)  # Dynamically adjust population size\n        \n        return self.best_solution, self.best_value", "name": "QuantumInspiredEvolutionaryOptimizer", "description": "This refined Quantum-Inspired Evolutionary Optimization algorithm introduces dynamic population size adjustment to enhance search efficiency.", "configspace": "", "generation": 1, "fitness": 0.752731492428438, "feedback": "The algorithm QuantumInspiredEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.753 with standard deviation 0.024. And the mean value of best solutions found was 0.176 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "ab1bf53d-9d5f-4364-9538-03edff631733", "metadata": {"aucs": [0.7701208427349122, 0.76890311738062, 0.7191705171697818], "final_y": [0.1677621434359059, 0.1702433386818767, 0.19103396660959382]}, "mutation_prompt": null}
{"id": "fcf61381-0fb8-4840-a292-fe1d6bb0dea2", "solution": "import numpy as np\n\nclass QuantumInspiredEvolutionaryOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.best_solution = None\n        self.best_value = float('inf')\n        \n    def initialize_population(self, lb, ub):\n        return np.random.uniform(lb, ub, (self.population_size, self.dim))\n    \n    def evaluate_population(self, func, population):\n        values = np.array([func(ind) for ind in population])\n        return values\n    \n    def superposition(self, population):\n        mean = np.mean(population, axis=0)\n        std_dev = np.std(population, axis=0)\n        return np.random.normal(mean, std_dev, (self.population_size, self.dim))\n    \n    def update_best(self, population, values):\n        min_idx = np.argmin(values)\n        if values[min_idx] < self.best_value:\n            self.best_value = values[min_idx]\n            self.best_solution = population[min_idx]\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population = self.initialize_population(lb, ub)\n        evaluations = 0\n        \n        while evaluations < self.budget:\n            values = self.evaluate_population(func, population)\n            self.update_best(population, values)\n            if evaluations + self.population_size > self.budget:\n                break\n            population = self.superposition(population)\n            mutation = np.random.uniform(-0.01, 0.01, population.shape) # Line changed for mutation\n            population = np.clip(population + mutation, lb, ub)\n            evaluations += self.population_size\n        \n        return self.best_solution, self.best_value", "name": "QuantumInspiredEvolutionaryOptimizer", "description": "Enhance Quantum-Inspired Evolutionary Optimization by adding a mutation step for increased diversity.", "configspace": "", "generation": 1, "fitness": 0.7625424559590831, "feedback": "The algorithm QuantumInspiredEvolutionaryOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.763 with standard deviation 0.027. And the mean value of best solutions found was 0.172 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "ab1bf53d-9d5f-4364-9538-03edff631733", "metadata": {"aucs": [0.7263219447698018, 0.76890311738062, 0.7924023057268273], "final_y": [0.18690187265835045, 0.1702433386818767, 0.16029015882708175]}, "mutation_prompt": null}
{"id": "81b5f279-f105-448d-99f6-d38ea37310df", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic algorithm with adaptive crossover probability to better balance exploration and exploitation.", "configspace": "", "generation": 1, "fitness": 0.8143496445620407, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.022. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "39133867-8680-4756-a478-bd1e6fb197b8", "metadata": {"aucs": [0.796845266477859, 0.8458000473327074, 0.800403619875556], "final_y": [0.15421899240406733, 0.1374613355515003, 0.14671274590407068]}, "mutation_prompt": null}
{"id": "c18d5e52-5fde-4c5d-8592-1cebbe577cb7", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamic population size adjustment\n            population_size = max(5, population_size - 1)\n\n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive crossover probability\n                CR = 0.8 + 0.2 * np.random.rand()\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation_scale = 0.05 * (1 - func_evals / self.budget)  # Decrease perturbation over time\n            perturbation = np.random.normal(0, perturbation_scale, self.dim)  # Variable perturbation\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced Hybrid Metaheuristic with Adaptive Parameters, Gaussian Perturbation, and Dynamic Population Sizing for Local Search Refinement.", "configspace": "", "generation": 2, "fitness": 0.7923974842606474, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.792 with standard deviation 0.023. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "98fec3a9-7817-4f24-8169-05eb0239e6d0", "metadata": {"aucs": [0.8253939186691205, 0.7754182012177155, 0.7763803328951062], "final_y": [0.14276831960387448, 0.16659872619552174, 0.1661176342360291]}, "mutation_prompt": null}
{"id": "c4ea354e-1d47-435a-bbb8-1bb3f1dcf7fd", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            for i in range(population_size):\n                # Tournament selection for mutation\n                candidates = np.random.choice(population_size, 5, replace=False)\n                candidates_fitness = fitness[candidates]\n                best_tournament_idx = candidates[np.argmin(candidates_fitness)]\n                indices = np.random.choice(np.delete(np.arange(population_size), best_tournament_idx), 2, replace=False)\n                a, b = population[indices]\n                mutant = np.clip(population[best_tournament_idx] + F * (a - b), lb, ub)\n\n                # Adaptive crossover probability\n                CR = 0.8 + 0.2 * np.random.rand()\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Dynamic perturbation scaling based on iterations\n            perturbation_scale = 0.1 * (1 - func_evals / self.budget)\n            perturbation = np.random.normal(0, perturbation_scale, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Incorporating dynamic scaling of perturbation based on iterations and introducing tournament selection to enhance solution diversity.", "configspace": "", "generation": 2, "fitness": 0.7910939240235472, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.022. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "98fec3a9-7817-4f24-8169-05eb0239e6d0", "metadata": {"aucs": [0.8221078117875299, 0.7758830132090432, 0.7752909470740683], "final_y": [0.12857075748327296, 0.16638455917631256, 0.1667022357208512]}, "mutation_prompt": null}
{"id": "29ac750b-04a5-4fc9-bef7-09ccde94dcb6", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive crossover probability\n                CR = 0.8 + 0.2 * np.random.rand()\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search with adaptive perturbation\n            perturbation = np.random.normal(0, 0.05 * (1 - func_evals / self.budget), self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced Hybrid Metaheuristic with Improved Local Search Refinement using Adaptive Perturbation.", "configspace": "", "generation": 2, "fitness": 0.783433107551824, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.783 with standard deviation 0.011. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "98fec3a9-7817-4f24-8169-05eb0239e6d0", "metadata": {"aucs": [0.7990286878854711, 0.775760417307063, 0.7755102174629381], "final_y": [0.14841877744032295, 0.16646334871276658, 0.16635147521722637]}, "mutation_prompt": null}
{"id": "051818dd-68a3-4c0a-b4d1-b8c645391a97", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = np.random.rand() * (0.5 + 0.5 * (fitness[i] - best_fitness) / (fitness.max() - best_fitness + 1e-8))  # Adaptive scaling\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive crossover probability\n                CR = 0.8 + 0.2 * np.random.rand()\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.05, self.dim)  # Reduced perturbation\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced Hybrid Metaheuristic with Adaptive Mutation Scaling to Improve Exploration", "configspace": "", "generation": 2, "fitness": 0.7864998160910742, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.786 with standard deviation 0.016. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "98fec3a9-7817-4f24-8169-05eb0239e6d0", "metadata": {"aucs": [0.8087012246500304, 0.775163011201851, 0.7756352124213413], "final_y": [0.13995148240362743, 0.16696136358984093, 0.16659597378651492]}, "mutation_prompt": null}
{"id": "00771949-b253-4f6d-808c-c62f60f9b101", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n                F = 0.5 + 0.5 * (1 - (func_evals / self.budget))  # Adaptive differential weight\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic algorithm with adaptive differential weight and crossover probability for improved exploration and exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.782432508059138, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.782 with standard deviation 0.009. And the mean value of best solutions found was 0.161 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "81b5f279-f105-448d-99f6-d38ea37310df", "metadata": {"aucs": [0.7956847608589227, 0.7755999846841262, 0.7760127786343651], "final_y": [0.14981232788531496, 0.16630041318145017, 0.16610798296785134]}, "mutation_prompt": null}
{"id": "64645a7e-193f-434e-9838-57f69c5516de", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = 0.5 + 0.1 * (fitness[i] / best_fitness)  # Adjust F based on fitness\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (fitness[i] / best_fitness))  # Adjust CR based on fitness\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved adaptive crossover and mutation strategies with fitness-based adjustments for better exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.7758438358476011, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.776 with standard deviation 0.000. And the mean value of best solutions found was 0.166 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "81b5f279-f105-448d-99f6-d38ea37310df", "metadata": {"aucs": [0.7760437593188168, 0.775733787317165, 0.7757539609068215], "final_y": [0.16616924844195413, 0.16625168413702818, 0.1662709867066704]}, "mutation_prompt": null}
{"id": "ad98d306-9047-4c29-ae1a-9cd3077fac06", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                # Adaptive F: Adjust differential weight based on fitness improvement\n                F = 0.5 + (0.5 * (1 - (func_evals / self.budget)))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "An enhanced hybrid metaheuristic algorithm with adaptive differential weight for dynamic exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.7901276400583838, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.790 with standard deviation 0.021. And the mean value of best solutions found was 0.157 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "81b5f279-f105-448d-99f6-d38ea37310df", "metadata": {"aucs": [0.8193685176013942, 0.7757752587746973, 0.7752391437990598], "final_y": [0.1383104560029178, 0.16654779275549336, 0.16676834731926282]}, "mutation_prompt": null}
{"id": "b9ded6d7-0414-4b64-9849-f865f240e92b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.05, self.dim)  # Refined perturbation scale\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic with enhanced local search perturbation scale for improved solution refinement.", "configspace": "", "generation": 2, "fitness": 0.7812756185370483, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.781 with standard deviation 0.008. And the mean value of best solutions found was 0.161 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "81b5f279-f105-448d-99f6-d38ea37310df", "metadata": {"aucs": [0.792801776039963, 0.7753996742226341, 0.7756254053485477], "final_y": [0.14970690376865192, 0.16651380564633222, 0.16674779145219165]}, "mutation_prompt": null}
{"id": "a7807e01-35b4-43af-aad8-cdcac358551d", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced a fitness-based strategy to dynamically adjust the population size for improved resource allocation.", "configspace": "", "generation": 2, "fitness": 0.7927928607385154, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.024. And the mean value of best solutions found was 0.158 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "81b5f279-f105-448d-99f6-d38ea37310df", "metadata": {"aucs": [0.8271439893780367, 0.7755929204539929, 0.7756416723835166], "final_y": [0.1399093154775649, 0.16673643030219554, 0.16661806692616388]}, "mutation_prompt": null}
{"id": "1dc4017d-9f5c-42e9-9b47-0999fbc22ac6", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F_base = 0.5  # Base differential weight\n        CR = 0.9  # Crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            for i in range(population_size):\n                # Dynamic differential weight\n                F = F_base + 0.1 * np.random.rand()\n                \n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive crossover probability\n                CR = 0.8 + 0.2 * np.random.rand()\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.05 + 0.02 * np.random.rand(), self.dim)  # Stochastic perturbation\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved Hybrid Metaheuristic with Dynamic Differential Weight and Stochastic Gaussian Perturbation for Enhanced Search Efficiency.", "configspace": "", "generation": 2, "fitness": 0.7844260945633815, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.784 with standard deviation 0.013. And the mean value of best solutions found was 0.161 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "98fec3a9-7817-4f24-8169-05eb0239e6d0", "metadata": {"aucs": [0.8021967732604608, 0.7757366793559912, 0.7753448310736923], "final_y": [0.14839333812846078, 0.1664144438429368, 0.1667428965393265]}, "mutation_prompt": null}
{"id": "5d910675-a58b-4b6e-bdba-8aa570b62a9c", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                # Change: Dynamic adjustment of F\n                F = 0.5 * (1 + (best_fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness)))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced a dynamic adjustment of the differential weight F based on the evolution of the fitness over iterations for enhanced exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8285290709351306, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.004. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a7807e01-35b4-43af-aad8-cdcac358551d", "metadata": {"aucs": [0.8229506593518464, 0.8313987992107134, 0.8312377542428319], "final_y": [0.13933413096190328, 0.14127972268075006, 0.14350968812124132]}, "mutation_prompt": null}
{"id": "7e8840fb-e9c5-4cb3-b7ee-57332441f917", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                F = 0.5 + 0.5 * (1 - (best_fitness / np.max(fitness)))  # Adjust differential weight\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced a fitness-based strategy to dynamically adjust the differential weight for improved exploitation.", "configspace": "", "generation": 3, "fitness": 0.8068013211649405, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.008. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a7807e01-35b4-43af-aad8-cdcac358551d", "metadata": {"aucs": [0.8184451935988623, 0.7996721933599156, 0.8022865765360437], "final_y": [0.13874885148368388, 0.14637096025034313, 0.15129818174104281]}, "mutation_prompt": null}
{"id": "c6eeaa73-6afb-4135-82d3-cf4776ccee90", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamic population size adjustment\n            population_size = max(5, population_size - 1)\n\n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Self-adaptive crossover probability\n                CR = 0.5 + 0.4 * np.random.rand()\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation_scale = 0.05 * (1 - func_evals / self.budget)  # Decrease perturbation over time\n            perturbation = np.random.normal(0, perturbation_scale, self.dim)  # Variable perturbation\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced a self-adaptive crossover mechanism and added random seed variability for robustness.", "configspace": "", "generation": 3, "fitness": 0.8082824526864897, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.007. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c18d5e52-5fde-4c5d-8592-1cebbe577cb7", "metadata": {"aucs": [0.8166490800204519, 0.8076477429292467, 0.8005505351097706], "final_y": [0.14584811388081098, 0.14190552211582397, 0.15543275369134546]}, "mutation_prompt": null}
{"id": "a992d732-c486-41a1-be25-f14c42fa0940", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Adaptive strategies based on exploration and exploitation phases\n            exploration_phase = func_evals < self.budget * 0.5\n\n            for i in range(population_size):\n                # Mutation with Lévy flight step for enhanced exploration\n                if exploration_phase:\n                    step = np.random.standard_normal(self.dim) * np.random.standard_cauchy(self.dim)\n                    mutant = np.clip(population[i] + step, lb, ub)\n                else:\n                    indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                    a, b, c = population[indices]\n                    mutant = a + F * (b - c)\n\n                # Adaptive crossover probability\n                CR = 0.8 + 0.2 * np.random.rand()\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Gradient-Based Local Search for refinement\n            if not exploration_phase:\n                gradient = np.random.normal(0, 1, self.dim)\n                candidate = np.clip(best_solution - 0.01 * gradient, lb, ub)\n                candidate_fitness = func(candidate)\n                func_evals += 1\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced Hybrid Metaheuristic with Adaptive Strategies, Lévy Flight-Based Exploration, and Gradient-Based Local Search for Improved Convergence.", "configspace": "", "generation": 3, "fitness": 0.804108045397388, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.005. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "c18d5e52-5fde-4c5d-8592-1cebbe577cb7", "metadata": {"aucs": [0.8051385290397637, 0.79713620209568, 0.8100494050567206], "final_y": [0.15346251701097002, 0.14484602487830345, 0.1419401426486403]}, "mutation_prompt": null}
{"id": "c4e541f7-e182-4343-a5fb-2792694df32c", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamic population size adjustment\n            population_size = max(5, population_size - 1)\n\n            for i in range(population_size):\n                # Mutation: Create a mutant vector using Lévy flights\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = 0.5 + 0.3 * np.random.rand()  # Adaptive differential weight\n                levy_step = np.random.normal(0, 1, self.dim) * (1 / np.abs(np.random.normal(0, 1)))**0.5\n                mutant = np.clip(a + F * (b - c) + levy_step, lb, ub)\n\n                # Adaptive crossover probability\n                CR = 0.8 + 0.2 * np.random.rand()\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation_scale = 0.05 * (1 - func_evals / self.budget)  # Decrease perturbation over time\n            perturbation = np.random.normal(0, perturbation_scale, self.dim)  # Variable perturbation\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Incorporating a Lévy flight-based exploration strategy and adaptive differential weight to enhance global search capabilities.", "configspace": "", "generation": 3, "fitness": 0.8084360779514452, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.012. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c18d5e52-5fde-4c5d-8592-1cebbe577cb7", "metadata": {"aucs": [0.8123307611248322, 0.7922305507942491, 0.8207469219352547], "final_y": [0.14577635686997348, 0.14716917358260329, 0.14232468750154226]}, "mutation_prompt": null}
{"id": "75200460-2a3f-4c15-8063-b5efc5becfa9", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        stagnation_counter = 0  # Add a stagnation counter\n\n        while func_evals < self.budget:\n            # Dynamic population size adjustment\n            population_size = max(5, population_size - 1)\n\n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive crossover probability\n                CR = 0.8 + 0.2 * np.random.rand()\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    stagnation_counter = 0  # Reset stagnation counter on improvement\n                else:\n                    stagnation_counter += 1\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation_scale = 0.05 * (1 - func_evals / self.budget)  # Decrease perturbation over time\n            perturbation = np.random.normal(0, perturbation_scale, self.dim)  # Variable perturbation\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n            # Reinitialize random individual if stagnation persists\n            if stagnation_counter >= 50:  # Threshold for stagnation\n                idx_to_replace = np.random.randint(population_size)\n                population[idx_to_replace] = np.random.uniform(lb, ub, self.dim)\n                fitness[idx_to_replace] = func(population[idx_to_replace])\n                func_evals += 1\n                stagnation_counter = 0  # Reset stagnation counter\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Incorporate a diversity preservation mechanism by reinitializing individuals when convergence stagnates, enhancing exploration capabilities.", "configspace": "", "generation": 3, "fitness": 0.8038285557726542, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.006. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c18d5e52-5fde-4c5d-8592-1cebbe577cb7", "metadata": {"aucs": [0.8020467907293908, 0.7977524447599299, 0.811686431828642], "final_y": [0.13693178466356404, 0.15082633871135864, 0.14387032240472708]}, "mutation_prompt": null}
{"id": "db058fa2-2623-42b3-a0cb-e5fe27542ef5", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamic population size adjustment\n            population_size = max(5, population_size - 1)\n\n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = 0.3 + 0.4 * np.random.rand()  # Stochastic adaptive F\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive crossover probability\n                CR = 0.8 + 0.2 * np.random.rand()\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation_scale = 0.03 * (1 - func_evals / self.budget)  # Fine-tuned perturbation scale\n            perturbation = np.random.normal(0, perturbation_scale, self.dim)  # Variable perturbation\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced stochastic adaptive differential weight strategy and fine-tuned local search for enhanced exploration and exploitation.", "configspace": "", "generation": 3, "fitness": 0.8066954739500919, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.011. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c18d5e52-5fde-4c5d-8592-1cebbe577cb7", "metadata": {"aucs": [0.8204157942519219, 0.7939364049682471, 0.8057342226301064], "final_y": [0.14150754861220238, 0.14026789891316405, 0.1454336258890302]}, "mutation_prompt": null}
{"id": "313b1bc1-fd73-428e-a3e8-5a5050f31880", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamic population size adjustment\n            population_size = max(5, population_size - 1)\n\n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive crossover probability\n                CR = 0.8 + 0.2 * np.random.rand()\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Probability-based local search to refine\n            if np.random.rand() < 0.3:  # Introduced a probability-based trigger\n                perturbation_scale = 0.05 * (1 - func_evals / self.budget)  # Decrease perturbation over time\n                perturbation = np.random.normal(0, perturbation_scale, self.dim)  # Variable perturbation\n                candidate = np.clip(best_solution + perturbation, lb, ub)\n                candidate_fitness = func(candidate)\n                func_evals += 1\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introducing a probability-based local search trigger to enhance exploration during the optimization process.", "configspace": "", "generation": 3, "fitness": 0.7969576861530757, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.797 with standard deviation 0.005. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "c18d5e52-5fde-4c5d-8592-1cebbe577cb7", "metadata": {"aucs": [0.8046952815471173, 0.7933901662141121, 0.7927876106979979], "final_y": [0.14252582597604602, 0.15677153095475072, 0.15171600130623364]}, "mutation_prompt": null}
{"id": "82f7ca93-45bc-4049-b167-6758d4630e97", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = 0.5 + 0.3 * (fitness[i] - best_fitness) / (np.max(fitness) - best_fitness) # Adaptive F\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced adaptive differential weight scaling to improve exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8183322763404867, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.022. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "a7807e01-35b4-43af-aad8-cdcac358551d", "metadata": {"aucs": [0.8393886176989247, 0.8269440868198676, 0.7886641245026673], "final_y": [0.13534151163868213, 0.1423567980529662, 0.1461846808155347]}, "mutation_prompt": null}
{"id": "bd5c005a-2d08-459f-9c8b-9095b3444033", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamic population size adjustment\n            population_size = max(5, population_size - 1)\n\n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(population_size), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = np.std(fitness) / np.mean(fitness)  # Adjust mutation factor based on fitness diversity\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive crossover probability\n                CR = 0.8 + 0.2 * np.random.rand()\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation_scale = 0.05 * (1 - func_evals / self.budget)  # Decrease perturbation over time\n            perturbation = np.random.normal(0, perturbation_scale, self.dim)  # Variable perturbation\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced a variable mutation factor that dynamically adjusts based on the fitness diversity in the population.", "configspace": "", "generation": 3, "fitness": 0.8085182700297121, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.008. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c18d5e52-5fde-4c5d-8592-1cebbe577cb7", "metadata": {"aucs": [0.8047695194406304, 0.8014356533579651, 0.8193496372905409], "final_y": [0.13687429351607672, 0.14627887825054653, 0.1409473978613699]}, "mutation_prompt": null}
{"id": "24509cb2-16f1-407f-9d10-4e564152fbbc", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        no_improve_count = 0  # Track no improvement iterations\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                # Change: Dynamic adjustment of F\n                F = 0.5 * (1 + (best_fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness)))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n                    no_improve_count = 0  # Reset no improvement counter\n                else:\n                    no_improve_count += 1\n\n                if func_evals >= self.budget or no_improve_count > 50:  # Early stopping\n                    return best_solution\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n                if no_improve_count > 50:  # Early stopping\n                    return best_solution\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced weight decay and an early stopping criterion based on stagnation in the best fitness to enhance convergence speed.", "configspace": "", "generation": 4, "fitness": 0.7989086641590104, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.017. And the mean value of best solutions found was 0.151 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "5d910675-a58b-4b6e-bdba-8aa570b62a9c", "metadata": {"aucs": [0.7748259292732169, 0.812659832458877, 0.8092402307449376], "final_y": [0.16715539111735223, 0.14294420247434125, 0.14249450843989186]}, "mutation_prompt": null}
{"id": "13037ce1-14f0-43d6-a340-ed0b661f4254", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                # Change: Dynamic adjustment of F\n                F = 0.5 * (1 + (best_fitness - np.min(fitness)) / (np.max(fitness) - np.min(fitness)))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation_scale = 0.1 * (1 - (func_evals / self.budget))  # Change: Adaptive perturbation scale\n            perturbation = np.random.normal(0, perturbation_scale, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduce an adaptive mechanism for the perturbation scale in local search to improve convergence speed and accuracy.", "configspace": "", "generation": 4, "fitness": 0.8023063430255856, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.802 with standard deviation 0.015. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "5d910675-a58b-4b6e-bdba-8aa570b62a9c", "metadata": {"aucs": [0.7920057233055536, 0.8230422148524073, 0.7918710909187961], "final_y": [0.15664966836154348, 0.12953208773034375, 0.15293528171085446]}, "mutation_prompt": null}
{"id": "574bd3b4-2cc4-498b-9381-4a43f67d3367", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5\n        CR = 0.9\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            for i in range(population_size):\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                # Change: Dynamic adjustment of F based on median fitness\n                F = 0.5 * (1 + (best_fitness - np.median(fitness)) / (np.max(fitness) - np.min(fitness)))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                CR = 0.9 * (1 - (func_evals / self.budget))\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search with Lévy flight\n            levy_step = np.random.standard_cauchy(self.dim)\n            candidate = np.clip(best_solution + 0.01 * levy_step, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration and exploitation balance through dynamic adjustment of differential weight and introduction of Lévy flight-based search for improved local refinement.", "configspace": "", "generation": 4, "fitness": 0.8048418623869015, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.004. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "5d910675-a58b-4b6e-bdba-8aa570b62a9c", "metadata": {"aucs": [0.8063007153628597, 0.8090376263388832, 0.7991872454589612], "final_y": [0.14227319090269308, 0.14360944168888568, 0.13630177618086392]}, "mutation_prompt": null}
{"id": "db4f932d-e503-4902-bf83-876f4bbf5222", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = 0.5 + 0.3 * (fitness[i] - best_fitness) / (np.max(fitness) - best_fitness) # Adaptive F\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            elite_indices = np.argsort(fitness)[:5]  # Select top 5 elites\n            elite_solutions = population[elite_indices]  # Preserve top solutions\n            population[:5] = elite_solutions  # Keep elites in the population\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced elite strategy by preserving the top individuals to maintain diversity and convergence speed.", "configspace": "", "generation": 4, "fitness": 0.8136976791328342, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.005. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "82f7ca93-45bc-4049-b167-6758d4630e97", "metadata": {"aucs": [0.8144800873790896, 0.8196995611119691, 0.8069133889074436], "final_y": [0.14237031624001573, 0.1396512741992596, 0.14115325061935569]}, "mutation_prompt": null}
{"id": "2e237834-1b08-4f06-89f5-04d9ebc0f0d7", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))  # Adaptive mutation strength\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced population diversity by incorporating an adaptive mutation strength based on fitness variance.", "configspace": "", "generation": 4, "fitness": 0.8137542873308922, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.004. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "5d910675-a58b-4b6e-bdba-8aa570b62a9c", "metadata": {"aucs": [0.8198525366857053, 0.8092324205760302, 0.8121779047309408], "final_y": [0.13760377515659483, 0.1407738628616979, 0.14634145411889]}, "mutation_prompt": null}
{"id": "ccd97758-deac-4d57-8b71-273b82f0c4fc", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                # Change: Dynamic adjustment of F\n                F = np.random.standard_cauchy()  # Lévy flight step size\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration by introducing Lévy flight step sizes for mutation, maintaining balance between exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.8038264646913809, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.804 with standard deviation 0.006. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "5d910675-a58b-4b6e-bdba-8aa570b62a9c", "metadata": {"aucs": [0.7985829595159837, 0.8011129132577532, 0.8117835213004055], "final_y": [0.14783901155209078, 0.1459644799118499, 0.14203287108313878]}, "mutation_prompt": null}
{"id": "821c7cc5-6f26-4ae6-b560-2ccf705aa09f", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                # Dynamic adjustment of F\n                F = 0.5 * (1 + ((np.median(fitness) - fitness[i]) / (np.max(fitness) - np.min(fitness))))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation_scale = 0.1 * (1 - (best_fitness / np.max(fitness)))\n            perturbation = np.random.normal(0, perturbation_scale, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration and exploitation by introducing dynamic mutation strategies and refined local search based on current fitness distribution.", "configspace": "", "generation": 4, "fitness": 0.8124895071077153, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.008. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "5d910675-a58b-4b6e-bdba-8aa570b62a9c", "metadata": {"aucs": [0.819462007669, 0.8016704987441416, 0.8163360149100042], "final_y": [0.1417915468885983, 0.1527924188447689, 0.13287117825440198]}, "mutation_prompt": null}
{"id": "da87df0a-12dd-44c2-852f-ac7faf799792", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = 0.5 + 0.3 * (fitness[i] - best_fitness) / (np.max(fitness) - best_fitness) # Adaptive F\n                mutant = a + F * (b - c)\n                \n                # Adaptive mutation based on fitness improvement\n                if fitness[i] < np.median(fitness):\n                    mutant = np.clip(mutant + 0.1 * np.random.randn(self.dim), lb, ub)\n                else:\n                    mutant = np.clip(mutant, lb, ub)\n\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Adaptive local search\n            perturbation = np.random.normal(0, 0.1 * (np.max(fitness) - best_fitness), self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced a fitness-based adaptive local search and mutation strategy to enhance the exploration of promising regions.", "configspace": "", "generation": 4, "fitness": 0.8118152835350688, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.007. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "82f7ca93-45bc-4049-b167-6758d4630e97", "metadata": {"aucs": [0.82134901827792, 0.8048562145590789, 0.8092406177682079], "final_y": [0.1291982871905084, 0.14782622865530937, 0.1477542456221952]}, "mutation_prompt": null}
{"id": "21257425-9e57-4694-9483-8890968c49f0", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = 0.5 + 0.3 * (fitness[i] - best_fitness) / (np.max(fitness) - best_fitness) # Adaptive F\n                # Chaos-based mutation strategy\n                chaotic_factor = np.random.normal(1, 0.1)\n                mutant = np.clip(a + F * (b - c) * chaotic_factor, lb, ub) \n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration by incorporating a chaos-based mutation strategy for generating mutant vectors.", "configspace": "", "generation": 4, "fitness": 0.8100710477195555, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.810 with standard deviation 0.013. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "82f7ca93-45bc-4049-b167-6758d4630e97", "metadata": {"aucs": [0.8190035887516028, 0.7912628494846368, 0.8199467049224269], "final_y": [0.1395747400027657, 0.15506116041268947, 0.13511136187677153]}, "mutation_prompt": null}
{"id": "c5fe5455-43c2-4aee-93a7-c16c63749646", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n        decay_factor = 0.99  # Decay factor for adaptive F\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = (0.5 + 0.3 * (fitness[i] - best_fitness) / (np.max(fitness) - best_fitness)) * decay_factor # Adaptive F with decay\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration by introducing a decay factor to dynamically reduce differential weight F over time for improved convergence.", "configspace": "", "generation": 4, "fitness": 0.8219309120581783, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.008. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "82f7ca93-45bc-4049-b167-6758d4630e97", "metadata": {"aucs": [0.825007345585307, 0.811109800133533, 0.8296755904556948], "final_y": [0.14090210218593735, 0.14145207128451165, 0.13384067612383332]}, "mutation_prompt": null}
{"id": "66dba1fe-f045-426f-ae3c-fe641eae54c6", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n        decay_factor = 0.99  # Decay factor for adaptive F\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = (0.5 + 0.3 * (fitness[i] - best_fitness) / (np.max(fitness) - best_fitness)) * decay_factor * (0.5 + func_evals/self.budget) # Adaptive F with decay and learning rate\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Leveraged adaptive learning rate for dynamic mutation strength to enhance convergence precision.", "configspace": "", "generation": 5, "fitness": 0.8071676487104185, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.015. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c5fe5455-43c2-4aee-93a7-c16c63749646", "metadata": {"aucs": [0.8275417525418091, 0.794526437880038, 0.7994347557094083], "final_y": [0.1344596832026308, 0.14955053320162104, 0.14859874327205014]}, "mutation_prompt": null}
{"id": "cd58f1a5-0ff4-4298-a5f0-b65b7a936253", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))  # Adaptive mutation strength\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.15, self.dim)  # Increased perturbation magnitude\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced local exploration by introducing a small perturbation magnitude increase in the local search phase.", "configspace": "", "generation": 5, "fitness": 0.8078210157528454, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.808 with standard deviation 0.008. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "2e237834-1b08-4f06-89f5-04d9ebc0f0d7", "metadata": {"aucs": [0.8175052368132205, 0.7971059923370665, 0.8088518181082492], "final_y": [0.13850892635308742, 0.14020135974219594, 0.14117586427993756]}, "mutation_prompt": null}
{"id": "186f5523-8fef-4d21-857c-8ef6c33a212b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n        decay_factor = 0.99  # Decay factor for adaptive F\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = (0.5 + 0.3 * (fitness[i] - best_fitness) / (np.max(fitness) - best_fitness)) * decay_factor # Adaptive F with decay\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget)) * decay_factor  # Adaptive CR with decay\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced convergence by introducing adaptive decay in both differential weight F and crossover probability CR over optimization iterations.", "configspace": "", "generation": 5, "fitness": 0.8175922542238158, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.818 with standard deviation 0.004. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "c5fe5455-43c2-4aee-93a7-c16c63749646", "metadata": {"aucs": [0.8146675618311543, 0.8150668946081197, 0.8230423062321733], "final_y": [0.14577718319671473, 0.14775375893088438, 0.1384014845239755]}, "mutation_prompt": null}
{"id": "baac2383-4cc2-47a8-b7d5-36a838ff96c2", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                recent_improvement = (best_fitness - np.median(fitness)) / (np.max(fitness) - np.min(fitness))\n                F = 0.5 * (1 + recent_improvement)  # Feedback-based adaptive mutation strength\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduce a feedback loop to dynamically adjust the differential weight F based on recent improvements in fitness, enhancing convergence speed.", "configspace": "", "generation": 5, "fitness": 0.8072515952241845, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.807 with standard deviation 0.008. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "2e237834-1b08-4f06-89f5-04d9ebc0f0d7", "metadata": {"aucs": [0.8073415396860177, 0.816585966703008, 0.797827279283528], "final_y": [0.1448497965408968, 0.14114612617291578, 0.1449866441783043]}, "mutation_prompt": null}
{"id": "8145add7-9786-46a2-9154-d8b5f287281a", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))  # Adaptive mutation strength\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced adaptive population size scaling based on the convergence rate to enhance exploration and exploitation balance.", "configspace": "", "generation": 5, "fitness": 0.8250039948993247, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.016. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "2e237834-1b08-4f06-89f5-04d9ebc0f0d7", "metadata": {"aucs": [0.8048086056316613, 0.842539954228922, 0.8276634248373906], "final_y": [0.14385602804251052, 0.1350158768280595, 0.1362000623736217]}, "mutation_prompt": null}
{"id": "a2864796-52c6-41d4-9a0a-9513cdb948d7", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))  # Adaptive mutation strength\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            if np.random.rand() < (1 - best_fitness / np.max(fitness)):  # Modify: Adaptive local search frequency\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(best_solution + perturbation, lb, ub)\n                candidate_fitness = func(candidate)\n                func_evals += 1\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced convergence by integrating a fitness-based adaptive local search frequency.", "configspace": "", "generation": 5, "fitness": 0.8050243823808149, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.015. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "2e237834-1b08-4f06-89f5-04d9ebc0f0d7", "metadata": {"aucs": [0.7928526296338401, 0.7960299167621012, 0.8261906007465032], "final_y": [0.15004888303061714, 0.15321321068586768, 0.13462982649185073]}, "mutation_prompt": null}
{"id": "c5ab4da8-bca6-4374-82e6-2e1d661498fd", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))  # Adaptive mutation strength\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.01, self.dim)  # Refined perturbation\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n            # Elitism: Preserve the best solution in the population\n            population[best_idx] = best_solution\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introducing elitism and refined local search to enhance convergence.", "configspace": "", "generation": 5, "fitness": 0.8029142301311772, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.803 with standard deviation 0.006. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "2e237834-1b08-4f06-89f5-04d9ebc0f0d7", "metadata": {"aucs": [0.8028107689842544, 0.795327884899069, 0.8106040365102082], "final_y": [0.14706234922463257, 0.1458958814767627, 0.14365557266645368]}, "mutation_prompt": null}
{"id": "d8bd82f8-7230-4196-9acd-d535825350b0", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n        decay_factor = 0.99  # Decay factor for adaptive F\n        mutation_factor = 0.1 / np.sqrt(self.dim)  # Dimensional scaling factor\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = (0.5 + 0.3 * (fitness[i] - best_fitness) / (np.max(fitness) - best_fitness)) * decay_factor\n                mutant = np.clip(a + F * (b - c) * mutation_factor, lb, ub)\n\n                CR = 0.9 * (1 - (func_evals / self.budget))\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            perturbation = np.random.normal(0, 0.1, self.dim) * mutation_factor\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration by incorporating dimensional-based mutation and adaptive scaling to improve convergence efficiency.", "configspace": "", "generation": 5, "fitness": 0.8132996096472217, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.021. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "c5fe5455-43c2-4aee-93a7-c16c63749646", "metadata": {"aucs": [0.8424027672171107, 0.8000741594568912, 0.7974219022676633], "final_y": [0.13608592582940393, 0.14809785407891207, 0.15267134701969698]}, "mutation_prompt": null}
{"id": "a337fcda-d7c8-4843-88fd-217568460751", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n        decay_factor = 0.99  # Decay factor for adaptive F\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = (0.5 + 0.3 * (fitness[i] - best_fitness) / (np.max(fitness) - best_fitness)) * decay_factor # Adaptive F with decay\n                mutant = np.clip(a + F * (b - c + (best_solution - a)), lb, ub)  # Elite-based perturbation\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced elite-based perturbation in mutation to enhance local search and convergence speed.", "configspace": "", "generation": 5, "fitness": 0.824034816235567, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.001. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c5fe5455-43c2-4aee-93a7-c16c63749646", "metadata": {"aucs": [0.8254491251685946, 0.8220937862282391, 0.8245615373098671], "final_y": [0.13714140451843038, 0.14101906564378086, 0.14099585909468326]}, "mutation_prompt": null}
{"id": "fa8e53b7-2ace-4749-83db-fb8d9242a2e5", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n        decay_factor = 0.99  # Decay factor for adaptive F\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = (0.5 + 0.3 * (fitness[i] - best_fitness) / (np.max(fitness) - best_fitness)) * decay_factor # Adaptive F with decay\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1 * (1 - func_evals / self.budget), self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhance local refinement using adaptive perturbation for increased precision in the search space.", "configspace": "", "generation": 5, "fitness": 0.8051975509701771, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.011. And the mean value of best solutions found was 0.146 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "c5fe5455-43c2-4aee-93a7-c16c63749646", "metadata": {"aucs": [0.7975928109199705, 0.7975155334133661, 0.8204843085771947], "final_y": [0.149287966195505, 0.1538376183607718, 0.13499749941842543]}, "mutation_prompt": null}
{"id": "9246cc96-61f8-4cff-bbc2-fef8b54c8a8b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n        decay_factor = 0.99  # Decay factor for adaptive F\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = (0.5 + 0.3 * (fitness[i] - best_fitness) / (np.max(fitness) - best_fitness)) * decay_factor # Adaptive F with decay\n                mutant = np.clip(a + F * (b - c + (best_solution - a)), lb, ub)  # Elite-based perturbation\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n            # Random immigrant introduction for diversification\n            if np.random.rand() < 0.1:  # 10% chance to introduce a random immigrant\n                random_immigrant = np.random.uniform(lb, ub, self.dim)\n                random_immigrant_fitness = func(random_immigrant)\n                func_evals += 1\n                if random_immigrant_fitness < best_fitness:\n                    best_solution = random_immigrant\n                    best_fitness = random_immigrant_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced adaptive mutation and diversification mechanism by incorporating fitness-based mutation rate adjustment and random immigrant introduction.", "configspace": "", "generation": 6, "fitness": 0.823589537498488, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.011. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a337fcda-d7c8-4843-88fd-217568460751", "metadata": {"aucs": [0.8343114131657439, 0.827859901825795, 0.8085972975039246], "final_y": [0.13425355560187913, 0.13722525522468443, 0.13274592908913319]}, "mutation_prompt": null}
{"id": "d4574e57-a301-44a0-a614-be57cc86f360", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n        decay_factor = 0.99  # Decay factor for adaptive F\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = (0.5 + 0.3 * (fitness[i] - best_fitness) / (np.max(fitness) - best_fitness)) * decay_factor # Adaptive F with decay\n                mutant = np.clip(a + F * (b - c + (best_solution - a)), lb, ub)  # Elite-based perturbation\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation_scale = 0.1 * (best_fitness / np.max(fitness))\n            perturbation = np.random.normal(0, perturbation_scale, self.dim)  # Adjusted perturbation scale\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploitation by introducing an adaptive Gaussian perturbation scale based on convergence progress.", "configspace": "", "generation": 6, "fitness": 0.8383054502318187, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.011. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "a337fcda-d7c8-4843-88fd-217568460751", "metadata": {"aucs": [0.8437231086278503, 0.8225375358657724, 0.8486557062018336], "final_y": [0.13010267398821407, 0.1380943017319094, 0.1313489948962746]}, "mutation_prompt": null}
{"id": "1cfa7ad0-a36c-4dc5-a476-cf9dca66528d", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n        decay_factor = 0.99  # Decay factor for adaptive F\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = (0.5 + 0.3 * (fitness[i] - best_fitness) / (np.max(fitness) - best_fitness)) * decay_factor * np.mean(np.std(population, axis=0))  # Adaptive F with diversity\n                mutant = np.clip(a + F * (b - c + (best_solution - a)), lb, ub)  # Elite-based perturbation\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced adaptive mutation scaling based on population diversity to enhance convergence speed.", "configspace": "", "generation": 6, "fitness": 0.8124556550675422, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.025. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "a337fcda-d7c8-4843-88fd-217568460751", "metadata": {"aucs": [0.7788951624162337, 0.8384361841365047, 0.8200356186498883], "final_y": [0.16278883446032966, 0.12727618119705075, 0.13448613581660618]}, "mutation_prompt": null}
{"id": "72e6ce91-16d5-46a7-ab7d-30038fee61c6", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n        decay_factor = 0.99  # Decay factor for adaptive F\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = (0.5 + 0.3 * (fitness[i] - best_fitness) / (np.max(fitness) - best_fitness)) * decay_factor # Adaptive F with decay\n                mutant = np.clip(a + F * (b - c + 0.5*(best_solution - a)), lb, ub)  # Adjusted elite-based perturbation\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget)) + 0.1  # Slight increase in CR\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced the elite-based perturbation and crossover mechanism using soft learning from the best solution to accelerate convergence.", "configspace": "", "generation": 6, "fitness": 0.8387247142838851, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.839 with standard deviation 0.015. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a337fcda-d7c8-4843-88fd-217568460751", "metadata": {"aucs": [0.8303962998595742, 0.8263196819285117, 0.8594581610635694], "final_y": [0.13568708593875956, 0.12851635975496212, 0.12428667222219081]}, "mutation_prompt": null}
{"id": "e1cb754e-85c3-40ec-b092-a4752f0d84e3", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))  # Adaptive mutation strength\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation_scale = 0.1 * (1 - best_fitness / np.max(fitness))  # Dynamic perturbation scale\n            perturbation = np.random.normal(0, perturbation_scale, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Incorporated a dynamic local search perturbation scale based on the best solution's convergence rate to enhance refinement precision.", "configspace": "", "generation": 6, "fitness": 0.8132500160192239, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.813 with standard deviation 0.011. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "8145add7-9786-46a2-9154-d8b5f287281a", "metadata": {"aucs": [0.797806401425206, 0.8203240905232022, 0.8216195561092634], "final_y": [0.14815770878208212, 0.1386145851679922, 0.13124951738584878]}, "mutation_prompt": null}
{"id": "fd47b070-396c-41bb-ab6c-f49d1b1a2894", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n        decay_factor = 0.99  # Decay factor for adaptive F\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = (0.5 + 0.3 * (fitness[i] - best_fitness) / (np.max(fitness) - best_fitness)) * decay_factor # Adaptive F with decay\n                F *= np.sin(0.5 * np.pi * (func_evals / self.budget))  # Time-varying adaptive mutation\n                mutant = np.clip(a + F * (b - c + (best_solution - a)), lb, ub)  # Elite-based perturbation\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced convergence by introducing a time-varying adaptive mutation coefficient.", "configspace": "", "generation": 6, "fitness": 0.828251756598997, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.007. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a337fcda-d7c8-4843-88fd-217568460751", "metadata": {"aucs": [0.8190980358222918, 0.8340711908592534, 0.8315860431154454], "final_y": [0.13091578443269014, 0.13628086177226229, 0.13268101209222793]}, "mutation_prompt": null}
{"id": "8e6d94e8-cb76-4648-952d-26fd976aa8b3", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Tournament selection for mutation\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced a tournament selection mechanism to enhance the convergence robustness by selecting the best individuals for mutation.", "configspace": "", "generation": 6, "fitness": 0.851400711680073, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.010. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "8145add7-9786-46a2-9154-d8b5f287281a", "metadata": {"aucs": [0.8655062223470342, 0.8434685676794673, 0.8452273450137178], "final_y": [0.12535038613677352, 0.13448736895064073, 0.12690277444114817]}, "mutation_prompt": null}
{"id": "d8bc3baa-9995-4180-be37-1ad8b44e3be1", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness)))) * np.random.rand()  # Self-adaptive learning rate\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced self-adaptive learning rate for mutation strength based on fitness diversity to enhance convergence rate.", "configspace": "", "generation": 6, "fitness": 0.8233575319734404, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.019. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "8145add7-9786-46a2-9154-d8b5f287281a", "metadata": {"aucs": [0.8004639508756917, 0.8231332276438804, 0.8464754174007489], "final_y": [0.1498233326671905, 0.1389466701694957, 0.12152847327525462]}, "mutation_prompt": null}
{"id": "b8bfd7e6-ddfb-4ad6-8a02-a9602444dadd", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n        decay_factor = 0.99  # Decay factor for adaptive F\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = (0.5 + 0.3 * (fitness[i] - best_fitness) / (np.max(fitness) - best_fitness)) * decay_factor # Adaptive F with decay\n                mutant = np.clip(a + F * (b - c + (best_solution - a)), lb, ub)  # Elite-based perturbation\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation * np.std(population, axis=0), lb, ub)  # Consider diversity\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced a local search mechanism by considering elite solution diversity to improve global search capability.", "configspace": "", "generation": 6, "fitness": 0.8308143645255751, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.831 with standard deviation 0.025. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "a337fcda-d7c8-4843-88fd-217568460751", "metadata": {"aucs": [0.8658163972578159, 0.8127261637025547, 0.8139005326163546], "final_y": [0.12436480882942491, 0.14230022358247085, 0.1447231338874676]}, "mutation_prompt": null}
{"id": "7ce7139a-820e-4720-873a-b7b4e234f3f0", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))  # Adaptive mutation strength\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (np.std(fitness) / np.mean(fitness)))  # Adapt CR based on fitness variance\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.05, self.dim)  # Reduced perturbation scale\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration by modifying perturbation scale and adaptive CR based on fitness variance.", "configspace": "", "generation": 6, "fitness": 0.8308513532613196, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.831 with standard deviation 0.036. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "8145add7-9786-46a2-9154-d8b5f287281a", "metadata": {"aucs": [0.7920261759943354, 0.8781878339858201, 0.8223400498038034], "final_y": [0.1464937860799278, 0.1217476879833368, 0.13518115911928685]}, "mutation_prompt": null}
{"id": "5985fd5a-e15f-4f57-a125-b5e933b8b53f", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n        decay_factor = 0.99  # Decay factor for adaptive F\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                F = (0.5 + 0.3 * (fitness[i] - best_fitness) / (np.max(fitness) - best_fitness))  # Removed decay\n                mutant = np.clip(a + F * (b - c + 0.5*(best_solution - a)), lb, ub)\n\n                CR = 1.0 - (func_evals / self.budget)  # Simplified CR adaptation\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved adaptive F and CR strategies, leveraging dynamic learning rates for better exploration and convergence.", "configspace": "", "generation": 7, "fitness": 0.8053362116659902, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.008. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "72e6ce91-16d5-46a7-ab7d-30038fee61c6", "metadata": {"aucs": [0.8160209967236065, 0.8045776307409512, 0.795410007533413], "final_y": [0.13383802747027784, 0.13834201646899602, 0.15402190178281305]}, "mutation_prompt": null}
{"id": "934f2cfd-dae6-4d3a-91a3-31219f73e4de", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Tournament selection for mutation\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced a dynamic scaling factor for mutation to improve exploration and convergence balance.", "configspace": "", "generation": 7, "fitness": 0.8359647208916411, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.836 with standard deviation 0.013. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "8e6d94e8-cb76-4648-952d-26fd976aa8b3", "metadata": {"aucs": [0.8505319131745643, 0.8197212652567951, 0.8376409842435636], "final_y": [0.1303283199070142, 0.12923623735762757, 0.13496686377621947]}, "mutation_prompt": null}
{"id": "b7d6778c-5ebe-420c-b889-133be958ffe0", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                # Dynamic Differential Weight\n                F = 0.5 * (1 + pop_convergence_factor) \n\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced a dynamic differential weight to enhance diversification and improve solution quality.", "configspace": "", "generation": 7, "fitness": 0.8124362391117046, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.019. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "8e6d94e8-cb76-4648-952d-26fd976aa8b3", "metadata": {"aucs": [0.838658373621948, 0.8051098403586926, 0.7935405033544731], "final_y": [0.13476751122710184, 0.13262954234540358, 0.15011228459955217]}, "mutation_prompt": null}
{"id": "60678bc3-b129-4be5-bcb9-013588d25ea2", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        historical_best_fitness = best_fitness\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Tournament selection for mutation\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                # Dynamic adaptive mutation strategy\n                F = 0.5 * ((1 + (best_fitness - historical_best_fitness) / historical_best_fitness) if historical_best_fitness != 0 else 1)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n            historical_best_fitness = best_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced a dynamic adaptive mutation strategy that adjusts based on historical convergence patterns to enhance exploration capabilities.", "configspace": "", "generation": 7, "fitness": 0.8292488897112943, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.014. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "8e6d94e8-cb76-4648-952d-26fd976aa8b3", "metadata": {"aucs": [0.8493238978423483, 0.818160979940365, 0.82026179135117], "final_y": [0.12764654028358546, 0.14071211509097825, 0.13202387958231998]}, "mutation_prompt": null}
{"id": "2509cc94-4fb3-4d84-974f-ede36166c759", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n        decay_factor = 0.99  # Decay factor for adaptive F\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on fitness\n            population_size = max(5, int(10 * self.dim * (1 - (best_fitness / np.max(fitness)))))\n            \n            for i in range(population_size):\n                # Mutation: Create a mutant vector\n                indices = np.random.choice(np.delete(np.arange(len(population)), i), 3, replace=False)\n                a, b, c = population[indices]\n                diversity = np.std(population, axis=0).mean()  # Calculating diversity of the population\n                F = (0.5 + 0.3 * (fitness[i] - best_fitness) / (np.max(fitness) - best_fitness)) * decay_factor * diversity # Adaptive F with diversity\n                mutant = np.clip(a + F * (b - c + 0.5*(best_solution - a)), lb, ub)  # Adjusted elite-based perturbation\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget)) + 0.1  # Slight increase in CR\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced a dynamic mutation strategy based on population diversity to enhance exploration capabilities.", "configspace": "", "generation": 7, "fitness": 0.8156926009099646, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.019. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "72e6ce91-16d5-46a7-ab7d-30038fee61c6", "metadata": {"aucs": [0.7921458508059502, 0.837678534926317, 0.8172534169976268], "final_y": [0.15596605985342682, 0.13554413966667977, 0.14240048212333278]}, "mutation_prompt": null}
{"id": "451b5d45-5eb2-465f-8dc6-cea8783fab2e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Tournament selection for mutation\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget) ** 1.5)  # Modified line\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced adaptive crossover rate by introducing a dynamic scaling factor to improve convergence speed.", "configspace": "", "generation": 7, "fitness": 0.8322319507236188, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.021. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "8e6d94e8-cb76-4648-952d-26fd976aa8b3", "metadata": {"aucs": [0.8601653379195778, 0.8250705213703144, 0.8114599928809642], "final_y": [0.12336853858400698, 0.13472028616841547, 0.13937246057945796]}, "mutation_prompt": null}
{"id": "f87804f8-45b6-4ab6-b43f-6ca74f6d15f9", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Tournament selection for mutation\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                # Adaptive F based on population diversity\n                F = 0.5 + 0.3 * np.var(fitness) / (np.max(fitness) - np.min(fitness))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            if np.random.rand() < 0.1:  # Added fitness-weighted local search probability\n                perturbation = np.random.normal(0, 0.1, self.dim)\n                candidate = np.clip(best_solution + perturbation, lb, ub)\n                candidate_fitness = func(candidate)\n                func_evals += 1\n                if candidate_fitness < best_fitness:\n                    best_solution = candidate\n                    best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced adaptive mutation and fitness-weighted selection to boost exploration while refining exploitation with limited changes.", "configspace": "", "generation": 7, "fitness": 0.8230673961507504, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.011. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "8e6d94e8-cb76-4648-952d-26fd976aa8b3", "metadata": {"aucs": [0.8384348692157102, 0.8191231659930129, 0.8116441532435283], "final_y": [0.12936529563375454, 0.1443966215800193, 0.14207500282436292]}, "mutation_prompt": null}
{"id": "035ade03-4a71-4b17-a49f-f9bea5b1c8b5", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Tournament selection for mutation\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                # Adaptive F based on diversity\n                F = 0.5 * (1 + (np.std(fitness) / (np.mean(fitness))))\n\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced adaptive differential weight F based on population diversity to improve exploration and convergence balance.", "configspace": "", "generation": 7, "fitness": 0.8243835468520091, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.003. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "8e6d94e8-cb76-4648-952d-26fd976aa8b3", "metadata": {"aucs": [0.8281535350149635, 0.8218978345977818, 0.8230992709432818], "final_y": [0.13843237747093529, 0.14052960038506068, 0.1285429801554263]}, "mutation_prompt": null}
{"id": "f4f9a815-9541-4201-8672-f50f403197e3", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Tournament selection for mutation\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                F = 0.9 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))  # Adjusted F\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced the tournament selection's initial population diversity and improved convergence by adjusting the differential weight adaptively.", "configspace": "", "generation": 7, "fitness": 0.8159840661236576, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.002. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "8e6d94e8-cb76-4648-952d-26fd976aa8b3", "metadata": {"aucs": [0.8181423482709417, 0.8143249888743889, 0.8154848612256425], "final_y": [0.13472028666678126, 0.1393770455096327, 0.14088892600066039]}, "mutation_prompt": null}
{"id": "0549ae61-fa04-4aae-96e6-343e222eadce", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Tournament selection for mutation\n                tournament_size = max(3, int(5 * (1 - pop_convergence_factor)))\n                tournament_indices = np.random.choice(population_size, tournament_size, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on population diversity\n                diversity_factor = np.std(population) / (ub - lb)\n                CR = 0.9 * (1 - diversity_factor)\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved adaptability by fine-tuning both tournament selection size and crossover rate based on population diversity to enhance exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.8405662345751858, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.841 with standard deviation 0.019. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "8e6d94e8-cb76-4648-952d-26fd976aa8b3", "metadata": {"aucs": [0.8294414738582601, 0.8669486337457664, 0.8253085961215306], "final_y": [0.13110443121491788, 0.12848960777683371, 0.13874646209636388]}, "mutation_prompt": null}
{"id": "426d2b27-b1f5-47f2-ac16-9e79ff37f0f3", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Tournament selection for mutation\n                tournament_size = max(3, int(5 * (1 - pop_convergence_factor)))\n                tournament_indices = np.random.choice(population_size, tournament_size, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness)))) * (1 + (best_fitness / np.min(fitness) - best_fitness))\n\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on population diversity\n                diversity_factor = np.std(population) / (ub - lb)\n                CR = 0.9 * (1 - diversity_factor)\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration by introducing a dynamic mutation factor proportional to the best solution's fitness improvement rate.", "configspace": "", "generation": 8, "fitness": 0.8334243808327431, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.020. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "0549ae61-fa04-4aae-96e6-343e222eadce", "metadata": {"aucs": [0.805310325526964, 0.8469912601059049, 0.8479715568653601], "final_y": [0.15030879642056072, 0.12945930336786438, 0.12478458070933829]}, "mutation_prompt": null}
{"id": "891d3bf4-a3a1-470f-a3a9-e50e6bb47a5f", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                # Lévy flight-inspired mutation\n                levy = np.random.standard_normal(self.dim) * np.power(np.random.uniform(0, 1), -1.0 / 3.0)\n                mutant = np.clip(a + F * (b - c) + levy, lb, ub)\n\n                # Adaptive Crossover: Adjust based on fitness diversity\n                fitness_diversity = np.std(fitness) / (np.mean(fitness) + 1e-8)\n                CR = 0.9 * (1 - fitness_diversity)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration through Lévy flight-inspired mutation and adaptive crossover based on fitness diversity to improve performance.", "configspace": "", "generation": 8, "fitness": 0.8496851524388355, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.020. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "934f2cfd-dae6-4d3a-91a3-31219f73e4de", "metadata": {"aucs": [0.8381713703442942, 0.8779979984246009, 0.8328860885476115], "final_y": [0.12843379720674086, 0.12194799950243607, 0.1289025675405795]}, "mutation_prompt": null}
{"id": "f111a2d8-6d64-45fd-98e8-f97a71be4a13", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Tournament selection for mutation\n                tournament_size = max(3, int(5 * (1 - pop_convergence_factor)))\n                tournament_indices = np.random.choice(population_size, tournament_size, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on population diversity\n                diversity_factor = np.std(population) / (ub - lb)\n                CR = 0.9 * (1 - diversity_factor * (np.std(fitness) / np.mean(fitness)))  # Changed line\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced adaptability by dynamically adjusting both crossover probability and mutation factor based on fitness variance to improve exploration-exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8494835675324603, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.006. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "0549ae61-fa04-4aae-96e6-343e222eadce", "metadata": {"aucs": [0.8456532033507126, 0.8446101541481065, 0.858187345098562], "final_y": [0.1298267841285896, 0.12913945671589278, 0.1279116781655233]}, "mutation_prompt": null}
{"id": "269fa3af-03b7-46a5-b123-2504ddc74b40", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Tournament selection for mutation\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                F = np.std(fitness) / (np.max(fitness) - np.min(fitness) + 1e-9)\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved mutation strategy with self-adaptive differential weight based on population diversity to enhance exploration and convergence.", "configspace": "", "generation": 8, "fitness": 0.8462798752113937, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.019. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "934f2cfd-dae6-4d3a-91a3-31219f73e4de", "metadata": {"aucs": [0.8700379824613409, 0.8462968327142786, 0.8225048104585617], "final_y": [0.12016644723194703, 0.13207948956326998, 0.13350157614859814]}, "mutation_prompt": null}
{"id": "534fc423-c33e-4c1a-94a9-2c422eb5e2ee", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Tournament selection for mutation\n                tournament_size = max(3, int(5 * (1 - pop_convergence_factor)))\n                tournament_indices = np.random.choice(population_size, tournament_size, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness)))) * (1 + np.abs(best_fitness - np.mean(fitness)) / np.mean(fitness))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on population diversity\n                diversity_factor = np.std(population) / (ub - lb)\n                CR = 0.9 * (1 - diversity_factor)\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced mutation scaling by incorporating a dynamic adjustment based on the best solution's fitness deviation to improve convergence precision.", "configspace": "", "generation": 8, "fitness": 0.8267596150992147, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.017. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "0549ae61-fa04-4aae-96e6-343e222eadce", "metadata": {"aucs": [0.8039754797788203, 0.8434859937767325, 0.8328173717420914], "final_y": [0.14493633851536358, 0.13275722373145937, 0.1360165468984682]}, "mutation_prompt": null}
{"id": "9f94e9ba-3842-4449-acca-112aa8eac025", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Tournament selection for mutation\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.05, self.dim)  # Changed the standard deviation from 0.1 to 0.05\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced a local search intensity modifier to further refine and exploit the best solution efficiently.", "configspace": "", "generation": 8, "fitness": 0.8449490294625505, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.009. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "934f2cfd-dae6-4d3a-91a3-31219f73e4de", "metadata": {"aucs": [0.8565456113237127, 0.8435690160914184, 0.8347324609725205], "final_y": [0.1254171843211227, 0.12992435565946647, 0.13246703807409987]}, "mutation_prompt": null}
{"id": "661b9e63-7680-41c6-81c9-9089713da1a5", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Tournament selection for mutation with added noise\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices] + np.random.normal(0, 0.01, 5)\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration by introducing noise in tournament selection to increase diversity.", "configspace": "", "generation": 8, "fitness": 0.8463614843479843, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.012. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "934f2cfd-dae6-4d3a-91a3-31219f73e4de", "metadata": {"aucs": [0.8318419686104896, 0.8610442562667344, 0.846198228166729], "final_y": [0.1344758222846375, 0.1291944833739851, 0.13034065232553582]}, "mutation_prompt": null}
{"id": "8ad5fed5-d3c6-4898-a625-278f026d0f8f", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Tournament selection for mutation\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                F = 0.5 + 0.3 * np.random.rand()  # Random scaling factor for mutation\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhance exploration and convergence by incorporating random scaling of mutation and adaptive population resizing.", "configspace": "", "generation": 8, "fitness": 0.8346919403756385, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.835 with standard deviation 0.010. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "934f2cfd-dae6-4d3a-91a3-31219f73e4de", "metadata": {"aucs": [0.8477588839376013, 0.8311143060806121, 0.8252026311087021], "final_y": [0.12659798201806594, 0.12930012713036731, 0.1337217656316274]}, "mutation_prompt": null}
{"id": "9fc3ef81-e5cc-47dc-951b-bf4008e95f67", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Adjust tournament size based on variance of fitness\n                tournament_size = max(3, int(5 * (1 + np.std(fitness) / (np.max(fitness) - np.min(fitness)))))\n                tournament_indices = np.random.choice(population_size, tournament_size, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration through tournament selection size adjustment based on fitness variance to improve solution diversity and convergence.", "configspace": "", "generation": 8, "fitness": 0.8535636290391294, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.021. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "934f2cfd-dae6-4d3a-91a3-31219f73e4de", "metadata": {"aucs": [0.8814075233188314, 0.8303763602918617, 0.8489070035066951], "final_y": [0.12166370730116227, 0.12555643524699645, 0.12810643303787894]}, "mutation_prompt": null}
{"id": "dcee5007-716a-48ed-b26a-9de8eed63ebf", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Tournament selection for mutation\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search with dynamic perturbation based on convergence status\n            perturbation_strength = 0.1 * (1 - (best_fitness / np.min(fitness)))\n            perturbation = np.random.normal(0, perturbation_strength, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved local search by introducing a more dynamic perturbation mechanism based on the convergence status to enhance local exploitation capability.", "configspace": "", "generation": 8, "fitness": 0.844205552252843, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.004. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "934f2cfd-dae6-4d3a-91a3-31219f73e4de", "metadata": {"aucs": [0.8419080182377398, 0.8402600671771048, 0.8504485713436845], "final_y": [0.13285709612384444, 0.13424753989345062, 0.12565089734689916]}, "mutation_prompt": null}
{"id": "96fb79e6-6411-4bad-b190-676069ef1e58", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                # Lévy flight-inspired mutation with Gaussian perturbation\n                levy = np.random.standard_normal(self.dim) * np.power(np.random.uniform(0, 1), -1.0 / 3.0)\n                gaussian_noise = np.random.normal(0, 0.05, self.dim)\n                mutant = np.clip(a + F * (b - c) + levy + gaussian_noise, lb, ub)\n\n                # Adaptive Crossover: Adjust based on fitness diversity\n                fitness_diversity = np.std(fitness) / (np.mean(fitness) + 1e-8)\n                CR = 0.9 * (1 - fitness_diversity)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Integrating strategic Gaussian perturbation with Lévy flight mutation for improved exploration and exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.8483038346722993, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.009. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "891d3bf4-a3a1-470f-a3a9-e50e6bb47a5f", "metadata": {"aucs": [0.8581446051425012, 0.8498071579111731, 0.8369597409632236], "final_y": [0.12086952063410739, 0.12755806122448876, 0.13115881524195117]}, "mutation_prompt": null}
{"id": "9ae0699d-ca76-474c-b8c3-c9f48272e615", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                # Lévy flight-inspired mutation\n                levy = np.random.standard_normal(self.dim) * np.power(np.random.uniform(0, 1), -1.0 / 3.0)\n                fitness_diversity = np.std(fitness) / (np.mean(fitness) + 1e-8)  # Precompute fitness diversity\n                F = 0.5 * (1 - fitness_diversity)  # Adaptive scaling factor\n                mutant = np.clip(a + F * (b - c) + levy, lb, ub)\n\n                # Adaptive Crossover: Adjust based on fitness diversity\n                CR = 0.9 * (1 - fitness_diversity)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration through Lévy flight-inspired mutation with adaptive scaling factor based on fitness diversity for improved convergence.", "configspace": "", "generation": 9, "fitness": 0.8488136004843004, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.004. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "891d3bf4-a3a1-470f-a3a9-e50e6bb47a5f", "metadata": {"aucs": [0.854196196296869, 0.8486590357398242, 0.8435855694162082], "final_y": [0.12223422144143004, 0.13079857202989775, 0.1323288908188106]}, "mutation_prompt": null}
{"id": "575e9e42-cdcf-4897-8d27-21957fd693ef", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Adjust tournament size based on variance of fitness\n                tournament_size = max(3, int(5 * (1 + np.std(fitness) / (np.max(fitness) - np.min(fitness)))))\n                tournament_indices = np.random.choice(population_size, tournament_size, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                # Adjust F dynamically based on fitness diversity\n                F = 0.5 + 0.2 * (np.std(fitness) / (np.max(fitness) - np.min(fitness)))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced solution diversity and convergence through tournament size adjustment based on fitness variance and adaptive mutation factor to improve performance.", "configspace": "", "generation": 9, "fitness": 0.8481079060007871, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.009. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "9fc3ef81-e5cc-47dc-951b-bf4008e95f67", "metadata": {"aucs": [0.8501689641390496, 0.8579516589482239, 0.8362030949150879], "final_y": [0.1271231408005581, 0.11801339725859583, 0.13378882043160256]}, "mutation_prompt": null}
{"id": "172355b0-f6b3-42e2-b32e-6a0e88f5b179", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                # Lévy flight-inspired mutation with dynamic scaling\n                levy_scale = (0.1 + 0.9 * pop_convergence_factor)\n                levy = np.random.standard_normal(self.dim) * np.power(np.random.uniform(0, 1), -1.0 / 3.0) * levy_scale\n                mutant = np.clip(a + F * (b - c) + levy, lb, ub)\n\n                # Adaptive Crossover: Adjust based on fitness diversity\n                fitness_diversity = np.std(fitness) / (np.mean(fitness) + 1e-8)\n                CR = 0.9 * (1 - fitness_diversity)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Integrating dynamic scaling of Lévy flight perturbation based on population convergence to enhance global search capability.", "configspace": "", "generation": 9, "fitness": 0.8403660165244409, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.010. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "891d3bf4-a3a1-470f-a3a9-e50e6bb47a5f", "metadata": {"aucs": [0.8283536076222419, 0.8401265011144979, 0.8526179408365826], "final_y": [0.12774718902172721, 0.12868183689306, 0.12728071935668173]}, "mutation_prompt": null}
{"id": "fc613eb5-6d14-4a7c-8bfd-d493066e71b3", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Adjust tournament size based on variance of fitness\n                tournament_size = max(3, int(5 * (1 + np.std(fitness) / (np.max(fitness) - np.min(fitness)))))\n                tournament_indices = np.random.choice(population_size, tournament_size, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Incorporate a dynamic mutation factor adjustment based on the spread of fitness values to enhance convergence.", "configspace": "", "generation": 9, "fitness": 0.8529633223768028, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.009. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "9fc3ef81-e5cc-47dc-951b-bf4008e95f67", "metadata": {"aucs": [0.8458350751218492, 0.8655001486050731, 0.8475547434034861], "final_y": [0.12774716684652343, 0.12050925082599095, 0.1281568135133585]}, "mutation_prompt": null}
{"id": "19287fa4-2626-4f08-9420-810f08dc1837", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                # Lévy flight-inspired mutation\n                levy = np.random.standard_normal(self.dim) * np.power(np.random.uniform(0, 1), -1.0 / 3.0)\n                F = 0.5 + 0.3 * (1 - pop_convergence_factor)  # Adaptive differential weight\n                mutant = np.clip(a + F * (b - c) + levy, lb, ub)\n\n                # Adaptive Crossover: Adjust based on fitness diversity\n                fitness_diversity = np.std(fitness) / (np.mean(fitness) + 1e-8)\n                CR = 0.9 * (1 - fitness_diversity)\n\n                crossover = np.random.rand(self.dim) < CR * (1 - pop_convergence_factor)\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved exploration through adaptive differential weight and novel fitness-based crossover to enhance performance.", "configspace": "", "generation": 9, "fitness": 0.8439354504962854, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.017. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "891d3bf4-a3a1-470f-a3a9-e50e6bb47a5f", "metadata": {"aucs": [0.8204236643145113, 0.8517209946022815, 0.8596616925720635], "final_y": [0.1262448931667236, 0.12764735185590104, 0.1241893026075086]}, "mutation_prompt": null}
{"id": "5e285910-c09e-4746-b617-869a138ce160", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Adjust tournament size based on variance of fitness\n                tournament_size = max(3, int(5 * (1 + np.std(fitness) / (np.max(fitness) - np.min(fitness)))))\n                tournament_indices = np.random.choice(population_size, tournament_size, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.05, self.dim)  # Change scaling from 0.1 to 0.05\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration through tournament selection size adjustment based on fitness variance and local perturbation scaling to improve solution diversity and convergence.", "configspace": "", "generation": 9, "fitness": 0.8503309559846931, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.014. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "9fc3ef81-e5cc-47dc-951b-bf4008e95f67", "metadata": {"aucs": [0.8325584563309444, 0.8661399717189419, 0.8522944399041927], "final_y": [0.1305614153866569, 0.1255213524299026, 0.13037452757234635]}, "mutation_prompt": null}
{"id": "ca1d0040-18c1-49bc-bc68-cc792f31ba23", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                # Adjust tournament size based on variance of fitness\n                tournament_size = max(3, int(5 * (1 + np.std(fitness) / (np.max(fitness) - np.min(fitness)))))\n                tournament_indices = np.random.choice(population_size, tournament_size, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.sin(np.random.rand(self.dim) * 2 * np.pi) * 0.1\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration by introducing a sinusoidal perturbation in local search for better exploration around the best solution.", "configspace": "", "generation": 9, "fitness": 0.8346442467528252, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.835 with standard deviation 0.012. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9fc3ef81-e5cc-47dc-951b-bf4008e95f67", "metadata": {"aucs": [0.8202746685414757, 0.84963171487475, 0.8340263568422503], "final_y": [0.13644671117929053, 0.12959897952553856, 0.13031798179749865]}, "mutation_prompt": null}
{"id": "23311184-9d00-4b4b-88e0-e5577819a1ab", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n            \n            for i in range(population_size):\n                tournament_indices = np.random.choice(population_size, 5, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                # Lévy flight-inspired mutation\n                levy = np.random.standard_normal(self.dim) * np.power(np.random.uniform(0, 1), -1.0 / 3.0)\n                dynamic_F = F + 0.5 * (1 - best_fitness / np.max(fitness))\n                mutant = np.clip(a + dynamic_F * (b - c) + levy, lb, ub)\n\n                # Adaptive Crossover: Adjust based on fitness diversity\n                fitness_diversity = np.std(fitness) / (np.mean(fitness) + 1e-8)\n                CR = 0.9 * (1 - fitness_diversity)\n\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            perturbation = np.random.normal(0, 0.1, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration through Lévy flight-inspired mutation, adaptive crossover based on fitness diversity, and fitness-based dynamic mutation strength for improved convergence.", "configspace": "", "generation": 9, "fitness": 0.8452201786769202, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.007. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "891d3bf4-a3a1-470f-a3a9-e50e6bb47a5f", "metadata": {"aucs": [0.8367782726854851, 0.854565019145321, 0.8443172441999547], "final_y": [0.12984778808706876, 0.121885673696287, 0.1322052755466886]}, "mutation_prompt": null}
{"id": "e789ebf4-f197-4db6-ac18-0027bceb4e1e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n\n    def __call__(self, func):\n        np.random.seed(42)  # For reproducibility\n        lb, ub = func.bounds.lb, func.bounds.ub\n        population_size = 10 * self.dim\n        F = 0.5  # Differential weight\n        CR = 0.9  # Initial crossover probability\n\n        # Initialize population\n        population = np.random.uniform(lb, ub, (population_size, self.dim))\n        fitness = np.array([func(ind) for ind in population])\n        func_evals = population_size\n\n        # Store the best solution found\n        best_idx = np.argmin(fitness)\n        best_solution = population[best_idx]\n        best_fitness = fitness[best_idx]\n\n        while func_evals < self.budget:\n            # Dynamically adjust population size based on convergence rate\n            pop_convergence_factor = 1 - (best_fitness / np.max(fitness))\n            population_size = max(5, int(10 * self.dim * pop_convergence_factor))\n\n            for i in range(population_size):\n                # Adjust tournament size based on variance of fitness\n                tournament_size = max(3, int(3 + 5 * (1 + np.std(fitness) / (np.max(fitness) - np.min(fitness)))))\n                tournament_indices = np.random.choice(population_size, tournament_size, replace=False)\n                tournament_fitness = fitness[tournament_indices]\n                selected_indices = tournament_indices[np.argsort(tournament_fitness)[:3]]\n                a, b, c = population[selected_indices]\n\n                F = 0.5 * (1 + (np.std(fitness) / (np.max(fitness) - np.min(fitness))))\n                mutant = np.clip(a + F * (b - c), lb, ub)\n\n                # Adaptive Crossover: Adjust crossover probability based on fitness improvement\n                CR = 0.9 * (1 - (func_evals / self.budget))\n\n                # Crossover: Create a trial vector\n                crossover = np.random.rand(self.dim) < CR\n                trial = np.where(crossover, mutant, population[i])\n\n                # Selection: Evaluate and select the better solution\n                trial_fitness = func(trial)\n                func_evals += 1\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n\n                # Update the best solution found\n                if trial_fitness < best_fitness:\n                    best_solution = trial\n                    best_fitness = trial_fitness\n\n                if func_evals >= self.budget:\n                    break\n\n            # Local search around the best solution to refine\n            perturbation = np.random.normal(0, 0.05, self.dim)\n            candidate = np.clip(best_solution + perturbation, lb, ub)\n            candidate_fitness = func(candidate)\n            func_evals += 1\n            if candidate_fitness < best_fitness:\n                best_solution = candidate\n                best_fitness = candidate_fitness\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced exploration and exploitation through adaptive tournament size and stochastic perturbation for swift convergence.", "configspace": "", "generation": 9, "fitness": 0.8518315548196732, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.014. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "9fc3ef81-e5cc-47dc-951b-bf4008e95f67", "metadata": {"aucs": [0.8716340990745852, 0.8427646494921146, 0.8410959158923199], "final_y": [0.12458541837655634, 0.12856843438424248, 0.13022923549712484]}, "mutation_prompt": null}
