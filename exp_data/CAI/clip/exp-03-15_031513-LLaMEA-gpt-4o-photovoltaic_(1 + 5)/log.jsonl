{"id": "450101db-6bcf-4051-b18e-9f753f916cb1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "14f222cb-2448-4450-b4ae-788edb617070", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Modified line\n            cognitive_coeff = 2.0 * adaptive_factor       # Modified line\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD) improves exploration by optimizing inertia weight and cognitive coefficients dynamically.", "configspace": "", "generation": 1, "fitness": 0.8229607415372584, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.022. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "450101db-6bcf-4051-b18e-9f753f916cb1", "metadata": {"aucs": [0.8372301688346888, 0.8391717640643142, 0.7924802917127723], "final_y": [0.13794296602583422, 0.13274711005129047, 0.14658414136316633]}, "mutation_prompt": null}
{"id": "d69312a4-9d41-4fab-8c3b-776c928368b9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (evaluations / self.budget)  # Changed line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic social coefficient to enhance global exploration gradually.", "configspace": "", "generation": 1, "fitness": 0.8232526914132313, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.823 with standard deviation 0.024. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "450101db-6bcf-4051-b18e-9f753f916cb1", "metadata": {"aucs": [0.8327302041088349, 0.7908777545901842, 0.8461501155406748], "final_y": [0.14086187230887637, 0.13811366230338362, 0.13871586904696243]}, "mutation_prompt": null}
{"id": "8ccb5e45-3642-44a6-a897-6f495bbab31a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * adaptive_factor  # Adjusted to increase exploration\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Reflect velocity if out of bounds\n                self.velocity[i] = np.where((swarm[i] == lb) | (swarm[i] == ub), -self.velocity[i], self.velocity[i])\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces dynamic velocity adjustment and boundary reflection to improve convergence efficiency.", "configspace": "", "generation": 1, "fitness": 0.7850353824993822, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.785 with standard deviation 0.020. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "450101db-6bcf-4051-b18e-9f753f916cb1", "metadata": {"aucs": [0.7581250400416637, 0.7921942383073353, 0.8047868691491478], "final_y": [0.16702487276203926, 0.1452644627425621, 0.13405928827211533]}, "mutation_prompt": null}
{"id": "26648df8-5104-46dd-88c8-8c9fa6627219", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.8 * adaptive_factor  # Adjusted for enhanced exploration\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Refines exploration by adjusting the cognitive coefficient for improved convergence.", "configspace": "", "generation": 1, "fitness": 0.8321423253448087, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.008. And the mean value of best solutions found was 0.136 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "450101db-6bcf-4051-b18e-9f753f916cb1", "metadata": {"aucs": [0.8423003343331718, 0.8320610261655387, 0.8220656155357156], "final_y": [0.12854089875130248, 0.1344696244672139, 0.14611625239872916]}, "mutation_prompt": null}
{"id": "da9d5d13-7bbe-4597-8680-72a3240a31bf", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.7 * adaptive_factor  # Increased cognitive coefficient\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Slightly increases cognitive coefficient to improve personal best convergence.", "configspace": "", "generation": 1, "fitness": 0.8138756237660392, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.014. And the mean value of best solutions found was 0.142 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "450101db-6bcf-4051-b18e-9f753f916cb1", "metadata": {"aucs": [0.8239496127420792, 0.8230837407659013, 0.794593517790137], "final_y": [0.14140124137853816, 0.14067661947798416, 0.14306525318481356]}, "mutation_prompt": null}
{"id": "9919d2ea-2615-4501-9e4d-b55574e24b26", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.8 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * adaptive_factor  # Adjusted for improved convergence\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "EASGD with Adaptive Social Coefficient: Enhances convergence by dynamically adjusting the social coefficient based on evaluations.", "configspace": "", "generation": 2, "fitness": 0.8533633185033969, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.853 with standard deviation 0.012. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "26648df8-5104-46dd-88c8-8c9fa6627219", "metadata": {"aucs": [0.8369822991908741, 0.8655704107587366, 0.8575372455605798], "final_y": [0.13431339455091718, 0.12777705286056074, 0.13274306581854345]}, "mutation_prompt": null}
{"id": "c4881cd1-11b5-4b71-84bd-6daf65c0c001", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.8 * adaptive_factor  # Adjusted for enhanced exploration\n            social_coeff = 1.5 * adaptive_factor  # Dynamic adjustment\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic social coefficient adjustment to enhance exploration and exploitation balance in different search phases.", "configspace": "", "generation": 2, "fitness": 0.8462898238647792, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.846 with standard deviation 0.029. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "26648df8-5104-46dd-88c8-8c9fa6627219", "metadata": {"aucs": [0.8628355730208583, 0.8058840488659617, 0.870149849707518], "final_y": [0.1239089660099777, 0.14174558255741265, 0.1218633914786521]}, "mutation_prompt": null}
{"id": "bb2a1101-ba81-49b0-ba6a-d86bb80cd1e5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 2.0 * adaptive_factor  # Increased base for enhanced exploration\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))  # Dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Modified cognitive and social coefficients dynamically based on swarm diversity to enhance exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.8619927461118233, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.010. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "26648df8-5104-46dd-88c8-8c9fa6627219", "metadata": {"aucs": [0.8484441083994018, 0.8711807917599479, 0.8663533381761203], "final_y": [0.12188636387471163, 0.13031155760334945, 0.12986506472779247]}, "mutation_prompt": null}
{"id": "0c6a49e6-fd34-41f5-9237-f0a63d5e227a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.4 + 0.4 * adaptive_factor  # Adjusted for dynamic balance\n            social_coeff = 1.7 - 0.2 * adaptive_factor  # Adjusted for dynamic balance\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Swarm with Dynamic Social-Cognitive Adjustment (ESDSCA): Introduces time-varying coefficients for balanced exploration and exploitation.", "configspace": "", "generation": 2, "fitness": 0.8145247643240853, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.017. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "26648df8-5104-46dd-88c8-8c9fa6627219", "metadata": {"aucs": [0.7919778065535593, 0.8317395667700334, 0.819856919648663], "final_y": [0.14906859702345332, 0.12355019684259949, 0.12990368312952205]}, "mutation_prompt": null}
{"id": "629957ec-4301-44f5-885f-3f8a0352c881", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.8 * adaptive_factor  # Adjusted for enhanced exploration\n            social_coeff = 1.5 * adaptive_factor  # Adjusted for enhanced exploitation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD+): Refines exploration by adjusting both cognitive and social coefficients for improved convergence.", "configspace": "", "generation": 2, "fitness": 0.8333060675455691, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.004. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "26648df8-5104-46dd-88c8-8c9fa6627219", "metadata": {"aucs": [0.8377171625572238, 0.8271811410925141, 0.8350198989869697], "final_y": [0.12687064650374846, 0.13647018427013247, 0.13884083147018644]}, "mutation_prompt": null}
{"id": "8d23389a-6352-4732-9fa6-d25351bec30a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            velocity_variance = np.var(self.velocity)\n            cognitive_coeff = 2.0 * adaptive_factor * (1 + velocity_variance)  # Adjusted to incorporate velocity variance\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))  # Dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration-exploitation by tweaking cognitive coefficient to be influenced by swarm's velocity variance.", "configspace": "", "generation": 3, "fitness": 0.827572028614583, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.021. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "bb2a1101-ba81-49b0-ba6a-d86bb80cd1e5", "metadata": {"aucs": [0.8055002209712249, 0.8209469653677958, 0.8562688995047283], "final_y": [0.15436011751069745, 0.13713171382693212, 0.12390053378192911]}, "mutation_prompt": null}
{"id": "3c20b2f2-aec3-4273-8f9b-a2922d46b5ae", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 2.0 * adaptive_factor  # Increased base for enhanced exploration\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))  # Dynamic social coefficient\n            exploration_coeff = 0.5 * (np.mean(swarm) - np.min(swarm)) / (np.max(swarm) - np.min(swarm))  # New adaptive exploration coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i] * (1 + exploration_coeff)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced an additional adaptive coefficient to fine-tune exploration based on the normalized range of swarm positions.", "configspace": "", "generation": 3, "fitness": 0.8115145612105361, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.016. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "bb2a1101-ba81-49b0-ba6a-d86bb80cd1e5", "metadata": {"aucs": [0.8250698637473176, 0.820057555150562, 0.7894162647337288], "final_y": [0.13729038169979757, 0.13352739540641945, 0.1457978834305509]}, "mutation_prompt": null}
{"id": "f7c6ebf7-fb97-4833-84e3-f79420fb149a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 2.0 * adaptive_factor  # Increased base for enhanced exploration\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))  # Dynamic social coefficient\n            velocity_scaling = 1.0 + 0.5 * adaptive_factor  # New line: Dynamic velocity scaling factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= velocity_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic velocity scaling factor based on iteration progress for improved convergence.", "configspace": "", "generation": 3, "fitness": 0.8404363748754108, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.033. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "bb2a1101-ba81-49b0-ba6a-d86bb80cd1e5", "metadata": {"aucs": [0.798741909897131, 0.8804647430718249, 0.8421024716572767], "final_y": [0.15178493037618912, 0.12217459208040227, 0.13858823786572927]}, "mutation_prompt": null}
{"id": "0b106319-58c1-483a-89a9-fe4a1606f770", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 2.0 * adaptive_factor  # Increased base for enhanced exploration\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))  # Dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (0.9 * (inertia_weight * self.velocity[i] +  # Velocity damping factor added\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced velocity damping to reduce overshooting and enhance convergence precision.", "configspace": "", "generation": 3, "fitness": 0.8465598362216818, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.012. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "bb2a1101-ba81-49b0-ba6a-d86bb80cd1e5", "metadata": {"aucs": [0.8370493246999606, 0.8628674281138571, 0.839762755851228], "final_y": [0.140756642078385, 0.1249431339732412, 0.12799877236030865]}, "mutation_prompt": null}
{"id": "97b14287-f74a-4596-88ce-0d3008e50b04", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.8 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / (np.max(personal_best_value) + 0.0001)  # Adjusted cognitive coefficient for enhanced exploration\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))  # Dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration by adjusting cognitive coefficient based on swarm divergence.", "configspace": "", "generation": 3, "fitness": 0.8395620979621569, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.018. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "bb2a1101-ba81-49b0-ba6a-d86bb80cd1e5", "metadata": {"aucs": [0.8171726442957639, 0.8610692267020283, 0.8404444228886782], "final_y": [0.14102971683548138, 0.12827262966804098, 0.1328862983740312]}, "mutation_prompt": null}
{"id": "da21418c-d2d9-462c-b41a-34e5d9d3029f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    adaptive_factor * np.random.uniform(-1, 1, self.dim))  # Added decaying perturbation\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate a decaying random perturbation to enhance exploration in early iterations while maintaining stability in later stages.", "configspace": "", "generation": 4, "fitness": 0.8609415468609017, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.030. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "bb2a1101-ba81-49b0-ba6a-d86bb80cd1e5", "metadata": {"aucs": [0.8292040633728095, 0.8515418843102396, 0.9020786928996559], "final_y": [0.14112628597566346, 0.13030576372711633, 0.11994310030104738]}, "mutation_prompt": null}
{"id": "46bab1af-f31a-4b25-943c-82cbd314e133", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * np.power(adaptive_factor, 2)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced nonlinear inertia weight decay for enhanced balance between exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.8749556195145027, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.006. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "bb2a1101-ba81-49b0-ba6a-d86bb80cd1e5", "metadata": {"aucs": [0.8822300233941622, 0.8753107458215741, 0.8673260893277721], "final_y": [0.11958995834448072, 0.12848388165301916, 0.11987968669893878]}, "mutation_prompt": null}
{"id": "a061f485-7b83-43f5-8351-69f68cc449d1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor * (np.std(personal_best_value) / np.mean(personal_best_value))  # Dynamic inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced a dynamic component to the inertia weight based on swarm fitness diversity to enhance performance.", "configspace": "", "generation": 4, "fitness": 0.871911669460963, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.030. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "bb2a1101-ba81-49b0-ba6a-d86bb80cd1e5", "metadata": {"aucs": [0.8448606237475281, 0.8575560591260117, 0.9133183255093491], "final_y": [0.1304745901438069, 0.13139278282144506, 0.11417462662175903]}, "mutation_prompt": null}
{"id": "2d7565e8-ff1b-47e5-98c6-a3d8aafdeb27", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget)**2  # Nonlinear decrease\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Nonlinear inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                local_best = (personal_best[(i-1) % self.population_size] + \n                              personal_best[(i+1) % self.population_size]) / 2  # Local best\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (local_best - swarm[i]))  # Use local best\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate a nonlinear decreasing inertia weight and introduce a dynamic neighborhood topology to enhance convergence speed and solution accuracy.", "configspace": "", "generation": 4, "fitness": 0.8719936373908267, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.043. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "bb2a1101-ba81-49b0-ba6a-d86bb80cd1e5", "metadata": {"aucs": [0.8167374024832071, 0.8785818498420881, 0.9206616598471846], "final_y": [0.1402024681128482, 0.12664533255409138, 0.111814421325649]}, "mutation_prompt": null}
{"id": "05e6bca7-4217-4fe8-b254-caaba87010b7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.8 * adaptive_factor  # Increased base for enhanced exploration\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))  # Dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved swarm diversity leveraging a dynamic perturbation factor for better global convergence.", "configspace": "", "generation": 4, "fitness": 0.840204978276085, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.840 with standard deviation 0.042. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "bb2a1101-ba81-49b0-ba6a-d86bb80cd1e5", "metadata": {"aucs": [0.7902172378161296, 0.8373360800218449, 0.8930616169902804], "final_y": [0.1448496955056301, 0.13603840084697738, 0.11692022623260523]}, "mutation_prompt": null}
{"id": "91bcc9f7-b162-478a-aac9-8f913d791d64", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * np.power(adaptive_factor, 2)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * np.power(adaptive_factor, 1.5)  # Modified cognitive coefficient decay\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrated cognitive coefficient decay to enhance local search capabilities over iterations.", "configspace": "", "generation": 5, "fitness": 0.8501567672432584, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.038. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "46bab1af-f31a-4b25-943c-82cbd314e133", "metadata": {"aucs": [0.8072085952160901, 0.8437004992086913, 0.8995612073049939], "final_y": [0.14454922422948002, 0.1349881664697441, 0.11669559782507599]}, "mutation_prompt": null}
{"id": "9c6a0b06-24db-4d0a-a246-48ad78df4aa4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * np.power(adaptive_factor, 2)\n            cognitive_coeff = 2.0 * (1 + 0.1 * adaptive_factor)  # Adjustment to cognitive coefficient\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced adaptive factors for improved balance between exploration and exploitation.", "configspace": "", "generation": 5, "fitness": 0.8685233408497832, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.021. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "46bab1af-f31a-4b25-943c-82cbd314e133", "metadata": {"aucs": [0.8638000852929271, 0.8960607667263955, 0.8457091705300274], "final_y": [0.11993940948261106, 0.11290460961689464, 0.12441887477571922]}, "mutation_prompt": null}
{"id": "28704a08-3629-4fe3-92de-ed01276085b2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.adaptive_learning_rate = 0.1  # New line for adaptive learning rate\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * np.power(adaptive_factor, 2)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.adaptive_learning_rate * self.velocity[i]  # Modified line for learning rate application\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n                    self.adaptive_learning_rate *= 1.05  # New line for adaptive learning rate increment\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced local search via adaptive learning rate and memory mechanism for improved convergence.", "configspace": "", "generation": 5, "fitness": 0.8551549371894103, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.855 with standard deviation 0.021. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "46bab1af-f31a-4b25-943c-82cbd314e133", "metadata": {"aucs": [0.8256707613896237, 0.8687415923326605, 0.8710524578459465], "final_y": [0.13500884893961096, 0.12226793098663391, 0.12888896373242487]}, "mutation_prompt": null}
{"id": "9dd32aca-e3ba-462a-9220-021761e2ab04", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * np.power(adaptive_factor, 2)\n            cognitive_coeff = 2.0 + 0.5 * adaptive_factor  # Adjusted scaling for cognitive coefficient\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration via dynamic cognitive coefficient scaling based on iteration proximity to the budget limit.", "configspace": "", "generation": 5, "fitness": 0.8561446635573556, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.040. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "46bab1af-f31a-4b25-943c-82cbd314e133", "metadata": {"aucs": [0.8007262765396319, 0.8958375985869883, 0.8718701155454467], "final_y": [0.1343947369265437, 0.11577886618073996, 0.12116321141508468]}, "mutation_prompt": null}
{"id": "64b8a3f5-79e4-44ec-b55a-f73a9a56e8f9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * np.power(adaptive_factor, 2)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.2 + 0.5 * (np.std(personal_best_value) / np.mean(personal_best_value))  # Adjusted range\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced social coefficient responsiveness by adjusting its range based on the standard deviation of personal best values.", "configspace": "", "generation": 5, "fitness": 0.8302474826996001, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.015. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "46bab1af-f31a-4b25-943c-82cbd314e133", "metadata": {"aucs": [0.8260277955127125, 0.8138207025180009, 0.8508939500680871], "final_y": [0.13667852064008945, 0.14520827762018296, 0.1284849155898331]}, "mutation_prompt": null}
{"id": "4ba8e46f-f866-4749-8cb4-ee5abbaca5e3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * np.power(adaptive_factor, 2)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.std(self.velocity) / np.mean(self.velocity))  # Changed line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic social coefficient based on the variance of velocity to enhance convergence precision.", "configspace": "", "generation": 6, "fitness": 0.7981049177075512, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.798 with standard deviation 0.088. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.042.", "error": "", "parent_id": "46bab1af-f31a-4b25-943c-82cbd314e133", "metadata": {"aucs": [0.6737438162512668, 0.8572854803761712, 0.8632854564952158], "final_y": [0.21185908847573987, 0.12425356316188252, 0.11973437018822364]}, "mutation_prompt": null}
{"id": "6a0c84fa-9580-46b2-84d6-93ddab59cd6d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * np.power(adaptive_factor, 2)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            # Change: Dynamic adjustment of population size\n            self.population_size = max(5, int((10 + 2 * int(np.sqrt(self.dim))) * adaptive_factor))\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic population resizing based on evaluation budget to subtly balance exploration and exploitation.", "configspace": "", "generation": 6, "fitness": 0.864191472395936, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.023. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "46bab1af-f31a-4b25-943c-82cbd314e133", "metadata": {"aucs": [0.8319440971840536, 0.8741691857119039, 0.88646113429185], "final_y": [0.13203451830887247, 0.12033387792755845, 0.1156296787278448]}, "mutation_prompt": null}
{"id": "883163bd-2298-46b5-8aa2-ca6b3646c174", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved inertia weight decay to enhance late-stage exploration.", "configspace": "", "generation": 6, "fitness": 0.8770175864874842, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.011. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "46bab1af-f31a-4b25-943c-82cbd314e133", "metadata": {"aucs": [0.8683385634990416, 0.8931368304553535, 0.869577365508057], "final_y": [0.1229996438026103, 0.1176636525789202, 0.12515407600788886]}, "mutation_prompt": null}
{"id": "cfa206e3-5b9c-45c5-84a0-150fb420eac6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        # Changed velocity initialization to scale with search space size\n        self.velocity = np.random.uniform(-0.1, 0.1, (self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * np.power(adaptive_factor, 2)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration by adapting velocity initialization based on search space size.", "configspace": "", "generation": 6, "fitness": 0.8328992622703563, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.040. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "46bab1af-f31a-4b25-943c-82cbd314e133", "metadata": {"aucs": [0.7826179194770488, 0.8798993022305525, 0.836180565103467], "final_y": [0.14348890522297397, 0.11831230845099983, 0.1315716032955998]}, "mutation_prompt": null}
{"id": "f0205127-c880-4816-9410-b9591f9f076c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * np.power(adaptive_factor, 2)  # Nonlinear decay for inertia weight\n            # Modified cognitive coefficient for improved exploration\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * np.power(adaptive_factor, 3))\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced balance with nonlinear cognitive coefficient adjustment for improved convergence.", "configspace": "", "generation": 6, "fitness": 0.8480863477541501, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.037. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "46bab1af-f31a-4b25-943c-82cbd314e133", "metadata": {"aucs": [0.7966261066170566, 0.8670642517232331, 0.8805686849221607], "final_y": [0.13440080878484084, 0.12234430256886653, 0.11964148866761493]}, "mutation_prompt": null}
{"id": "f52da14d-78ec-4e00-84ab-b34e56421ee0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.4 * (np.std(swarm) / np.mean(np.abs(swarm)))  # Increased diversity impact\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration via adaptive social coefficient based on diversity.", "configspace": "", "generation": 7, "fitness": 0.8652324104713314, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.020. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "883163bd-2298-46b5-8aa2-ca6b3646c174", "metadata": {"aucs": [0.8491981169426193, 0.8931385732044127, 0.853360541266962], "final_y": [0.12403340769806837, 0.11677502258900874, 0.12163636254814769]}, "mutation_prompt": null}
{"id": "85acf8bd-ca93-497c-90d8-f998d7f96f07", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            population_diversity = np.mean(np.std(swarm, axis=0))\n            cognitive_coeff = 1.5 + 0.5 * (population_diversity / (ub - lb).mean())  # Dynamic cognitive coefficient\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporating dynamic learning coefficients based on population diversity to improve convergence.", "configspace": "", "generation": 7, "fitness": 0.8701046116947252, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.024. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "883163bd-2298-46b5-8aa2-ca6b3646c174", "metadata": {"aucs": [0.8399456930619486, 0.8718566931579854, 0.8985114488642416], "final_y": [0.13067097436537256, 0.11736391367440369, 0.11435619557424215]}, "mutation_prompt": null}
{"id": "4739b3e1-cabf-416c-b90f-80ac67f16736", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        prev_global_best_value = global_best_value\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n\n            # Adjust social coefficient dynamically based on optimization speed\n            optimization_speed = (prev_global_best_value - global_best_value) / global_best_value if global_best_value != 0 else 0\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value)) + 0.5 * optimization_speed\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    prev_global_best_value = global_best_value\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm convergence with dynamic coefficient adjustment based on optimization speed.", "configspace": "", "generation": 7, "fitness": 0.8732894420854628, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.016. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "883163bd-2298-46b5-8aa2-ca6b3646c174", "metadata": {"aucs": [0.852848188488788, 0.8754800617974381, 0.8915400759701626], "final_y": [0.1252721993605842, 0.11863943037307878, 0.11521398964560892]}, "mutation_prompt": null}
{"id": "942f279a-26ec-4c99-8143-f52bc862ae42", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                mutation = np.random.normal(0, 0.1, self.dim)  # Mutation strategy added\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    mutation)  # Incorporating mutation into velocity update\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced velocity adjustment by incorporating a mutation strategy for diversity.", "configspace": "", "generation": 7, "fitness": 0.8478622822012643, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.015. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "883163bd-2298-46b5-8aa2-ca6b3646c174", "metadata": {"aucs": [0.8270976710726129, 0.8627750276368998, 0.85371414789428], "final_y": [0.12695310584031394, 0.1268041768937721, 0.12902096330593216]}, "mutation_prompt": null}
{"id": "5f459dd9-5bcc-4ef4-8ed2-e4049b209d6e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n            adaptive_lr = 0.5 + 0.5 * adaptive_factor  # New adaptive learning rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * adaptive_lr  # Applied adaptive learning rate\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive learning rate for velocity updates to enhance convergence efficiency.", "configspace": "", "generation": 7, "fitness": 0.867811550200808, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.014. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "883163bd-2298-46b5-8aa2-ca6b3646c174", "metadata": {"aucs": [0.8768228071516764, 0.8781533400964487, 0.8484585033542987], "final_y": [0.12723466324436672, 0.12449519530623787, 0.13022059270874276]}, "mutation_prompt": null}
{"id": "f6f888d9-8d8a-4306-8427-2b341d5e75fa", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 - 1.5 * adaptive_factor  # Time-varying cognitive coefficient\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce time-varying cognitive coefficient for enhanced local exploration.", "configspace": "", "generation": 8, "fitness": 0.859352755434661, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.032. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "883163bd-2298-46b5-8aa2-ca6b3646c174", "metadata": {"aucs": [0.8188615777907973, 0.8629957170597522, 0.8962009714534338], "final_y": [0.14671855095832542, 0.12709433400306436, 0.11169730016279455]}, "mutation_prompt": null}
{"id": "b28a87b0-8339-48a7-93de-55c0bf0cea7b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Chaotic map-based update\n                if np.random.rand() < 0.1:  # 10% chance for chaotic perturbation\n                    chaos_factor = np.sin(np.pi * swarm[i])\n                    swarm[i] += 0.05 * chaos_factor\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate chaotic map-based position updates to enhance solution diversity.", "configspace": "", "generation": 8, "fitness": 0.8683695423788809, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.006. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "883163bd-2298-46b5-8aa2-ca6b3646c174", "metadata": {"aucs": [0.8655252792984477, 0.8769674562157871, 0.8626158916224078], "final_y": [0.12734133090102395, 0.124118300765237, 0.11639625902528938]}, "mutation_prompt": null}
{"id": "20f1bd12-cb18-4cd1-9f4b-e9f13675f014", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.5 * (np.std(personal_best_value) / np.mean(personal_best_value))  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic adaptation of social coefficient based on personal best standard deviation to enhance exploration capabilities.", "configspace": "", "generation": 8, "fitness": 0.861620924259717, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.024. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "883163bd-2298-46b5-8aa2-ca6b3646c174", "metadata": {"aucs": [0.8304384841971633, 0.8672254653367775, 0.8871988232452105], "final_y": [0.13141197783515268, 0.11652874134173996, 0.12079764954085725]}, "mutation_prompt": null}
{"id": "9cd48834-74aa-457f-a539-bea7b26c5315", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor  # Adjusted cognitive coefficient for adaptive influence\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive personal-best influence to balance exploration and exploitation based on diversity.", "configspace": "", "generation": 8, "fitness": 0.8511402917741823, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.027. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "883163bd-2298-46b5-8aa2-ca6b3646c174", "metadata": {"aucs": [0.8127234801495125, 0.872448791631286, 0.8682486035417483], "final_y": [0.13235876632739052, 0.1264418694720203, 0.11762189944855239]}, "mutation_prompt": null}
{"id": "a1072313-6eaf-495a-a77e-88239b500db2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n            \n            # Dynamic resizing of the population\n            self.population_size = int((10 + 2 * np.sqrt(self.dim)) * (1 + 0.5 * adaptive_factor))\n\n            for i in range(self.population_size):\n                if i >= len(swarm):  # Rescale swarm size\n                    swarm = np.append(swarm, [np.random.uniform(lb, ub, self.dim)], axis=0)\n                    self.velocity = np.append(self.velocity, [np.zeros(self.dim)], axis=0)\n                    personal_best = np.append(personal_best, [swarm[i]], axis=0)\n                    personal_best_value = np.append(personal_best_value, func(swarm[i]))\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic population resizing based on convergence speed to improve exploration-exploitation balance.", "configspace": "", "generation": 8, "fitness": 0.8599233272694558, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.028. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "883163bd-2298-46b5-8aa2-ca6b3646c174", "metadata": {"aucs": [0.8209027072863777, 0.871653043747116, 0.8872142307748735], "final_y": [0.13151850834234302, 0.1221956300190018, 0.11544227630379056]}, "mutation_prompt": null}
{"id": "e2cec729-3f8e-4099-8588-99f388d588b6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            iteration_progress = evaluations / self.budget  # Calculate iteration progress\n            social_coeff = 1.3 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value)) * (1 + 0.5 * np.sin(np.pi * iteration_progress))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration by introducing adaptive social coefficient variation based on iteration progress.", "configspace": "", "generation": 9, "fitness": 0.8776496356635578, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.005. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "883163bd-2298-46b5-8aa2-ca6b3646c174", "metadata": {"aucs": [0.8728236461938079, 0.8763283958621536, 0.8837968649347121], "final_y": [0.12479333722600205, 0.11659164041982817, 0.11456646057826636]}, "mutation_prompt": null}
{"id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            # Modified line for social coefficient\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive social coefficient based on population diversity to enhance exploration.", "configspace": "", "generation": 9, "fitness": 0.8933867712608364, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.019. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "883163bd-2298-46b5-8aa2-ca6b3646c174", "metadata": {"aucs": [0.8660956407931791, 0.9037169264413333, 0.9103477465479967], "final_y": [0.12410900609913278, 0.1165270179796466, 0.11087296466814411]}, "mutation_prompt": null}
{"id": "ccd336c7-9170-4efb-b973-c5ddfa082f27", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.5 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            if evaluations >= 0.5 * self.budget:\n                self.velocity = np.zeros((self.initial_population_size // 2, self.dim))\n                swarm = swarm[:self.initial_population_size // 2]\n                personal_best = personal_best[:self.initial_population_size // 2]\n                personal_best_value = personal_best_value[:self.initial_population_size // 2]\n\n            for i in range(len(swarm)):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced AdaptiveSwarmGradientDescent with adaptive social coefficient scaling and dynamic population size adjustment.", "configspace": "", "generation": 9, "fitness": 0.8724162743230428, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.026. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "883163bd-2298-46b5-8aa2-ca6b3646c174", "metadata": {"aucs": [0.8552654902758982, 0.85351809751819, 0.9084652351750404], "final_y": [0.12614488141379487, 0.12617757102725957, 0.11525786556945783]}, "mutation_prompt": null}
{"id": "7ee8a97f-1670-460e-ace4-198bb039912f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * np.power(adaptive_factor, 3)  # Adjusted decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.5 + 0.1 * (np.std(personal_best_value) / np.mean(personal_best_value))\n            velocity_clamp = (ub - lb) * adaptive_factor \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = np.clip((inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])), -velocity_clamp, velocity_clamp)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm exploration and convergence by introducing adaptive velocity clamping and dynamic population size adjustment.", "configspace": "", "generation": 9, "fitness": 0.8728521217583358, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.004. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "883163bd-2298-46b5-8aa2-ca6b3646c174", "metadata": {"aucs": [0.8776347536253851, 0.8732518079024874, 0.8676698037471346], "final_y": [0.11951286566076924, 0.12353657901217219, 0.11815117033502298]}, "mutation_prompt": null}
{"id": "5d38b436-af57-494d-974b-58032be30aa3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            \n            # Change: Dynamic adjustment to population size\n            self.population_size = max(5, int((10 + 2 * np.sqrt(self.dim)) * adaptive_factor))\n            cognitive_coeff = 2.0 * adaptive_factor\n            \n            # Change: Enhanced social coefficient for better balance\n            social_coeff = 1.5 + 0.2 * (np.std(personal_best_value) / np.mean(personal_best_value))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic population size adjustment and enhanced social coefficient for better exploration and exploitation balance.", "configspace": "", "generation": 9, "fitness": 0.8700194034909076, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.013. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "883163bd-2298-46b5-8aa2-ca6b3646c174", "metadata": {"aucs": [0.8825217445557969, 0.8515123980758457, 0.8760240678410801], "final_y": [0.11299477104632649, 0.13546831128412096, 0.1263838623250777]}, "mutation_prompt": null}
{"id": "e9f2c723-07f0-4fc2-98e5-c61b2f01d87a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * np.power(adaptive_factor, 5)  # More aggressive nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adjust inertia weight decay to be more aggressive for better convergence.", "configspace": "", "generation": 10, "fitness": 0.8802593829873139, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.033. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.83373901254859, 0.9046126358522909, 0.9024265005610608], "final_y": [0.1379892436469502, 0.11631515512415835, 0.11409784801281875]}, "mutation_prompt": null}
{"id": "1d927af7-526c-41e0-b02f-850795665793", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                sigmoid_component = 1 / (1 + np.exp(-adaptive_factor * 10))  # Sigmoid function\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) * sigmoid_component)  # Adjusted line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic velocity adjustment using a nonlinear sigmoid function to enhance convergence.", "configspace": "", "generation": 10, "fitness": 0.8674035354925104, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.016. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8470178781721202, 0.8687507994745097, 0.8864419288309013], "final_y": [0.13078878010163475, 0.12667321946949228, 0.11742500120070443]}, "mutation_prompt": null}
{"id": "9dbd9772-c0e7-400a-a689-18e7f24f18a2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            # Modified lines for social coefficient and adding dynamic learning factor\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n            dynamic_learning = 0.5 + 0.5 * adaptive_factor  # New dynamic learning factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    dynamic_learning * cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic learning factor to enhance exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.8749923635451401, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.023. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8439506628587217, 0.8983330315470344, 0.8826933962296644], "final_y": [0.13292062599685706, 0.11630668900861829, 0.11979878940822208]}, "mutation_prompt": null}
{"id": "7231c5a3-f5de-4638-8643-2953c5daa010", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            # Modified line for social coefficient\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value) + 0.1 * np.linalg.norm(self.velocity)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance the adaptive social coefficient further by incorporating velocity information to adjust exploration-exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.8581712309322151, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.063. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.7710298158524602, 0.8885723153272255, 0.9149115616169594], "final_y": [0.16086437281120458, 0.11621687326785723, 0.11783987530815954]}, "mutation_prompt": null}
{"id": "7d116b2a-d6b3-40d3-af4b-5d71906f53b1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            # Dynamic adjustment of population size\n            dynamic_population_size = max(5, int(self.population_size * adaptive_factor))\n\n            for i in range(dynamic_population_size):  # Updated line\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic population size adjustment based on iterations to improve diversity and convergence.", "configspace": "", "generation": 10, "fitness": 0.876446978135723, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.876 with standard deviation 0.013. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8781452414104963, 0.860183323519746, 0.8910123694769267], "final_y": [0.12439743074722676, 0.12667926441346167, 0.11786172336582845]}, "mutation_prompt": null}
{"id": "c86e19c0-3423-4802-9cda-463bdfb9ab58", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.initial_population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * np.power(adaptive_factor, 2)  # Adjusted for velocity scaling\n            cognitive_coeff = 2.0 * (1 - adaptive_factor * 0.5)\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            # Dynamic population size adjustment\n            current_population_size = int(self.initial_population_size * (1 + adaptive_factor * 0.5))\n            current_population_size = min(current_population_size, len(swarm))\n\n            for i in range(current_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive velocity scaling and dynamic population size to improve convergence and exploration.  ", "configspace": "", "generation": 11, "fitness": 0.8769511148417953, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.003. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.873427760083318, 0.8815604554158617, 0.8758651290262062], "final_y": [0.11079626208339943, 0.12013261344490367, 0.11706583533526804]}, "mutation_prompt": null}
{"id": "3134a54b-6a4c-4797-8269-646e8aa2bcb2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)\n            # Modified line for cognitive coefficient\n            cognitive_coeff = 2.0 * np.power(adaptive_factor, 2)\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate a nonlinear decay for cognitive coefficient to enhance convergence speed and accuracy.", "configspace": "", "generation": 11, "fitness": 0.8657106222968743, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.009. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8770184481155698, 0.8641808788065073, 0.8559325399685458], "final_y": [0.1212013040339116, 0.12668368509406036, 0.11765275286552246]}, "mutation_prompt": null}
{"id": "a70c6c18-9893-4e57-87f6-658b94bb98aa", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            # Modified line for cognitive coefficient\n            cognitive_coeff = 2.0 * np.power(adaptive_factor, 2) \n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a nonlinear scaling factor for the cognitive coefficient to improve convergence in Adaptive Swarm Gradient Descent.", "configspace": "", "generation": 11, "fitness": 0.859376152807697, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.015. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8457450508309443, 0.8518381589042621, 0.8805452486878849], "final_y": [0.13004531801750263, 0.1344212238117789, 0.11243095210086063]}, "mutation_prompt": null}
{"id": "976fda66-ce52-406d-838d-8827e30ca6fe", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] *= np.power(0.99, adaptive_factor)  # Non-linear velocity decay\n                self.velocity[i] += (cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                     social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                # Adaptive boundary handling\n                swarm[i] = np.clip(swarm[i], lb - 0.1 * np.abs(self.velocity[i]), ub + 0.1 * np.abs(self.velocity[i]))\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a non-linear velocity decay and adaptive boundary handling to enhance convergence precision.", "configspace": "", "generation": 11, "fitness": 0.8469676459950058, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.048. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.022.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.7800250393429128, 0.8909141945575577, 0.8699637040845473], "final_y": [0.16360177884391347, 0.11975684798404695, 0.11610461898109259]}, "mutation_prompt": null}
{"id": "ebd5e01b-8224-4e6d-b53c-c78ab3a6828d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        success_rate = np.zeros(self.population_size)\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)\n            cognitive_coeff = 1.5 + 0.5 * np.mean(success_rate)  # Dynamic cognitive coefficient\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n                    success_rate[i] = 1.0\n                else:\n                    success_rate[i] = 0.0\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Include a dynamic cognitive coefficient based on historical success rates to enhance convergence.", "configspace": "", "generation": 11, "fitness": 0.8617578757748814, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.012. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8469794599008775, 0.8750500290030208, 0.863244138420746], "final_y": [0.12752435090280445, 0.1203622425877321, 0.11713642400015312]}, "mutation_prompt": null}
{"id": "acba3ebb-61fc-4dc9-a194-28b733eecf5a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            # Dynamic population size scaling\n            self.population_size = int((1 + adaptive_factor) * self.population_size)\n            self.velocity = np.zeros((self.population_size, self.dim))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic population size scaling based on convergence speed to enhance exploitation.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {}, "mutation_prompt": null}
{"id": "ee59616a-a77c-4d1c-9c0f-667d1b98fdcb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            if evaluations % (self.budget // 4) == 0 and evaluations > self.budget // 2:\n                self.population_size = max(5, self.population_size - 1)  # Decrease population size to enhance exploitation\n                # Update velocity array to match new population size\n                self.velocity = self.velocity[:self.population_size]\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n\n                if evaluations % (self.budget // 10) == 0:  # Introduce perturbation\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += perturbation\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n                    f_value = func(swarm[i])\n\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration-exploitation balance by dynamically adjusting swarm size and introducing a perturbation mechanism.", "configspace": "", "generation": 12, "fitness": 0.8582903365159399, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.011. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8720129876654232, 0.8444984462397875, 0.858359575642609], "final_y": [0.12114246235620685, 0.1348177994721781, 0.1268475137592232]}, "mutation_prompt": null}
{"id": "73f61e04-4c08-49a4-aaa6-eb0efdbc87fa", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * np.cos(np.pi * adaptive_factor)  # Introduce cosine function for smoother nonlinear decay\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive inertia weight with nonlinear decay to balance exploration and exploitation.", "configspace": "", "generation": 12, "fitness": 0.873232225791591, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.026. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8685973082525064, 0.9066874358665483, 0.8444119332557183], "final_y": [0.13022993215308554, 0.11500692663667844, 0.13392366757114926]}, "mutation_prompt": null}
{"id": "136bcc23-abab-42b3-a3da-1336af8f7e7f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamic adjustment of population size\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(5, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate a dynamic population size adjustment based on convergence rate to improve exploration and exploitation balance.", "configspace": "", "generation": 12, "fitness": 0.8704472269662741, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.870 with standard deviation 0.016. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8495172854878061, 0.8743493044571675, 0.8874750909538486], "final_y": [0.12423614151652007, 0.11871342559006548, 0.11204761757376702]}, "mutation_prompt": null}
{"id": "d8290a48-4bd0-47bb-a254-dd2a8be33ace", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                # Introduce adaptive mutation\n                mutation_strength = 0.1 * adaptive_factor\n                swarm[i] += mutation_strength * np.random.normal(0, 1, self.dim)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive mutation mechanism to encourage early-stage exploration and late-stage exploitation.", "configspace": "", "generation": 12, "fitness": 0.8726565791080968, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.009. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8607794019473716, 0.8812604841172141, 0.8759298512597047], "final_y": [0.12210640093682956, 0.11880672308245455, 0.11695265976621039]}, "mutation_prompt": null}
{"id": "cdca2cef-8a74-4e8e-80a3-4b525d058d92", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            # Dynamic adjustment of population size based on convergence rate\n            self.population_size = max(5, int((10 + 2 * int(np.sqrt(self.dim))) * adaptive_factor))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic population size adjustment based on convergence rate to balance exploration and exploitation.", "configspace": "", "generation": 13, "fitness": 0.887689822590279, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.019. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8836363893831923, 0.8663365823533624, 0.913096496034282], "final_y": [0.12276416598911521, 0.127232917689162, 0.1130737165893887]}, "mutation_prompt": null}
{"id": "654236a1-74ac-400a-8355-bb35a82f395b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.initial_population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.initial_population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraints on function evaluations and initializations\n        evaluations = self.initial_population_size\n        previous_best_value = global_best_value\n\n        while evaluations < self.budget:\n            convergence_rate = np.abs(previous_best_value - global_best_value) / (previous_best_value + 1e-10)\n            previous_best_value = global_best_value\n            population_size = max(5, int(self.initial_population_size * (1 - convergence_rate)))\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Utilize a dynamic population size based on convergence rate to adapt exploration and exploitation phases effectively.", "configspace": "", "generation": 13, "fitness": 0.8523008236270667, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.025. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8188064748678834, 0.8585553916042191, 0.879540604409098], "final_y": [0.14308480213931252, 0.12088661130962963, 0.12494523975083349]}, "mutation_prompt": null}
{"id": "050a8904-dee1-4eff-9c19-33eb7a3a0c55", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            # Change line: Dynamic population size to enhance exploitation\n            self.population_size = max(5, int((10 + 2 * int(np.sqrt(self.dim))) * adaptive_factor))\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic swarm size that decreases over time to enhance exploitation as the search progresses.", "configspace": "", "generation": 13, "fitness": 0.8736391174165204, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.037. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8214632916044236, 0.896988032831353, 0.9024660278137852], "final_y": [0.14468320816925972, 0.11259468496809655, 0.11058800692692006]}, "mutation_prompt": null}
{"id": "30110bdb-3143-4bf3-999d-16052e2744bf", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * np.power(adaptive_factor, 2)  # Modified line for cognitive coefficient\n            # Modified line for social coefficient\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce nonlinear decay for the cognitive coefficient to balance exploration and exploitation.", "configspace": "", "generation": 13, "fitness": 0.8590703972422391, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.011. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8667002272218933, 0.8670480201275115, 0.8434629443773123], "final_y": [0.12764759965165529, 0.12270873025467299, 0.12302752182325294]}, "mutation_prompt": null}
{"id": "7f4f7199-4c87-4612-840d-227c6e24ae52", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)\n            # Modified line for cognitive coefficient\n            cognitive_coeff = 2.0 * (1 + np.std(personal_best_value) / np.mean(personal_best_value))\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance the exploration capability by dynamically adjusting the cognitive coefficient based on solution dispersion.", "configspace": "", "generation": 13, "fitness": 0.861087466829994, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.031. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8226595876418475, 0.8620652320486271, 0.8985375807995072], "final_y": [0.13464077895963145, 0.11699839827568415, 0.11379373483659883]}, "mutation_prompt": null}
{"id": "01715903-2f30-4859-b915-fe0bf988d8fc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)\n            # Modified lines for cognitive and social coefficients\n            fitness_variance = np.var(personal_best_value) / np.mean(personal_best_value)\n            cognitive_coeff = 1.5 + 0.5 * fitness_variance\n            social_coeff = 1.5 + 0.5 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic cognitive and social coefficients based on fitness variance to optimize exploration-exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.8720845560801728, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.015. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8774607158321682, 0.8868691723548848, 0.8519237800534656], "final_y": [0.11643812656442931, 0.1223697774735899, 0.1231317767031036]}, "mutation_prompt": null}
{"id": "65f8d454-8991-485c-a04b-df5f1e9e5732", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            # Modified line for social coefficient\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / (np.mean(personal_best_value) * (1 + evaluations / self.budget))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine the adaptive social coefficient by incorporating both diversity and convergence speed to enhance exploration and exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.8707550296866469, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.871 with standard deviation 0.010. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8841096219524208, 0.8585433650161101, 0.8696121020914095], "final_y": [0.1171926994075354, 0.12500942141712468, 0.11496688029461577]}, "mutation_prompt": null}
{"id": "f52327d6-306d-4219-8407-feef52bf8109", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            # Modified line for cognitive coefficient\n            cognitive_coeff = 2.0 * np.power(adaptive_factor, 3)\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce nonlinear decay for cognitive coefficient to enhance convergence by focusing on local search as evaluations progress.", "configspace": "", "generation": 14, "fitness": 0.872688395733868, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.873 with standard deviation 0.021. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8611190549843439, 0.8552378130414957, 0.9017083191757645], "final_y": [0.12401135136283636, 0.13123315828006532, 0.11274725591565915]}, "mutation_prompt": null}
{"id": "44db5652-ec82-45d1-b514-4a2829058896", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Mutation step to enhance diversity\n                if np.random.rand() < 0.1:\n                    swarm[i] += np.random.normal(0, 0.1, self.dim)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance particle diversity by introducing a mutation step to prevent premature convergence.", "configspace": "", "generation": 14, "fitness": 0.88275608673503, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.883 with standard deviation 0.019. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.876432840333558, 0.8628852969721674, 0.9089501228993648], "final_y": [0.11594358936241433, 0.12674269695668627, 0.1128027054692794]}, "mutation_prompt": null}
{"id": "75969dfb-c38d-4bfa-bdff-e45c686c1b0a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Modified line for adaptive velocity scaling factor\n                velocity_scaling = 1 + 0.5 * (1 - adaptive_factor)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * velocity_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive velocity scaling factor based on evaluations to enhance convergence.", "configspace": "", "generation": 14, "fitness": 0.842690289794937, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.843 with standard deviation 0.039. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.016.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.796581369064383, 0.8923550489371226, 0.839134451383305], "final_y": [0.15506842915561148, 0.1164507038130489, 0.1302569101386465]}, "mutation_prompt": null}
{"id": "e1a83454-47a6-4e6d-9bf7-265fbf7daded", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            # Modified line for cognitive coefficient\n            cognitive_coeff = 2.0 * adaptive_factor * (1 + np.std(personal_best_value) / np.mean(personal_best_value))\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic adjustment to the cognitive coefficient based on the stagnation of the swarm to enhance exploration.", "configspace": "", "generation": 15, "fitness": 0.8564613498156217, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.856 with standard deviation 0.008. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8465510342766558, 0.8662656167720647, 0.8565673983981447], "final_y": [0.13202066169582916, 0.12691726410284543, 0.12501671689522253]}, "mutation_prompt": null}
{"id": "3f9f70d2-8309-42a7-ab82-670778866f67", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            # Change: Adaptive velocity scaling based on diversity\n            diversity = np.std(swarm, axis=0)\n            velocity_scaling = 1.0 + 0.5 * (np.mean(diversity) / (ub - lb).mean())\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= velocity_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Leverage adaptive velocity scaling based on diversity to improve convergence speed in swarm optimization.", "configspace": "", "generation": 15, "fitness": 0.8521789308112481, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.012. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8377485761180324, 0.8667709741515669, 0.852017242164145], "final_y": [0.134656278005302, 0.1231220865269057, 0.1316442915667616]}, "mutation_prompt": null}
{"id": "9e50368a-6064-4529-ab06-ab8e56a1c1f7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 1.5 + 0.5 * adaptive_factor  # Modified line for cognitive coefficient\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a decay factor for cognitive coefficient to balance exploration and exploitation over iterations.", "configspace": "", "generation": 15, "fitness": 0.867663244102158, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.011. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8806869584452868, 0.8544988693662015, 0.8678039044949858], "final_y": [0.12039010091747249, 0.13471886089630336, 0.12665352671028907]}, "mutation_prompt": null}
{"id": "6ed68de0-d104-4435-88e2-543d99c4be2f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                # Change: Dynamic strategy to maintain diversity\n                if f_value < personal_best_value[i] or np.random.rand() < 0.1: \n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by using a dynamic personal best strategy to maintain diversity.", "configspace": "", "generation": 15, "fitness": 0.8492967903701181, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.004. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8456276883200002, 0.8551414581451, 0.8471212246452541], "final_y": [0.13644508747603723, 0.12324057131647792, 0.12413553880439299]}, "mutation_prompt": null}
{"id": "d7236b49-da08-4a32-bfbe-9d91c4faec89", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 + 0.4 * np.power(adaptive_factor, 3)  # Nonlinear decay for inertia weight\n            cognitive_coeff = 2.0 * adaptive_factor\n            # Modified line for social coefficient\n            social_coeff = 1.3 + 0.2 * (np.max(personal_best_value) - np.min(personal_best_value)) / np.mean(personal_best_value)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best with reduced frequency\n                if evaluations % 5 == 0 and f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adjust personal and global best update frequencies to improve convergence speed.", "configspace": "", "generation": 15, "fitness": 0.8572946458800086, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.008. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "b5cafd2c-4726-4481-9333-cb47b27d14f5", "metadata": {"aucs": [0.8682923787318189, 0.8525584236022883, 0.8510331353059185], "final_y": [0.120644140097386, 0.120931416538276, 0.11774657825219903]}, "mutation_prompt": null}
