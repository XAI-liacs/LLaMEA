{"id": "29bf4cb1-deb2-42f4-8c82-ff2a27c29ba4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "240718e8-2e23-4234-94f3-bfc788a5925b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * 0.95  # Introduce a decay factor to cognitive coefficient\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (E-ASGD): Integrates a decay factor for the cognitive coefficient to dynamically adjust exploration based on progress.", "configspace": "", "generation": 1, "fitness": 0.8327217749643104, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.011. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "29bf4cb1-deb2-42f4-8c82-ff2a27c29ba4", "metadata": {"aucs": [0.8170129416148477, 0.8375417887982404, 0.8436105944798431], "final_y": [0.13454229702398912, 0.12759723840387382, 0.12439951968851504]}, "mutation_prompt": null}
{"id": "8259caee-5556-49e9-a362-04b9dd196a6e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted inertia weight strategy\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5  + 0.5 * (1 - adaptive_factor)  # Make social coefficient slightly dynamic\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Dynamic neighborhood search\n                if np.random.rand() < 0.1: \n                    neighbor = swarm[np.random.choice(self.population_size)]\n                    if func(neighbor) < func(swarm[i]):\n                        swarm[i] = neighbor\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Hybrid Swarm Gradient Descent (HSGD): Introduces an adaptive inertia weight strategy and dynamic neighborhood search to balance exploration and exploitation.", "configspace": "", "generation": 2, "fitness": 0.8860671841060745, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.019. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "240718e8-2e23-4234-94f3-bfc788a5925b", "metadata": {"aucs": [0.8696018596550872, 0.8765234412155043, 0.912076251447632], "final_y": [0.1250664714197247, 0.1272224273878525, 0.11614875577209605]}, "mutation_prompt": null}
{"id": "466d651d-103d-497d-8fbe-8fd2a0cd3c13", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted inertia weight strategy\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Make social coefficient slightly dynamic\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Stochastic tunneling step for exploration\n                if np.random.rand() < 0.05:  \n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                # Dynamic neighborhood search\n                if np.random.rand() < 0.1:\n                    neighbor = swarm[np.random.choice(self.population_size)]\n                    if func(neighbor) < func(swarm[i]):\n                        swarm[i] = neighbor\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a stochastic tunneling step to escape local optima by allowing occasional exploration outside the current search space.", "configspace": "", "generation": 3, "fitness": 0.8948352720738771, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.006. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "8259caee-5556-49e9-a362-04b9dd196a6e", "metadata": {"aucs": [0.887341477278351, 0.8967676368507136, 0.9003967020925667], "final_y": [0.11843718137495496, 0.1198424497668803, 0.12160772787907059]}, "mutation_prompt": null}
{"id": "60e36ed8-de7f-4078-ae0d-1585f8d6bce0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.2 * np.sin(2 * np.pi * evaluations / self.budget)  # Oscillating inertia weight\n            cognitive_coeff = 1.5 * (0.5 + adaptive_factor / 2)  # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * np.cos(np.pi * evaluations / self.budget)  # Dynamic social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Enhanced stochastic tunneling step\n                if np.random.rand() < adaptive_factor * 0.1:  \n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n\n                # Competitive neighborhood search\n                if np.random.rand() < 0.2:\n                    candidate_idx = np.random.choice(self.population_size)\n                    candidate = swarm[candidate_idx]\n                    if func(candidate) < func(swarm[i]):\n                        swarm[i] = candidate\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrates a dynamic adaptive tunneling step and a competitive neighborhood strategy to improve exploitation and exploration balance in the swarm optimization process.", "configspace": "", "generation": 4, "fitness": 0.811775185156085, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.010. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "466d651d-103d-497d-8fbe-8fd2a0cd3c13", "metadata": {"aucs": [0.8006226572618413, 0.8102280740761432, 0.8244748241302708], "final_y": [0.14263780831748563, 0.12505096469942445, 0.12802180631184568]}, "mutation_prompt": null}
{"id": "4e2841ef-1ee6-441b-87c1-c493b0168004", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted inertia weight strategy\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Make social coefficient slightly dynamic\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Adaptive mutation based on convergence\n                mutation_rate = 0.02 + 0.1 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    mutation_strength = 0.1 * (1 - adaptive_factor)\n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces an adaptive mutation strategy to improve exploration and exploitation balance dynamically based on convergence progress.", "configspace": "", "generation": 5, "fitness": 0.8951504103816935, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.019. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "466d651d-103d-497d-8fbe-8fd2a0cd3c13", "metadata": {"aucs": [0.8690923189836584, 0.9027431799759348, 0.9136157321854874], "final_y": [0.13065793245668045, 0.11652051898316307, 0.11532413220940285]}, "mutation_prompt": null}
{"id": "26b2efc6-497e-4ef3-9ab8-ed5e4e0e96fd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted inertia weight strategy\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Make social coefficient slightly dynamic\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Adaptive mutation based on convergence\n                mutation_rate = 0.02 + 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Added decay function\n                mutation_strength = 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Added decay function\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances exploration by adding a decay function to the mutation rate for a more dynamic adaptation.", "configspace": "", "generation": 6, "fitness": 0.8974090436126146, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.017. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "4e2841ef-1ee6-441b-87c1-c493b0168004", "metadata": {"aucs": [0.8740385257879542, 0.9040408095987829, 0.9141477954511071], "final_y": [0.12218592497648628, 0.11630548218012193, 0.11514931342514834]}, "mutation_prompt": null}
{"id": "1ba925fa-5a4a-4c0c-89be-9167ba615ba7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            self.population_size = max(5, int(10 + 2 * np.sqrt(self.dim) * (1 + 0.5 * adaptive_factor)))  # Dynamic scaling\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted inertia weight strategy\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Make social coefficient slightly dynamic\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Adaptive mutation based on convergence\n                mutation_rate = 0.02 + 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Added decay function\n                mutation_strength = 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Added decay function\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic population size scaling based on convergence to enhance exploration and exploitation balance.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "26b2efc6-497e-4ef3-9ab8-ed5e4e0e96fd", "metadata": {}, "mutation_prompt": null}
{"id": "871e1bb4-3276-4ba1-a9f8-d5fd3fcc2bc0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted inertia weight strategy\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Make social coefficient slightly dynamic\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb + adaptive_factor*(swarm[i]-lb), ub - adaptive_factor*(ub-swarm[i]))  # Dynamic boundary constraint\n\n                # Adaptive mutation based on convergence\n                mutation_rate = 0.02 + 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Added decay function\n                mutation_strength = 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Added decay function\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a dynamic boundary constraint adjustment to increase solution diversity near search space limits.", "configspace": "", "generation": 8, "fitness": 0.8931664399950687, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.021. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "26b2efc6-497e-4ef3-9ab8-ed5e4e0e96fd", "metadata": {"aucs": [0.8740505151282831, 0.8823086120504504, 0.9231401928064724], "final_y": [0.12657276967586129, 0.12677257815930743, 0.11370699611320889]}, "mutation_prompt": null}
{"id": "8f66d507-eda7-4ac6-833c-a4d1271a7f26", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted inertia weight strategy\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Make social coefficient slightly dynamic\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Adaptive mutation based on convergence\n                mutation_rate = 0.02 + 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Added decay function\n                mutation_strength = 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Added decay function\n                if np.random.rand() < mutation_rate:  \n                    random_index = np.random.randint(self.population_size)  # New line\n                    swarm[i] = swarm[random_index] + np.random.normal(0, mutation_strength, self.dim)  # Modified line\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces perturbation by random selection of an alternate position to enhance escape from local optima.", "configspace": "", "generation": 9, "fitness": 0.8796581451254574, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.880 with standard deviation 0.027. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "26b2efc6-497e-4ef3-9ab8-ed5e4e0e96fd", "metadata": {"aucs": [0.8465063139964598, 0.8798747512922896, 0.9125933700876225], "final_y": [0.13387431946709416, 0.12732915841656567, 0.11616180787198227]}, "mutation_prompt": null}
{"id": "fff30772-6d95-43f6-a7ea-370e26f7f2b8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted inertia weight strategy\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Make social coefficient slightly dynamic\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor  # Introduced adaptive velocity dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Adaptive mutation based on convergence\n                mutation_rate = 0.02 + 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Added decay function\n                mutation_strength = 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Added decay function\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive velocity dampening factor to improve convergence speed by reducing premature oscillations.", "configspace": "", "generation": 10, "fitness": 0.8977158162827145, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.011. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "26b2efc6-497e-4ef3-9ab8-ed5e4e0e96fd", "metadata": {"aucs": [0.884164780222681, 0.898501987438678, 0.9104806811867845], "final_y": [0.1207469249139912, 0.11647021749261688, 0.1157881772071161]}, "mutation_prompt": null}
{"id": "5b8ea3c5-22ba-495a-a642-1c5002dc6bdc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.85 - 0.45 * adaptive_factor  # Adjusted inertia weight strategy\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.7 * (1 - adaptive_factor)  # Make social coefficient slightly dynamic\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor  # Introduced adaptive velocity dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Adaptive mutation based on convergence\n                mutation_rate = 0.02 + 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Added decay function\n                mutation_strength = 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Added decay function\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance global exploration by dynamically adjusting velocity based on a novel adaptive inertia and social coefficient strategy.", "configspace": "", "generation": 11, "fitness": 0.8948660160201388, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.018. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "fff30772-6d95-43f6-a7ea-370e26f7f2b8", "metadata": {"aucs": [0.8688207194248256, 0.9058187318310513, 0.9099585968045395], "final_y": [0.13088824910430874, 0.1163049495599765, 0.11626426501631992]}, "mutation_prompt": null}
{"id": "da851543-bced-4e07-9c41-5b5a36d604d0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        last_best_value = global_best_value\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted inertia weight strategy\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Make social coefficient slightly dynamic\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor  # Introduced adaptive velocity dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Adaptive mutation based on fitness improvement rate\n                improvement_rate = np.abs(last_best_value - global_best_value) / (1 + np.abs(last_best_value))\n                mutation_rate = 0.02 + 0.08 * np.exp(-improvement_rate * 10)\n                mutation_strength = 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance the exploration capability by introducing a dynamic adaptive mutation based on fitness improvement rate.", "configspace": "", "generation": 12, "fitness": 0.8791775367471296, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.036. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "fff30772-6d95-43f6-a7ea-370e26f7f2b8", "metadata": {"aucs": [0.8339575564928078, 0.8818855442413567, 0.9216895095072242], "final_y": [0.1416277554005454, 0.12675749460133778, 0.11361903966604403]}, "mutation_prompt": null}
{"id": "be416866-1f56-4afd-ac0b-a0ea3a3ff59a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted inertia weight strategy\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Make social coefficient slightly dynamic\n\n            # Introduce dynamic swarm size adjustment\n            new_population_size = int((10 + 2 * int(np.sqrt(self.dim))) * (1 + 0.1 * np.sin(evaluations / self.budget * np.pi)))\n            self.velocity = np.resize(self.velocity, (new_population_size, self.dim))\n            swarm = np.resize(swarm, (new_population_size, self.dim))\n\n            for i in range(new_population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor  # Introduced adaptive velocity dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i % self.population_size] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Adaptive mutation based on convergence\n                mutation_rate = 0.02 + 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Added decay function\n                mutation_strength = 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Added decay function\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i % self.population_size]:\n                    personal_best[i % self.population_size] = swarm[i]\n                    personal_best_value[i % self.population_size] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic swarm size adjustment to enhance exploration and exploitation balance.", "configspace": "", "generation": 13, "fitness": 0.8953447586128459, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.033. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "fff30772-6d95-43f6-a7ea-370e26f7f2b8", "metadata": {"aucs": [0.8496479862249903, 0.9103602175124789, 0.9260260721010684], "final_y": [0.13686012868320407, 0.11936601657442236, 0.11220801844526218]}, "mutation_prompt": null}
{"id": "417d7b8c-9cff-4383-bbb0-c6525dcf8939", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.2 * np.sin(np.pi * adaptive_factor)  # Dynamic inertia weight adjustment\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Make social coefficient slightly dynamic\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor  # Introduced adaptive velocity dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Adaptive mutation based on convergence\n                mutation_rate = 0.02 + 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Added decay function\n                mutation_strength = 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Added decay function\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate dynamic inertia weight adjustment for improved convergence and exploration balance.", "configspace": "", "generation": 14, "fitness": 0.8451295223356189, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.011. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "fff30772-6d95-43f6-a7ea-370e26f7f2b8", "metadata": {"aucs": [0.8480653490214753, 0.8574276953070425, 0.8298955226783391], "final_y": [0.13267416028333134, 0.13100404436501378, 0.13683420263579316]}, "mutation_prompt": null}
{"id": "9004e481-a399-4f74-9224-012d63e3a095", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted inertia weight strategy\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Make social coefficient slightly dynamic\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor  # Introduced adaptive velocity dampening factor\n                \n                # Line changed: Introduced velocity normalization\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = self.velocity[i] / np.linalg.norm(self.velocity[i])  # Normalize velocity\n                \n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Adaptive mutation based on convergence\n                mutation_rate = 0.02 + 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Added decay function\n                mutation_strength = 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Added decay function\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic velocity normalization to enhance convergence and prevent stagnation.", "configspace": "", "generation": 15, "fitness": 0.7222790653755343, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.722 with standard deviation 0.037. And the mean value of best solutions found was 0.186 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "fff30772-6d95-43f6-a7ea-370e26f7f2b8", "metadata": {"aucs": [0.679275742297374, 0.7686720472528704, 0.7188894065763588], "final_y": [0.19742449709100884, 0.1702433386818767, 0.19103396660959382]}, "mutation_prompt": null}
{"id": "3d81ed84-aa37-4ae5-b40b-7f704d2a3fee", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.5 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate adaptive learning rates for cognitive and social coefficients to enhance exploration and convergence balance.", "configspace": "", "generation": 16, "fitness": 0.9025772371073164, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.019. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "fff30772-6d95-43f6-a7ea-370e26f7f2b8", "metadata": {"aucs": [0.8767019070719022, 0.9084728018173187, 0.9225570024327283], "final_y": [0.12458353390184784, 0.11637886267412312, 0.11237188276454091]}, "mutation_prompt": null}
{"id": "37939cc0-7d12-4113-a2d6-d12678ad6121", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.5 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by refining the mutation strategy to better balance exploration and exploitation phases.", "configspace": "", "generation": 17, "fitness": 0.9030187127383527, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.019. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3d81ed84-aa37-4ae5-b40b-7f704d2a3fee", "metadata": {"aucs": [0.8770235189877646, 0.9080718163288118, 0.9239608028984816], "final_y": [0.12076573609836772, 0.11647488953705898, 0.11209592318383632]}, "mutation_prompt": null}
{"id": "f8adaa8f-92c5-48b9-80c2-48f389825deb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.5 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.1 * (1 - adaptive_factor ** 2)  # Modified mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive mutation strategy that varies based on evaluation progress to enhance solution diversity.", "configspace": "", "generation": 18, "fitness": 0.8996692685026408, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.022. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "37939cc0-7d12-4113-a2d6-d12678ad6121", "metadata": {"aucs": [0.8693530248636439, 0.9081877773955053, 0.9214670032487737], "final_y": [0.13098259236740084, 0.11635742352821432, 0.11332204788173317]}, "mutation_prompt": null}
{"id": "237f91d5-d429-4dbc-bd80-5ea817760ab4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.3 * adaptive_factor  # Modified inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.03 + 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Modified mutation rate\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration and exploitation balance by tuning inertia weight and mutation strategy parameters.", "configspace": "", "generation": 19, "fitness": 0.9006111589114546, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.019. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "37939cc0-7d12-4113-a2d6-d12678ad6121", "metadata": {"aucs": [0.8737383260958684, 0.9123724728413903, 0.915722677797105], "final_y": [0.12731933802602602, 0.11636004680632162, 0.1137346803601419]}, "mutation_prompt": null}
{"id": "866d40eb-4df4-4277-a9f6-d6d9eeb530c0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.8 - 0.6 * adaptive_factor  # Adjusted inertia weight decay\n            cognitive_coeff = 1.5 * adaptive_factor * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.1 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Adjusted mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improve convergence by fine-tuning inertia weight decay and mutation strength evolution.", "configspace": "", "generation": 20, "fitness": 0.8923937439494317, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.045. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "37939cc0-7d12-4113-a2d6-d12678ad6121", "metadata": {"aucs": [0.8294022670975776, 0.9185769292508115, 0.9292020354999063], "final_y": [0.14595392439083754, 0.11623070042603822, 0.11224604597495125]}, "mutation_prompt": null}
{"id": "36aefd34-6da2-42e9-b334-7211754eb004", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted mutation rate\n                mutation_strength = 0.18 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Utilize adaptive strategy to enhance velocity update and mutation strength for improved exploration.", "configspace": "", "generation": 21, "fitness": 0.897293085129999, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.021. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "37939cc0-7d12-4113-a2d6-d12678ad6121", "metadata": {"aucs": [0.8692383358020543, 0.9040339972115126, 0.9186069223764299], "final_y": [0.13083947536873597, 0.11868834165388098, 0.11398347839570111]}, "mutation_prompt": null}
{"id": "a20393a9-f9db-465a-a6cd-9b146d74e501", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.5 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.1 + 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Change here\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate adaptive mutation strength to further balance exploration and exploitation.", "configspace": "", "generation": 22, "fitness": 0.9004451136632974, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.021. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "37939cc0-7d12-4113-a2d6-d12678ad6121", "metadata": {"aucs": [0.8709942928181129, 0.9089027287437965, 0.9214383194279826], "final_y": [0.12830671449647157, 0.11651671655705387, 0.11330112997045316]}, "mutation_prompt": null}
{"id": "abe2bda0-2438-464e-a963-f1b89a875c10", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Adjusted inertia weight decay mechanism\n            cognitive_coeff = 1.5 * adaptive_factor * (0.5 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adjust inertia weight decay mechanism for improved adaptability and convergence control.", "configspace": "", "generation": 23, "fitness": 0.8491508994480768, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.009. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "37939cc0-7d12-4113-a2d6-d12678ad6121", "metadata": {"aucs": [0.8610357070454622, 0.8457344298064019, 0.8406825614923662], "final_y": [0.12651418592546115, 0.13194944355306415, 0.13262975679459854]}, "mutation_prompt": null}
{"id": "21ccd9d2-9e3e-4cf9-a2c8-866ab5780a3b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.5 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.05 + 0.20 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive mutation strength to balance exploration and exploitation dynamically.", "configspace": "", "generation": 24, "fitness": 0.8992278818282147, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.022. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "37939cc0-7d12-4113-a2d6-d12678ad6121", "metadata": {"aucs": [0.8693913589329576, 0.9067310559169101, 0.9215612306347762], "final_y": [0.13094927493705655, 0.1177102966877086, 0.11276929812218106]}, "mutation_prompt": null}
{"id": "a2e68eaa-40ae-4c2a-9e4c-5c364c0ca0ee", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive mutation and inertia strategy with adjusted coefficients for enhanced convergence and exploration.", "configspace": "", "generation": 25, "fitness": 0.9123168893502452, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.009. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "37939cc0-7d12-4113-a2d6-d12678ad6121", "metadata": {"aucs": [0.9017864013837029, 0.9107531754315289, 0.9244110912355042], "final_y": [0.1175194563005103, 0.11690834491397883, 0.113518737602599]}, "mutation_prompt": null}
{"id": "675366dd-7f06-4543-9019-f95c47525c7d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.45 + 0.55 * adaptive_factor)  # Adjusted cognitive coefficient\n            social_coeff = 1.6 + 0.4 * (1 - adaptive_factor) * (0.55 + 0.45 * adaptive_factor)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved adaptive coefficients for efficient convergence and exploration balance.", "configspace": "", "generation": 26, "fitness": 0.9045140952405916, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.023. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "a2e68eaa-40ae-4c2a-9e4c-5c364c0ca0ee", "metadata": {"aucs": [0.8743242867285803, 0.9080069072828285, 0.9312110917103656], "final_y": [0.12755066068800414, 0.11972725311219612, 0.11159175088251028]}, "mutation_prompt": null}
{"id": "40ae50f3-1986-4663-baeb-746d0b721a53", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.3 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.7 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.4 + 0.5 * adaptive_factor) # Adjusted mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration by adapting mutation strategy and reassessing cognitive and social coefficients balance.", "configspace": "", "generation": 27, "fitness": 0.9061259889931025, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "a2e68eaa-40ae-4c2a-9e4c-5c364c0ca0ee", "metadata": {"aucs": [0.8838862504052356, 0.9143955268119709, 0.9200961897621011], "final_y": [0.12044966971550486, 0.11648489438411158, 0.11385971371127634]}, "mutation_prompt": null}
{"id": "3e34089c-da63-4d76-b530-3c26077e4ba3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic population size adjustment\n            self.population_size = max(10, int(self.population_size * (0.9 + 0.2 * adaptive_factor)))\n            self.velocity = np.resize(self.velocity, (self.population_size, self.dim))\n            swarm = np.resize(swarm, (self.population_size, self.dim))\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate dynamic population size adjustment to enhance exploratory capability and exploitative balance.", "configspace": "", "generation": 28, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "a2e68eaa-40ae-4c2a-9e4c-5c364c0ca0ee", "metadata": {}, "mutation_prompt": null}
{"id": "6f53ad25-c44f-40af-aeb9-d185d2ec6aff", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * np.sqrt(adaptive_factor)  # Non-linear decay for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced a non-linear decay for the inertia weight to balance exploration and exploitation more effectively.", "configspace": "", "generation": 29, "fitness": 0.9020373381887259, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.021. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "a2e68eaa-40ae-4c2a-9e4c-5c364c0ca0ee", "metadata": {"aucs": [0.8766260994633635, 0.9021390932953415, 0.9273468218074727], "final_y": [0.1276186700298766, 0.11940804582869502, 0.11221163950325896]}, "mutation_prompt": null}
{"id": "1e228827-c1d9-4b66-946a-01322c438112", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor  \n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            # Dynamically adjust population size\n            self.population_size = max(5, int((10 + 2 * int(np.sqrt(dim))) * adaptive_factor))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introducing dynamic population sizing to enhance adaptability and convergence in varying problem landscapes.", "configspace": "", "generation": 30, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'dim' is not defined\").", "error": "NameError(\"name 'dim' is not defined\")", "parent_id": "a2e68eaa-40ae-4c2a-9e4c-5c364c0ca0ee", "metadata": {}, "mutation_prompt": null}
{"id": "f13e6995-eaf6-4215-a8f5-6842054c1063", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.5 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.7 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.3 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced dynamic adaptation of coefficients and mutation strategy for improved exploration and convergence balance.", "configspace": "", "generation": 31, "fitness": 0.8990048691879965, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.013. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a2e68eaa-40ae-4c2a-9e4c-5c364c0ca0ee", "metadata": {"aucs": [0.886137869400285, 0.8946719251043748, 0.9162048130593295], "final_y": [0.12518034165192993, 0.12370297399480823, 0.11435418707589484]}, "mutation_prompt": null}
{"id": "6468aed6-f721-46cf-8fc7-5f83974723f4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.55 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.5 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.6 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.13 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.6 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced adaptive inertia and mutation strategy with dynamic population updates for balanced exploration and exploitation.", "configspace": "", "generation": 32, "fitness": 0.9016924713005388, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.024. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "a2e68eaa-40ae-4c2a-9e4c-5c364c0ca0ee", "metadata": {"aucs": [0.8678939741532139, 0.916746627488009, 0.9204368122603935], "final_y": [0.13083566520466394, 0.11381820477462845, 0.11409700725039396]}, "mutation_prompt": null}
{"id": "bc43591f-d654-4060-9450-28832c8bd743", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim)) + int(0.1 * (budget / dim))  # Dynamic population size\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved adaptive strategy by introducing dynamic population size for better exploration-exploitation balance.", "configspace": "", "generation": 33, "fitness": 0.8830445062586237, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.883 with standard deviation 0.041. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "a2e68eaa-40ae-4c2a-9e4c-5c364c0ca0ee", "metadata": {"aucs": [0.8252015486208569, 0.9153143273475384, 0.9086176428074757], "final_y": [0.1449551340056956, 0.11581761950996894, 0.11153870723676795]}, "mutation_prompt": null}
{"id": "c9fbec29-b6e3-4ffa-8dd1-026d94d268df", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n\n                # Modified velocity update\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i] +\n                                                         np.random.normal(0, 0.01, self.dim)))  # Added random perturbation\n\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced velocity update with dynamic mutation to refine exploration and convergence.", "configspace": "", "generation": 34, "fitness": 0.9058193540948748, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.014. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "a2e68eaa-40ae-4c2a-9e4c-5c364c0ca0ee", "metadata": {"aucs": [0.920555154664406, 0.887753985589957, 0.9091489220302613], "final_y": [0.11202331106898955, 0.1267602554149625, 0.1186232013771823]}, "mutation_prompt": null}
{"id": "f4daf2a9-8d48-46f8-a436-ae323a2451bc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        chaotic_map = np.random.rand(self.population_size, self.dim)  # Initialize chaotic map\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n            \n            chaotic_map = np.mod(4 * chaotic_map * (1 - chaotic_map), 1)  # Update chaotic map\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) * chaotic_map[i])  # Applying chaotic map\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:\n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration by incorporating chaotic map-driven velocity updates for global convergence.", "configspace": "", "generation": 35, "fitness": 0.9014180676119193, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.019. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "a2e68eaa-40ae-4c2a-9e4c-5c364c0ca0ee", "metadata": {"aucs": [0.8748865204121032, 0.910029095564617, 0.9193385868590379], "final_y": [0.12434119891565643, 0.1162563238496852, 0.11110988697113278]}, "mutation_prompt": null}
{"id": "0b48d20b-4939-46a3-adb7-32ba4e721108", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                learning_rate = 0.8 + 0.2 * adaptive_factor  # Introduced adaptive learning rate\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    learning_rate * (cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive learning rates for personal and global best influences to enhance convergence speed.  ", "configspace": "", "generation": 36, "fitness": 0.9020340260682298, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.020. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "a2e68eaa-40ae-4c2a-9e4c-5c364c0ca0ee", "metadata": {"aucs": [0.8743376267649292, 0.9155959391954476, 0.9161685122443128], "final_y": [0.12724277199510114, 0.11625577236165152, 0.11474319299500024]}, "mutation_prompt": null}
{"id": "e75a364a-62be-4cac-8e4f-780964d0e8f9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Increased mutation rate\n                mutation_strength = 0.20 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Increased mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced adaptive strategy with increased mutation influence for improved exploration and convergence.", "configspace": "", "generation": 37, "fitness": 0.9025614541682804, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.022. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "a2e68eaa-40ae-4c2a-9e4c-5c364c0ca0ee", "metadata": {"aucs": [0.8732965269757985, 0.9097277162033468, 0.9246601193256957], "final_y": [0.1283657898328855, 0.11793593854099738, 0.11276372580405558]}, "mutation_prompt": null}
{"id": "96938599-3551-4b0b-9f6f-dface8461cbc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = np.var(personal_best_value) * 0.15  # Dynamic mutation rate based on variance\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic mutation rate based on the variance of personal bests to enhance exploration.", "configspace": "", "generation": 38, "fitness": 0.8860567279955495, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.023. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "a2e68eaa-40ae-4c2a-9e4c-5c364c0ca0ee", "metadata": {"aucs": [0.865008293712206, 0.874688570636218, 0.9184733196382242], "final_y": [0.12843807743044833, 0.1268184657831417, 0.11521967378845765]}, "mutation_prompt": null}
{"id": "d301a983-2029-462d-934b-53aa0dc3941e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.03 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Slightly increased mutation rate\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Slightly increased mutation rate for improved exploration and convergence.", "configspace": "", "generation": 39, "fitness": 0.9143224898492966, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a2e68eaa-40ae-4c2a-9e4c-5c364c0ca0ee", "metadata": {"aucs": [0.9020913082464546, 0.9147756239768255, 0.9261005373246101], "final_y": [0.11918723642875184, 0.11632477325713886, 0.11358352930606452]}, "mutation_prompt": null}
{"id": "bc169433-1095-4aca-8196-45803d040d20", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            self.population_size = int(10 + 2 * np.sqrt(dim) * (1 + adaptive_factor))  # Dynamically varying population size\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.03 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Slightly increased mutation rate\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamically varying population size to enhance exploration and exploitation balance.", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'dim' is not defined\").", "error": "NameError(\"name 'dim' is not defined\")", "parent_id": "d301a983-2029-462d-934b-53aa0dc3941e", "metadata": {}, "mutation_prompt": null}
{"id": "a5a51ed2-3fbb-4b6d-9c30-a6f8648a4d77", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.85 - 0.55 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) \n            social_coeff = 1.7 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.05 + 0.10 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Adjusted mutation rate\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced AdaptiveSwarmGradientDescent with dynamic velocity adjustment and mutation rate for improved exploration-exploitation balance.", "configspace": "", "generation": 41, "fitness": 0.8894462507032806, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.045. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "d301a983-2029-462d-934b-53aa0dc3941e", "metadata": {"aucs": [0.8274624767332595, 0.9071066619061957, 0.9337696134703867], "final_y": [0.14597047116151485, 0.11970553206959555, 0.11168788369179938]}, "mutation_prompt": null}
{"id": "664f47f3-98cc-4c5e-afe0-64fce0b7d562", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            # Adjust population size dynamically\n            if evaluations % 10 == 0:\n                self.population_size = int(10 + 2 * np.sqrt(self.dim) * (1 + 0.5 * adaptive_factor))\n                self.velocity = np.zeros((self.population_size, self.dim))\n                \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                momentum = np.linalg.norm(global_best - swarm[i])  # Added momentum-based approach\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * momentum\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.03 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved exploration via dynamic population size adjustment and momentum-based velocity updating.", "configspace": "", "generation": 42, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "d301a983-2029-462d-934b-53aa0dc3941e", "metadata": {}, "mutation_prompt": null}
{"id": "e4f07bbc-5fb8-481f-bf92-75c89e3e572c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Adjusted increased mutation rate\n                mutation_strength = 0.18 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Adjusted mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm adaptability with finely tuned mutation dynamics for better convergence.", "configspace": "", "generation": 43, "fitness": 0.9023025209054366, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.021. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "d301a983-2029-462d-934b-53aa0dc3941e", "metadata": {"aucs": [0.8733116569256343, 0.909755027090579, 0.9238408787000965], "final_y": [0.1283955653901373, 0.1179162470674695, 0.11386252935230312]}, "mutation_prompt": null}
{"id": "13646e40-009a-4a03-84ea-f00423e85083", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 10)  # New learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.03 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Slightly increased mutation rate\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced learning rate scaling to improve convergence speed and accuracy.", "configspace": "", "generation": 44, "fitness": 0.914325189910428, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "d301a983-2029-462d-934b-53aa0dc3941e", "metadata": {"aucs": [0.9020938370293907, 0.9147755635781439, 0.9261061691237493], "final_y": [0.11916929349792116, 0.11632494266464277, 0.11357661444665568]}, "mutation_prompt": null}
{"id": "ba1cff85-aabc-4014-91c7-5ab9f40da0dd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 10)  # New learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.03 + 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed mutation rate formula\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced balance between exploration and exploitation by tweaking the mutation rate formula.", "configspace": "", "generation": 45, "fitness": 0.9129770395592728, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.011. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "13646e40-009a-4a03-84ea-f00423e85083", "metadata": {"aucs": [0.8984689556408092, 0.9142286004361508, 0.9262335626008583], "final_y": [0.11939826303842738, 0.11642480055466009, 0.11319865534038587]}, "mutation_prompt": null}
{"id": "2729330d-111d-4795-82d1-8ffb0a72341c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget)**2  # Modified adaptive factor to improve precision\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 10)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.03 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor**2)  # Adjusted mutation strength formula\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced adaptive factor and mutation strategy in AdaptiveSwarmGradientDescent to improve convergence precision.", "configspace": "", "generation": 46, "fitness": 0.8951940506207268, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.027. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "13646e40-009a-4a03-84ea-f00423e85083", "metadata": {"aucs": [0.8576288143029279, 0.9060977243299984, 0.9218556132292539], "final_y": [0.13415340419357424, 0.119405996763422, 0.11333510370408306]}, "mutation_prompt": null}
{"id": "52a1716f-996c-49c2-b0ba-2c662a3ddbb3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.7 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.45 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.55 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 10)  # New learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.03 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Slightly increased mutation rate\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm adaptation by introducing dynamic social coefficient and inertia weight adjustments based on evaluation progress.", "configspace": "", "generation": 47, "fitness": 0.8920902371524461, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.045. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "13646e40-009a-4a03-84ea-f00423e85083", "metadata": {"aucs": [0.8294754390212153, 0.9162939787572627, 0.9305012936788601], "final_y": [0.14595358079005627, 0.11629489767287948, 0.11226640633835827]}, "mutation_prompt": null}
{"id": "631d3875-a458-420e-9e61-7ac1cdb87384", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)  # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Adjusted social coefficient\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 10)  # New learning rate scaling\n\n            decay_factor = 0.98  # New decay factor for enhanced performance\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = decay_factor * (dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.03 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Slightly increased mutation rate\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced velocity update to incorporate a decay factor for improved exploration and exploitation balance.", "configspace": "", "generation": 48, "fitness": 0.8933449566429182, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.034. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "13646e40-009a-4a03-84ea-f00423e85083", "metadata": {"aucs": [0.8463749012857548, 0.9078292930269259, 0.9258306756160739], "final_y": [0.1379826919761321, 0.11723844678480044, 0.1136610963417728]}, "mutation_prompt": null}
{"id": "4376b6b8-8b61-4481-a873-9156e445d924", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 12 + 2 * int(np.sqrt(dim))  # Increased population size by 2\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 10)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.03 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Slightly increase population size to potentially explore more promising regions.", "configspace": "", "generation": 49, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'AdaptiveSwarmGradientDescent' object has no attribute 'velocity'\").", "error": "AttributeError(\"'AdaptiveSwarmGradientDescent' object has no attribute 'velocity'\")", "parent_id": "13646e40-009a-4a03-84ea-f00423e85083", "metadata": {}, "mutation_prompt": null}
{"id": "6dcb6f80-af99-4944-823c-986e7f6a9123", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.7 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)  # Adjusted cognitive coefficient\n            social_coeff = 1.3 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 10)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.03 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration by modifying cognitive and social coefficients to improve convergence efficiency.", "configspace": "", "generation": 50, "fitness": 0.894390404341336, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.018. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "13646e40-009a-4a03-84ea-f00423e85083", "metadata": {"aucs": [0.8779968950988548, 0.8852980703437292, 0.9198762475814237], "final_y": [0.12557405256261123, 0.12667660808349634, 0.11252144297111955]}, "mutation_prompt": null}
{"id": "df7787d2-67e2-43f7-9a9b-89a01a9744db", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 10)  # New learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.03 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Slightly increased mutation rate\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n                # Adjusted mutation rate to enhance exploration\n                mutation_rate += 0.01 * adaptive_factor\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate an adaptive diversity mechanism to maintain exploration-exploitation balance.", "configspace": "", "generation": 51, "fitness": 0.914325189910428, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "13646e40-009a-4a03-84ea-f00423e85083", "metadata": {"aucs": [0.9020938370293907, 0.9147755635781439, 0.9261061691237493], "final_y": [0.11916929349792116, 0.11632494266464277, 0.11357661444665568]}, "mutation_prompt": null}
{"id": "ef005b88-7ac9-412d-b919-eb32a395c501", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 10)  # New learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.03 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Slightly increased mutation rate\n                mutation_strength = 0.15 * (1 - adaptive_factor)  # Enhanced mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced mutation strength to promote diversity in late-stage optimization for improved exploration.", "configspace": "", "generation": 52, "fitness": 0.914420080167846, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "13646e40-009a-4a03-84ea-f00423e85083", "metadata": {"aucs": [0.9021012731243653, 0.9148192019764224, 0.9263397654027505], "final_y": [0.11917964835254846, 0.11627251753088741, 0.11333445737357517]}, "mutation_prompt": null}
{"id": "de99ca6a-5358-46f2-a506-8a3c06924ecb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.6 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) \n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) \n\n            learning_rate_scaling = np.tanh(adaptive_factor * 10)  \n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.03 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  \n                mutation_strength = 0.15 * (1 - adaptive_factor)  \n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive inertia weight based on evaluations to improve search balance between exploration and exploitation.", "configspace": "", "generation": 53, "fitness": 0.9094865488110607, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.013. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ef005b88-7ac9-412d-b919-eb32a395c501", "metadata": {"aucs": [0.8992470595275233, 0.9016882316839491, 0.9275243552217098], "final_y": [0.11782661500535996, 0.1197743545293154, 0.11359670558060353]}, "mutation_prompt": null}
{"id": "a03ee17d-d259-418c-b037-760415306a44", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 10)  # New learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                if adaptive_factor < 0.1 and np.random.rand() < 0.05:  # Adaptive swarm resampling condition\n                    swarm[i] = np.random.uniform(lb, ub, self.dim)\n                \n                mutation_rate = 0.03 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Slightly increased mutation rate\n                mutation_strength = 0.15 * (1 - adaptive_factor)  # Enhanced mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive swarm resampling to enhance exploration and fine-tuning in challenging landscapes.", "configspace": "", "generation": 54, "fitness": 0.914420080167846, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ef005b88-7ac9-412d-b919-eb32a395c501", "metadata": {"aucs": [0.9021012731243653, 0.9148192019764224, 0.9263397654027505], "final_y": [0.11917964835254846, 0.11627251753088741, 0.11333445737357517]}, "mutation_prompt": null}
{"id": "9edb5f15-717a-4ca2-a4a1-50b4c6116fd4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 10)  # New learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.03 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Slightly increased mutation rate\n                diversity_factor = np.std(swarm, axis=0).mean() / (ub - lb).mean()  # Calculate diversity\n                mutation_strength = 0.15 * (1 - adaptive_factor) * (1 + diversity_factor)  # Enhanced mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive mutation scaling based on swarm diversity for enhanced late-stage exploration.", "configspace": "", "generation": 55, "fitness": 0.9142964900423789, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ef005b88-7ac9-412d-b919-eb32a395c501", "metadata": {"aucs": [0.9021019085867439, 0.9148188987192921, 0.9259686628211008], "final_y": [0.11917967724679623, 0.11627252525461496, 0.11365102902517576]}, "mutation_prompt": null}
{"id": "e8d34e47-482e-4e11-a502-1761f485c957", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor * (0.7 + 0.3 * adaptive_factor)  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 10)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.03 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive inertia weight damping to enhance convergence stability.", "configspace": "", "generation": 56, "fitness": 0.9129742453051138, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.010. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ef005b88-7ac9-412d-b919-eb32a395c501", "metadata": {"aucs": [0.9022414443030858, 0.9107291126191958, 0.9259521789930598], "final_y": [0.1192077847376255, 0.11708774680970091, 0.11363953898977452]}, "mutation_prompt": null}
{"id": "42ed544d-f846-4eda-bf01-3dc2c5fd3208", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor) # Adjusted social coefficient\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 10)  # New learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.03 + 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Slightly increased mutation rate\n                mutation_strength = 0.15 * (1 - adaptive_factor)  # Enhanced mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a dynamic mutation rate that adapts more aggressively to late-stage optimization for enhanced exploration.", "configspace": "", "generation": 57, "fitness": 0.9130627268954705, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.012. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "ef005b88-7ac9-412d-b919-eb32a395c501", "metadata": {"aucs": [0.8982106779225045, 0.9141956112815919, 0.9267818914823153], "final_y": [0.11956512208224734, 0.11646123569058386, 0.11300525746396783]}, "mutation_prompt": null}
{"id": "c2de9f48-5e46-4f75-b06c-58eabd90e7dc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 12)  # Changed learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Slightly increased mutation rate\n                mutation_strength = 0.2 * (1 - adaptive_factor)  # Enhanced mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined balance between exploration and exploitation by adjusting learning rate and mutation dynamics.", "configspace": "", "generation": 58, "fitness": 0.9152632182664996, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.010. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "ef005b88-7ac9-412d-b919-eb32a395c501", "metadata": {"aucs": [0.90345989068733, 0.9141602420019598, 0.9281695221102091], "final_y": [0.11734120232473921, 0.11654296166141942, 0.11240989614491448]}, "mutation_prompt": null}
{"id": "d8690e36-2d30-4f9b-8840-6663f38dc470", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.5 * adaptive_factor  # Changed inertia weight calculation\n            cognitive_coeff = 1.4 * adaptive_factor * (0.4 + 0.6 * adaptive_factor)  # Adjusted cognitive coefficient\n            social_coeff = 1.6 + 0.4 * (1 - adaptive_factor) * (0.6 + 0.4 * adaptive_factor)  # Adjusted social coefficient\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 12)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.2 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced dynamic factor adjustments and swarm diversity to refine the exploration-exploitation balance.", "configspace": "", "generation": 59, "fitness": 0.8933959990005974, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.025. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "c2de9f48-5e46-4f75-b06c-58eabd90e7dc", "metadata": {"aucs": [0.8583228578873904, 0.9132693650857963, 0.9085957740286059], "final_y": [0.13201030593445562, 0.11331336839358896, 0.11526383667793272]}, "mutation_prompt": null}
{"id": "52114fe0-5256-457d-a425-ee8273ed018f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)  # Changed learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor  # Adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed mutation rate\n                mutation_strength = 0.25 * (1 - adaptive_factor)  # Changed mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive velocity scaling and modified mutation dynamics for enhanced convergence.", "configspace": "", "generation": 60, "fitness": 0.916038888349796, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.011. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "c2de9f48-5e46-4f75-b06c-58eabd90e7dc", "metadata": {"aucs": [0.9038188152765103, 0.914783174015624, 0.9295146757572536], "final_y": [0.11772795745250175, 0.116290307352929, 0.1121659475583745]}, "mutation_prompt": null}
{"id": "2116b004-08a2-4046-810d-1b9534f2b20e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * np.sin(np.pi * adaptive_factor / 2)  # Non-linear transformation for inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)  # Changed learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor  # Adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed mutation rate\n                mutation_strength = 0.25 * (1 - adaptive_factor)  # Changed mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced dynamic adaptation by introducing a non-linear transformation to inertia weight for improved convergence.", "configspace": "", "generation": 61, "fitness": 0.9142613653937541, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.011. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.9055970342539258, 0.9076947057074106, 0.9294923562199258], "final_y": [0.11769355287888295, 0.11937398524907161, 0.11227544949981894]}, "mutation_prompt": null}
{"id": "8c75006f-51ed-4261-954a-32803d7a8d64", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Added r3\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * r3 * (global_best - personal_best[i])) * learning_rate_scaling  # Added local-global influence\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.25 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced velocity update considering both local and global contextual influence for improved convergence.", "configspace": "", "generation": 62, "fitness": 0.9045199264075454, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.018. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.905104671049721, 0.9267168480129742, 0.8817382601599411], "final_y": [0.11732949530453429, 0.11239722911716277, 0.12461512597219293]}, "mutation_prompt": null}
{"id": "952513af-4684-4d2d-abac-b0e0014dcada", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.7 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.05 + 0.15 * (1 - adaptive_factor)  # Adjusted mutation rate\n                mutation_strength = 0.2 * (1 - adaptive_factor)  # Adjusted mutation strength\n                if np.random.rand() < mutation_rate:\n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence via dynamic inertia weight and improved mutation strategy.", "configspace": "", "generation": 63, "fitness": 0.8924560620074572, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.045. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8292257571879385, 0.9193684880716131, 0.9287739407628203], "final_y": [0.1459634345011913, 0.11622722200873525, 0.11158921679397749]}, "mutation_prompt": null}
{"id": "a265903c-c4cb-4229-bc7b-b174526e3568", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 10 + 2 * int(np.sqrt(dim))\n        self.population_size = self.initial_population_size\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            # Adjusting population size dynamically\n            self.population_size = self.initial_population_size + int((self.budget - evaluations) / self.budget * 10)\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.25 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced strategic exploration by varying population size dynamically for enhanced diversity and convergence.", "configspace": "", "generation": 64, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 16 is out of bounds for axis 0 with size 16').", "error": "IndexError('index 16 is out of bounds for axis 0 with size 16')", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {}, "mutation_prompt": null}
{"id": "2a212913-0e67-46b3-9454-c62a7bd86f0a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.3 * adaptive_factor  # Adjusted inertia weight scaling\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.25 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic inertia weight scaling for improved convergence.", "configspace": "", "generation": 65, "fitness": 0.8743700322182203, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.874 with standard deviation 0.025. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8435282815040928, 0.8748604365723234, 0.9047213785782448], "final_y": [0.13772551013768708, 0.1280154095184184, 0.11635148784947069]}, "mutation_prompt": null}
{"id": "db7f5bec-77e7-4be7-b320-03516c1d6826", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.7 + 0.3 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Modified social coefficient scaling\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)  # Changed learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor  # Adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed mutation rate\n                mutation_strength = 0.25 * (1 - adaptive_factor)  # Changed mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adjusted social coefficient scaling for improved balance between exploration and exploitation.", "configspace": "", "generation": 66, "fitness": 0.8936733042748964, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.033. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8496120808372821, 0.9022698023510225, 0.9291380296363845], "final_y": [0.13689111338720183, 0.12043782690508664, 0.11171921162090104]}, "mutation_prompt": null}
{"id": "ad6f9d4f-22f0-4266-a84f-4a6e5d0ea0c3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.25 * (1 - np.power(adaptive_factor, 2))  # Non-linear scaling applied\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced non-linear scaling to mutation strength for a more effective exploration-exploitation balance.", "configspace": "", "generation": 67, "fitness": 0.9140620472371032, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.011. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.899877446747565, 0.9148079053510069, 0.9275007896127379], "final_y": [0.11960993483486004, 0.11625153603448468, 0.1127883560086268]}, "mutation_prompt": null}
{"id": "6f9cc94c-e828-4242-ae01-4383ed89df19", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.6 + 0.5 * adaptive_factor)  # Modified cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.25 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:\n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive coefficient for cognitive influence to improve convergence speed and solution quality.", "configspace": "", "generation": 68, "fitness": 0.9108632829676969, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.006. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.9090637009951643, 0.904044094882242, 0.9194820530256844], "final_y": [0.1171110510849821, 0.11952034167414227, 0.11356817701192756]}, "mutation_prompt": null}
{"id": "3834a7b7-4de3-49d8-acbb-3c1be916b35e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted inertia weight adaptation\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.25 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence by modifying the inertia weight dynamic adaptation.", "configspace": "", "generation": 69, "fitness": 0.8972020302062496, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.027. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8594781065582908, 0.9147377044135152, 0.9173902796469426], "final_y": [0.1325474402721566, 0.11657805388200038, 0.11459176095290757]}, "mutation_prompt": null}
{"id": "298a66e2-6334-49e6-beeb-3680cf4beec2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.8 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)  # Fine-tuned cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)  # Changed learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor  # Adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed mutation rate\n                mutation_strength = 0.25 * (1 - adaptive_factor)  # Changed mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Fine-tuned the cognitive coefficient formula for improved personal exploration in AdaptiveSwarmGradientDescent.", "configspace": "", "generation": 70, "fitness": 0.9106920807804876, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.007. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.9092313684085332, 0.9024825109032971, 0.9203623630296324], "final_y": [0.11734301843839912, 0.11977808990103445, 0.1137733557928785]}, "mutation_prompt": null}
{"id": "b054e063-6a64-4e3a-afa7-d79bfd84a7f3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n            cognitive_social_ratio = adaptive_factor  # Added factor to balance cognitive-social influence\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) * cognitive_social_ratio +\n                                    social_coeff * r2 * (global_best - swarm[i]) * (1 - cognitive_social_ratio)) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.25 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced velocity update by introducing an adaptive cognitive-social factor ratio for improved convergence efficiency.", "configspace": "", "generation": 71, "fitness": 0.8654240899353205, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.016. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8465727904397531, 0.8637795074155898, 0.8859199719506187], "final_y": [0.12301498817479584, 0.12423858952018374, 0.1117586906060456]}, "mutation_prompt": null}
{"id": "5d44dacb-12b8-413e-a821-39b200316ce4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.25 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                if evaluations // self.population_size % 2 == 0:\n                    global_best = personal_best[np.argmin(personal_best_value)]\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm exploration by introducing history-based leader selection.", "configspace": "", "generation": 72, "fitness": 0.8788479782974848, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.879 with standard deviation 0.038. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8294493714730887, 0.885032860309956, 0.9220617031094102], "final_y": [0.1459534990422101, 0.12667304860260487, 0.11251802836898372]}, "mutation_prompt": null}
{"id": "776da0e3-8b6a-45e3-b6dc-a5a15db0cc0a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)  # Changed learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor  # Adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.06 + 0.12 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed mutation rate\n                mutation_strength = 0.25 * (1 - adaptive_factor)  # Changed mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration by adjusting the mutation rate formula to increase adaptability in diverse search spaces.", "configspace": "", "generation": 73, "fitness": 0.9144307939989932, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.010. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.9049223715498395, 0.9103868386244914, 0.9279831718226488], "final_y": [0.11727950726579472, 0.11638458177325128, 0.11249968987286252]}, "mutation_prompt": null}
{"id": "76abbf1c-2805-47b3-8cb9-5cb4dd7201c5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.05 + 0.15 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Enhanced mutation rate\n                mutation_strength = 0.3 * (1 - adaptive_factor)  # Enhanced mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced global search capability by adjusting the mutation strategy and global-best update probability for improved convergence.", "configspace": "", "generation": 74, "fitness": 0.911184574417117, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.013. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.895280567939069, 0.9100684441269925, 0.9282047111852892], "final_y": [0.11892238508073472, 0.11627250273964318, 0.11259479182752352]}, "mutation_prompt": null}
{"id": "c6e1dcc4-0e33-4aee-8a20-aeff71126f79", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 15)  # Changed learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor  # Adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed mutation rate\n                mutation_strength = 0.25 * (1 - adaptive_factor)  # Changed mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence by adjusting mutation dynamics and learning rate scaling based on adaptive factors.", "configspace": "", "generation": 75, "fitness": 0.9160386568715494, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.011. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.9038189354406446, 0.9147832224136366, 0.9295138127603668], "final_y": [0.1177278015031118, 0.11629015299945822, 0.11216730918950713]}, "mutation_prompt": null}
{"id": "a628f3a0-1821-42cd-982c-9603875a488e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.4 + 0.5 * adaptive_factor**2)  # Adjusted cognitive coefficient impact\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.25 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adjusted adaptive factor impact on cognitive coefficient for better exploration.", "configspace": "", "generation": 76, "fitness": 0.9061457460090473, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.017. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.9023150412541769, 0.8880926237917182, 0.9280295729812467], "final_y": [0.11764832888902366, 0.12530228913016095, 0.11251628568313021]}, "mutation_prompt": null}
{"id": "c627b13c-9995-41f6-9b56-17d887f61c0f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * np.power(adaptive_factor, 0.5)  # Nonlinear inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)  # Changed learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor  # Adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed mutation rate\n                mutation_strength = 0.25 * (1 - adaptive_factor)  # Changed mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced a nonlinear inertia weight for improved adaptability and convergence precision.", "configspace": "", "generation": 77, "fitness": 0.9091705810316513, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.013. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.9027090013688354, 0.8973401625575411, 0.9274625791685773], "final_y": [0.1181911217526127, 0.11997871144169214, 0.11243342384752808]}, "mutation_prompt": null}
{"id": "524f0b98-cf6c-42ea-a271-bc7cb306c082", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                \n                # Dynamic population resizing\n                if evaluations % 10 == 0 and np.std(personal_best_value) < 0.01:\n                    self.population_size = max(5, self.population_size - 1)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.25 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic population resizing based on convergence progress to improve efficiency.", "configspace": "", "generation": 78, "fitness": 0.9160304668963607, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.009. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.9061378621510682, 0.9136480654122129, 0.9283054731258009], "final_y": [0.11708919857670919, 0.11622391708870694, 0.11219648434758678]}, "mutation_prompt": null}
{"id": "cf8edf02-2c63-42eb-84b7-4c2304f1703f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.5 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.7 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)  # Modified cognitive coeff\n            social_coeff = 1.4 + 0.6 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Modified social coeff\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.25 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence by optimizing the balance between exploration and exploitation with fine-tuned coefficients.", "configspace": "", "generation": 79, "fitness": 0.8946217713731355, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.024. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8747709251244774, 0.8806396100720072, 0.9284547789229218], "final_y": [0.12644753079173032, 0.12563904680790983, 0.11245618688426551]}, "mutation_prompt": null}
{"id": "4e0116ef-94bd-45a9-acc0-baa6da515c72", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)  # Changed learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor  # Adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed mutation rate\n                mutation_strength = 0.25 * (1 - adaptive_factor) + 0.05  # Changed mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence with modified mutation strategy for improved exploration.", "configspace": "", "generation": 80, "fitness": 0.9140332219138229, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.011. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8997421241580256, 0.9147766596201548, 0.9275808819632885], "final_y": [0.11968297531946204, 0.1162844135181148, 0.11256331885183801]}, "mutation_prompt": null}
{"id": "68234748-4a3d-4395-93e0-1ef7299c762b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.25 * (1 - adaptive_factor)\n                # Changed mutation logic to enhance exploration\n                if np.random.rand() < mutation_rate * np.exp(-adaptive_factor):\n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive mutation strategy to enhance exploration and convergence.", "configspace": "", "generation": 81, "fitness": 0.9028554796402494, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.020. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.87472574889346, 0.9145139112283074, 0.9193267787989808], "final_y": [0.12716714472048563, 0.11627670536874801, 0.11499782420808202]}, "mutation_prompt": null}
{"id": "bbb03429-9083-4778-8192-440b0d3708b0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 1.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Modified social coefficient\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.25 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Modified the social coefficient to boost exploration in early stages of optimization.", "configspace": "", "generation": 82, "fitness": 0.9080839935626571, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.013. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.9002757514227507, 0.8980621846442522, 0.9259140446209682], "final_y": [0.11782338968619466, 0.1194771046894797, 0.11373931859970543]}, "mutation_prompt": null}
{"id": "29ae89d7-394b-4ecf-a701-6f3bc8afdf5e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)  # Changed learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor  # Adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.02 + 0.28 * (1 - (personal_best_value[i] / global_best_value))  # Adjusted mutation rate\n                mutation_strength = 0.25 * (1 - adaptive_factor)  # Changed mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved swarm adaptability by adjusting the mutation rate based on local best performance.", "configspace": "", "generation": 83, "fitness": 0.8812938018239022, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.027. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8541871168419178, 0.8712688382712208, 0.918425450358568], "final_y": [0.13415062864191707, 0.12726107024184785, 0.11395571841879226]}, "mutation_prompt": null}
{"id": "4ff782d1-55da-4d24-b1f7-4cf10f22d654", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Enhanced inertia weight\n            cognitive_coeff = 1.7 * adaptive_factor * (0.5 + 0.5 * adaptive_factor)  # Modified cognitive coefficient\n            social_coeff = 1.6 + 0.4 * (1 - adaptive_factor) * (0.6 + 0.4 * adaptive_factor)  # Adjusted social coefficient\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 12)  # Adjusted learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.95 + 0.05 * adaptive_factor  # Further adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.03 + 0.12 * (1 - adaptive_factor) * (0.6 + 0.4 * adaptive_factor)  # Adjusted mutation rate\n                mutation_strength = 0.3 * (1 - adaptive_factor)  # Modified mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced adaptive swarm strategy with improved inertia and mutation dynamics for superior convergence and exploration.", "configspace": "", "generation": 84, "fitness": 0.902542415190516, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.014. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8861607682682088, 0.9011130449410221, 0.920353432362317], "final_y": [0.12026779444304159, 0.11980155697611672, 0.11257523221460164]}, "mutation_prompt": null}
{"id": "b002ee3f-627b-4736-829d-16de122f0028", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.7 * adaptive_factor  # Tweaked inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)  # Changed learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor  # Adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed mutation rate\n                mutation_strength = 0.25 * (1 - adaptive_factor)  # Changed mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Tweaked inertia weight to dynamically adapt based on the number of evaluations and convergence to improve solution exploration and exploitation balance.", "configspace": "", "generation": 85, "fitness": 0.88965718148887, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.044. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8293645039306464, 0.9090398304415703, 0.9305672100943932], "final_y": [0.14595359099352712, 0.11938834168953893, 0.11030894665103796]}, "mutation_prompt": null}
{"id": "3cb3ad71-c061-462a-83d2-cde85628e616", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Changed inertia weight scaling\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)  # Changed learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor  # Adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed mutation rate\n                mutation_strength = 0.25 * (1 - adaptive_factor)  # Changed mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced dynamic inertia weight scaling based on evaluation progress for enhanced exploration-exploitation balance.", "configspace": "", "generation": 86, "fitness": 0.8623351393090263, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.862 with standard deviation 0.007. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.870416682232512, 0.8523553730367149, 0.8642333626578519], "final_y": [0.12452041989299889, 0.12858753896780362, 0.1195191460676327]}, "mutation_prompt": null}
{"id": "a8f22dc0-02bd-4678-9801-a0220e609d23", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.95 - 0.5 * adaptive_factor  # Adjusted inertia weight calculation\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.25 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced dynamic velocity adaptation by modifying the inertia weight calculation for improved exploration and exploitation balance.", "configspace": "", "generation": 87, "fitness": 0.9070687478680027, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.011. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8938686006478792, 0.9065444508059093, 0.9207931921502195], "final_y": [0.1194253995090021, 0.11713026257702153, 0.11368567702228394]}, "mutation_prompt": null}
{"id": "30ad74f3-4e11-4658-bf53-8406faeb2ec5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            diversity = np.mean(np.std(swarm, axis=0))  # Calculate diversity of the swarm\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor) * (1 + diversity)  # Updated cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)  # Changed learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor  # Adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed mutation rate\n                mutation_strength = 0.25 * (1 - adaptive_factor)  # Changed mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence by dynamically adjusting the cognitive coefficient based on the swarm's diversity.", "configspace": "", "generation": 88, "fitness": 0.8219757496168244, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.027. And the mean value of best solutions found was 0.145 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.7911384138400441, 0.8178746330698519, 0.8569142019405771], "final_y": [0.14685516409352029, 0.15165018071263658, 0.13685866940321]}, "mutation_prompt": null}
{"id": "6cb19951-344c-4ea4-a5c6-a606a3ad18b2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.6 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Adjusted social coefficient\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.25 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved balance between exploration and exploitation by fine-tuning social coefficient.", "configspace": "", "generation": 89, "fitness": 0.9019833867421724, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.024. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8715898003754607, 0.9031122564379507, 0.9312481034131055], "final_y": [0.1200373816616842, 0.11996896620571351, 0.11186465614393093]}, "mutation_prompt": null}
{"id": "2a0fd4b4-f343-4467-8e13-5a1b7dc7b9c0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 15)  # Changed learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor  # Adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed mutation rate\n                mutation_strength = 0.3 * (1 - adaptive_factor)  # Changed mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence by refining learning rate scaling and mutation strength for better adaptability.", "configspace": "", "generation": 90, "fitness": 0.9143844230637993, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.012. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8996675942920597, 0.9148050805280118, 0.9286805943713267], "final_y": [0.1198167567142836, 0.11624768683119235, 0.11259945512119662]}, "mutation_prompt": null}
{"id": "861c8bdc-8d35-4ffc-9ef6-b6263ff68d50", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * adaptive_factor  # Adjusted cognitive coefficient calculation\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)  # Changed learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor  # Adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed mutation rate\n                mutation_strength = 0.25 * (1 - adaptive_factor)  # Changed mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced global search by adjusting the cognitive coefficient calculation for better exploration-exploitation balance.", "configspace": "", "generation": 91, "fitness": 0.9138735754221058, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.009. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.9051796907176628, 0.9094010237953208, 0.9270400117533335], "final_y": [0.11731820429856032, 0.11747070156086226, 0.1124092206967634]}, "mutation_prompt": null}
{"id": "ad295bc8-9a24-4eeb-9e76-14d12506f98d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.15 * (1 - adaptive_factor)  # Changed mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced local exploration by modifying mutation strength dynamics for improved convergence.", "configspace": "", "generation": 92, "fitness": 0.9151502077772428, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.9030193906823206, 0.9147935607644566, 0.9276376718849513], "final_y": [0.11801763025224332, 0.11628419664891843, 0.11253610010569726]}, "mutation_prompt": null}
{"id": "ac477aa6-b338-499a-8036-0e85d14b2b86", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * (adaptive_factor + 0.3 * (1 - adaptive_factor)) * (0.4 + 0.5 * adaptive_factor)  # Adjusted cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)  # Changed learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor  # Adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed mutation rate\n                mutation_strength = 0.25 * (1 - adaptive_factor)  # Changed mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration by adjusting adaptive factor influence on social and cognitive coefficients.", "configspace": "", "generation": 93, "fitness": 0.9072630358733024, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.014. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.9008204677282898, 0.8947061709719368, 0.9262624689196803], "final_y": [0.11910262440828168, 0.12071981028221868, 0.11369196022120753]}, "mutation_prompt": null}
{"id": "d37d86ab-6155-44fe-9e93-1dac94ec8431", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.8 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed social_coeff\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.25 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:\n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced social influence and mutation strategy for better exploration and convergence.", "configspace": "", "generation": 94, "fitness": 0.8500760995177531, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.030. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8251042122665739, 0.8918969004486771, 0.8332271858380079], "final_y": [0.14597365316197464, 0.12326277341646896, 0.1428905640552961]}, "mutation_prompt": null}
{"id": "a8c60434-85c7-48a6-b25d-759abea48cf3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)  # Changed learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor  # Adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed mutation rate\n                mutation_strength = 0.3 * (1 - adaptive_factor)  # Changed mutation strength to improve exploration\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Implemented a modified mutation strategy to improve exploration capability.", "configspace": "", "generation": 95, "fitness": 0.9143843676956115, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.012. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8996671723050473, 0.9148051067245879, 0.9286808240571995], "final_y": [0.11981766146173967, 0.11624761670138717, 0.11259888878560453]}, "mutation_prompt": null}
{"id": "af2dff7d-0173-49df-bdcf-e137fef4fcdf", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            \n            # Updated cognitive_coeff to dynamically adjust based on evaluations\n            cognitive_coeff = 1.2 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            \n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)  # Changed learning rate scaling\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor  # Adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed mutation rate\n                mutation_strength = 0.25 * (1 - adaptive_factor)  # Changed mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration by dynamically adjusting cognitive and social coefficients.", "configspace": "", "generation": 96, "fitness": 0.9118526504676671, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.010. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8982326865570779, 0.9136901242815536, 0.9236351405643699], "final_y": [0.11987604433788412, 0.11678315593337196, 0.11387375514798859]}, "mutation_prompt": null}
{"id": "7208d279-d8dd-44f4-a02d-c0efe99143c5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)  # Changed learning rate scaling\n\n            elite_particle = personal_best[np.argmin(personal_best_value)]  # Added elite particle feedback\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor  # Adjusted dampening factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * (elite_particle - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Changed mutation rate\n                mutation_strength = 0.25 * (1 - adaptive_factor)  # Changed mutation strength\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced information sharing by incorporating elite particle feedback for improved convergence.", "configspace": "", "generation": 97, "fitness": 0.8844593708291429, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.047. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8185905376325517, 0.9077642076549994, 0.9270233671998777], "final_y": [0.14480951480726445, 0.11975737791828744, 0.1133174272787777]}, "mutation_prompt": null}
{"id": "a042e6a0-7275-48e4-98e8-50524dbadf66", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.045 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Adjusted mutation rate\n                mutation_strength = 0.25 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:\n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced exploration by slightly increasing the mutation rate to improve convergence to global optima.", "configspace": "", "generation": 98, "fitness": 0.9102253824750285, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.012. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.9021933376435717, 0.9011514658019671, 0.9273313439795464], "final_y": [0.11812593092731716, 0.11695582075817312, 0.11293029155323708]}, "mutation_prompt": null}
{"id": "77fbdda0-f887-4c0e-8b8f-93f5865667a2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                if np.any(swarm[i] < lb) or np.any(swarm[i] > ub):  # Dynamic boundary reflection\n                    self.velocity[i] = -self.velocity[i]  # Reflect velocity\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.25 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:\n                    diversity_injection = np.random.normal(0, mutation_strength, self.dim)  # Diversity injection\n                    swarm[i] += diversity_injection\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced the algorithm by introducing adaptive swarm diversity injection and a dynamic boundary reflection strategy to improve exploration and convergence.", "configspace": "", "generation": 99, "fitness": 0.900717053507181, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.023. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.8722966874974026, 0.9020322013062512, 0.9278222717178891], "final_y": [0.127557577960414, 0.11951535463884333, 0.11218592953404061]}, "mutation_prompt": null}
{"id": "46b88bf8-02e5-489f-bf46-7b79a3f56e11", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.92 - 0.6 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor * (0.4 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.6 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)  # Modified scaling factor\n\n            learning_rate_scaling = np.tanh(adaptive_factor * 14)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dampening_factor = 0.93 + 0.07 * adaptive_factor\n                self.velocity[i] = dampening_factor * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * learning_rate_scaling\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.04 + 0.14 * (1 - adaptive_factor) * (0.5 + 0.5 * adaptive_factor)\n                mutation_strength = 0.25 * (1 - adaptive_factor)\n                if np.random.rand() < mutation_rate:  \n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced social coefficient's adaptive scaling for improved convergence.", "configspace": "", "generation": 100, "fitness": 0.9151040869074253, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "52114fe0-5256-457d-a425-ee8273ed018f", "metadata": {"aucs": [0.902339177117941, 0.9154646947804881, 0.9275083888238469], "final_y": [0.11773213841417285, 0.11627262474832567, 0.11284325218781321]}, "mutation_prompt": null}
