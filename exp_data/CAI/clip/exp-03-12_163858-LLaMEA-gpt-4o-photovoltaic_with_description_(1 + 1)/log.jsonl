{"id": "9e6edac7-b7b0-4587-bfb9-66a1f3f19090", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "dfe15b6d-716a-43e9-965e-850bb3edf452", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (1 + 0.5 * adaptive_factor)  # Modified line\n            social_coeff = 1.5 * (1 - 0.5 * adaptive_factor)     # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced ASGD with dynamically adjusted cognitive and social coefficients for improved exploration-exploitation balance.", "configspace": "", "generation": 1, "fitness": 0.8282359322302405, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.024. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "9e6edac7-b7b0-4587-bfb9-66a1f3f19090", "metadata": {"aucs": [0.7939264841257004, 0.8440078245027575, 0.8467734880622636], "final_y": [0.1520033675645176, 0.12383775552856802, 0.13579328660415468]}, "mutation_prompt": null}
{"id": "94060ee3-47b5-4c4a-9702-73d767207360", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (1 + 0.3 * adaptive_factor)  # Modified line\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)     # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                mutation_rate = 0.1 * adaptive_factor  # New line\n                if np.random.rand() < mutation_rate:  # New line\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)  # New line\n                    swarm[i] += mutation_vector  # New line\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Hybrid Swarm Gradient with Adaptive Mutation for enhanced balance between exploitation and exploration.", "configspace": "", "generation": 2, "fitness": 0.8478887934457534, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.017. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "dfe15b6d-716a-43e9-965e-850bb3edf452", "metadata": {"aucs": [0.8306398184743153, 0.8424644665653035, 0.8705620952976412], "final_y": [0.13471005318124585, 0.12484281810098508, 0.12011976422204185]}, "mutation_prompt": null}
{"id": "f89e1be7-739a-4ab0-880f-41487131016d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (1 + 0.3 * adaptive_factor)\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                mutation_rate = 0.1 * adaptive_factor\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1 * np.sqrt(adaptive_factor), self.dim)  # Adjusted line\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance balance between exploration and exploitation by introducing non-uniform mutation for adaptation.", "configspace": "", "generation": 3, "fitness": 0.8477327117735536, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.017. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "94060ee3-47b5-4c4a-9702-73d767207360", "metadata": {"aucs": [0.830550833903168, 0.8423059159824207, 0.8703413854350722], "final_y": [0.1347635451645811, 0.12534909599350774, 0.12029659772464774]}, "mutation_prompt": null}
{"id": "cf24b0e2-759d-4dac-9e54-76edb63fe1ec", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (1 + 0.3 * adaptive_factor)  # Modified line\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)     # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation with proximity-based strategy\n                mutation_rate = 0.1 * adaptive_factor  # New line\n                if np.random.rand() < mutation_rate:  # New line\n                    # Using proximity to global best for mutation influence\n                    proximity_to_gbest = np.linalg.norm(global_best - swarm[i])\n                    mutation_vector = np.random.normal(0, 0.1 + 0.05 * proximity_to_gbest, self.dim)  # Modified line\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced particle diversity by integrating a proximity-based mutation strategy.", "configspace": "", "generation": 4, "fitness": 0.8317084302297456, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.015. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "94060ee3-47b5-4c4a-9702-73d767207360", "metadata": {"aucs": [0.8251388796407043, 0.81755251549589, 0.8524338955526429], "final_y": [0.13318127334430152, 0.13805698142286482, 0.12789750492823704]}, "mutation_prompt": null}
{"id": "c1dc4552-163d-4e53-af18-f35dece2d368", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (1 + 0.3 * adaptive_factor)\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                mutation_rate = 0.1 * adaptive_factor\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1 * adaptive_factor, self.dim)  # Modified line\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Mutation by introducing a decaying mutation strength for improved exploration near convergence.", "configspace": "", "generation": 5, "fitness": 0.8476150534592178, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.017. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "94060ee3-47b5-4c4a-9702-73d767207360", "metadata": {"aucs": [0.8304831783209562, 0.8422255398907529, 0.8701364421659444], "final_y": [0.13480340002439617, 0.12545841222789256, 0.12045777747303188]}, "mutation_prompt": null}
{"id": "16e67795-dae4-4186-be93-2f747e672fd6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (1 + 0.3 * adaptive_factor)  # Modified line\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)     # Modified line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                momentum = 0.9  # New line\n                self.velocity[i] = (momentum * self.velocity[i] +  # Modified line\n                                    inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                mutation_rate = 0.1 * adaptive_factor  # New line\n                if np.random.rand() < mutation_rate:  # New line\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)  # New line\n                    swarm[i] += mutation_vector  # New line\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm movement update using momentum to potentially improve convergence speed.", "configspace": "", "generation": 6, "fitness": 0.7910613778316938, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.791 with standard deviation 0.020. And the mean value of best solutions found was 0.161 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "94060ee3-47b5-4c4a-9702-73d767207360", "metadata": {"aucs": [0.8192964803248991, 0.7791012201983656, 0.7747864329718169], "final_y": [0.15045327190813684, 0.16485791850380904, 0.16695765702676124]}, "mutation_prompt": null}
{"id": "250e2818-7a36-416a-9ef8-2df23745c649", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (1 + 0.3 * adaptive_factor)\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Refined adaptive mutation with dynamic rate\n                mutation_rate = 0.1 * (1 - adaptive_factor)  # Changed line\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic mutation rate that increases the diversity of search around promising areas as the budget depletes.", "configspace": "", "generation": 7, "fitness": 0.8272232587881402, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.006. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "94060ee3-47b5-4c4a-9702-73d767207360", "metadata": {"aucs": [0.8326555666297122, 0.8195857714150856, 0.8294284383196227], "final_y": [0.13374399960693972, 0.13502368868390002, 0.1317365977252739]}, "mutation_prompt": null}
{"id": "00f075d0-a05f-4a5f-8ed9-cb3dc3e304a5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            \n            # Dynamically adapt coefficients based on distance to global best\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))  # Updated line\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                mutation_rate = 0.1 * adaptive_factor\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced the balance between exploration and exploitation by dynamically adapting cognitive and social coefficients based on the current best solution distance.", "configspace": "", "generation": 8, "fitness": 0.8496089649710074, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.004. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "94060ee3-47b5-4c4a-9702-73d767207360", "metadata": {"aucs": [0.8487408662721994, 0.8447378565850882, 0.8553481720557344], "final_y": [0.13767612799965823, 0.12819703599011711, 0.12731966535055994]}, "mutation_prompt": null}
{"id": "a531dd01-20ee-4741-9677-a9a3d6bc931d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            \n            # Dynamically adapt coefficients based on distance to global best\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                mutation_rate = 0.1 * adaptive_factor\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced a dynamic inertia weight cap to enhance adaptability based on the convergence speed.", "configspace": "", "generation": 9, "fitness": 0.8496089649710074, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.004. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "00f075d0-a05f-4a5f-8ed9-cb3dc3e304a5", "metadata": {"aucs": [0.8487408662721994, 0.8447378565850882, 0.8553481720557344], "final_y": [0.13767612799965823, 0.12819703599011711, 0.12731966535055994]}, "mutation_prompt": null}
{"id": "a459f7ff-8915-4339-bff4-30ab771a2005", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            \n            # Dynamically adapt coefficients based on distance to global best\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))  # Updated line\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                temperature = 1 - (evaluations / self.budget)  # New line\n                mutation_rate = 0.1 * adaptive_factor * temperature  # Updated line\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a temperature-based annealing factor to adjust the mutation rate, enhancing exploration in early stages.", "configspace": "", "generation": 10, "fitness": 0.85004939558782, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.010. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "00f075d0-a05f-4a5f-8ed9-cb3dc3e304a5", "metadata": {"aucs": [0.8484817501463249, 0.8380883820673242, 0.8635780545498108], "final_y": [0.13755666503598085, 0.12811895648065152, 0.11928068505301193]}, "mutation_prompt": null}
{"id": "cb51089a-df16-467f-8d39-eaf4673d6260", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value  # New line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Dynamic inertia weight adjustment based on improvement rate\n            improvement_rate = np.abs(prev_global_best_value - global_best_value) / (np.abs(prev_global_best_value) + 1e-9)  # New line\n            inertia_weight = 0.5 + 0.5 * improvement_rate  # Updated line\n            \n            # Dynamically adapt coefficients based on distance to global best\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                temperature = 1 - (evaluations / self.budget)\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value  # New line\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic inertia weight based on fitness improvement rate to enhance convergence speed and solution quality.", "configspace": "", "generation": 11, "fitness": 0.9136379562570438, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.007. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "a459f7ff-8915-4339-bff4-30ab771a2005", "metadata": {"aucs": [0.9075175726764809, 0.9101411783397075, 0.9232551177549428], "final_y": [0.11062773512327173, 0.1162170941842624, 0.11333226283550601]}, "mutation_prompt": null}
{"id": "2f915aca-a8c2-4217-bf3e-a335299fff2e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            improvement_rate = np.abs(prev_global_best_value - global_best_value) / (np.abs(prev_global_best_value) + 1e-9)\n            inertia_weight = 0.5 + 0.5 * improvement_rate\n            \n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            # Adjust mutation strategy based on fitness landscape complexity\n            complexity_factor = np.std(personal_best_value) / (np.mean(personal_best_value) + 1e-9)  # New line\n            mutation_strength = 0.1 + 0.9 * complexity_factor  # Updated line for mutation strength\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                temperature = 1 - (evaluations / self.budget)\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, mutation_strength, self.dim)  # Updated line for mutation vector\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence and solution diversity by integrating an adaptive mutation strategy that adjusts based on the fitness landscape's complexity.", "configspace": "", "generation": 12, "fitness": 0.9094214689304971, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.013. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "cb51089a-df16-467f-8d39-eaf4673d6260", "metadata": {"aucs": [0.8931258703549716, 0.9102107490191838, 0.9249277874173361], "final_y": [0.11209635799974338, 0.11621723581754262, 0.11317148178193104]}, "mutation_prompt": null}
{"id": "02cc9bd6-8bc2-41fa-adda-39d6686c5a32", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n\n        learning_rate = np.ones(self.dim)  # New line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            improvement_rate = np.abs(prev_global_best_value - global_best_value) / (np.abs(prev_global_best_value) + 1e-9)\n            inertia_weight = 0.5 + 0.5 * improvement_rate\n            \n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * learning_rate * (personal_best[i] - swarm[i]) +  # Updated line\n                                    social_coeff * r2 * learning_rate * (global_best - swarm[i]))  # Updated line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                temperature = 1 - (evaluations / self.budget)\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n                    learning_rate *= 1.1  # New line\n                else:\n                    learning_rate *= 0.9  # New line\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate self-adjusting learning rates based on historical success to refine swarm movements and enhance solution precision.", "configspace": "", "generation": 13, "fitness": 0.8239285959219144, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.824 with standard deviation 0.008. And the mean value of best solutions found was 0.149 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "cb51089a-df16-467f-8d39-eaf4673d6260", "metadata": {"aucs": [0.8302829302470303, 0.8131073015425848, 0.8283955559761278], "final_y": [0.14619335904700503, 0.15336720500181478, 0.1473145650801504]}, "mutation_prompt": null}
{"id": "6be16654-374f-409a-a7e5-26675578f9a4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            improvement_rate = np.abs(prev_global_best_value - global_best_value) / (np.abs(prev_global_best_value) + 1e-9)\n            inertia_weight = 0.5 + 0.5 * improvement_rate\n            \n            # Dynamically adapt coefficients based on distance to global best\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            diversity_threshold = (ub - lb) * 0.1  # New line\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                temperature = 1 - (evaluations / self.budget)\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, temperature, self.dim)  # Updated line\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    if np.linalg.norm(swarm[i] - personal_best[i]) > diversity_threshold:  # New line\n                        personal_best[i] = swarm[i]\n                        personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate diversity management via distance-based selection and adaptive cooling mutation to enhance exploration and exploitation balance.", "configspace": "", "generation": 14, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "cb51089a-df16-467f-8d39-eaf4673d6260", "metadata": {}, "mutation_prompt": null}
{"id": "dd36ae05-f968-4bfe-a43d-f17be0b0377c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            improvement_rate = np.abs(prev_global_best_value - global_best_value) / (np.abs(prev_global_best_value) + 1e-9)\n            inertia_weight = 0.5 + 0.5 * improvement_rate\n            \n            # Adaptive learning coefficient based on swarm diversity\n            diversity = np.mean(np.linalg.norm(swarm - swarm.mean(axis=0), axis=1)) / (np.linalg.norm(ub - lb) + 1e-9)  # New line\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - diversity))  # Changed line\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                temperature = 1 - (evaluations / self.budget)\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive learning coefficients based on swarm diversity to enhance exploration-exploitation balance.", "configspace": "", "generation": 15, "fitness": 0.9097673672949761, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.018. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "cb51089a-df16-467f-8d39-eaf4673d6260", "metadata": {"aucs": [0.8881408370854196, 0.9094477146293807, 0.9317135501701278], "final_y": [0.12513906291577626, 0.11622404855892077, 0.11226751303244853]}, "mutation_prompt": null}
{"id": "7e1dc394-b4ea-4923-b8d5-685e31d527d1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            improvement_rate = np.abs(prev_global_best_value - global_best_value) / (np.abs(prev_global_best_value) + 1e-9)\n            inertia_weight = 0.5 + 0.5 * improvement_rate\n            \n            # Fitness diversity consideration for coefficient adaptation\n            fitness_diversity = np.std(personal_best_value) / (np.mean(personal_best_value) + 1e-9)  # New line\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * fitness_diversity)  # Updated line\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor * fitness_diversity)  # Updated line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                temperature = 1 - (evaluations / self.budget)\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a convergence acceleration mechanism by adjusting the cognitive and social coefficients dynamically based on the fitness diversity, to enhance exploration-exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.886903919291111, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.887 with standard deviation 0.019. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "cb51089a-df16-467f-8d39-eaf4673d6260", "metadata": {"aucs": [0.8663444942313931, 0.8826330402864269, 0.9117342233555132], "final_y": [0.12642337740304244, 0.12667288268368748, 0.11364470356170009]}, "mutation_prompt": null}
{"id": "60a7133f-ad4a-442c-839a-914e17433676", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            improvement_rate = np.abs(prev_global_best_value - global_best_value) / (np.abs(prev_global_best_value) + 1e-9)\n            inertia_weight = 0.5 + 0.5 * improvement_rate\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive neighborhood search with Lévy flight\n                if np.random.rand() < 0.2 * adaptive_factor:\n                    levy_flight = np.random.standard_cauchy(self.dim) * 0.01  # New line\n                    swarm[i] += levy_flight  # New line\n                    swarm[i] = np.clip(swarm[i], lb, ub)  # New line\n\n                temperature = 1 - (evaluations / self.budget)\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive neighborhood search with Lévy flight to enhance exploration capabilities and solution diversity.", "configspace": "", "generation": 17, "fitness": 0.8946426079702596, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.033. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "cb51089a-df16-467f-8d39-eaf4673d6260", "metadata": {"aucs": [0.8488380708735719, 0.9082604314999286, 0.9268293215372782], "final_y": [0.1323745033971141, 0.1152403290725108, 0.11233160483297921]}, "mutation_prompt": null}
{"id": "b4cf5885-ba25-44b6-b80a-4501cf93158e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value  # New line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Dynamic inertia weight adjustment based on improvement rate\n            improvement_rate = np.abs(prev_global_best_value - global_best_value) / (np.abs(prev_global_best_value) + 1e-9)  # New line\n            inertia_weight = 0.5 + 0.5 * improvement_rate  # Updated line\n            \n            # Dynamically adapt coefficients based on distance to global best\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                temperature = 1 - (evaluations / self.budget)\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value  # New line\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic swarm reduction\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate a dynamic swarm reduction mechanism to enhance exploration-exploitation balance and solution quality.", "configspace": "", "generation": 18, "fitness": 0.9147202858574935, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.006. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "cb51089a-df16-467f-8d39-eaf4673d6260", "metadata": {"aucs": [0.9104004586823959, 0.9100248913614781, 0.9237355075286063], "final_y": [0.1106683226171371, 0.11621950454926178, 0.11333988946717433]}, "mutation_prompt": null}
{"id": "499387c3-793b-4884-b2de-88ca08f808c1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            improvement_rate = np.abs(prev_global_best_value - global_best_value) / (np.abs(prev_global_best_value) + 1e-9)\n            inertia_weight = 0.5 + 0.5 * improvement_rate\n            \n            # Dynamic learning rate based on the progress toward global best\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor)) * (1 + adaptive_factor)  # Updated line\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor) * (1 + improvement_rate)  # Updated line\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                temperature = 1 - (evaluations / self.budget)\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim) * (1 - dist_factor)  # Updated line\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic learning rates and a locally informed mutation to enhance adaptive swarm balance and convergence speed.", "configspace": "", "generation": 19, "fitness": 0.8994018162462031, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.016. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b4cf5885-ba25-44b6-b80a-4501cf93158e", "metadata": {"aucs": [0.8784415639145348, 0.9023512329598018, 0.9174126518642723], "final_y": [0.1252133135037099, 0.11632331607494517, 0.11341934511394025]}, "mutation_prompt": null}
{"id": "944034f1-45b0-4113-8bbd-dff690a19839", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            improvement_rate = np.abs(prev_global_best_value - global_best_value) / (np.abs(prev_global_best_value) + 1e-9)\n            inertia_weight = 0.5 + 0.5 * improvement_rate\n            \n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Update mutation dynamics\n                temperature = (1 - (evaluations / self.budget))**2  # Changed line\n                mutation_rate = 0.05 * adaptive_factor * temperature  # Changed line\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.05, self.dim)  # Changed line\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic exploration decay and enhance adaptive mutation for improved convergence in noisy environments.", "configspace": "", "generation": 20, "fitness": 0.9011531842842805, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.018. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b4cf5885-ba25-44b6-b80a-4501cf93158e", "metadata": {"aucs": [0.8820479376854111, 0.8965160447473894, 0.924895570420041], "final_y": [0.1251405215699961, 0.11624823069780454, 0.11360774530012763]}, "mutation_prompt": null}
{"id": "cccbb1d7-d3ce-4635-acd0-26d46a3e9038", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value  # New line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Dynamic inertia weight adjustment based on improvement rate\n            improvement_rate = np.abs(prev_global_best_value - global_best_value) / (np.abs(prev_global_best_value) + 1e-9)  # New line\n            inertia_weight = 0.5 + 0.5 * improvement_rate * (1 - evaluations / self.budget)  # Updated line\n            \n            # Dynamically adapt coefficients based on distance to global best\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                temperature = 1 - (evaluations / self.budget)\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value  # New line\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic swarm reduction\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Implement a temperature-dependent inertia weight to dynamically adjust the balance between exploration and exploitation over iterations.", "configspace": "", "generation": 21, "fitness": 0.9055240019464827, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.014. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "b4cf5885-ba25-44b6-b80a-4501cf93158e", "metadata": {"aucs": [0.8864100820350757, 0.9100183667759535, 0.9201435570284192], "final_y": [0.12513731424774466, 0.11622741762314592, 0.11333434022461941]}, "mutation_prompt": null}
{"id": "f33e3be1-6889-4bc6-96e2-51fba972fc5d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n\n        def levy_flight(Lambda):\n            sigma = (np.gamma(1 + Lambda) * np.sin(np.pi * Lambda / 2) / \n                    (np.gamma((1 + Lambda) / 2) * Lambda * \n                    2**((Lambda - 1) / 2)))**(1 / Lambda)\n            u = np.random.randn(self.dim) * sigma\n            v = np.random.randn(self.dim)\n            step = u / np.abs(v)**(1 / Lambda)\n            return step\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            improvement_rate = np.abs(prev_global_best_value - global_best_value) / (np.abs(prev_global_best_value) + 1e-9)\n            inertia_weight = 0.5 + 0.5 * improvement_rate\n            \n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                temperature = 1 - (evaluations / self.budget)\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim) + levy_flight(1.5)  # Updated line\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance AdaptiveSwarmGradientDescent with a novel hybrid mutation strategy combining global-best guidance and Lévy flight perturbation for robust exploration-exploitation balance.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"module 'numpy' has no attribute 'gamma'\").", "error": "AttributeError(\"module 'numpy' has no attribute 'gamma'\")", "parent_id": "b4cf5885-ba25-44b6-b80a-4501cf93158e", "metadata": {}, "mutation_prompt": null}
{"id": "01ccca5e-3874-4fdf-bf88-7dcc09c28a2a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value  # New line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Dynamic inertia weight adjustment based on improvement rate\n            improvement_rate = np.abs(prev_global_best_value - global_best_value) / (np.abs(prev_global_best_value) + 1e-9)  # New line\n            inertia_weight = 0.5 + 0.5 * improvement_rate  # Updated line\n            \n            # Dynamically adapt coefficients based on distance to global best\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor * improvement_rate))  # Change made here\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                temperature = 1 - (evaluations / self.budget)\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value  # New line\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic swarm reduction\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic cognitive coefficient scaling based on improvement rate to enhance convergence speed and solution quality.", "configspace": "", "generation": 23, "fitness": 0.8991254078271459, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.013. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "b4cf5885-ba25-44b6-b80a-4501cf93158e", "metadata": {"aucs": [0.8837729704744142, 0.8988709671760156, 0.914732285831008], "final_y": [0.12119246438587272, 0.11621782647078571, 0.11331507887203718]}, "mutation_prompt": null}
{"id": "1b02e473-2ef9-45ee-8406-1bf5d7d2496f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            improvement_rate = np.abs(prev_global_best_value - global_best_value) / (np.abs(prev_global_best_value) + 1e-9)\n            inertia_weight = 0.7 + 0.3 * improvement_rate  # Updated line\n\n            # Dynamic constriction factor based on diversity\n            diversity = np.std(swarm, axis=0).mean() / np.linalg.norm(ub - lb)\n            constriction_factor = 0.5 + 0.5 * (1 - diversity)  # New line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (constriction_factor *  # Updated line\n                                    (inertia_weight * self.velocity[i] +\n                                     cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                     social_coeff * r2 * (global_best - swarm[i])))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Adaptive mutation frequency\n                temperature = 1 - (evaluations / self.budget)\n                mutation_rate = 0.15 * adaptive_factor * temperature  # Updated line\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration-exploitation by incorporating an adaptive mutation frequency and dynamic constriction factor.", "configspace": "", "generation": 24, "fitness": 0.8984802565084328, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.011. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "b4cf5885-ba25-44b6-b80a-4501cf93158e", "metadata": {"aucs": [0.9137571740240382, 0.8862287484085046, 0.8954548470927554], "final_y": [0.11120715500178824, 0.11975446954141711, 0.11765502982404585]}, "mutation_prompt": null}
{"id": "e937e911-ff92-47b1-b558-38ebb0736c20", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value  # New line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Dynamic inertia weight adjustment based on improvement rate\n            improvement_rate = np.abs(prev_global_best_value - global_best_value) / (np.abs(prev_global_best_value) + 1e-9)  # New line\n            inertia_weight = 0.5 + 0.5 * improvement_rate  # Updated line\n            \n            # Dynamically adapt coefficients based on distance to global best\n            dist_factor = np.linalg.norm(global_best - swarm.std(axis=0)) / np.linalg.norm(ub - lb)  # Modified line\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                temperature = 1 - (evaluations / self.budget)\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value and evaluations % 5 == 0:  # Modified line\n                    prev_global_best_value = global_best_value  # New line\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic swarm reduction\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm diversity and global best update frequency for improved convergence stability and solution quality.", "configspace": "", "generation": 25, "fitness": 0.8875940477008024, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.888 with standard deviation 0.033. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "b4cf5885-ba25-44b6-b80a-4501cf93158e", "metadata": {"aucs": [0.8428737315514585, 0.8999453741681817, 0.9199630373827673], "final_y": [0.13048179811747618, 0.11723012237046904, 0.11259218053676978]}, "mutation_prompt": null}
{"id": "014b9a29-f1e9-449e-aa12-5d540eae8310", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value  # New line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Temperature-based adaptive inertia weight\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)  # Updated line\n            \n            # Dynamically adapt coefficients based on distance to global best\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)  # New line\n            for i in range(self.population_size):\n                if i == elite_index:  # New line\n                    continue  # Elite preservation\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value  # New line\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic swarm reduction\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm intelligence by incorporating a temperature-based adaptive inertia weight and introducing elite preservation.", "configspace": "", "generation": 26, "fitness": 0.9256669445040945, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.012. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "b4cf5885-ba25-44b6-b80a-4501cf93158e", "metadata": {"aucs": [0.9246112448582333, 0.9119597625283412, 0.9404298261257087], "final_y": [0.11217576475908508, 0.11719003668790173, 0.11011723499247705]}, "mutation_prompt": null}
{"id": "d12d91b1-b494-43b9-b7a2-d1a90d0bd188", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value  # New line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Temperature-based adaptive inertia weight\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)  # Updated line\n            \n            # Dynamically adapt coefficients based on distance to global best\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)  # New line\n            for i in range(self.population_size):\n                if i == elite_index:  # New line\n                    continue  # Elite preservation\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                dynamic_learning_factor = 0.8 + 0.2 * np.random.random()  # Changed line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * dynamic_learning_factor  # Changed line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim) + 0.05 * (global_best - swarm[i])  # Changed line\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value  # New line\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic swarm reduction\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic learning factor and stochastic correction mechanism to enhance convergence and robustness of the swarm.", "configspace": "", "generation": 27, "fitness": 0.9169794456368514, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.013. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "014b9a29-f1e9-449e-aa12-5d540eae8310", "metadata": {"aucs": [0.9165400482579856, 0.9009405391061173, 0.9334577495464516], "final_y": [0.10994959062103515, 0.12010464056920056, 0.11011386206024876]}, "mutation_prompt": null}
{"id": "26d6fa9d-aede-400f-b7f4-8ccccbfa9374", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value  # New line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Temperature-based adaptive inertia weight\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)  # Updated line\n            \n            # Dynamically adapt coefficients based on distance to global best\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)  # New line\n            for i in range(self.population_size):\n                if i == elite_index:  # New line\n                    continue  # Elite preservation\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value  # New line\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations < self.budget and np.random.rand() < 0.05:  # New line for elite mutation\n                    swarm[elite_index] += np.random.normal(0, 0.1, self.dim)  # New line for elite mutation\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic swarm reduction\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm intelligence by introducing elite mutation and maintaining diversity through dynamic exploration.", "configspace": "", "generation": 28, "fitness": 0.9162908378744751, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.013. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "014b9a29-f1e9-449e-aa12-5d540eae8310", "metadata": {"aucs": [0.8992909767624894, 0.9317234013346023, 0.9178581355263334], "final_y": [0.11587659867954514, 0.11189919824831673, 0.11275507680806618]}, "mutation_prompt": null}
{"id": "b834b53f-363e-4098-bd8f-048906ce59d8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value  # New line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Temperature-based adaptive inertia weight\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)  # Updated line\n            \n            # Dynamically adapt coefficients based on distance to global best\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)  # New line\n            neighborhood_size = max(2, int(self.population_size * (0.1 + 0.4 * adaptive_factor)))  # Dynamic neighborhood\n            for i in range(self.population_size):\n                if i == elite_index:  # New line\n                    continue  # Elite preservation\n\n                neighbors = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                local_best = personal_best[neighbors[np.argmin(personal_best_value[neighbors])]]\n                \n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (local_best - swarm[i]) +  # Use local_best instead of global_best\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value  # New line\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic swarm reduction\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate a dynamic topological neighborhood structure to boost the convergence rate of swarm intelligence.", "configspace": "", "generation": 29, "fitness": 0.8657916328622367, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.033. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "014b9a29-f1e9-449e-aa12-5d540eae8310", "metadata": {"aucs": [0.8205571561175388, 0.878882228245379, 0.8979355142237921], "final_y": [0.13719182410965092, 0.12753185279663726, 0.12229148598692663]}, "mutation_prompt": null}
{"id": "13f45acb-1226-4cc3-8776-61c54e692bbc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value  # New line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Temperature-based adaptive inertia weight\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)  # Updated line\n            \n            # Dynamically adapt coefficients based on distance to global best\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)  # New line\n            for i in range(self.population_size):\n                if i == elite_index:  # New line\n                    continue  # Elite preservation\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1 / (1 + np.abs(global_best_value - prev_global_best_value)))  # Modified line\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value  # New line\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic swarm reduction\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n            # Re-evaluate elite solution periodically  # New line\n            if evaluations % (self.budget // 5) == 0:  # New line\n                f_value = func(personal_best[elite_index])\n                if f_value < personal_best_value[elite_index]:\n                    personal_best_value[elite_index] = f_value\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm intelligence with a dynamic mutation rate based on convergence speed and a periodic re-evaluation of the elite solution.", "configspace": "", "generation": 30, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 14 is out of bounds for axis 0 with size 14').", "error": "IndexError('index 14 is out of bounds for axis 0 with size 14')", "parent_id": "014b9a29-f1e9-449e-aa12-5d540eae8310", "metadata": {}, "mutation_prompt": null}
{"id": "5e542292-f1b7-4d00-9c95-44ff99407021", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value  # New line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Temperature-based adaptive inertia weight\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)  # Updated line\n            \n            # Dynamically adapt coefficients based on distance to global best\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)  # New line\n            for i in range(self.population_size):\n                if i == elite_index:  # New line\n                    continue  # Elite preservation\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 ** 2 * (global_best - swarm[i]))  # Modified line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate * (1 - global_best_value):  # Modified line\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value  # New line\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic swarm reduction\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm performance by introducing a nonlinear velocity update mechanism and stochastic thresholding for mutation.", "configspace": "", "generation": 31, "fitness": 0.9023720069382879, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.015. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "014b9a29-f1e9-449e-aa12-5d540eae8310", "metadata": {"aucs": [0.910204858397466, 0.881090993498449, 0.9158201689189485], "final_y": [0.11632074360428868, 0.12678952337003546, 0.11393497756687687]}, "mutation_prompt": null}
{"id": "9e6286f1-605c-4d28-ba25-169573951ba0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n            \n            # Adaptive learning rates for coefficients\n            learning_rate = 1 - adaptive_factor ** 2  # New line\n            cognitive_coeff = 1.5 * learning_rate  # Updated line\n            social_coeff = 1.5 * learning_rate  # Updated line\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate adaptive learning rates for cognitive and social coefficients to dynamically balance exploration and exploitation.", "configspace": "", "generation": 32, "fitness": 0.8819527222927744, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.013. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "014b9a29-f1e9-449e-aa12-5d540eae8310", "metadata": {"aucs": [0.8648397441086849, 0.8860916443864861, 0.8949267783831522], "final_y": [0.11650815839307949, 0.11679276672732752, 0.1138773598877385]}, "mutation_prompt": null}
{"id": "07cc22c9-04fc-4c6f-82f4-315629ac5de8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n            \n            # Variance-based swarm adaptation\n            swarm_variance = np.var(swarm, axis=0).mean()  # New line\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - swarm_variance))  # Updated line\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic population resizing and variance-based swarm adaptation to improve exploration and convergence.", "configspace": "", "generation": 33, "fitness": 0.8521014870258125, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.852 with standard deviation 0.017. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "014b9a29-f1e9-449e-aa12-5d540eae8310", "metadata": {"aucs": [0.8277903191502101, 0.8679861216758799, 0.8605280202513474], "final_y": [0.14689557687803245, 0.13382161648804403, 0.13553118754358662]}, "mutation_prompt": null}
{"id": "f3ce8145-6f55-488c-b654-f733941b1e4f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n            \n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Local search around global best\n            if evaluations % (self.budget // 20) == 0:  # Added line\n                local_search_vector = np.random.normal(0, 0.05, self.dim)  # Added line\n                candidate_solution = np.clip(global_best + local_search_vector, lb, ub)  # Added line\n                candidate_value = func(candidate_solution)  # Added line\n                evaluations += 1  # Added line\n                if candidate_value < global_best_value:  # Added line\n                    global_best, global_best_value = candidate_solution, candidate_value  # Added line\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate local search with adaptive swarm for enhanced convergence speed and accuracy.", "configspace": "", "generation": 34, "fitness": 0.9256669445040945, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.012. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "014b9a29-f1e9-449e-aa12-5d540eae8310", "metadata": {"aucs": [0.9246112448582333, 0.9119597625283412, 0.9404298261257087], "final_y": [0.11217446959887489, 0.11718279498743966, 0.11011373838016059]}, "mutation_prompt": null}
{"id": "acd043d9-75dd-4a4e-bbcd-1a503bd8dc47", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value  # New line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Temperature-based adaptive inertia weight\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)  # Updated line\n            \n            # Dynamically adapt coefficients based on distance to global best\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            # Introducing a dynamic scaling factor\n            scaling_factor = (prev_global_best_value - global_best_value) / max(abs(prev_global_best_value), 1e-8)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor)) * (1 + scaling_factor)\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor) * (1 + scaling_factor)\n\n            elite_index = np.argmin(personal_best_value)  # New line\n            for i in range(self.population_size):\n                if i == elite_index:  # New line\n                    continue  # Elite preservation\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value  # New line\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic swarm reduction\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm intelligence by introducing a dynamic scaling factor to the cognitive and social coefficients based on historical convergence data.", "configspace": "", "generation": 35, "fitness": 0.9232496466709748, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.923 with standard deviation 0.014. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "014b9a29-f1e9-449e-aa12-5d540eae8310", "metadata": {"aucs": [0.9141005666914259, 0.9120307086202135, 0.9436176647012847], "final_y": [0.1156025227645755, 0.11743369225692513, 0.11012558936382943]}, "mutation_prompt": null}
{"id": "1edf8266-2876-4157-ac38-1e46384acbe6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n\n            # New line: Determine neighborhood influence factor\n            neighborhood_coeff = 0.5 + 0.5 * np.sin(np.pi * evaluations / self.budget)\n\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # New line: Include neighborhood influence in velocity update\n                neighborhood_influence = neighborhood_coeff * np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    neighborhood_influence)\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance Particle Swarm Optimization by introducing a dynamic neighborhood influence and adaptive learning strategy for improved convergence.", "configspace": "", "generation": 36, "fitness": 0.9199878791007835, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.004. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "014b9a29-f1e9-449e-aa12-5d540eae8310", "metadata": {"aucs": [0.9149785952059265, 0.9193470596515698, 0.9256379824448537], "final_y": [0.11183341163050031, 0.11702509485179025, 0.11272569880677974]}, "mutation_prompt": null}
{"id": "8d376ea6-ee70-4871-98e8-d1113328e1ff", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value  # New line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Temperature-based adaptive inertia weight\n            temperature = 1 - (evaluations / self.budget)\n            velocity_diversity = np.std(self.velocity) / (np.linalg.norm(ub - lb) + 1e-10)  # New line\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2) * velocity_diversity  # Updated line\n            \n            # Dynamically adapt coefficients based on distance to global best\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)  # New line\n            for i in range(self.population_size):\n                if i == elite_index:  # New line\n                    continue  # Elite preservation\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value  # New line\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic swarm reduction\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce dynamic inertia weight adjustment based on both temperature and velocity diversity to enhance convergence.", "configspace": "", "generation": 37, "fitness": 0.925575476049678, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.011. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "014b9a29-f1e9-449e-aa12-5d540eae8310", "metadata": {"aucs": [0.9330578689573527, 0.9099805896678633, 0.9336879695238179], "final_y": [0.1116458181085831, 0.11754716044054048, 0.11209580734363433]}, "mutation_prompt": null}
{"id": "46887b6b-dc27-49d5-af42-2749191d1856", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n            \n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor)) * (1 + 0.1 * adaptive_factor)  # Changed line\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor) * (1 + 0.1 * temperature)  # Changed line\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation_vector\n\n                # Elite-guided search operator\n                if np.random.rand() < 0.05:\n                    swarm[i] += 0.1 * (global_best - swarm[i])  # New line\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm dynamics by introducing adaptive learning coefficients and an elite-guided search operator.", "configspace": "", "generation": 38, "fitness": 0.9080612134639532, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.019. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "014b9a29-f1e9-449e-aa12-5d540eae8310", "metadata": {"aucs": [0.8821439637021423, 0.9166291865482331, 0.925410490141484], "final_y": [0.12632971739089893, 0.11683306859604581, 0.11240985323221153]}, "mutation_prompt": null}
{"id": "23035a92-0f3e-46e6-85e3-b7c96ced198d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value  # New line\n        stagnation_counter = 0  # New line\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Temperature-based adaptive inertia weight\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)  # Updated line\n            \n            # Dynamically adapt coefficients based on distance to global best\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)  # New line\n            for i in range(self.population_size):\n                if i == elite_index:  # New line\n                    continue  # Elite preservation\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce adaptive mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.05 + 0.05 * stagnation_counter, self.dim)  # Modified line\n                    swarm[i] += mutation_vector\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value  # New line\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # New line\n                else:\n                    stagnation_counter += 1  # New line\n\n                if evaluations >= self.budget:\n                    break\n\n            # Dynamic swarm reduction\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm convergence by introducing adaptive stagnation handling and refined mutation scaling.", "configspace": "", "generation": 39, "fitness": 0.9262732241943136, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "014b9a29-f1e9-449e-aa12-5d540eae8310", "metadata": {"aucs": [0.9259176356913772, 0.9129200526925247, 0.9399819841990388], "final_y": [0.11194505786916964, 0.11725039718980956, 0.11031295387202722]}, "mutation_prompt": null}
{"id": "4ea5e02c-307e-460c-abcc-794faccaf04e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 3)  # Changed line\n            \n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.6 * (1 - dist_factor))  # Changed line\n            social_coeff = 1.5 * (1 - 0.4 * adaptive_factor)  # Changed line\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.15 * adaptive_factor * temperature  # Changed line\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.1 + 0.05 * stagnation_counter, self.dim)  # Changed line\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Optimize swarm dynamics by incorporating adaptive learning rates and enhanced diversity through dynamic mutation strategies.", "configspace": "", "generation": 40, "fitness": 0.9005185058250097, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.020. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "23035a92-0f3e-46e6-85e3-b7c96ced198d", "metadata": {"aucs": [0.8739218565796982, 0.9050133625131367, 0.9226202983821943], "final_y": [0.12611943562655847, 0.12038145388675336, 0.11371087344072406]}, "mutation_prompt": null}
{"id": "8af9eb4e-6be3-40e7-9855-ad20685dd7fd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n            \n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor)) * (0.5 + 0.5 * adaptive_factor)  # Modified line\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor) * (0.5 + 0.5 * temperature)  # Modified line\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.05 + 0.05 * stagnation_counter, self.dim)\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive decay in social and cognitive coefficients for improved exploration-exploitation balance.", "configspace": "", "generation": 41, "fitness": 0.9224168650022045, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.922 with standard deviation 0.008. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "23035a92-0f3e-46e6-85e3-b7c96ced198d", "metadata": {"aucs": [0.9267787213220167, 0.9118167200596112, 0.9286551536249856], "final_y": [0.11194405496220872, 0.11705821266844696, 0.11282344267916578]}, "mutation_prompt": null}
{"id": "82486baa-e0cd-4de1-8935-f8096312e3e9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0  \n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2) \n            \n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            prev_elite_index = np.argmin(personal_best_value)  # New line\n            for i in range(self.population_size):\n                if i == prev_elite_index:  # New line\n                    continue  \n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.05 * (1 + stagnation_counter), self.dim)  # Modified line\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm efficiency by introducing dynamic leader swapping and smarter mutation strategy.", "configspace": "", "generation": 42, "fitness": 0.9262732241943136, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "23035a92-0f3e-46e6-85e3-b7c96ced198d", "metadata": {"aucs": [0.9259176356913772, 0.9129200526925247, 0.9399819841990388], "final_y": [0.11194505786916964, 0.11725039718980956, 0.11031295387202722]}, "mutation_prompt": null}
{"id": "b8a04711-393d-41b0-b6cd-f05f78b4730e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.15 * adaptive_factor * temperature  # Modified line\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.05 + 0.05 * stagnation_counter, self.dim)\n                    swarm[i] += mutation_vector + 0.01 * (global_best - personal_best[i])  # Modified line\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.85))  # Modified line\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm efficiency by incorporating elite-enhanced learning and dynamic diversity preservation techniques.", "configspace": "", "generation": 43, "fitness": 0.9084290294909777, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.018. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "23035a92-0f3e-46e6-85e3-b7c96ced198d", "metadata": {"aucs": [0.8863102283126134, 0.9078238469178053, 0.9311530132425145], "final_y": [0.1202429788658973, 0.12014828063909455, 0.11028488373022294]}, "mutation_prompt": null}
{"id": "bca40991-333e-4924-9e3a-7a8f83e1f58d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.5 + 0.4 * (1 - temperature ** 2)  # Updated line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:  # New line\n                    swarm[i] = global_best  # Updated line for stronger elite preservation\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.15 * adaptive_factor * temperature  # Updated line for more dynamic mutation\n                if np.random.rand() < mutation_rate:\n                    mutation_vector = np.random.normal(0, 0.05 + 0.05 * stagnation_counter, self.dim)\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * 0.9))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance convergence by reinforcing adaptive inertia and mutation dynamics, alongside intensified elite preservation.", "configspace": "", "generation": 44, "fitness": 0.9120396815347099, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.008. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "23035a92-0f3e-46e6-85e3-b7c96ced198d", "metadata": {"aucs": [0.9007914331495828, 0.9158199202746931, 0.9195076911798536], "final_y": [0.1174314608648287, 0.1153421370862483, 0.11152963745948752]}, "mutation_prompt": null}
{"id": "7fcfb4d0-5b44-4728-8f41-33558c2fe18f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce chaos-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    chaos_factor = np.sin(2 * np.pi * np.random.rand())  # Changed line\n                    mutation_vector = np.random.normal(0, 0.05 + 0.05 * chaos_factor, self.dim)  # Changed line\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))  # Changed line\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce chaos-based mutation and adaptivity in swarm size for enhanced exploration and convergence.", "configspace": "", "generation": 45, "fitness": 0.9296557645599214, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "23035a92-0f3e-46e6-85e3-b7c96ced198d", "metadata": {"aucs": [0.9380065486532905, 0.9137634829601395, 0.937197262066334], "final_y": [0.11019676677549484, 0.11712933478132981, 0.1102010523976007]}, "mutation_prompt": null}
{"id": "0f64618d-a571-4646-afea-e2a61994010e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.5 + 0.5 * (1 - temperature ** 2)  # Changed line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce chaos-based mutation\n                mutation_rate = 0.15 * adaptive_factor * temperature  # Changed line\n                if np.random.rand() < mutation_rate:\n                    chaos_factor = np.sin(2 * np.pi * np.random.rand())\n                    mutation_vector = np.random.normal(0, 0.05 + 0.05 * chaos_factor, self.dim)\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Fine-tune the inertia weight and mutation rate for better convergence and solution quality.", "configspace": "", "generation": 46, "fitness": 0.9244171855969919, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.006. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "7fcfb4d0-5b44-4728-8f41-33558c2fe18f", "metadata": {"aucs": [0.9320400499103058, 0.9237875770845496, 0.9174239297961203], "final_y": [0.11066829355989871, 0.11303269498428725, 0.11379046916073887]}, "mutation_prompt": null}
{"id": "921aeb77-c931-4cee-9316-dc5f8cb67aae", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce dynamic chaos-based mutation frequency\n                mutation_rate = 0.1 * adaptive_factor * temperature  # Adjusted line\n                if np.random.rand() < mutation_rate:\n                    chaos_factor = np.sin(2 * np.pi * np.random.rand())\n                    mutation_vector = np.random.normal(0, 0.05 + 0.05 * chaos_factor, self.dim)\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrate dynamic chaos-based mutation frequency to balance exploration and exploitation.", "configspace": "", "generation": 47, "fitness": 0.9296557645599214, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "7fcfb4d0-5b44-4728-8f41-33558c2fe18f", "metadata": {"aucs": [0.9380065486532905, 0.9137634829601395, 0.937197262066334], "final_y": [0.11019676677549484, 0.11712933478132981, 0.1102010523976007]}, "mutation_prompt": null}
{"id": "696d25ad-c6c4-4a54-ae26-05f3665de9f9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce chaos-based mutation with logistic map\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    chaos_factor = np.random.rand()\n                    chaos_factor = 4 * chaos_factor * (1 - chaos_factor)  # Logistic map\n                    mutation_vector = np.random.normal(0, 0.05 + 0.05 * chaos_factor, self.dim)\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance chaos-based mutation with a logistic map and adjust cognitive and social coefficients dynamically for improved convergence.", "configspace": "", "generation": 48, "fitness": 0.9295673038764146, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "7fcfb4d0-5b44-4728-8f41-33558c2fe18f", "metadata": {"aucs": [0.93783803970618, 0.9137426701937243, 0.9371212017293391], "final_y": [0.11037147253135804, 0.11714840236359758, 0.11021207468347838]}, "mutation_prompt": null}
{"id": "ce195db4-ff7c-48ae-9bc5-b6fe60830f8d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.9 - 0.5 * (1 - temperature ** 2)  # Changed line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Enhance chaos-based mutation\n                mutation_rate = 0.15 * adaptive_factor * (1 - temperature)  # Changed line\n                if np.random.rand() < mutation_rate:\n                    chaos_factor = np.sin(2 * np.pi * np.random.rand())\n                    mutation_vector = np.random.normal(0, 0.05 + 0.05 * chaos_factor, self.dim)\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance chaos-based mutation and adapt inertia dynamically for improved exploration and convergence.", "configspace": "", "generation": 49, "fitness": 0.909830177545162, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.910 with standard deviation 0.010. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "7fcfb4d0-5b44-4728-8f41-33558c2fe18f", "metadata": {"aucs": [0.9158238773625081, 0.8959528966547284, 0.9177137586182497], "final_y": [0.1096664995502804, 0.11621973580410982, 0.1149439876437921]}, "mutation_prompt": null}
{"id": "ed89fe63-e994-4c89-9931-3e54c4b74785", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce chaos-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    chaos_factor = np.sin(2 * np.pi * np.random.rand())\n                    mutation_vector = np.random.normal(0, (0.05 + 0.05 * chaos_factor) * (1.0 - adaptive_factor), self.dim)  # Changed line\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance chaos-based mutation by incorporating dynamic noise scaling to improve exploration-exploitation balance.", "configspace": "", "generation": 50, "fitness": 0.9295032789079581, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "7fcfb4d0-5b44-4728-8f41-33558c2fe18f", "metadata": {"aucs": [0.9377228958804539, 0.9136366376840982, 0.9371503031593222], "final_y": [0.11040952766273593, 0.1172039162709877, 0.11020951557361358]}, "mutation_prompt": null}
{"id": "7e20ffa8-fd18-4ab8-9203-2dcd7417d07b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - np.sqrt(temperature))  # Changed line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce chaos-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    chaos_factor = np.sin(2 * np.pi * np.random.rand())\n                    mutation_vector = np.random.normal(0, 0.05 + 0.1 * chaos_factor, self.dim)  # Changed line\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive mutation radius and nonlinear inertia weight for improved exploration and convergence.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('scale < 0').", "error": "ValueError('scale < 0')", "parent_id": "7fcfb4d0-5b44-4728-8f41-33558c2fe18f", "metadata": {}, "mutation_prompt": null}
{"id": "6f94c001-5ca3-4100-9065-9f19de00ef5a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * np.random.rand() * (1 - temperature ** 2)  # Changed line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce chaos-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    chaos_factor = np.sin(2 * np.pi * np.random.rand())  # Changed line\n                    mutation_vector = np.random.normal(0, 0.05 + 0.05 * chaos_factor, self.dim)  # Changed line\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))  # Changed line\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce randomness in updating the inertia weight for better exploration and convergence.", "configspace": "", "generation": 52, "fitness": 0.8980877000269287, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.027. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "7fcfb4d0-5b44-4728-8f41-33558c2fe18f", "metadata": {"aucs": [0.8601370196734347, 0.9205398486293073, 0.9135862317780444], "final_y": [0.13031553209796398, 0.11621674655641878, 0.11356280940993235]}, "mutation_prompt": null}
{"id": "38bda783-b89f-418e-93cb-f661e8fd9627", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.3 * (1 - dist_factor))  # Changed line\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor * dist_factor)  # Changed line\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    chaos_factor = np.sin(2 * np.pi * np.random.rand())\n                    mutation_vector = np.random.normal(0, 0.05 + 0.05 * chaos_factor, self.dim)\n                    swarm[i] += mutation_vector\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive cognitive and social coefficients based on the population's diversity for improved convergence.", "configspace": "", "generation": 53, "fitness": 0.8911348792587918, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.056. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "7fcfb4d0-5b44-4728-8f41-33558c2fe18f", "metadata": {"aucs": [0.8119068295111871, 0.9232989539544355, 0.9381988543107525], "final_y": [0.15085873194461386, 0.11279092440316385, 0.1103934328178221]}, "mutation_prompt": null}
{"id": "ea80c464-c879-4e03-9296-3cf33cbf6a4d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.05 + 0.05 * adaptive_factor)  # Changed line\n                    swarm[i] += levy_step  # Changed line\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce Levy flight-based mutation for improved exploration and convergence in adaptive swarm optimization.", "configspace": "", "generation": 54, "fitness": 0.9300053595791419, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.006. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "7fcfb4d0-5b44-4728-8f41-33558c2fe18f", "metadata": {"aucs": [0.9284505304888963, 0.9232864279261837, 0.9382791203223456], "final_y": [0.11042879156331087, 0.11118982251601228, 0.1102292801081628]}, "mutation_prompt": null}
{"id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)  # Changed line\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Optimize swarm dynamics by enhancing Levy flight step size for improved exploration in adaptive swarm optimization.", "configspace": "", "generation": 55, "fitness": 0.9308424503223084, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.006. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "ea80c464-c879-4e03-9296-3cf33cbf6a4d", "metadata": {"aucs": [0.9294835495715963, 0.9244442317980126, 0.9385995695973162], "final_y": [0.11103848244921877, 0.11054667343746027, 0.11024696969679215]}, "mutation_prompt": null}
{"id": "c62ca158-5141-4ac3-95d4-f3db305c6044", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.08 + 0.05 * adaptive_factor)  # Changed line\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm exploration and exploitation balance by optimizing the adaptive Levy flight and mutation rate.", "configspace": "", "generation": 56, "fitness": 0.9278008730446344, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.928 with standard deviation 0.007. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.9207140666652173, 0.9245387121682636, 0.9381498403004227], "final_y": [0.11111896231591378, 0.11051732567004269, 0.11056790785034432]}, "mutation_prompt": null}
{"id": "aa1bd028-47e9-4542-8a53-3b7f13bf4da1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + temperature * 0.05 * adaptive_factor)  # Changed line\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a temperature-dependent levy step size to improve global exploration and balance exploration-exploitation trade-off.", "configspace": "", "generation": 57, "fitness": 0.9308282618203941, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.006. And the mean value of best solutions found was 0.110 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.929786473395251, 0.9245002348331206, 0.9381980772328105], "final_y": [0.11043052066314285, 0.1105298375272401, 0.11046918728179311]}, "mutation_prompt": null}
{"id": "297540f9-f9d0-4297-98bc-e0700498a86a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocity_variance = self.velocity.var()  # Added line\n                inertia_weight = 0.4 + 0.6 * (1 - velocity_variance)  # Changed line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Optimize swarm stability by adjusting inertia weight adaptively based on velocity variance for improved convergence in adaptive swarm optimization.", "configspace": "", "generation": 58, "fitness": 0.7652751441208511, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.765 with standard deviation 0.015. And the mean value of best solutions found was 0.171 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.7818451353038769, 0.7686720472528678, 0.7453082498058085], "final_y": [0.16417573162496646, 0.1702433386818767, 0.17949076415457677]}, "mutation_prompt": null}
{"id": "046c2b4f-9f31-4bee-8163-d018a3b48156", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    direction = np.sign(np.random.random(self.dim) - 0.5)  # Changed line\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor) * direction\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance exploration by dynamically adjusting Levy flight step direction based on swarm diversity.", "configspace": "", "generation": 59, "fitness": 0.9237983489264051, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.010. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.9262144362718608, 0.9109573261729056, 0.9342232843344485], "final_y": [0.11206565627444354, 0.11735148717545585, 0.11033218521447241]}, "mutation_prompt": null}
{"id": "e082d192-ef33-4a64-a7cf-4367dd32c4a3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.2 + 0.05 * adaptive_factor)  # Changed line\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance the Levy flight step initialization for improved exploration by sampling from a broader Cauchy distribution.", "configspace": "", "generation": 60, "fitness": 0.9299367926316168, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.005. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.9266074645202006, 0.9255932728930902, 0.9376096404815596], "final_y": [0.1109011940714899, 0.1104524024818726, 0.11063215524294301]}, "mutation_prompt": null}
{"id": "2283387e-d5db-4561-af4e-d32bd118ff17", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor) \n                    swarm[i] += levy_step * (personal_best[i] - global_best)  # Changed line\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Optimize swarm dynamics by introducing elite-based Levy flight for enhanced exploration in adaptive swarm optimization.", "configspace": "", "generation": 61, "fitness": 0.9061094089546146, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.023. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.8808115763973194, 0.9019717503060899, 0.9355449001604341], "final_y": [0.12666443300225994, 0.11828125482533192, 0.11061867696045125]}, "mutation_prompt": null}
{"id": "5f0223df-8cc6-42bb-9066-5290b1cd4e25", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor * np.linalg.norm(ub - lb))  # Changed line\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance global search by introducing a dynamic mutation rate scaling with the search space size in adaptive swarm optimization.", "configspace": "", "generation": 62, "fitness": 0.9154156115567003, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.915 with standard deviation 0.015. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.9052245294718384, 0.9044933679255187, 0.9365289372727436], "final_y": [0.11898243124073848, 0.11716832176428926, 0.11053783344236545]}, "mutation_prompt": null}
{"id": "8bbc428c-4997-4d0b-b303-d57bdca429e3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.5 * np.std(swarm) / np.mean(swarm))  # Changed line\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refine swarm dynamics by dynamically adjusting social coefficient based on the swarm diversity for improved convergence in adaptive swarm optimization.", "configspace": "", "generation": 63, "fitness": 0.9238260757449193, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.012. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.926659940717779, 0.9080435982374498, 0.9367746882795288], "final_y": [0.11127650408666301, 0.11786154355461553, 0.11164278426678931]}, "mutation_prompt": null}
{"id": "d843bade-360c-4f85-b2e5-b707c1c3a62f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.5 + 0.5 * (1 - temperature ** 2)  # Changed line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Optimize swarm dynamics by refining optimizer inertia weight for improved convergence in adaptive swarm optimization.", "configspace": "", "generation": 64, "fitness": 0.9194858698713969, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.015. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.9233861744988776, 0.8998893535365045, 0.9351820815788084], "final_y": [0.11257465231376096, 0.12067173088381966, 0.11032222819424031]}, "mutation_prompt": null}
{"id": "04dfce27-037e-4489-b225-e50d32b869cd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1 - dist_factor)  # Changed line\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improve adaptive exploration by dynamically adjusting mutation rates based on population diversity within swarm optimization.", "configspace": "", "generation": 65, "fitness": 0.9298626962945438, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.004. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.9315144013301819, 0.9244442317980126, 0.9336294557554367], "final_y": [0.11045109770666495, 0.11054667343746027, 0.11154186396098764]}, "mutation_prompt": null}
{"id": "9af9d908-bd03-4fec-a742-835999f3a4e4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                levy_scale = 0.1 + 0.05 * (stagnation_counter / 10)  # Changed line\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * levy_scale  # Changed line\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved global search by dynamically adjusting Levy flight scale based on global best improvement frequency.", "configspace": "", "generation": 66, "fitness": 0.9300505779016501, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.007. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.9309874026964167, 0.9214908753363672, 0.9376734556721663], "final_y": [0.11002492363316974, 0.11188628753564367, 0.11062210765306446]}, "mutation_prompt": null}
{"id": "102e6e7a-4e8f-4be1-a892-8cc0025f313a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                improvement_rate = np.abs(prev_global_best_value - global_best_value) / prev_global_best_value\n                mutation_rate = 0.05 * (1 + improvement_rate)  # Changed line\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced swarm exploration by dynamically adjusting the mutation rate based on global-best improvement rate.", "configspace": "", "generation": 67, "fitness": 0.9298988556762972, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.004. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.9322065412554983, 0.9236334862789837, 0.9338565394944098], "final_y": [0.1107718281746295, 0.11126629386565656, 0.11033449595163647]}, "mutation_prompt": null}
{"id": "498697ee-29aa-4eb1-a4db-9abe7dd429dc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.5 + 0.5 * (1 - temperature ** 3)  # Updated line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * (1 - dist_factor))  # Updated line\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.15 * adaptive_factor * temperature  # Updated line\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.15 + 0.1 * adaptive_factor)  # Updated line\n                    elite_contribution = 0.5 * (personal_best[elite_index] - swarm[i])  # New line\n                    swarm[i] += levy_step + elite_contribution  # Updated line\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.85 + 0.15 * adaptive_factor)))  # Updated line\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance the existing adaptive swarm optimization by introducing elite-based mutation, diversity preservation, and dynamic learning factors for improved convergence stability.", "configspace": "", "generation": 68, "fitness": 0.915507941013867, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.916 with standard deviation 0.004. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.9114432720319274, 0.9136203601786793, 0.9214601908309942], "final_y": [0.11566392211405652, 0.11647847069930983, 0.11409255953927622]}, "mutation_prompt": null}
{"id": "31d06f18-15b3-409a-8ef9-7148a124a628", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.5 + 0.5 * (1 - temperature ** 1.5)  # Changed line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)  # Changed line\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm exploration by fine-tuning the inertia weight adaptability for improved function convergence. ", "configspace": "", "generation": 69, "fitness": 0.9203394453978616, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.920 with standard deviation 0.007. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.9260696037273413, 0.9100849722498311, 0.9248637602164128], "final_y": [0.11184457447469398, 0.11515394678195345, 0.11320662796029812]}, "mutation_prompt": null}
{"id": "07388473-103b-415e-ae7c-d15b0887fb6a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * dist_factor  # Changed line\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm exploration by adjusting mutation rate dynamically based on swarm diversity in adaptive swarm optimization.", "configspace": "", "generation": 70, "fitness": 0.9289738287088042, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.929 with standard deviation 0.005. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.9293003569764553, 0.9223178528860339, 0.9353032762639235], "final_y": [0.11064472738954423, 0.11299465118402396, 0.11055685724426634]}, "mutation_prompt": null}
{"id": "5553f2d6-ddd2-4bc4-bf42-cc33da440813", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature / (1 + stagnation_counter)  # Changed line\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a dynamic mutation rate based on the inverse of the stagnation counter to enhance exploration.", "configspace": "", "generation": 71, "fitness": 0.9251671754747689, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.011. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.9296266415623293, 0.9105745812481207, 0.9353003036138565], "final_y": [0.1120299761375203, 0.11757297504346553, 0.11067544443539234]}, "mutation_prompt": null}
{"id": "eb25246f-2546-45a7-946e-23f5ac539ecd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.5 + 0.5 * np.sin(0.5 * np.pi * temperature)  # Changed line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.15 * adaptive_factor * temperature  # Changed line\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.05 + 0.1 * adaptive_factor)  # Changed line\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance global exploration by introducing a dynamic inertia weight and adaptive mutation for improved convergence in swarm-based optimization.", "configspace": "", "generation": 72, "fitness": 0.8418331990643574, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.008. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.8432625311734951, 0.8314826192463055, 0.8507544467732715], "final_y": [0.1305402175463064, 0.12455080665407647, 0.12373217781797652]}, "mutation_prompt": null}
{"id": "70279b53-6663-4555-a7f3-b5b108d0a660", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                improvement_rate = abs(prev_global_best_value - global_best_value) / max(1e-10, abs(prev_global_best_value))\n                mutation_rate = 0.1 * adaptive_factor * temperature / (1 + improvement_rate)  # Changed line\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhance swarm exploration by dynamically adjusting Levy flight mutation rate based on global best value improvement rate.", "configspace": "", "generation": 73, "fitness": 0.9306311313377105, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.005. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.9315144013301819, 0.9244442317980126, 0.9359347608849368], "final_y": [0.11045109770666495, 0.11054667343746027, 0.11065983210555319]}, "mutation_prompt": null}
{"id": "2287d55e-b33c-4350-bf2e-fef3e36d9172", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)  # Changed line\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a dynamic mutation rate scaling to enhance exploration and convergence in adaptive swarm optimization.", "configspace": "", "generation": 74, "fitness": 0.9309041403631718, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.006. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "9174b7cf-fad5-4ab7-8ea1-dea32be13af8", "metadata": {"aucs": [0.9294835495715963, 0.9244442317980126, 0.9387846397199068], "final_y": [0.11103848244921877, 0.11054667343746027, 0.11027827844604454]}, "mutation_prompt": null}
{"id": "35dc2cee-edf8-4660-a69a-9e7c0793c757", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.12 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)  # Changed line\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.15 + 0.05 * adaptive_factor)  # Changed line\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced convergence through adaptive levy mutation rate balancing exploration and exploitation.", "configspace": "", "generation": 75, "fitness": 0.9256332872877283, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.017. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "2287d55e-b33c-4350-bf2e-fef3e36d9172", "metadata": {"aucs": [0.9365000934292946, 0.9015416458524337, 0.9388581225814567], "final_y": [0.10978878206699971, 0.11753406506232256, 0.11031877454250316]}, "mutation_prompt": null}
{"id": "3daa03c8-cb56-4c90-99e3-41c84fb7f862", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.5 + 0.4 * np.sin(np.pi * temperature)  # Changed line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb * (1 - adaptive_factor), ub * (1 + adaptive_factor))  # Changed line\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a nonlinear adaptive inertia weight and dynamic boundary adaptation to improve convergence and exploration in adaptive swarm optimization.", "configspace": "", "generation": 76, "fitness": 0.9174112034263974, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.917 with standard deviation 0.014. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "2287d55e-b33c-4350-bf2e-fef3e36d9172", "metadata": {"aucs": [0.9244069144736994, 0.8973712956943507, 0.930455400111142], "final_y": [0.112125379012187, 0.11846973656478454, 0.11019812687297781]}, "mutation_prompt": null}
{"id": "850c8519-315c-4cd1-9e1c-a97926890153", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor + adaptive_factor))  # Changed line\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)  # Changed line\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refines swarm dynamics by incorporating an adaptive cognitive coefficient for improved diversity and convergence.", "configspace": "", "generation": 77, "fitness": 0.9117588449415172, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.010. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "2287d55e-b33c-4350-bf2e-fef3e36d9172", "metadata": {"aucs": [0.9135842774326665, 0.8981536444094993, 0.9235386129823862], "final_y": [0.11569429157361422, 0.12012373050478076, 0.11327965884390767]}, "mutation_prompt": null}
{"id": "81579883-48d3-4541-9e52-33f658d7158e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    1.7 * cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +  # Changed line\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.15 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)  # Changed line\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refines dynamic mutation and velocity update rules to balance exploration-exploitation in adaptive swarm optimization.", "configspace": "", "generation": 78, "fitness": 0.8982627350243249, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.011. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "2287d55e-b33c-4350-bf2e-fef3e36d9172", "metadata": {"aucs": [0.8836120841086926, 0.901288377688402, 0.9098877432758796], "final_y": [0.12609844507737056, 0.11998796075408735, 0.11799377908985953]}, "mutation_prompt": null}
{"id": "5869a080-bb1f-41db-ac3f-cd91fd182ff5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - (global_best_value / prev_global_best_value) ** 2)  # Changed line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporates an adaptive inertia weight strategy based on search progress to improve convergence speed and solution quality.", "configspace": "", "generation": 79, "fitness": 0.9179881534689609, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.918 with standard deviation 0.005. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "2287d55e-b33c-4350-bf2e-fef3e36d9172", "metadata": {"aucs": [0.9249125601688135, 0.9121790636941645, 0.9168728365439047], "final_y": [0.11198851923277042, 0.1171033127430271, 0.11680391796970424]}, "mutation_prompt": null}
{"id": "aae6f7fc-f951-4b47-8da0-5a7e9e810cdf", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * adaptive_factor  # Changed line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, min(50, int(self.population_size * (0.8 + 0.2 * adaptive_factor))))  # Changed line\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces adaptive inertia weight and dynamic swarm size adjustment to improve exploration and convergence.", "configspace": "", "generation": 80, "fitness": 0.8941833174954023, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.017. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "2287d55e-b33c-4350-bf2e-fef3e36d9172", "metadata": {"aucs": [0.9030652147352103, 0.8709784418440791, 0.9085062959069172], "final_y": [0.11228245971921857, 0.12734197103456713, 0.11481935027580403]}, "mutation_prompt": null}
{"id": "70c251d3-fece-42c3-b865-e0d8034c0c62", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                stochastic_factor = np.random.uniform(0.8, 1.2)  # Changed line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * stochastic_factor  # Changed line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)  # Changed line\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.025 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances exploration and convergence by adjusting the velocity update with a stochastic control factor and refined mutation step size.", "configspace": "", "generation": 81, "fitness": 0.914177902846624, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.914 with standard deviation 0.012. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "2287d55e-b33c-4350-bf2e-fef3e36d9172", "metadata": {"aucs": [0.8975827344550631, 0.921934607696348, 0.9230163663884611], "final_y": [0.11972612419212858, 0.11212929186230292, 0.1115462360648154]}, "mutation_prompt": null}
{"id": "fcf245cd-60d8-46b1-871b-48bd8677339d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        # Introducing chaotic sequence for chaos-based initialization\n        chaotic_sequence = np.sin(np.linspace(0, np.pi, self.population_size))\n        \n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.5 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.7 * (1 - 0.3 * adaptive_factor)  # Adjusted coefficient\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Self-adaptive mutation rate based on chaotic sequence\n                mutation_rate = 0.05 * chaotic_sequence[i] * (1.0 + 0.5 * dist_factor)\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances exploration and convergence by integrating self-adaptive parameters and chaotic sequences into adaptive swarm optimization.", "configspace": "", "generation": 82, "fitness": 0.9004126168373482, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.027. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "2287d55e-b33c-4350-bf2e-fef3e36d9172", "metadata": {"aucs": [0.862901465663887, 0.9104747931375882, 0.9278615917105694], "final_y": [0.12764671942569372, 0.11695690231027733, 0.11220822009749842]}, "mutation_prompt": null}
{"id": "1c932003-aafd-46c5-a034-a71c362a19b0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)  # Changed line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances adaptability with an additional stochastic element to diversify search and prevent premature convergence.", "configspace": "", "generation": 83, "fitness": 0.9026427010911834, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.030. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "2287d55e-b33c-4350-bf2e-fef3e36d9172", "metadata": {"aucs": [0.8605059495682776, 0.9163865864346221, 0.9310355672706504], "final_y": [0.12934962067590705, 0.11749181192979186, 0.1110994206973609]}, "mutation_prompt": null}
{"id": "e9f2c845-000f-4abf-b0fd-7b5a5e6f7e9f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)  \n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (\n                        0.1 + 0.05 * np.random.random() * (global_best_value - prev_global_best_value))  # Changed line\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances exploitation by adjusting mutation intensity using a stochastic approach based on current global best improvements.", "configspace": "", "generation": 84, "fitness": 0.9270220220897528, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.927 with standard deviation 0.008. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "2287d55e-b33c-4350-bf2e-fef3e36d9172", "metadata": {"aucs": [0.9328591273877301, 0.9164016168899207, 0.931805321991608], "final_y": [0.10974481892735266, 0.11272045037560885, 0.11169385577587954]}, "mutation_prompt": null}
{"id": "efd3bdb3-e3b6-4d60-975f-f67d06c2a9a4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)  # Changed line\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    decay_rate = 0.95  # Changed line\n                    personal_best[i] = personal_best[i] * decay_rate + swarm[i] * (1 - decay_rate)  # Changed line\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Integrates a decaying learning rate for personal best updates, enhancing convergence stability in adaptive swarm optimization.", "configspace": "", "generation": 85, "fitness": 0.8448648096371812, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.845 with standard deviation 0.013. And the mean value of best solutions found was 0.139 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "2287d55e-b33c-4350-bf2e-fef3e36d9172", "metadata": {"aucs": [0.8368832092187874, 0.8343352389014417, 0.8633759807913148], "final_y": [0.14180962157536336, 0.14391744002694962, 0.13228679408436772]}, "mutation_prompt": null}
{"id": "68f2600f-8237-4e9d-86b5-b32971eba339", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature * adaptive_factor)  # Changed line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances convergence by introducing a dynamic inertia weight adjustment in adaptive swarm optimization.", "configspace": "", "generation": 86, "fitness": 0.9309041403631718, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.006. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2287d55e-b33c-4350-bf2e-fef3e36d9172", "metadata": {"aucs": [0.9294835495715963, 0.9244442317980126, 0.9387846397199068], "final_y": [0.11103848244921877, 0.11054667343746027, 0.11027827844604454]}, "mutation_prompt": null}
{"id": "088ac811-83ac-4409-bbf8-e524e5f7dd73", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            # Dynamic constriction factor\n            constriction_factor = 0.729 * (1 + 0.1 * adaptive_factor) # Added line\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = constriction_factor * (inertia_weight * self.velocity[i] + # Modified line\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporates a dynamic constriction factor to enhance convergence in adaptive swarm optimization.", "configspace": "", "generation": 87, "fitness": 0.9112091064995248, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.010. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "2287d55e-b33c-4350-bf2e-fef3e36d9172", "metadata": {"aucs": [0.9212884578373141, 0.8980373790825206, 0.9143014825787399], "final_y": [0.11323720581038565, 0.11627368705334262, 0.11160762845698591]}, "mutation_prompt": null}
{"id": "410707d8-d35f-488e-a43f-ba6d94356ffd", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.07 * adaptive_factor)  # Changed line\n                    swarm[i] += levy_step * np.random.uniform(-1, 1, self.dim)  # Changed line\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhances exploration and convergence with adaptive random perturbation in swarm optimization.", "configspace": "", "generation": 88, "fitness": 0.9112127004068428, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.019. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "2287d55e-b33c-4350-bf2e-fef3e36d9172", "metadata": {"aucs": [0.8859299023629205, 0.9160914465309489, 0.9316167523266591], "final_y": [0.12557013996098765, 0.11300393352412075, 0.11182620210937422]}, "mutation_prompt": null}
{"id": "fa3f4710-a9fc-438c-9137-2ba02684729f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature)  # Changed line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refines inertia weight scaling for improved exploration-exploitation balance in adaptive swarm optimization.", "configspace": "", "generation": 89, "fitness": 0.9251452401021112, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.010. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "2287d55e-b33c-4350-bf2e-fef3e36d9172", "metadata": {"aucs": [0.9326278707876775, 0.9115885391085434, 0.9312193104101125], "final_y": [0.10967190802365367, 0.11310108159938703, 0.1121569050222172]}, "mutation_prompt": null}
{"id": "c45b0ae0-2797-473a-b7ff-321d6ab65741", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)  # Changed line\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n                if stagnation_counter > (self.budget * 0.1):  # Changed line\n                    swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))  # Changed line\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adjusts swarm reinitialization and cognitive-social balance to prevent premature convergence in adaptive swarm optimization.", "configspace": "", "generation": 90, "fitness": 0.9309041403631718, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.931 with standard deviation 0.006. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2287d55e-b33c-4350-bf2e-fef3e36d9172", "metadata": {"aucs": [0.9294835495715963, 0.9244442317980126, 0.9387846397199068], "final_y": [0.11103848244921877, 0.11054667343746027, 0.11027827844604454]}, "mutation_prompt": null}
{"id": "844f6054-9a7b-474d-aa6f-0c4734f097de", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            # Adjusted social_coeff to use temperature\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor * temperature)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)  # Changed line\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporates a temperature-adjusted social coefficient to enhance convergence towards the global best.", "configspace": "", "generation": 91, "fitness": 0.9316645050582141, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.932 with standard deviation 0.002. And the mean value of best solutions found was 0.110 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "2287d55e-b33c-4350-bf2e-fef3e36d9172", "metadata": {"aucs": [0.9293149963112792, 0.931468979330017, 0.9342095395333461], "final_y": [0.11028342258602553, 0.10992942756747082, 0.11077415548367209]}, "mutation_prompt": null}
{"id": "17bd171c-061e-4012-ac07-df88ba6d682e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.3 + 0.7 * (1 - temperature ** 2)  # Changed line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            # Adjusted social_coeff to use temperature\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor * temperature)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.15 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)  # Changed line\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.15 + 0.05 * adaptive_factor)  # Changed line\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces a dynamic inertia weight and mutation based on temperature to enhance exploration and convergence.", "configspace": "", "generation": 92, "fitness": 0.9126187463156005, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.913 with standard deviation 0.010. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "844f6054-9a7b-474d-aa6f-0c4734f097de", "metadata": {"aucs": [0.9086085919487653, 0.9026569482637695, 0.9265906987342666], "final_y": [0.11546462748269815, 0.11635633156460723, 0.11237839319309284]}, "mutation_prompt": null}
{"id": "97e1c3fa-933d-47bd-add0-fbf97165e0f5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2) * (1 - adaptive_factor)  # Changed line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor * temperature)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a decayed inertia weight strategy for better exploration-exploitation balance.", "configspace": "", "generation": 93, "fitness": 0.9214310609605226, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.921 with standard deviation 0.011. And the mean value of best solutions found was 0.112 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "844f6054-9a7b-474d-aa6f-0c4734f097de", "metadata": {"aucs": [0.927241596507814, 0.9063474161938498, 0.9307041701799041], "final_y": [0.11012996231214889, 0.11231393774939125, 0.11219834918681926]}, "mutation_prompt": null}
{"id": "5a952cbc-21af-49cb-8066-6fd619aeed2c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor * temperature)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce elite-driven mutation \n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)\n                if np.random.rand() < mutation_rate:\n                    elite_influence = np.random.standard_normal(self.dim) * (0.05 * adaptive_factor)\n                    swarm[i] += elite_influence * (global_best - swarm[i])  # Changed line\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduces an elite-driven mutation strategy and adaptive mutation rate to enhance convergence towards the global best.", "configspace": "", "generation": 94, "fitness": 0.9248290337392925, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.925 with standard deviation 0.010. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "844f6054-9a7b-474d-aa6f-0c4734f097de", "metadata": {"aucs": [0.9233352682985602, 0.9138348501679778, 0.9373169827513393], "final_y": [0.11180471537586456, 0.11664990127743435, 0.11077959271393134]}, "mutation_prompt": null}
{"id": "38cb13f9-c173-4a21-b79e-27bd848b9712", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor * temperature)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                velocity_scale = 0.5 + (0.5 * adaptive_factor * (1 - temperature))  # New line\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= velocity_scale  # New line\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporates a self-adaptive velocity scaling mechanism to enhance convergence and exploration in the swarm.", "configspace": "", "generation": 95, "fitness": 0.8843006571934865, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.884 with standard deviation 0.023. And the mean value of best solutions found was 0.115 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "844f6054-9a7b-474d-aa6f-0c4734f097de", "metadata": {"aucs": [0.8586611821321075, 0.8793288954282173, 0.9149118940201346], "final_y": [0.11539439573255117, 0.11763309296221969, 0.11116841528846788]}, "mutation_prompt": null}
{"id": "1c73705d-2599-4d98-8d49-14da54a3d4f9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))  # Changed line\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor * temperature)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adjustable cognition and social coefficients based on swarm diversity to improve exploration and exploitation balance.", "configspace": "", "generation": 96, "fitness": 0.9316645050582141, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.932 with standard deviation 0.002. And the mean value of best solutions found was 0.110 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "844f6054-9a7b-474d-aa6f-0c4734f097de", "metadata": {"aucs": [0.9293149963112792, 0.931468979330017, 0.9342095395333461], "final_y": [0.11028342258602553, 0.10992942756747082, 0.11077415548367209]}, "mutation_prompt": null}
{"id": "96d9c2ed-7b6c-4dc9-b2ab-ccfdf3ccfbe3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            # Adjusted social_coeff to use temperature\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor * temperature)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce Levy flight-based mutation\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)  # Changed line\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.05 + 0.025 * adaptive_factor)  # Changed line\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            # Adaptive swarm size based on evaluations\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "An enhanced Adaptive Swarm Gradient Descent algorithm with temperature-adjusted social coefficients and elite elitism strategy.", "configspace": "", "generation": 97, "fitness": 0.9325341271978717, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.933 with standard deviation 0.003. And the mean value of best solutions found was 0.110 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "844f6054-9a7b-474d-aa6f-0c4734f097de", "metadata": {"aucs": [0.9349244859015595, 0.9290722042039125, 0.9336056914881427], "final_y": [0.10983307930418673, 0.11060933162898334, 0.11101070458208939]}, "mutation_prompt": null}
{"id": "710f101e-8f96-46ed-99a4-1a9afa43fe98", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.3 * (1 - temperature ** 3)  # Changed line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor * temperature)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.05 + 0.01 * adaptive_factor)  # Changed line\n                    grad_approx = (func(swarm[i] + 0.01) - func(swarm[i] - 0.01)) / 0.02  # Changed line\n                    swarm[i] += levy_step * grad_approx\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "An enhanced Adaptive Swarm Gradient Descent algorithm with improved convergence control through dynamic inertia weight adjustment and gradient-informed mutation strategy.", "configspace": "", "generation": 98, "fitness": 0.9237311667192607, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.924 with standard deviation 0.011. And the mean value of best solutions found was 0.111 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "96d9c2ed-7b6c-4dc9-b2ab-ccfdf3ccfbe3", "metadata": {"aucs": [0.9252508176414534, 0.9096929325988176, 0.936249749917511], "final_y": [0.110130495678604, 0.11181758503896844, 0.11003303172023882]}, "mutation_prompt": null}
{"id": "e839ad94-b225-4ca1-a28d-84e2bc7ce537", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - (temperature * (1 + stagnation_counter / 10)) ** 2)  # Changed line\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor * temperature)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.05 + 0.025 * adaptive_factor)\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations % (self.budget // 10) == 0:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Leveraged dynamic inertia weight adaptation based on swarm diversity and convergence rate.", "configspace": "", "generation": 99, "fitness": 0.7995804867014796, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.800 with standard deviation 0.056. And the mean value of best solutions found was 0.159 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "96d9c2ed-7b6c-4dc9-b2ab-ccfdf3ccfbe3", "metadata": {"aucs": [0.8780686441190924, 0.76890311738062, 0.7517696986047264], "final_y": [0.13001098716810255, 0.1702433386818767, 0.17687869913665355]}, "mutation_prompt": null}
{"id": "80b06feb-11af-4341-9bcd-c84f3dd7cf8d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.eval_schedule = np.linspace(0, budget, 11, dtype=int)\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        prev_global_best_value = global_best_value\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            temperature = 1 - (evaluations / self.budget)\n            inertia_weight = 0.4 + 0.6 * (1 - temperature ** 2)\n\n            dist_factor = np.linalg.norm(global_best - swarm.mean(axis=0)) / np.linalg.norm(ub - lb)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * (1 - dist_factor))\n            social_coeff = 1.5 * (1 - 0.3 * adaptive_factor * temperature)\n\n            elite_index = np.argmin(personal_best_value)\n            for i in range(self.population_size):\n                if i == elite_index:\n                    continue\n\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                mutation_rate = 0.1 * adaptive_factor * temperature * (1.0 + 0.5 * dist_factor)\n                if np.random.rand() < mutation_rate:\n                    levy_step = np.random.standard_cauchy(self.dim) * (0.1 + 0.05 * adaptive_factor)  # Changed line\n                    swarm[i] += levy_step\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    prev_global_best_value = global_best_value\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget:\n                    break\n\n            if evaluations in self.eval_schedule:\n                self.population_size = max(2, int(self.population_size * (0.8 + 0.2 * adaptive_factor)))  # Changed line\n                swarm = swarm[:self.population_size]\n                personal_best = personal_best[:self.population_size]\n                personal_best_value = personal_best_value[:self.population_size]\n                self.velocity = self.velocity[:self.population_size]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with dynamic mutation and adaptive evaluation scheduling.", "configspace": "", "generation": 100, "fitness": 0.9316645050582141, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.932 with standard deviation 0.002. And the mean value of best solutions found was 0.110 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "96d9c2ed-7b6c-4dc9-b2ab-ccfdf3ccfbe3", "metadata": {"aucs": [0.9293149963112792, 0.931468979330017, 0.9342095395333461], "final_y": [0.11028342258602553, 0.10992942756747082, 0.11077415548367209]}, "mutation_prompt": null}
