{"id": "dfc491e3-f69d-4648-a8da-0fb367b5479f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent (ASGD): Combines swarm intelligence and gradient estimation to explore and exploit search space efficiently.", "configspace": "", "generation": 0, "fitness": 0.8264407036439118, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.826 with standard deviation 0.020. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": null, "metadata": {"aucs": [0.8041324604654931, 0.8227266579918514, 0.8524629924743906], "final_y": [0.1412466306774247, 0.13112094863304602, 0.12789490696654837]}, "mutation_prompt": null}
{"id": "21d9d783-e09b-45da-9f7a-a1fadbae62a8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            # Changed line\n            social_coeff = 1.5 * (1 + 0.2 * (1 - adaptive_factor))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces dynamic adjustment of social coefficient based on progress to refine global-best convergence.", "configspace": "", "generation": 1, "fitness": 0.8421178959588306, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.842 with standard deviation 0.032. And the mean value of best solutions found was 0.137 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "dfc491e3-f69d-4648-a8da-0fb367b5479f", "metadata": {"aucs": [0.8055614007483372, 0.8843469895841429, 0.8364452975440114], "final_y": [0.15138494901195865, 0.12180843770558947, 0.13646728410616105]}, "mutation_prompt": null}
{"id": "84105f45-d5a2-4ff7-a381-9bbff334f62b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            \n            # Add adaptive learning rate\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                # Apply adaptive learning rate\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (E-ASGD): Integrates adaptive learning rate and diversity promotion to balance exploration and exploitation effectively.", "configspace": "", "generation": 1, "fitness": 0.8592455373478664, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.859 with standard deviation 0.017. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "dfc491e3-f69d-4648-a8da-0fb367b5479f", "metadata": {"aucs": [0.835668993887494, 0.8684076311777906, 0.8736599869783147], "final_y": [0.12988026814280085, 0.1251333965271969, 0.11546917308336357]}, "mutation_prompt": null}
{"id": "a835e5e2-d847-4084-924a-3142a2f384e0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.restarts = 3  # Control parameter for random restarts\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        failed_iterations = 0  # Counter for stagnation detection\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - adaptive_factor * 0.4  # Dynamic adjustment\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n                    failed_iterations = 0  # Reset stagnation counter\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            failed_iterations += 1\n\n            # Random restart mechanism\n            if failed_iterations > self.population_size and self.restarts > 0:\n                swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                evaluations += self.population_size\n                self.restarts -= 1\n                failed_iterations = 0\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Incorporates dynamic inertia weight adjustment and random restart mechanism to escape local optima and improve performance.", "configspace": "", "generation": 1, "fitness": 0.8508671344169204, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.851 with standard deviation 0.003. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "dfc491e3-f69d-4648-a8da-0fb367b5479f", "metadata": {"aucs": [0.8538914751021527, 0.8520171982939475, 0.8466927298546612], "final_y": [0.1352329374765573, 0.12302753590659288, 0.12320658397472684]}, "mutation_prompt": null}
{"id": "1386cfe7-fea1-4e95-8c15-aef15488ac22", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Adjusted social coefficient\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= np.random.uniform(0.9, 1.1)  # Dynamic velocity adjustment\n                swarm[i] += self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD): Introduces dynamic velocity adjustment and adaptive social coefficient scaling for improved convergence and exploration balance.", "configspace": "", "generation": 1, "fitness": 0.8293290489223031, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.002. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "dfc491e3-f69d-4648-a8da-0fb367b5479f", "metadata": {"aucs": [0.8271263316735322, 0.8283864263621269, 0.8324743887312505], "final_y": [0.13346684386494945, 0.12589806644748125, 0.13240037471968802]}, "mutation_prompt": null}
{"id": "806d59b7-4e0b-4b2d-ab4a-8aeaa44b6f75", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.f = 0.8  # mutation factor\n        self.cr = 0.9  # crossover probability\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                a, b, c = np.random.choice(self.population_size, 3, replace=False)\n                mutant = np.clip(swarm[a] + self.f * (swarm[b] - swarm[c]), lb, ub)\n                trial = np.where(np.random.rand(self.dim) < self.cr, mutant, swarm[i])\n\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] = np.where(np.random.rand(self.dim) < 0.5, trial, swarm[i] + self.velocity[i])\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "EnhancedAdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (EASGD) integrates differential evolution to improve exploration capabilities and convergence speed.", "configspace": "", "generation": 1, "fitness": 0.7926119396251531, "feedback": "The algorithm EnhancedAdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.793 with standard deviation 0.012. And the mean value of best solutions found was 0.153 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "dfc491e3-f69d-4648-a8da-0fb367b5479f", "metadata": {"aucs": [0.7895730417440049, 0.8082737631673813, 0.7799890139640733], "final_y": [0.1537525618776524, 0.14254251703601162, 0.16268640276252944]}, "mutation_prompt": null}
{"id": "acf440e3-353f-4b56-a588-f47c2e356098", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                chaos_factor = np.random.uniform(-0.05, 0.05, self.dim)  # Introduce a chaos factor\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) + chaos_factor)\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Particle Dynamics Optimization (EPDO): Improves exploration by integrating a chaos factor for velocity perturbation to diversify swarm dynamics.", "configspace": "", "generation": 2, "fitness": 0.8438247672089497, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.844 with standard deviation 0.007. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "84105f45-d5a2-4ff7-a381-9bbff334f62b", "metadata": {"aucs": [0.8354561644831303, 0.8437213046069851, 0.8522968325367335], "final_y": [0.1360804191009204, 0.13239068753366368, 0.12889009812988472]}, "mutation_prompt": null}
{"id": "a503ba23-b593-4e13-9079-6f564edd95da", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor ** 2  # Nonlinear inertia weight\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            \n            # Add adaptive learning rate\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                # Apply adaptive learning rate\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (E-ASGD+): Introduces nonlinear inertia weight for improved convergence dynamics.", "configspace": "", "generation": 2, "fitness": 0.8818111300702137, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.882 with standard deviation 0.023. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "84105f45-d5a2-4ff7-a381-9bbff334f62b", "metadata": {"aucs": [0.8573008293612541, 0.875384479365579, 0.9127480814838083], "final_y": [0.12024434222698688, 0.1267252043475684, 0.11398520761572029]}, "mutation_prompt": null}
{"id": "0260c1a3-0ddc-4290-8620-f1a68ad8394a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            \n            # Add adaptive learning rate\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                # Apply adaptive learning rate\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (E-ASGD) with dynamic inertia reversal for improved convergence.", "configspace": "", "generation": 2, "fitness": 0.9011892260876097, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.006. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "84105f45-d5a2-4ff7-a381-9bbff334f62b", "metadata": {"aucs": [0.9103693948358091, 0.8968271283686607, 0.8963711550583592], "final_y": [0.11875307382650035, 0.11792566220918632, 0.12002855207519936]}, "mutation_prompt": null}
{"id": "f4d46525-e48e-41ae-8357-b299f0dc4358", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 + 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            \n            # Add adaptive learning rate\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n            \n            # Adaptive population size\n            self.population_size = int(10 + 2 * np.sqrt(self.dim) * (1 - adaptive_factor))\n            swarm = np.resize(swarm, (self.population_size, self.dim))\n            personal_best = np.resize(personal_best, (self.population_size, self.dim))\n            self.velocity = np.resize(self.velocity, (self.population_size, self.dim))\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                # Apply adaptive learning rate\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced E-ASGD with adaptive population size adjustment for better balance between exploration and exploitation.", "configspace": "", "generation": 2, "fitness": 0.8647482549502414, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.020. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "84105f45-d5a2-4ff7-a381-9bbff334f62b", "metadata": {"aucs": [0.8519171618532023, 0.8495313337146385, 0.8927962692828834], "final_y": [0.13722724523980734, 0.13464051755054396, 0.11770612360327815]}, "mutation_prompt": null}
{"id": "e2f1817e-93a5-4abe-8cd4-e27b6adecd71", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Improved inertia weight with non-linear decay\n            inertia_weight = 0.9 - 0.7 * (1 - np.exp(-4 * adaptive_factor))\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            \n            # Add adaptive learning rate\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                # Apply adaptive learning rate\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Enhanced Adaptive Swarm Gradient Descent (I-EASGD): Introduces non-linear inertia weight decay for better exploration-exploitation trade-off.  ", "configspace": "", "generation": 2, "fitness": 0.8814219491914201, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.881 with standard deviation 0.018. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "84105f45-d5a2-4ff7-a381-9bbff334f62b", "metadata": {"aucs": [0.8577594687317901, 0.886414978789221, 0.9000914000532492], "final_y": [0.135386651999701, 0.11644596779529215, 0.1196393985946893]}, "mutation_prompt": null}
{"id": "6716b339-106a-4fe6-917a-aed9650b9b06", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic cognitive coefficient\n            social_coeff = 1.5\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.5:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (E-ASGD) with dynamic cognitive coefficient and selective global best update for improved exploration.", "configspace": "", "generation": 3, "fitness": 0.9053104821034358, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.905 with standard deviation 0.020. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "0260c1a3-0ddc-4290-8620-f1a68ad8394a", "metadata": {"aucs": [0.9132480289482414, 0.877737036257294, 0.9249463811047718], "final_y": [0.11418897917643678, 0.1268332248798557, 0.11350526987322584]}, "mutation_prompt": null}
{"id": "ba4b666a-6277-440f-8f9b-67c62bd1864b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = (0.7 - 0.3 * adaptive_factor) * np.random.choice([-1, 1])  # Dynamic inertia reversal with random switching\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            \n            # Add adaptive learning rate\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                # Apply adaptive learning rate\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Incorporate random inertial switching in Adaptive Swarm Gradient Descent for improved exploration.", "configspace": "", "generation": 3, "fitness": 0.9009705348365324, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.016. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "0260c1a3-0ddc-4290-8620-f1a68ad8394a", "metadata": {"aucs": [0.8786431329681386, 0.9072204735887458, 0.917047997952713], "final_y": [0.1239222131350276, 0.11678757111195315, 0.11715978798010318]}, "mutation_prompt": null}
{"id": "40e19954-2671-4bda-8c9b-8866637cc851", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            \n            # Add adaptive learning rate\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            # Identify elite particle\n            elite_particle = swarm[np.argmin(personal_best_value)]\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.4 * r3 * (elite_particle - swarm[i]))  # Elite influence\n                # Apply adaptive learning rate\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced elite particle influence in Enhanced Adaptive Swarm Gradient Descent (E-ASGD) to promote exploration and prevent premature convergence.", "configspace": "", "generation": 3, "fitness": 0.8936364409990114, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.894 with standard deviation 0.015. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "0260c1a3-0ddc-4290-8620-f1a68ad8394a", "metadata": {"aucs": [0.9089305528716797, 0.8727865185714966, 0.899192251553858], "final_y": [0.11741661468638587, 0.13137122270107704, 0.11972185706505911]}, "mutation_prompt": null}
{"id": "2ce108bc-5653-4dcb-a507-9efe8ea9f745", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.5 * np.cos(np.pi * adaptive_factor)  # Nonlinear dynamic inertia\n            cognitive_coeff = 1.5 * adaptive_factor\n            social_coeff = 1.5\n            \n            # Add adaptive learning rate\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                # Apply adaptive learning rate\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n            # Elite re-evaluation\n            if evaluations + self.population_size <= self.budget:\n                reevaluated_values = np.array([func(x) for x in personal_best])\n                evaluations += self.population_size\n                better_indices = reevaluated_values < personal_best_value\n                personal_best_value[better_indices] = reevaluated_values[better_indices]\n                if np.min(reevaluated_values) < global_best_value:\n                    global_best = personal_best[np.argmin(reevaluated_values)]\n                    global_best_value = np.min(reevaluated_values)\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduction of nonlinear dynamic inertia weight strategy and elite re-evaluation to enhance convergence accuracy.", "configspace": "", "generation": 3, "fitness": 0.8918307112024153, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.036. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "0260c1a3-0ddc-4290-8620-f1a68ad8394a", "metadata": {"aucs": [0.8413962532555486, 0.9143223977710467, 0.9197734825806506], "final_y": [0.1377171613648006, 0.11629579223406084, 0.11442396815851552]}, "mutation_prompt": null}
{"id": "6715a6cc-529d-4c78-9732-a82baf9e4f38", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * adaptive_factor\n\n            # Changed in this line to include adaptive social coefficient\n            social_coeff = 1.5 + 0.5 * adaptive_factor\n            \n            # Add adaptive learning rate\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                # Apply adaptive learning rate\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Evaluate and update personal best\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Update global best\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce an adaptive social coefficient for enhanced convergence by dynamically modulating with evaluations.", "configspace": "", "generation": 3, "fitness": 0.8987457696911129, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.032. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "0260c1a3-0ddc-4290-8620-f1a68ad8394a", "metadata": {"aucs": [0.8551907632938388, 0.9078502095069332, 0.9331963362725663], "final_y": [0.13450272363115, 0.1194795265807519, 0.11163889955708217]}, "mutation_prompt": null}
{"id": "3eb69dcd-9408-46ef-9611-a37941161189", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic cognitive coefficient\n            social_coeff = 1.5\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Improved selective global best update probability\n                if f_value < global_best_value and np.random.rand() < 0.7:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (E-ASGD) with improved selective global best update probability for better convergence.", "configspace": "", "generation": 4, "fitness": 0.8268148014349586, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.033. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "6716b339-106a-4fe6-917a-aed9650b9b06", "metadata": {"aucs": [0.8693887734919958, 0.8206594129388431, 0.7903962178740366], "final_y": [0.1272919888801699, 0.13544285037675385, 0.1419647756498401]}, "mutation_prompt": null}
{"id": "7bbe3c3f-774d-4f66-b654-4726c63cc0e7", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic cognitive coefficient\n            social_coeff = 1.5 + 0.5 * (1 - adaptive_factor)  # Enhanced social learning\n\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                velocity_cap = 0.1 * (ub - lb) * (1 - adaptive_factor)  # Adaptive velocity cap\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_cap, velocity_cap)  # Apply velocity cap\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.5:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Modified E-ASGD with adaptive velocity cap and enhanced social learning for improved convergence.", "configspace": "", "generation": 4, "fitness": 0.7987476798759486, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.013. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "6716b339-106a-4fe6-917a-aed9650b9b06", "metadata": {"aucs": [0.7866554020786465, 0.8173694084810099, 0.7922182290681898], "final_y": [0.13535144772425822, 0.13401379919951206, 0.13498316176126746]}, "mutation_prompt": null}
{"id": "0f3570f7-fa04-4859-b3f1-ab19c6da9242", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, self.dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic cognitive coefficient\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.5:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Enhanced Adaptive Swarm Gradient Descent (E-ASGD) with dynamic social coefficient for better convergence.", "configspace": "", "generation": 4, "fitness": 0.8267793638350766, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.028. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "6716b339-106a-4fe6-917a-aed9650b9b06", "metadata": {"aucs": [0.8662013918167396, 0.8080312398113668, 0.8061054598771235], "final_y": [0.13071432237768188, 0.14095538268292884, 0.12254433534418074]}, "mutation_prompt": null}
{"id": "8ef6b611-2268-4f85-b0f4-49862217efd3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.3 + 0.4 * (1 / (1 + np.exp(-5 * (adaptive_factor - 0.5))))  # Dynamic inertia with sigmoid\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 + 0.5 * np.random.random()  # Stochastic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                stochastic_velocity = np.random.random()  # Stochastic element for velocity\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])) * stochastic_velocity\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.7:  # Increased probability\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Swarm Gradient Descent with dynamic inertia-sigmoid function and stochastic velocity update for robust global exploration and convergence.", "configspace": "", "generation": 4, "fitness": 0.8153129037507799, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.815 with standard deviation 0.010. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "6716b339-106a-4fe6-917a-aed9650b9b06", "metadata": {"aucs": [0.8252788995558322, 0.8182596025987436, 0.802400209097764], "final_y": [0.14485218174952552, 0.13249140157247363, 0.12262292695272348]}, "mutation_prompt": null}
{"id": "cbaa47e8-781e-48eb-9348-57482be62da3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            diversity = np.std(swarm, axis=0)  # calculate diversity\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Selective velocity perturbation\n                if np.random.rand() < 0.3:  \n                    self.velocity[i] += np.random.normal(scale=diversity, size=self.dim)\n                    \n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with dynamic diversity preservation and selective velocity perturbation for improved exploration and exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.8290662111520396, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.829 with standard deviation 0.030. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "6716b339-106a-4fe6-917a-aed9650b9b06", "metadata": {"aucs": [0.8713312839511063, 0.8151108170128426, 0.8007565324921702], "final_y": [0.12344463180529952, 0.1354333483522807, 0.12938469280181308]}, "mutation_prompt": null}
{"id": "1fcb6cf4-ed41-4689-b5e8-873cb8fb3b4f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic cognitive coefficient\n            social_coeff = 1.5\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i] and np.random.rand() < 0.7:  # Probabilistic personal best update\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.5:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with probabilistic personal best update to enhance diversity.", "configspace": "", "generation": 5, "fitness": 0.8328981763870745, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.028. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6716b339-106a-4fe6-917a-aed9650b9b06", "metadata": {"aucs": [0.849078429087722, 0.7934267865631215, 0.85618931351038], "final_y": [0.13600713363037942, 0.12718234803480633, 0.13232321514722523]}, "mutation_prompt": null}
{"id": "67208eea-2da4-4fd9-b130-d05d5b5e4998", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic cognitive coefficient\n            social_coeff = 1.5 - 0.5 * adaptive_factor  # Time-varying social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.5:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (E-ASGD) with dynamic cognitive coefficient, selective global best update, and time-varying social coefficient for improved exploration and convergence.", "configspace": "", "generation": 5, "fitness": 0.8250399370691538, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.825 with standard deviation 0.054. And the mean value of best solutions found was 0.144 (0. is the best) with standard deviation 0.021.", "error": "", "parent_id": "6716b339-106a-4fe6-917a-aed9650b9b06", "metadata": {"aucs": [0.8769253251716627, 0.749911409849745, 0.8482830761860537], "final_y": [0.12608645123384954, 0.17356918506299823, 0.13212165206757942]}, "mutation_prompt": null}
{"id": "598c8a72-732f-485c-963c-8bde195aa7d1", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.4 * adaptive_factor  # Enhanced inertia adaptation\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic cognitive coefficient\n            social_coeff = 1.5\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Probabilistic selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.7:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Optimized Adaptive Swarm Gradient Descent (OASGD) with enhanced inertia adaptation and probabilistic selective global best update for improved performance.", "configspace": "", "generation": 5, "fitness": 0.858139542162886, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.858 with standard deviation 0.058. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "6716b339-106a-4fe6-917a-aed9650b9b06", "metadata": {"aucs": [0.9073741454426999, 0.7773330534077814, 0.8897114276381766], "final_y": [0.11724269083905947, 0.13901091214933115, 0.12108542708176595]}, "mutation_prompt": null}
{"id": "de8b0677-afb4-42f6-b9c3-33df9b4bdbd4", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.random.uniform(-1, 1, (self.population_size, dim))  # Stochastic initial velocity\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        # Memory for local optima escape\n        memory = np.full((self.population_size, self.dim), np.inf)\n        escape_threshold = 50\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = np.random.rand()  # Stochastic adaptive factor\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.5:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Memory-augmented local optima escape\n                if evaluations % escape_threshold == 0:\n                    if np.all(memory[i] == swarm[i]):\n                        swarm[i] = np.random.uniform(lb, ub, self.dim)  # Perturb to escape\n                    memory[i] = swarm[i]\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined Enhanced Adaptive Swarm Gradient Descent (RE-ASGD) with stochastic adaptive velocity and memory-augmented local optima escape strategy.", "configspace": "", "generation": 5, "fitness": 0.8205344979982737, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.821 with standard deviation 0.034. And the mean value of best solutions found was 0.141 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "6716b339-106a-4fe6-917a-aed9650b9b06", "metadata": {"aucs": [0.7719696556119588, 0.8477165410873123, 0.8419172972955502], "final_y": [0.16545222944235194, 0.12371673482531398, 0.13432452796862948]}, "mutation_prompt": null}
{"id": "c18f58c9-c56d-4d5e-8fd0-fdbbf05f85e8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor) * (0.5 + 0.5 * np.random.rand())  # Probabilistic cognitive coefficient\n            social_coeff = 1.5\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.5:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with probabilistic cognitive factor adjustment for diversified local search.", "configspace": "", "generation": 5, "fitness": 0.8284710894980801, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.828 with standard deviation 0.066. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "6716b339-106a-4fe6-917a-aed9650b9b06", "metadata": {"aucs": [0.8515353366185725, 0.7383521080945419, 0.8955258237811261], "final_y": [0.1349809561169718, 0.17817835450732655, 0.11568531908531887]}, "mutation_prompt": null}
{"id": "d5a10b3d-52ca-49e9-b9c2-205c07e73821", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = np.sin(np.pi * evaluations / self.budget)  # Nonlinear adaptive factor\n            inertia_weight = 0.6 - 0.4 * adaptive_factor  # Adjusted dynamic inertia reversal\n            cognitive_coeff = 1.5 * (0.7 + 0.3 * adaptive_factor)  # Nonlinear cognitive coefficient\n            social_coeff = 1.7  # Adjusted social coefficient\n\n            adaptive_lr = 0.2 + 0.8 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.3:  # Adjusted selection probability\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Elite reinitiation strategy\n                if evaluations % (self.budget // 10) == 0:\n                    worst_idx = np.argmax(personal_best_value)\n                    personal_best[worst_idx] = np.random.uniform(lb, ub, self.dim)\n                    personal_best_value[worst_idx] = func(personal_best[worst_idx])\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent with Nonlinear Adaptive Coefficients and Elite Reinitiation for Enhanced Convergence.", "configspace": "", "generation": 6, "fitness": 0.8926120402804149, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.015. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6716b339-106a-4fe6-917a-aed9650b9b06", "metadata": {"aucs": [0.8810200982150973, 0.8833377652952665, 0.9134782573308806], "final_y": [0.12453224754362335, 0.12632846597712788, 0.11603886834015864]}, "mutation_prompt": null}
{"id": "6f0a58f8-99ca-431d-9c4b-98db6882b148", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic cognitive coefficient\n            social_coeff = 1.5\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Adaptive selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (E-ASGD) with adaptive selective global best update probability for improved exploration and exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.9189222958540154, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.004. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "6716b339-106a-4fe6-917a-aed9650b9b06", "metadata": {"aucs": [0.9200377001740768, 0.9235138084635017, 0.9132153789244679], "final_y": [0.11623173406258902, 0.11519826866914029, 0.11554526574250856]}, "mutation_prompt": null}
{"id": "74d90241-0673-413e-ba2d-d16d2935c015", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.4 * adaptive_factor  # Adjusted dynamic inertia\n            cognitive_coeff = 1.2 + 0.3 * adaptive_factor  # Slightly adjusted cognitive coefficient\n            social_coeff = 1.8\n            \n            # Introduce neighborhood influence\n            neighborhood_coeff = 0.5 + 0.3 * adaptive_factor\n\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2, r3 = np.random.random(self.dim), np.random.random(self.dim), np.random.random(self.dim)\n                best_neighbor = personal_best[np.random.choice(self.population_size)]\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    neighborhood_coeff * r3 * (best_neighbor - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                \n                # Adaptive mutation\n                if np.random.rand() < 0.1:\n                    mutation_strength = (ub - lb) * 0.02 * adaptive_factor\n                    swarm[i] += np.random.normal(0, mutation_strength, self.dim)\n                    \n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Enhanced Adaptive Swarm Gradient Descent (IE-ASGD) with dynamic neighborhood influence and adaptive mutation for enhanced convergence.", "configspace": "", "generation": 6, "fitness": 0.9024921131986213, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.008. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "6716b339-106a-4fe6-917a-aed9650b9b06", "metadata": {"aucs": [0.8916095474917335, 0.90524930807843, 0.9106174840257006], "final_y": [0.11917295378345238, 0.12146549167133791, 0.11953497193201323]}, "mutation_prompt": null}
{"id": "5dd31a35-cb79-416a-b7e7-89a3a91b4977", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic cognitive coefficient\n            social_coeff = 1.5 * adaptive_factor  # Adaptive social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.5:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined Enhanced Adaptive Swarm Gradient Descent (R-EASGD) with an adaptive social coefficient based on progress towards the optimum for improved convergence.", "configspace": "", "generation": 6, "fitness": 0.8949496203971555, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.018. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "6716b339-106a-4fe6-917a-aed9650b9b06", "metadata": {"aucs": [0.8694344137442964, 0.905871392984015, 0.9095430544631554], "final_y": [0.1282184437720043, 0.11957534033575057, 0.11821778880973999]}, "mutation_prompt": null}
{"id": "4e8b0892-eba5-4505-bda9-29d05979e672", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.constriction_factor = 0.729  # Added constriction factor\n    \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.0 + adaptive_factor  # Adaptive social coefficient\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (self.constriction_factor *  # Added constriction factor\n                                    (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i])))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Dynamic personal best reset\n                if np.random.rand() < 0.1:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Enhanced Adaptive Swarm Gradient Descent (IE-ASGD) with stochastic constriction coefficient, adaptive social coefficient, and dynamic personal best reset for enhanced exploration and convergence.", "configspace": "", "generation": 6, "fitness": 0.9060010404054862, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.906 with standard deviation 0.017. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "6716b339-106a-4fe6-917a-aed9650b9b06", "metadata": {"aucs": [0.889727507936993, 0.8982614634249734, 0.9300141498544923], "final_y": [0.12333149706276492, 0.12190439368417505, 0.11294069842502175]}, "mutation_prompt": null}
{"id": "c44aee74-835b-4b0f-97d6-9674bd126ca0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic cognitive coefficient\n            social_coeff = 1.5\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Adaptive selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                # Local search enhancement\n                if evaluations < self.budget and np.random.rand() < 0.1: \n                    local_search_candidate = swarm[i] + np.random.uniform(-0.1, 0.1, self.dim)\n                    local_search_candidate = np.clip(local_search_candidate, lb, ub)\n                    local_f_value = func(local_search_candidate)\n                    evaluations += 1\n                    if local_f_value < f_value:\n                        personal_best[i] = local_search_candidate\n                        personal_best_value[i] = local_f_value\n                        if local_f_value < global_best_value:\n                            global_best = local_search_candidate\n                            global_best_value = local_f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with an additional local search mechanism for improved convergence precision.", "configspace": "", "generation": 7, "fitness": 0.8907776779696155, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.891 with standard deviation 0.025. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "6f0a58f8-99ca-431d-9c4b-98db6882b148", "metadata": {"aucs": [0.8616730525167895, 0.888430264739889, 0.9222297166521682], "final_y": [0.13183857436697877, 0.12632679553709003, 0.11470390894545424]}, "mutation_prompt": null}
{"id": "b73ceda7-4bd3-45ff-8264-7ff3175f9ea0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Modified dynamic inertia weight\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic cognitive coefficient\n            social_coeff = 1.5\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Adaptive selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (E-ASGD) with a modified adaptive inertia weight formula for improved convergence speed.", "configspace": "", "generation": 7, "fitness": 0.9017743381339894, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.034. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "6f0a58f8-99ca-431d-9c4b-98db6882b148", "metadata": {"aucs": [0.8537413307836457, 0.9243699539115178, 0.9272117297068048], "final_y": [0.13135557306603796, 0.11283323277715174, 0.11325071555560418]}, "mutation_prompt": null}
{"id": "9bdf32ae-52e0-4079-8c12-4d0fccfa6a13", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic cognitive coefficient\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Adaptive selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved E-ASGD by introducing a dynamic social coefficient to further enhance the exploration-exploitation balance.", "configspace": "", "generation": 7, "fitness": 0.8896792535020265, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.030. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "6f0a58f8-99ca-431d-9c4b-98db6882b148", "metadata": {"aucs": [0.9097471244950955, 0.8470614471498025, 0.9122291888611814], "final_y": [0.11845647412370064, 0.1341926105573633, 0.11389772492294359]}, "mutation_prompt": null}
{"id": "7ebddb98-d832-4ede-a00b-6a62b3c199d5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic cognitive coefficient\n            social_coeff = 1.5\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i] + np.random.normal(0, adaptive_factor, self.dim)\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Adaptive selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (E-ASGD) with dynamic selective global best update probability and improved exploration using stochastic perturbation.", "configspace": "", "generation": 7, "fitness": 0.9003057229472181, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.026. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "6f0a58f8-99ca-431d-9c4b-98db6882b148", "metadata": {"aucs": [0.8732882167386811, 0.8926248123713338, 0.9350041397316394], "final_y": [0.12847912227819458, 0.12120459721493548, 0.11187899439992277]}, "mutation_prompt": null}
{"id": "faf6099a-9b51-4788-939f-d9a9bf93f9c0", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # Dynamically adjust population size based on evaluations\n            self.population_size = max(5, int((1 - evaluations / self.budget) * (10 + 2 * int(np.sqrt(self.dim)))))\n\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic cognitive coefficient\n            social_coeff = 1.5\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Adaptive selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced E-ASGD with dynamic population size adjustment based on budget utilization to improve exploration.", "configspace": "", "generation": 7, "fitness": 0.8753501510906236, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.875 with standard deviation 0.038. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "6f0a58f8-99ca-431d-9c4b-98db6882b148", "metadata": {"aucs": [0.8317683109181926, 0.8701073834359978, 0.9241747589176807], "final_y": [0.14295286597812096, 0.1283737712670564, 0.11303062463536151]}, "mutation_prompt": null}
{"id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a dynamic social coefficient and early stopping based on stagnation detection.", "configspace": "", "generation": 8, "fitness": 0.930383086866274, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.930 with standard deviation 0.002. And the mean value of best solutions found was 0.113 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "6f0a58f8-99ca-431d-9c4b-98db6882b148", "metadata": {"aucs": [0.932986098323813, 0.9284066208362167, 0.9297565414387923], "final_y": [0.11130305381341199, 0.11383619211341667, 0.11328620233291364]}, "mutation_prompt": null}
{"id": "4f2b0e64-b577-40ab-a914-de5161d6e50b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20 + 2 * int(np.sqrt(dim))  # Increased base population size\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic cognitive coefficient\n            social_coeff = 1.5\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Adaptive selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (E-ASGD) with adaptive selective global best update probability and increased population size for improved convergence rates.", "configspace": "", "generation": 8, "fitness": 0.9077174618457633, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.002. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "6f0a58f8-99ca-431d-9c4b-98db6882b148", "metadata": {"aucs": [0.9092094112974156, 0.9055373693849229, 0.9084056048549511], "final_y": [0.11705243966275469, 0.1171423245190556, 0.11862524807319519]}, "mutation_prompt": null}
{"id": "0c0d44e8-28cf-4971-b447-be3408932fe8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.4 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.7 * (0.5 + 0.5 * adaptive_factor)  # Dynamic cognitive coefficient\n            social_coeff = 1.7\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Adaptive selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined Enhanced Adaptive Swarm Gradient Descent (R-EASGD) with enhanced velocity update dynamics and adaptive inertia weight balancing for improved convergence.", "configspace": "", "generation": 8, "fitness": 0.9008974828047559, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.901 with standard deviation 0.019. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "6f0a58f8-99ca-431d-9c4b-98db6882b148", "metadata": {"aucs": [0.8787960610134454, 0.8977798315395557, 0.9261165558612668], "final_y": [0.12413510185645371, 0.1209962322263961, 0.11293572906475846]}, "mutation_prompt": null}
{"id": "a742b010-a45c-4ed0-b920-65a161eed67f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor  # Dynamic inertia reversal\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic cognitive coefficient\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Adaptive social coefficient\n\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Adaptive selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce adaptive social coefficient dynamic adjustment based on function evaluations to balance exploration and exploitation.", "configspace": "", "generation": 8, "fitness": 0.9068916531974439, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.020. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "6f0a58f8-99ca-431d-9c4b-98db6882b148", "metadata": {"aucs": [0.8785370580211693, 0.9203633912265388, 0.9217745103446233], "final_y": [0.12755176547808267, 0.11278410446167986, 0.11164478899895003]}, "mutation_prompt": null}
{"id": "b5ce5c4d-9452-443f-a840-91aefbf1b823", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n            velocity_scaling = 0.5 + 0.5 * adaptive_factor  # Dynamic velocity scaling\n            \n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = velocity_scaling * (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Adaptive selective global best update\n                if f_value < global_best_value and np.random.rand() < 0.6 + 0.4 * adaptive_factor:  # Increased exploration probability\n                    global_best = swarm[i]\n                    global_best_value = f_value\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent (E-ASGD) with dynamic velocity scaling and adaptive exploration probability for improved convergence rate.", "configspace": "", "generation": 8, "fitness": 0.8955583678778319, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.896 with standard deviation 0.030. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "6f0a58f8-99ca-431d-9c4b-98db6882b148", "metadata": {"aucs": [0.8534079837281269, 0.9242095075062765, 0.9090576123990921], "final_y": [0.1353390784801588, 0.1130674391893145, 0.11538282603620875]}, "mutation_prompt": null}
{"id": "cbc83173-531d-42f1-8031-88b8ed1d5094", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 * (1 - (adaptive_factor ** 2))  # Non-linear decrease in inertia\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced adaptive inertia weight decreasing non-linearly to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 9, "fitness": 0.8953147024259996, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.895 with standard deviation 0.007. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8859668790363049, 0.9008489333545365, 0.8991282948871574], "final_y": [0.12620694764833806, 0.1217684591652417, 0.11948164899610925]}, "mutation_prompt": null}
{"id": "e3bac12f-29f5-45a3-9dbd-da5387542d39", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                # Modified line (with exponential decay factor)\n                if f_value < global_best_value and np.random.rand() < np.exp(-0.01 * evaluations):\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a probabilistic element to update the global best position based on exponential decay function to balance exploration and exploitation.", "configspace": "", "generation": 9, "fitness": 0.8888671432557436, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.018. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8902362300151639, 0.909989239935611, 0.8663759598164555], "final_y": [0.1227387620079653, 0.11891322335536758, 0.13017534713485912]}, "mutation_prompt": null}
{"id": "e5cec7e5-05b2-4c70-b6f3-321b009e79c3", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.neighborhood_size = max(2, self.population_size // 5)  # Neighborhood influence\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                # Neighborhood influence\n                neighborhood_best = np.min(personal_best_value[max(0, i - self.neighborhood_size):min(self.population_size, i + self.neighborhood_size)])\n                if neighborhood_best < personal_best_value[i]:\n                    self.velocity[i] += 0.1 * r2 * (neighborhood_best - swarm[i])\n\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Multi-faceted Adaptive Swarm Optimization with dynamic learning rates and neighborhood influence to enhance global exploration and convergence.", "configspace": "", "generation": 9, "fitness": 0.9089697488397902, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.909 with standard deviation 0.004. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.9141974478698859, 0.9045038658820077, 0.908207932767477], "final_y": [0.11771935281895862, 0.12083388699610398, 0.11979602629411401]}, "mutation_prompt": null}
{"id": "8e40096e-3a67-4922-b6b5-396e6e72ef29", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Local neighborhood search around personal best\n                local_search = personal_best[i] + 0.05 * np.random.randn(self.dim) * adaptive_factor\n                local_search = np.clip(local_search, lb, ub)\n                f_value = func(local_search)\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = local_search  # Store local search result\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhancing exploitation by introducing local neighborhood search around the personal best solutions.", "configspace": "", "generation": 9, "fitness": 0.8157217303533674, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.816 with standard deviation 0.099. And the mean value of best solutions found was 0.154 (0. is the best) with standard deviation 0.040.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.6757799961819868, 0.8931584190225035, 0.8782267758556117], "final_y": [0.21057026200359574, 0.12494897384421288, 0.12777059225548437]}, "mutation_prompt": null}
{"id": "cf3b6b22-0f53-481e-8a6b-77e3d24c966e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                stochastic_component = np.random.randn(self.dim) * 0.01  # Added stochastic component\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    stochastic_component)\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a stochastic component for velocity update to improve exploration.", "configspace": "", "generation": 9, "fitness": 0.8859867577238485, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.886 with standard deviation 0.012. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8782664305513059, 0.9023465333089163, 0.8773473093113231], "final_y": [0.12585354072369737, 0.12157682504956302, 0.1291989249730534]}, "mutation_prompt": null}
{"id": "6f2e43cb-984a-409a-8bc5-cf89a6c6728e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    if stagnation_counter > 100:\n                        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))  # Random restart\n                        personal_best = swarm.copy()\n                        personal_best_value = np.array([func(x) for x in swarm])\n                        global_best = personal_best[np.argmin(personal_best_value)]\n                        global_best_value = np.min(personal_best_value)\n                        evaluations += self.population_size\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce a random restart mechanism to escape local optima and maintain exploration.", "configspace": "", "generation": 10, "fitness": 0.9035919365093553, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.904 with standard deviation 0.015. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8823509297582408, 0.9153903370615832, 0.9130345427082419], "final_y": [0.12433365762802506, 0.1165816993991734, 0.11553596488495155]}, "mutation_prompt": null}
{"id": "c08e2f43-f740-446c-b315-cf160fc40f89", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget)**2  # Non-linear decay\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Modified inertia range\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.7 * (0.5 + 0.5 * adaptive_factor)  # Increased social influence\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Enhanced Adaptive Swarm Gradient Descent with non-linear inertia weight decay and modified social coefficient for increased exploration.", "configspace": "", "generation": 10, "fitness": 0.902968416272321, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.031. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8666418972595625, 0.8998450252100909, 0.9424183263473094], "final_y": [0.13028274179012544, 0.12059179429047984, 0.11005072660596282]}, "mutation_prompt": null}
{"id": "3804a6ea-941b-4283-851d-89fd8c0614e2", "solution": "import numpy as np\n\nclass HybridSwarmEvolutionDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                if np.random.rand() < self.mutation_rate:\n                    mutation = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] += mutation\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "HybridSwarmEvolutionDescent", "description": "A novel Hybrid Swarm Evolution Descent combining adaptive swarm exploration with genetic mutation to enhance solution diversity and convergence.", "configspace": "", "generation": 10, "fitness": 0.8990735264204511, "feedback": "The algorithm HybridSwarmEvolutionDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.012. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8823557924904173, 0.9037989441593445, 0.9110658426115914], "final_y": [0.12608090701698926, 0.11933510063986441, 0.1142919361708079]}, "mutation_prompt": null}
{"id": "cc2f3dd2-0564-46ac-9507-beba906d344f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * np.random.random()  # Stochastic inertia weight\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:  # More frequent global best update\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Enhanced Adaptive Swarm Gradient Descent with stochastic inertia weight and a more frequent global best update.", "configspace": "", "generation": 10, "fitness": 0.9020902939102277, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.027. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8679606197047158, 0.9052181961396331, 0.9330920658863344], "final_y": [0.13057316502897864, 0.11990356140065617, 0.11178276261140407]}, "mutation_prompt": null}
{"id": "dcf0f299-061b-4730-9378-9614daa37c83", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor * np.random.uniform(0.5, 1.5)  # Dynamic adjustment\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with stochastic layer search and dynamic learning rate adjustment.", "configspace": "", "generation": 10, "fitness": 0.8610381404682995, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.031. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8201934165360372, 0.8685400496876727, 0.8943809551811888], "final_y": [0.14558568686070805, 0.1320294424612105, 0.12334176979788847]}, "mutation_prompt": null}
{"id": "232cfa57-75af-49e3-b7e2-eca68ddd9ce2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if stagnation_counter > 50:  # Decreased threshold for quicker mutation\n                    mutation_idx = np.random.randint(0, self.dim)\n                    mutation_amount = 0.1 * (ub - lb) * np.random.randn()\n                    swarm[i][mutation_idx] += mutation_amount\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n                    stagnation_counter = 0\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Hybrid Swarm-Based Optimization with Enhanced Stagnation Detection and Mutation for Exploration.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('setting an array element with a sequence.').", "error": "ValueError('setting an array element with a sequence.')", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {}, "mutation_prompt": null}
{"id": "e977af72-43f5-4f1c-afef-16562aaf0bee", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            # Updated inertia weight using chaotic sequence\n            inertia_weight = 0.7 - 0.3 * np.sin(np.pi * adaptive_factor)\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with increased velocity update diversity through chaotic sequence-based inertia weight.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('setting an array element with a sequence.').", "error": "ValueError('setting an array element with a sequence.')", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {}, "mutation_prompt": null}
{"id": "bac5495a-a22c-4d4e-b63a-88e703241a67", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = np.random.uniform(0.4, 0.7)  # Random inertia weight initialization\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a dynamic social coefficient, early stopping based on stagnation detection, and refined velocity update using random inertia weight initialization.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('setting an array element with a sequence.').", "error": "ValueError('setting an array element with a sequence.')", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {}, "mutation_prompt": null}
{"id": "869762c7-1c83-448d-bf93-5eb547b6fd55", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor) + np.random.uniform(-0.1, 0.1)  # Randomly perturbed social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a randomly perturbed social coefficient for better exploration.", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('setting an array element with a sequence.').", "error": "ValueError('setting an array element with a sequence.')", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {}, "mutation_prompt": null}
{"id": "dec86bfd-dcba-4522-9da5-8d65849299db", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < (0.5 + 0.5 * adaptive_factor) * (stagnation_counter < 50):\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a modified global best update condition to increase exploration when stagnation is detected.", "configspace": "", "generation": 11, "fitness": 0.9106557810328885, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.911 with standard deviation 0.008. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.9069087657690477, 0.9032059508338925, 0.9218526264957255], "final_y": [0.11846815893505869, 0.1169395813859232, 0.11286791075435554]}, "mutation_prompt": null}
{"id": "2440198e-ee73-4739-8b72-d9e803056c7d", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Refined Enhanced Adaptive Swarm Gradient Descent with dynamic inertia weight adjustment based on convergence speed.", "configspace": "", "generation": 12, "fitness": 0.8652001246138105, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.865 with standard deviation 0.023. And the mean value of best solutions found was 0.127 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8981812521038248, 0.8514272510266273, 0.845991870710979], "final_y": [0.12090630022764515, 0.13008108601982316, 0.13132282841656717]}, "mutation_prompt": null}
{"id": "2a70344a-1818-456d-bc44-20eafdbc52b6", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.phases = np.array([0.6, 0.3, 0.1])  # Exploration, Exploitation, Refinement\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            phase_ratio = evaluations / self.budget\n            if phase_ratio < self.phases[0]:\n                inertia_weight = 0.9\n            elif phase_ratio < self.phases[0] + self.phases[1]:\n                inertia_weight = 0.5\n            else:\n                inertia_weight = 0.3\n\n            cognitive_coeff = 1.5\n            social_coeff = 1.5 * (0.3 + 0.7 * (1 - phase_ratio))\n\n            adaptive_lr = 0.1 + 0.9 * (1 - phase_ratio)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * (1 - phase_ratio):\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduce tri-phased exploration-exploitation with momentum adaptation to improve convergence and robustness.", "configspace": "", "generation": 12, "fitness": 0.8626501403175443, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.034. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8160490305291465, 0.8751014942099864, 0.8967998962135002], "final_y": [0.14189181374280035, 0.125803652801054, 0.11561635505729873]}, "mutation_prompt": null}
{"id": "cc269aa6-2e21-42cc-a2b9-71058bf8c3d9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                perturbation = np.random.normal(0, 0.1, self.dim) * (0.5 - 0.5 * adaptive_factor)  # New line 1\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i] + perturbation  # New line 2\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent with perturbation-based exploration enhancement for diverse solution space search.", "configspace": "", "generation": 12, "fitness": 0.8666500262318043, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.867 with standard deviation 0.017. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8544250801275951, 0.8554722154831172, 0.8900527830847008], "final_y": [0.13429157962242777, 0.1387208087459717, 0.1212981511486817]}, "mutation_prompt": null}
{"id": "f9ee3a19-e35d-4396-b160-15f9437a24e8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.3 * adaptive_factor  # Reduced inertia weight\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with reduced inertia weight for improved convergence speed.", "configspace": "", "generation": 12, "fitness": 0.86143346333883, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.019. And the mean value of best solutions found was 0.131 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.884772660838794, 0.8380595108483724, 0.8614682183293234], "final_y": [0.1261002962028226, 0.1319434442533184, 0.13460781044206804]}, "mutation_prompt": null}
{"id": "423ef904-4f41-45ad-8127-b6464d7fdd58", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.7 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.55 + 0.45 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Optimized Adaptive Swarm Gradient Descent with improved velocity update and diversity maintenance to enhance exploration capabilities.", "configspace": "", "generation": 12, "fitness": 0.8494567460360113, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.849 with standard deviation 0.020. And the mean value of best solutions found was 0.134 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8525012265499672, 0.8723115653894513, 0.8235574461686157], "final_y": [0.13421042503356317, 0.12077556376425136, 0.14707127654626428]}, "mutation_prompt": null}
{"id": "aff02f1c-6172-4b66-b056-5181cd75043a", "solution": "import numpy as np\n\nclass HybridAdaptiveSwarmQuantumLeap:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.quantum_probability = 0.1  # Added quantum probability for random jumps\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 - 0.3 * adaptive_factor  # Adjusted inertia\n            cognitive_coeff = 1.5 * (0.3 + 0.7 * adaptive_factor)  # Adjusted cognitive\n            social_coeff = 1.7 * (0.5 + 0.5 * adaptive_factor)  # Adjusted social coefficient\n            adaptive_lr = 0.1 + 0.8 * adaptive_factor  # Adjusted learning rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                \n                if np.random.rand() < self.quantum_probability:  # Quantum leap condition\n                    swarm[i] = lb + np.random.rand(self.dim) * (ub - lb)\n                else:\n                    swarm[i] += adaptive_lr * self.velocity[i]\n                \n                swarm[i] = np.clip(swarm[i], lb, ub)\n                f_value = func(swarm[i])\n                evaluations += 1\n\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.3 * adaptive_factor:  # Adjusted probability\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "HybridAdaptiveSwarmQuantumLeap", "description": "Hybrid Adaptive Swarm with Dynamic Quantum Leap integrates quantum-inspired perturbation for enhanced exploration and adaptive convergence.", "configspace": "", "generation": 13, "fitness": 0.8683005504499043, "feedback": "The algorithm HybridAdaptiveSwarmQuantumLeap got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.868 with standard deviation 0.022. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8372971866887531, 0.8866102428639765, 0.8809942217969834], "final_y": [0.14268500714443433, 0.11896617545121746, 0.12717500857621167]}, "mutation_prompt": null}
{"id": "70345208-fe6d-4a06-8055-d44d0376bb9b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.elite_fraction = 0.2  # Proportion of the elite individuals\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted inertia\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n            elite_count = int(self.elite_fraction * self.population_size)\n            elite_indices = np.argsort(personal_best_value)[:elite_count]\n            elite_swarm = personal_best[elite_indices]\n            global_best = elite_swarm[np.argmin([func(x) for x in elite_swarm])]\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with dynamic inertia and an elite learning mechanism to improve solution quality and convergence rate.", "configspace": "", "generation": 13, "fitness": 0.8987392492751439, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.010. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.884782632533337, 0.9067487245205418, 0.9046863907715529], "final_y": [0.1244768072495741, 0.12023214544992245, 0.12020416463509631]}, "mutation_prompt": null}
{"id": "25709019-689d-4d8b-ab5d-2604d2d5a402", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.3 + 0.7 * adaptive_factor:  # Adjusted acceptance probability\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with probabilistic global best acceptance and increased perturbation for exploration.", "configspace": "", "generation": 13, "fitness": 0.8661984430216828, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.866 with standard deviation 0.016. And the mean value of best solutions found was 0.126 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8452578905462073, 0.8832738356374472, 0.8700636028813942], "final_y": [0.12333369521400583, 0.12652519614814772, 0.1286276068799782]}, "mutation_prompt": null}
{"id": "1126e984-ec44-4f03-b876-510d27bec8de", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Introduce an adaptive mutation for diversity control\n                if np.random.rand() < 0.1 * (1 - adaptive_factor):  \n                    mutation = np.random.normal(0, 0.1, self.dim) \n                    swarm[i] += mutation\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introducing adaptive mutation for diversity control to enhance global exploration and prevent premature convergence.", "configspace": "", "generation": 13, "fitness": 0.9031607448774485, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.903 with standard deviation 0.021. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8740898577580425, 0.912067818911236, 0.9233245579630668], "final_y": [0.12901356401941055, 0.11639887260618398, 0.11351324381373085]}, "mutation_prompt": null}
{"id": "68c05968-293c-475c-8e9e-d359f72ece60", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        \n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n        \n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - (evaluations / self.budget) ** 1.5  # Nonlinear decay\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best * adaptive_factor - swarm[i]))  # Dynamic influence\n                \n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduction of a dynamic particle influence mechanism and a nonlinear decay schedule for inertia and learning rates to enhance convergence rate and solution accuracy.", "configspace": "", "generation": 13, "fitness": 0.8984796975114957, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.010. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.9054355857289267, 0.9050149141874892, 0.8849885926180712], "final_y": [0.12000131250851376, 0.11715782185794565, 0.12562660945535853]}, "mutation_prompt": null}
{"id": "b61e5d72-1b0b-4aa5-b8d2-830a2b0b7fd2", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.4 * adaptive_factor  # Adjusted dynamic inertia weight\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i] or np.random.rand() < 0.2 * adaptive_factor:  # Modified personal best update criteria\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with dynamic inertia weight adjustment and improved personal best update criteria.", "configspace": "", "generation": 14, "fitness": 0.89692932233062, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.024. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8640520551127201, 0.9058436549797975, 0.9208922568993421], "final_y": [0.12245802981798437, 0.11685634343149942, 0.11220041112948842]}, "mutation_prompt": null}
{"id": "1f8078dd-a306-4461-9c45-c1f824f23c89", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] *= 0.9  # Momentum enhancement\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 80:  # Adjusted stagnation reset\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Adaptive Swarm Gradient Descent with Momentum-enhanced Velocity Update and Adjusted Stagnation Reset.", "configspace": "", "generation": 14, "fitness": 0.899471170917132, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.014. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8798793985007901, 0.9055331409314791, 0.913000973319127], "final_y": [0.12289452413689439, 0.11848051482717703, 0.11487973043347688]}, "mutation_prompt": null}
{"id": "5870a2fe-cce5-4772-a1b9-cd6b5c09e240", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n            momentum = 0.9  # Added momentum term\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (momentum * self.velocity[i] +  # Incorporating momentum\n                                    inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced a momentum component to the swarm's velocity to enhance the exploration and exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.8611086969545448, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.081. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.7461418094558055, 0.9146308597004217, 0.9225534217074072], "final_y": [0.17799673692863072, 0.11491426332099253, 0.11239449965370596]}, "mutation_prompt": null}
{"id": "1e33fd5e-c132-4711-9d47-6305b864b09f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n\n            # Changed line: Introduced a nonlinear adaptive learning rate\n            adaptive_lr = 0.1 + 0.9 * np.sin(np.pi / 2 * adaptive_factor)\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced a nonlinear adaptive learning rate based on a sinusoidal function to enhance exploration-exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.8897918004448865, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.008. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8934585240638603, 0.8967530969472446, 0.8791637803235546], "final_y": [0.12091105986603201, 0.12190096225839053, 0.12450583850062924]}, "mutation_prompt": null}
{"id": "e130cb67-5e69-446d-9a0a-1c3298e4fc9e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Changed line 1\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.3 * adaptive_factor:  # Changed line 2\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with dynamic inertia adjustment and improved stagnation detection for refined exploration and exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.8990986648370581, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.899 with standard deviation 0.014. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.9086881039431455, 0.9092266365144819, 0.8793812540535471], "final_y": [0.11753834384569883, 0.11834075591409177, 0.1271821463560857]}, "mutation_prompt": null}
{"id": "d20976dc-fb5b-495c-9106-f5faacaea746", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n            \n            velocity_clipping = 0.1 + 0.4 * adaptive_factor  # Dynamic velocity clipping\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                self.velocity[i] = np.clip(self.velocity[i], -velocity_clipping, velocity_clipping)  # Apply clipping\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                # Diversity preservation mechanism\n                if stagnation_counter > 50:\n                    swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                    stagnation_counter = 0\n\n                if evaluations >= self.budget:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a novel diversity preservation mechanism and dynamic velocity clipping.", "configspace": "", "generation": 15, "fitness": 0.7288337906555292, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.729 with standard deviation 0.035. And the mean value of best solutions found was 0.185 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.6832152201615397, 0.7692355764660446, 0.7340505753390033], "final_y": [0.20363402778168005, 0.16989837544903252, 0.1818362035141038]}, "mutation_prompt": null}
{"id": "25fbedf3-2510-4945-bfec-d4e2aaa205c9", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 + 0.3 * adaptive_factor  # Modified inertia_weight\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a dynamic social coefficient and early stopping based on stagnation detection using an adaptive inertia weight adjustment.  ", "configspace": "", "generation": 15, "fitness": 0.8045553624781464, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.805 with standard deviation 0.058. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.886018547397225, 0.76890311738062, 0.758744422656594], "final_y": [0.12051892070328984, 0.1702433386818767, 0.13953346376747078]}, "mutation_prompt": null}
{"id": "b60bd47a-e9b2-4e13-a405-138d98d0817c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.05 + 0.95 * adaptive_factor  # Adjusted adaptive learning rate\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a dynamic social coefficient and early stopping based on stagnation detection, refined by adjusting the adaptive learning rate to improve convergence speed and precision.", "configspace": "", "generation": 15, "fitness": 0.8269129057135073, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.055. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.020.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.9032969279419802, 0.7758231489951135, 0.8016186402034278], "final_y": [0.12080763012831652, 0.16697505600542628, 0.15558451321344913]}, "mutation_prompt": null}
{"id": "a81d6bfa-677d-4fad-bee9-0d75d9b7502b", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random_sample(self.dim), np.random.random_sample(self.dim)  # Improved random sampling\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a dynamic social coefficient and early stopping based on stagnation detection, now with improved random number generation for diversity.", "configspace": "", "generation": 15, "fitness": 0.8107241030215571, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.811 with standard deviation 0.047. And the mean value of best solutions found was 0.152 (0. is the best) with standard deviation 0.017.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8271122605905589, 0.8589084509508538, 0.7461515975232587], "final_y": [0.14378033819713865, 0.1361184518410815, 0.17636748354182707]}, "mutation_prompt": null}
{"id": "255d2974-4cee-480c-91d6-47843eb9384c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Apply adaptive mutation to enhance exploration\n                if np.random.rand() < 0.1 + 0.4 * adaptive_factor:\n                    swarm[i] += np.random.normal(0, 0.1 * adaptive_factor, self.dim)\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with adaptive mutation for increased exploration and precision in convergence.", "configspace": "", "generation": 15, "fitness": 0.8116331549823005, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.812 with standard deviation 0.040. And the mean value of best solutions found was 0.150 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8666555072999576, 0.7755439808050915, 0.7926999768418526], "final_y": [0.13356998549351706, 0.15840392401851244, 0.15749618718524483]}, "mutation_prompt": null}
{"id": "b0d7e98e-1aef-4b9e-9fd8-ec5e96f60e66", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # More dynamic inertia weight\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Local search perturbation\n                if np.random.rand() < 0.05:\n                    perturbation = np.random.normal(0, 0.1, self.dim)\n                    swarm[i] = np.clip(swarm[i] + perturbation, lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a dynamic inertia weight and local search perturbation for improved exploration-exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.88465748868279, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.885 with standard deviation 0.031. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.011.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.9246701311198533, 0.8813736726225213, 0.8479286623059956], "final_y": [0.11228986687258069, 0.12578483211461777, 0.13831715448245563]}, "mutation_prompt": null}
{"id": "d11cadd3-73a9-434c-b4da-00ebe7243ec8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Improved inertia strategy\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            if stagnation_counter > 50:  # Dynamic swarm adjustment\n                self.population_size = max(5, self.population_size - 1)\n                stagnation_counter = 0\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with dynamic swarm adjustment and improved inertia strategy for faster convergence.", "configspace": "", "generation": 16, "fitness": 0.9116852408766386, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.912 with standard deviation 0.004. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.906974408892986, 0.9161991332565785, 0.9118821804803515], "final_y": [0.11744595747697184, 0.116243189420279, 0.11675734458689468]}, "mutation_prompt": null}
{"id": "720a905f-bafb-4fec-abab-4f3b4dc5cabc", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Improved inertia weight adaptation\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a dynamic social coefficient, early stopping based on stagnation detection, and improved inertia weight adaptation.", "configspace": "", "generation": 16, "fitness": 0.9065555401737941, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.009. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8950407834385213, 0.9084322053739584, 0.9161936317089027], "final_y": [0.12121467096247929, 0.11669115644243555, 0.11498604427745474]}, "mutation_prompt": null}
{"id": "33616da9-9a0e-489a-ae78-79d8afaf8cb8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                \n                # Stochastic perturbation for exploration\n                if np.random.rand() < 0.05:\n                    swarm[i] += np.random.normal(0, 0.1, self.dim)\n                \n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Extended Adaptive Swarm Gradient Descent with stochastic perturbations for diversity maintenance and local search efficiency.", "configspace": "", "generation": 16, "fitness": 0.9068254636548633, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.907 with standard deviation 0.018. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8945779013179813, 0.8942312970202084, 0.9316671926264], "final_y": [0.12164851843661806, 0.12012975508884083, 0.11116617761566916]}, "mutation_prompt": null}
{"id": "a3e5a75c-31d7-42c4-8a5c-e1ccea5ff80e", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.elite_size = max(1, self.population_size // 5)\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.8 * (0.5 + 0.5 * adaptive_factor)  # Increased dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.7 * adaptive_factor  # Reduced adaptive learning rate variation\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 50:  # Reduced stagnation threshold\n                    elite_indices = np.argsort(personal_best_value)[:self.elite_size]\n                    elite_swarm = personal_best[elite_indices]\n                    swarm[:self.elite_size] = elite_swarm  # Elite migration\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Hybrid Adaptive Swarm Gradient Descent with Elite Migration and Dynamic Stagnation Avoidance.", "configspace": "", "generation": 16, "fitness": 0.901577435217474, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.902 with standard deviation 0.022. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.007.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8972760513545461, 0.8765565962569154, 0.9308996580409604], "final_y": [0.12138233102764628, 0.12951857536407174, 0.11230737469705909]}, "mutation_prompt": null}
{"id": "72c664d0-07e0-41e3-8dc8-259649e057b5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * np.sin(5 * np.pi * adaptive_factor)  # Chaotic inertia weight\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with chaotic inertia weight for improved exploration.", "configspace": "", "generation": 17, "fitness": 0.8774916316589968, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.877 with standard deviation 0.038. And the mean value of best solutions found was 0.129 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.900038052909339, 0.9088655640645771, 0.8235712780030743], "final_y": [0.12069259723634007, 0.12024194562921875, 0.14716351540019534]}, "mutation_prompt": null}
{"id": "4f0a8c16-3ca4-4499-856a-1e5869f24d55", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                perturbation = np.random.uniform(-0.1, 0.1, self.dim)  # Introduced perturbation\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) + perturbation)\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced a velocity perturbation element to enhance exploration and reduce premature convergence.", "configspace": "", "generation": 17, "fitness": 0.8965391265637669, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.897 with standard deviation 0.042. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.013.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8375928173815291, 0.9220594432207251, 0.9299651190890464], "final_y": [0.13952279195280914, 0.11204323007188766, 0.11234228746513164]}, "mutation_prompt": null}
{"id": "3e7cf5e7-e7b5-415c-9077-7de4633012ca", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                \n                # Adaptive mutation for enhanced exploration\n                if np.random.rand() < 0.1 * adaptive_factor:\n                    swarm[i] += np.random.normal(0, 0.1, self.dim)  # Add a mutation step\n\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with an adaptive social coefficient and adaptive mutation for improved global exploration.", "configspace": "", "generation": 17, "fitness": 0.9082202641812045, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.009. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8976604002842962, 0.9076119339318068, 0.9193884583275106], "final_y": [0.11983867868750686, 0.12010786790266348, 0.11422594166353162]}, "mutation_prompt": null}
{"id": "c93cbba5-a75a-4d54-978c-b895ebc0481a", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.4 * adaptive_factor  # Adjusted inertia weight decay\n            cognitive_coeff = 2.0 * (0.5 + 0.5 * adaptive_factor)  # Adaptive cognitive coefficient\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a dynamic inertia weight decay and adaptive cognitive coefficient for improved convergence.", "configspace": "", "generation": 17, "fitness": 0.9188228093125823, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.919 with standard deviation 0.018. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.9103619520334812, 0.9017952203685873, 0.9443112555356784], "final_y": [0.11709970304519624, 0.12116428774665267, 0.11039616603858193]}, "mutation_prompt": null}
{"id": "9e6f20a2-c3c4-4414-b39b-82699b193b55", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.6 + 0.4 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a dynamic social coefficient, early stopping based on stagnation detection, and more frequent global best updates.", "configspace": "", "generation": 17, "fitness": 0.8919811915426021, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.029. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8548409180663168, 0.8952800744780104, 0.9258225820834793], "final_y": [0.13382928361007373, 0.12370172602618623, 0.11379454059248562]}, "mutation_prompt": null}
{"id": "3306de7e-993d-4109-baaf-6352d30427fb", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                \n                # Additional random exploration\n                swarm[i] += np.random.uniform(-adaptive_factor, adaptive_factor, self.dim)\n                \n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with additional random exploration factor for diversity maintenance.", "configspace": "", "generation": 18, "fitness": 0.8311047507485666, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.831 with standard deviation 0.037. And the mean value of best solutions found was 0.143 (0. is the best) with standard deviation 0.014.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8381794764524474, 0.872276715735931, 0.7828580600573213], "final_y": [0.13880670343210866, 0.12905285851542392, 0.16173893453804533]}, "mutation_prompt": null}
{"id": "311e9618-476c-4771-9079-ff7c190803ce", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Adjusted inertia weight range\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with dynamic inertia weight tuning and diversified initialization.", "configspace": "", "generation": 18, "fitness": 0.857007563684682, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.857 with standard deviation 0.039. And the mean value of best solutions found was 0.133 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8984360469897554, 0.805063421041293, 0.8675232230229976], "final_y": [0.11870327874881392, 0.1542815519377957, 0.12663275463604973]}, "mutation_prompt": null}
{"id": "2d1c0275-df82-44e8-aa24-a564ffd3af16", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = np.random.uniform(0.6, 0.9)  # Dynamic inertia adjustment\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                if np.random.rand() < 0.5:  # Probabilistic exploration\n                    r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                    self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                        cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                        social_coeff * r2 * (global_best - swarm[i]))\n                    swarm[i] += adaptive_lr * self.velocity[i]\n                    swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with dynamic inertia adjustment and probabilistic exploration for improved convergence.", "configspace": "", "generation": 18, "fitness": 0.8602053594566583, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.860 with standard deviation 0.030. And the mean value of best solutions found was 0.130 (0. is the best) with standard deviation 0.010.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.818335510601452, 0.8819668732520972, 0.8803136945164258], "final_y": [0.14349682437224975, 0.12015565136879358, 0.12575904975462093]}, "mutation_prompt": null}
{"id": "a2cab229-78e1-4a18-a37b-ed7aea997598", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            swarm_diversity = np.std(swarm, axis=0).mean() / (ub - lb).mean()  # New line for global diversity\n            inertia_weight = 0.7 - 0.3 * adaptive_factor * (1 - swarm_diversity)  # Modified inertia weight\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a dynamic inertia weight update incorporating global diversity and early stopping based on stagnation detection.", "configspace": "", "generation": 18, "fitness": 0.8218835739800476, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.023. And the mean value of best solutions found was 0.147 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8417838382537106, 0.8339527043348333, 0.789914179351599], "final_y": [0.14015627015925414, 0.14478475650181366, 0.15554991514496486]}, "mutation_prompt": null}
{"id": "358b3a25-a6bb-405d-8802-183bc2330df8", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.5 - 0.3 * adaptive_factor  # Change made here\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Fine-tuning the balance between exploration and exploitation by adjusting inertia weight.", "configspace": "", "generation": 18, "fitness": 0.8690225810848311, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.869 with standard deviation 0.019. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8880071241407335, 0.8751858655570844, 0.8438747535566751], "final_y": [0.12572158901070696, 0.12494607588317719, 0.13334080135818793]}, "mutation_prompt": null}
{"id": "64df6439-ae30-460c-abfa-97b7b184c56f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations % 50 == 0:  # Introduce periodic perturbation\n                    global_best += np.random.uniform(-0.1, 0.1, self.dim) * adaptive_factor\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Introduced a periodic random perturbation to the global best position to enhance exploration and avoid local optima.", "configspace": "", "generation": 19, "fitness": 0.878066422118248, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.878 with standard deviation 0.029. And the mean value of best solutions found was 0.128 (0. is the best) with standard deviation 0.009.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8445208119180372, 0.9143835826852473, 0.8752948717514597], "final_y": [0.13859524418776992, 0.1160762102030718, 0.12888699117776325]}, "mutation_prompt": null}
{"id": "b74ac8d9-9c78-4619-b02b-773ae637d04f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * (1 - adaptive_factor):  # Modified line\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a modified social coefficient that increases the probability of updating the global best based on iteration progress.", "configspace": "", "generation": 19, "fitness": 0.8895233119160562, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.890 with standard deviation 0.013. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8810604356941788, 0.9078431118616285, 0.8796663881923612], "final_y": [0.1259114137670586, 0.1179321788305916, 0.12727543097096983]}, "mutation_prompt": null}
{"id": "07e0064a-d58f-4091-943d-316abf763a5f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.momentum = np.zeros((self.population_size, dim))  # Added momentum component\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]) +\n                                    0.1 * self.momentum[i])  # Integrated momentum for smoother updates\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n                self.momentum[i] = self.velocity[i]  # Update momentum\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    if stagnation_counter > 100:  # Dynamic restart mechanism\n                        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                        stagnation_counter = 0\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with momentum-based velocity update and dynamic restart mechanism to improve exploration and convergence.", "configspace": "", "generation": 19, "fitness": 0.8644130746582057, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.864 with standard deviation 0.016. And the mean value of best solutions found was 0.132 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8468398036913822, 0.8851727543004146, 0.8612266659828203], "final_y": [0.1357360947933327, 0.12630134784576452, 0.13505926007360203]}, "mutation_prompt": null}
{"id": "2ed3cc47-b260-439c-8e1d-ea303b801bf5", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor * (1 - stagnation_counter / 100)  # Adjusted inertia weight\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent with inertia weight adaptation based on global best improvement rate.", "configspace": "", "generation": 19, "fitness": 0.8997908438561364, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.900 with standard deviation 0.007. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.908472435234436, 0.8918660819915061, 0.8990340143424669], "final_y": [0.11640308383092302, 0.11850305116990645, 0.11688679358154719]}, "mutation_prompt": null}
{"id": "ce205a2e-f8c5-47cd-9803-603e2ee2a32c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n        max_stagnation = 50  # Changed from 100 to 50\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > max_stagnation:\n                    if stagnation_counter > max_stagnation:  # Add a restart mechanism\n                        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                        stagnation_counter = 0\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Improved Adaptive Swarm Gradient Descent with enhanced local search via random perturbation and additional restart mechanism.", "configspace": "", "generation": 19, "fitness": 0.9075575536595174, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.908 with standard deviation 0.018. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8887503379850035, 0.9016900288079006, 0.9322322941856479], "final_y": [0.12356352859089526, 0.1200759952427014, 0.11130814754852103]}, "mutation_prompt": null}
{"id": "1f445e5a-0f89-404f-8b04-9162dc0f8094", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    if stagnation_counter > 100:  # New line: Improved random restart mechanism upon stagnation\n                        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n                        stagnation_counter = 0\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a dynamic social coefficient, early stopping, and improved random restart mechanism upon stagnation.", "configspace": "", "generation": 20, "fitness": 0.8893887633090017, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.889 with standard deviation 0.038. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.012.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8357418471159618, 0.9166044171533867, 0.915820025657657], "final_y": [0.14279133610771744, 0.11680421323250867, 0.11641442960512716]}, "mutation_prompt": null}
{"id": "39e624cf-f727-48b0-953e-2cc080158638", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.4 * adaptive_factor  # Changed from 0.7 to 0.9 for better exploration\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)  # Dynamic social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a further refined dynamic inertia weight for improved convergence.", "configspace": "", "generation": 20, "fitness": 0.8980021472763168, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.898 with standard deviation 0.021. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8686809440763925, 0.9062237570199969, 0.9191017407325606], "final_y": [0.13048596119136435, 0.12081054189253049, 0.11661056987753815]}, "mutation_prompt": null}
{"id": "3125e6d0-4039-4277-8642-3f6c7e844018", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n        self.mutation_rate = 0.05  # Added mutation rate\n        self.mutation_scale = 0.1  # Added mutation scale\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.6 - 0.4 * adaptive_factor  # Modified inertia weight range\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.6 * (0.5 + 0.5 * adaptive_factor)  # Adjusted social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                # Apply mutation\n                if np.random.rand() < self.mutation_rate:\n                    swarm[i] += self.mutation_scale * np.random.normal(size=self.dim)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Hybrid Particle Swarm Optimization with Adaptive Mutation for Improved Exploration and Exploitation Balance.", "configspace": "", "generation": 20, "fitness": 0.9261312594511502, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.926 with standard deviation 0.007. And the mean value of best solutions found was 0.114 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.9156452850793022, 0.9324543749163868, 0.9302941183577612], "final_y": [0.11746747742038555, 0.11226283719202779, 0.11195242032886554]}, "mutation_prompt": null}
{"id": "db50fc85-6667-4155-bf30-e0d81b6c456c", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        # Constraint on function evaluations\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.9 - 0.5 * adaptive_factor  # Improved inertia weight\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * np.random.random()  # Stochastic element in social coefficient\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                swarm[i] += adaptive_lr * self.velocity[i]\n                swarm[i] = np.clip(swarm[i], lb, ub)\n\n                f_value = func(swarm[i])\n                evaluations += 1\n                if f_value < personal_best_value[i]:\n                    personal_best[i] = swarm[i]\n                    personal_best_value[i] = f_value\n\n                if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                    global_best = swarm[i]\n                    global_best_value = f_value\n                    stagnation_counter = 0  # Reset stagnation counter\n                else:\n                    stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "Enhanced Adaptive Swarm Gradient Descent with a stochastic element in social coefficient and improved inertia weight formula.", "configspace": "", "generation": 20, "fitness": 0.8917236383310797, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.892 with standard deviation 0.028. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8569495524163359, 0.8938805795404668, 0.9243407830364361], "final_y": [0.13415235936703973, 0.1226506506514361, 0.11393429622549278]}, "mutation_prompt": null}
{"id": "4b68898c-c265-4a30-b93d-5c2eb600d11f", "solution": "import numpy as np\n\nclass AdaptiveSwarmGradientDescent:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.velocity = np.zeros((self.population_size, dim))\n\n    def __call__(self, func):\n        lb, ub = func.bounds.lb, func.bounds.ub\n        swarm = np.random.uniform(lb, ub, (self.population_size, self.dim))\n        personal_best = swarm.copy()\n        personal_best_value = np.array([func(x) for x in swarm])\n        global_best = personal_best[np.argmin(personal_best_value)]\n        global_best_value = np.min(personal_best_value)\n\n        evaluations = self.population_size\n        stagnation_counter = 0\n\n        while evaluations < self.budget:\n            adaptive_factor = 1 - evaluations / self.budget\n            inertia_weight = 0.7 - 0.3 * adaptive_factor\n            cognitive_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            social_coeff = 1.5 * (0.5 + 0.5 * adaptive_factor)\n            \n            adaptive_lr = 0.1 + 0.9 * adaptive_factor\n            new_swarm = np.zeros_like(swarm)  # Initialize new swarm\n\n            for i in range(self.population_size):\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                self.velocity[i] = (inertia_weight * self.velocity[i] +\n                                    cognitive_coeff * r1 * (personal_best[i] - swarm[i]) +\n                                    social_coeff * r2 * (global_best - swarm[i]))\n                new_swarm[i] = swarm[i] + adaptive_lr * self.velocity[i]\n                new_swarm[i] = np.clip(new_swarm[i], lb, ub)\n\n                if np.random.rand() < 0.8:\n                    f_value = func(new_swarm[i])\n                    evaluations += 1\n                    if f_value < personal_best_value[i]:\n                        personal_best[i] = new_swarm[i]\n                        personal_best_value[i] = f_value\n\n                    if f_value < global_best_value and np.random.rand() < 0.5 + 0.5 * adaptive_factor:\n                        global_best = new_swarm[i]\n                        global_best_value = f_value\n                        stagnation_counter = 0\n                    else:\n                        stagnation_counter += 1\n\n                if evaluations >= self.budget or stagnation_counter > 100:\n                    break\n            \n            swarm = new_swarm  # Update swarm after evaluation\n\n        return global_best, global_best_value", "name": "AdaptiveSwarmGradientDescent", "description": "A refined Adaptive Swarm Gradient Descent with stochastic selection for population updates and multi-swarm communication to enhance exploration and exploitation balance.", "configspace": "", "generation": 20, "fitness": 0.8931701063872975, "feedback": "The algorithm AdaptiveSwarmGradientDescent got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.893 with standard deviation 0.025. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "3dae7a41-9915-41f1-8a15-c92dd3ffbe3d", "metadata": {"aucs": [0.8671509459683948, 0.8862033274876031, 0.9261560457058945], "final_y": [0.13107425423291796, 0.1267744360935601, 0.1134150600866829]}, "mutation_prompt": null}
