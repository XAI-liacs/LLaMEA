{"id": "4dcf5886-0d51-44bc-803d-d021328ce066", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic combining Differential Evolution (DE) for global exploration and a local search optimizer, with adaptive layer growth and robustness-driven cost adjustments for optimizing multilayered structures.", "configspace": "", "generation": 0, "fitness": -Infinity, "feedback": "An exception occured: Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 52, in __call__\n  File \"<string>\", line 29, in _local_search\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 738, in minimize\n    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 386, in _minimize_lbfgsb\n    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 291, in _prepare_scalar_function\n    sf = ScalarFunction(fun, x0, args, grad, hess,\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 223, in __init__\n    self._update_fun()\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 295, in _update_fun\n    fx = self._wrapped_fun(self.x)\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 21, in wrapped\n    fx = fun(np.copy(x), *args)\n  File \"<string>\", line 27, in wrapped_func\nNameError: name 'func' is not defined\n.", "error": "NameError(\"name 'func' is not defined\")Traceback (most recent call last):\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 192, in initialize_single\n    new_individual = self.evaluate_fitness(new_individual)\n  File \"/home/ian/LLaMEA/./llamea/llamea.py\", line 281, in evaluate_fitness\n    updated_individual = self.f(individual, self.logger)\n  File \"/home/ian/LLaMEA/benchmarks/tuto_global_optimization_photonics/exp_photonic.py\", line 143, in evaluatePhotonic\n    algorithm(problem)\n  File \"<string>\", line 52, in __call__\n  File \"<string>\", line 29, in _local_search\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_minimize.py\", line 738, in minimize\n    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 386, in _minimize_lbfgsb\n    sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_optimize.py\", line 291, in _prepare_scalar_function\n    sf = ScalarFunction(fun, x0, args, grad, hess,\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 223, in __init__\n    self._update_fun()\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 295, in _update_fun\n    fx = self._wrapped_fun(self.x)\n  File \"/home/ian/anaconda3/envs/llm/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 21, in wrapped\n    fx = fun(np.copy(x), *args)\n  File \"<string>\", line 27, in wrapped_func\nNameError: name 'func' is not defined\n", "parent_id": null, "metadata": {}, "mutation_prompt": null}
{"id": "2cbd654d-4bf8-472d-b6bb-5eec78fce88b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop, bounds):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        mutant = np.clip(a + self.f * (b - c), bounds[:, 0], bounds[:, 1])\n        return mutant\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop, bounds)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhance the HybridMetaheuristic by properly scoping the `func` variable in the local search function and improving mutation bounds handling.", "configspace": "", "generation": 1, "fitness": 0.847967903016408, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.848 with standard deviation 0.051. And the mean value of best solutions found was 0.122 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "4dcf5886-0d51-44bc-803d-d021328ce066", "metadata": {"aucs": [0.7764203599947412, 0.8858884904073446, 0.8815948586471379], "final_y": [0.13165843032376423, 0.12198100740057771, 0.11148579853123786]}, "mutation_prompt": null}
{"id": "91d61162-b4b8-43ef-a787-7ea22fb6791d", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func as parameter to fix NameError\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Updated to pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic with DE for global exploration and local search, corrected for proper function reference and improved memory handling.", "configspace": "", "generation": 1, "fitness": 0.8539102851168586, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.025. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "4dcf5886-0d51-44bc-803d-d021328ce066", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8262283049574385], "final_y": [0.11874804534293504, 0.12198100740057771, 0.11874675418757141]}, "mutation_prompt": null}
{"id": "ae986847-dc6b-497b-b4a7-b7d613e115a7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic using Differential Evolution (DE) for global exploration and integrating a local search optimizer with fixed dimension local search and robustness-driven cost adjustments for optimizing multilayered structures.", "configspace": "", "generation": 1, "fitness": 0.8626610732702257, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.016. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "4dcf5886-0d51-44bc-803d-d021328ce066", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8524806694175395], "final_y": [0.11874804534293504, 0.12198100740057771, 0.11874046818009976]}, "mutation_prompt": null}
{"id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic using DE for global exploration and local search refinement, fixing bug in function reference.", "configspace": "", "generation": 1, "fitness": 0.863214343435212, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "4dcf5886-0d51-44bc-803d-d021328ce066", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8541404799124982], "final_y": [0.11874804534293504, 0.12198100740057771, 0.1114884579974087]}, "mutation_prompt": null}
{"id": "282f442d-2d15-4779-9e77-60b0f63a3ba0", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func as a parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Use func parameter\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved function reference in local search to prevent NameError, ensuring optimized performance of a hybrid metaheuristic for multilayered photonic structures.", "configspace": "", "generation": 1, "fitness": 0.8169742504588607, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.817 with standard deviation 0.052. And the mean value of best solutions found was 0.123 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "4dcf5886-0d51-44bc-803d-d021328ce066", "metadata": {"aucs": [0.8054325663467226, 0.8858884904073446, 0.7596016946225149], "final_y": [0.12428051531774664, 0.12198100740057771, 0.12214275989147505]}, "mutation_prompt": null}
{"id": "8660969d-60e2-42a7-b14f-f56104372846", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1) * np.std(pop)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved DE strategy by adjusting the scale factor dynamically based on population diversity for enhanced exploration.", "configspace": "", "generation": 2, "fitness": 0.8381467340482193, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.838 with standard deviation 0.040. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.8799876646202376, 0.7843068621978617, 0.8501456753265585], "final_y": [0.12607186217935074, 0.11875336010085202, 0.1170826433129104]}, "mutation_prompt": null}
{"id": "a624c306-556e-4928-9758-efbea99c5fc2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Increased population size\n        self.f = 0.9  # Adjusted DE scale factor\n        self.cr = 0.95  # Adjusted DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 3, self.dim)  # Increment layer growth\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced hybrid algorithm integrating Differential Evolution with dynamic layer adjustments and robustness checks.", "configspace": "", "generation": 2, "fitness": 0.8224376580064815, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.822 with standard deviation 0.042. And the mean value of best solutions found was 0.118 (0. is the best) with standard deviation 0.001.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.8652116144099673, 0.7648715385654372, 0.83722982104404], "final_y": [0.118739310799161, 0.11874057244286862, 0.11765045752757741]}, "mutation_prompt": null}
{"id": "efb1b812-7c4d-4a76-ae5c-9ea56e826742", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n        self.layer_roles = np.random.randint(0, 2, size=self.dim)  # Added modular role detection\n        self.robustness_weight = 0.05  # Added robustness metric weight\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n\n    def _robustness_penalty(self, x):  # Added robustness penalty calculation\n        perturbation = np.random.uniform(-0.01, 0.01, size=x.shape)  \n        return self.robustness_weight * np.linalg.norm(perturbation)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  \n        \n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial) + self._robustness_penalty(trial)  # Included robustness\n                f_target = func(target) + self._robustness_penalty(target)  # Included robustness\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual) + self._robustness_penalty(individual)  # Included robustness\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic using DE for global exploration and local search refinement, with modular structure detection and robustness metrics.", "configspace": "", "generation": 2, "fitness": 0.8086202172603133, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.061. And the mean value of best solutions found was 0.140 (0. is the best) with standard deviation 0.026.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.8518776912535455, 0.7227051067067112, 0.8512778538206833], "final_y": [0.12477075748621902, 0.17709519919659122, 0.11874285735259216]}, "mutation_prompt": null}
{"id": "2ac4c16a-d7c3-4cdd-a6d0-966d51632c18", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adaptive_f = self.f * (1 - (len(self.history) / self.budget))  # Adapt mutation scale\n        return np.clip(a + adaptive_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE crossover with adaptive mutation scale for improved convergence in hybrid metaheuristic.", "configspace": "", "generation": 2, "fitness": 0.8140953653331927, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.814 with standard deviation 0.037. And the mean value of best solutions found was 0.135 (0. is the best) with standard deviation 0.024.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.849614059985793, 0.8293987590285454, 0.7632732769852398], "final_y": [0.11874804534293504, 0.11874910257627325, 0.16884397986018473]}, "mutation_prompt": null}
{"id": "78365459-1321-44e6-a05d-365c78980295", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim + 1)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "An enhanced hybrid algorithm that combines Differential Evolution and local search with adaptive population growth to efficiently explore high-dimensional spaces.", "configspace": "", "generation": 2, "fitness": 0.8304022107858305, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.021. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.849614059985793, 0.8015030710305189, 0.8400895013411802], "final_y": [0.11874804534293504, 0.12990623909007915, 0.12331070989832238]}, "mutation_prompt": null}
{"id": "d4ec02b9-46a4-49e4-8c8e-bbaac9ca4d17", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n            self.cr = 0.7 + 0.3 * (1 - evaluations / self.budget)  # Adaptive crossover probability\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic using DE for global exploration and local search refinement with adaptive crossover probability.", "configspace": "", "generation": 3, "fitness": 0.809002044121748, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.809 with standard deviation 0.067. And the mean value of best solutions found was 0.138 (0. is the best) with standard deviation 0.033.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.7301953483802466, 0.8029963170382293, 0.8938144669467684], "final_y": [0.18500990431892295, 0.11873941039392266, 0.11012082087147657]}, "mutation_prompt": null}
{"id": "1a23b96d-f9d5-4591-a1fb-b779c8f62d80", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved DE tournament selection to enhance exploration-exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8503806475002286, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.035. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.849614059985793, 0.8077134155681246, 0.8938144669467684], "final_y": [0.11874804534293504, 0.11906053971928432, 0.11012082087147657]}, "mutation_prompt": null}
{"id": "97cb9ab1-aeeb-4d7a-a9d3-0b35dd4576a2", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant, evaluations):  # Added evaluations\n        dynamic_cr = self.cr * (1 - evaluations / self.budget)  # Dynamic crossover probability\n        cross_points = np.random.rand(self.dim) < dynamic_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant, evaluations)  # Pass evaluations\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Refined DE crossover to improve diversity by using a dynamic crossover probability based on evaluations.", "configspace": "", "generation": 3, "fitness": 0.854003992277784, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.031. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.849614059985793, 0.8185834499007907, 0.8938144669467684], "final_y": [0.11874804534293504, 0.1187407172701751, 0.11012082087147657]}, "mutation_prompt": null}
{"id": "30e62ab4-1143-4d68-a166-79a00fa41af3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        d = pop[np.random.randint(self.population_size)]  # New: additional vector for mutation\n        return np.clip(a + self.f * (b - c) + self.f * (d - a), 0, 1)  # Modified mutation\n\n    def _de_crossover(self, target, mutant):\n        self.cr = 0.5 + (0.4 * np.random.rand())  # New: dynamic crossover probability\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhance DE mutation strategy and introduce dynamic crossover probability for better exploration and exploitation balance.", "configspace": "", "generation": 3, "fitness": 0.8333342348622307, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.833 with standard deviation 0.045. And the mean value of best solutions found was 0.116 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.8204692463083103, 0.7857189913316132, 0.8938144669467684], "final_y": [0.11874370858125605, 0.11969535191079239, 0.11012082087147657]}, "mutation_prompt": null}
{"id": "5d799fc9-a846-4bd8-9712-880e78d60b54", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 2, replace=False)\n        b, c = pop[idxs]\n        population_mean = np.mean(pop, axis=0)  # Added line\n        return np.clip(population_mean + self.f * (b - c), 0, 1)  # Modified line\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced mutation strategy by using the average of the whole population to guide differential evolution.", "configspace": "", "generation": 3, "fitness": 0.8359698971633662, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.836 with standard deviation 0.054. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.008.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.849614059985793, 0.7644811645575376, 0.8938144669467684], "final_y": [0.11874804534293504, 0.1303073213283087, 0.11012082087147657]}, "mutation_prompt": null}
{"id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with adaptive scaling for improved exploration and convergence.", "configspace": "", "generation": 4, "fitness": 0.8723658030134253, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8815948586471379], "final_y": [0.11874804534293504, 0.12198100740057771, 0.11148579853123786]}, "mutation_prompt": null}
{"id": "2e118b41-5445-4bf4-b7b1-2c0517416643", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                self.f = 0.5 + (0.9 - 0.5) * (evaluations / self.budget)  # Adaptive DE scale factor\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved HybridMetaheuristic with adaptive DE parameters for dynamic exploration-exploitation balance.", "configspace": "", "generation": 4, "fitness": 0.8539102851168586, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.025. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8262283049574385], "final_y": [0.11874804534293504, 0.12198100740057771, 0.11874675418757141]}, "mutation_prompt": null}
{"id": "8ed3ec32-5f1b-46fa-b79b-ff70b6054799", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n            self.population_size = min(50, int(self.population_size * 1.1))  # Dynamic adjustment\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic combining DE and local search with adaptive layer growth and dynamic population size for enhanced exploration and exploitation.", "configspace": "", "generation": 4, "fitness": 0.8317014150052175, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.832 with standard deviation 0.053. And the mean value of best solutions found was 0.121 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.7596016946225149], "final_y": [0.11874804534293504, 0.12198100740057771, 0.12214275989147505]}, "mutation_prompt": null}
{"id": "292e7db7-700c-41d5-9751-757b14b4f047", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):  # Added func parameter\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)  # Pass func\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                    self.f = min(1.0, self.f + 0.1)  # Adjust DE scale factor\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            # Evaluate the best solution in the current population\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            # Gradually increase the dimensionality\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved global exploration by adjusting DE scale factor dynamically based on performance.", "configspace": "", "generation": 4, "fitness": 0.8626610732702257, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.016. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8524806694175395], "final_y": [0.11874804534293504, 0.12198100740057771, 0.11874046818009976]}, "mutation_prompt": null}
{"id": "70cf28f0-a641-4b93-987f-0e50f5aca7e5", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25  # Changed population size\n        self.f = 0.9  # Adjusted DE scale factor\n        self.cr = 0.85  # Adjusted DE crossover probability\n        self.history = []\n        self.epsilon = 0.01  # Perturbation step size for robustness\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        return np.clip(a + self.f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        # Apply perturbation for robustness\n        for _ in range(5):\n            perturbed_x = result.x + np.random.uniform(-self.epsilon, self.epsilon, size=result.x.shape)\n            perturbed_x = np.clip(perturbed_x, bounds[:, 0], bounds[:, 1])\n            perturbed_value = func(perturbed_x)\n            if perturbed_value < func(result.x):\n                result.x = perturbed_x\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 3, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n        \n        return best_solution", "name": "HybridMetaheuristic", "description": "A refined hybrid metaheuristic combining DE, adaptive layer growth, and perturbation-based local search for robust photonic structure optimization.", "configspace": "", "generation": 4, "fitness": 0.8501418050775333, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.850 with standard deviation 0.031. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.005.", "error": "", "parent_id": "13a3dc0b-91aa-4df9-bd6a-8c2e7108614c", "metadata": {"aucs": [0.8103964449127572, 0.8858884904073446, 0.8541404799124982], "final_y": [0.12341039885374938, 0.12198100740057771, 0.1114884579974087]}, "mutation_prompt": null}
{"id": "6a76f7cf-bfdc-4483-b71d-b1de3bc04c86", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        init_guess = best_solution if best_solution is not None else x  # Changed line\n        result = minimize(wrapped_func, init_guess, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved local search initialization by using the best solution found so far for enhanced convergence.", "configspace": "", "generation": 5, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'best_solution' is not defined\").", "error": "NameError(\"name 'best_solution' is not defined\")", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {}, "mutation_prompt": null}
{"id": "4bcc8dc6-e6a1-491b-b3a9-bf391eb7c833", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                if evaluations % 50 == 0:  # Intensify local search periodically\n                    trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with adaptive scaling and periodic local search intensification for improved exploration and convergence.", "configspace": "", "generation": 5, "fitness": 0.7778807395301065, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.778 with standard deviation 0.054. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.7655085432502247, 0.7185196153543019], "final_y": [0.11874804534293504, 0.1702433386818767, 0.19103396660959382]}, "mutation_prompt": null}
{"id": "1afa9f9a-0094-49d0-b986-e27e439c388f", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        # Changed crossover rate to be adaptive\n        self.cr = 0.9 * (0.5 + 0.5 * np.random.rand())  \n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved DE mutation strategy with a dynamic crossover rate for enhanced diversification and convergence.", "configspace": "", "generation": 5, "fitness": 0.7886207229733165, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.789 with standard deviation 0.042. And the mean value of best solutions found was 0.156 (0. is the best) with standard deviation 0.018.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.8479175208624656, 0.7655605235629769, 0.7523841244945068], "final_y": [0.13049656078779093, 0.1702433386818767, 0.16606019353260815]}, "mutation_prompt": null}
{"id": "aeea1e76-1480-4fe3-b55b-62b6af691ad8", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8\n        self.cr = 0.9\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _robust_neighborhood_search(self, x, bounds, func):\n        noise_amplitude = 0.05 * (bounds[:, 1] - bounds[:, 0])\n        for _ in range(5):  # Conduct multiple local perturbations\n            perturb = np.random.uniform(-noise_amplitude, noise_amplitude)\n            candidate = np.clip(x + perturb, bounds[:, 0], bounds[:, 1])\n            candidate_value = func(candidate)\n            if candidate_value < func(x):\n                x = candidate\n        return x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._robust_neighborhood_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            if evaluations % (self.budget // 5) == 0:  # Dynamically adjust population size\n                self.population_size = max(10, int(self.population_size * 0.9))\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Integrate robust neighborhood search and dynamic population size adjustment for enhanced exploitation and exploration.", "configspace": "", "generation": 5, "fitness": 0.7476913047442609, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.748 with standard deviation 0.028. And the mean value of best solutions found was 0.169 (0. is the best) with standard deviation 0.015.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.7082694273152014, 0.7645532161774838, 0.7702512707400977], "final_y": [0.18724094295371618, 0.1702433386818767, 0.14985575073548707]}, "mutation_prompt": null}
{"id": "99ee943b-41f2-4a4a-8d4b-a539fd721466", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant, iteration):\n        adapt_cr = self.cr * (0.5 + 0.5 * np.cos(np.pi * iteration / self.budget))  # Dynamic crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def _adaptive_population_size(self, evaluations):\n        return max(10, int(self.population_size * (1 - (evaluations / self.budget))))  # Adaptive population\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n            self.population_size = self._adaptive_population_size(evaluations)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant, evaluations)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhances HybridMetaheuristic with adaptive population size and dynamic crossover probability for improved convergence.", "configspace": "", "generation": 5, "fitness": 0.7788112214606174, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.779 with standard deviation 0.053. And the mean value of best solutions found was 0.160 (0. is the best) with standard deviation 0.030.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.7653772545435434, 0.721442349852516], "final_y": [0.11874804534293504, 0.1702433386818767, 0.18951544282499466]}, "mutation_prompt": null}
{"id": "5816799c-9a3d-4959-995a-26f713055d59", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n            self.population_size = max(10, int(self.population_size * 0.95))  # Adaptive population size\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "An improved hybrid strategy with adaptive population size to enhance exploitation while maintaining exploration.", "configspace": "", "generation": 6, "fitness": 0.8723658030134253, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.872 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8815948586471379], "final_y": [0.11874804534293504, 0.12198100740057771, 0.11148579853123786]}, "mutation_prompt": null}
{"id": "c405f18b-61ac-470b-84da-eb20edc82152", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n            pop += np.random.normal(0, 0.01, pop.shape)  # Added line for diversity preservation\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation with adaptive scaling and diversity preservation for improved exploration and convergence.", "configspace": "", "generation": 6, "fitness": 0.8539102851168586, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.854 with standard deviation 0.025. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8262283049574385], "final_y": [0.11874804534293504, 0.12198100740057771, 0.11874675418757141]}, "mutation_prompt": null}
{"id": "8da4bd39-b41e-4845-9c9b-7fc480004e9e", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = self.cr * (1 - (len(self.history) / (2 * self.budget)))  # Dynamic crossover probability\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduce dynamic crossover probability in DE to enhance the exploration-exploitation balance.", "configspace": "", "generation": 6, "fitness": 0.863214343435212, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.016. And the mean value of best solutions found was 0.117 (0. is the best) with standard deviation 0.004.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8541404799124982], "final_y": [0.11874804534293504, 0.12198100740057771, 0.1114884579974087]}, "mutation_prompt": null}
{"id": "c175d09e-3e79-4690-8ce6-8b2bf7cd8242", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < (self.cr * (1 - len(self.history) / self.budget))  # Adaptive crossover\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B', options={'maxiter': 20})  # Limited iterations\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved hybrid algorithm with adaptive crossover probability and enhanced local search for better convergence.", "configspace": "", "generation": 6, "fitness": 0.8272841033726883, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.827 with standard deviation 0.052. And the mean value of best solutions found was 0.124 (0. is the best) with standard deviation 0.003.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.8363621250882054, 0.8858884904073446, 0.7596016946225149], "final_y": [0.12816976325694884, 0.12198100740057771, 0.12214275989147505]}, "mutation_prompt": null}
{"id": "515a90fa-c9ee-4848-bfec-fcf805b9f409", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.92  # DE crossover probability (adjusted from 0.9)\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with fine-tuned crossover probability for improved exploration and convergence.", "configspace": "", "generation": 6, "fitness": 0.8469394138541563, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.847 with standard deviation 0.034. And the mean value of best solutions found was 0.125 (0. is the best) with standard deviation 0.006.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.8024490817375847, 0.8858884904073446, 0.8524806694175395], "final_y": [0.1331152301709333, 0.12198100740057771, 0.11874046818009976]}, "mutation_prompt": null}
{"id": "02a37573-b649-418c-9b14-a7e3fd31f715", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B', options={'ftol': 1e-9})  # Improved precision\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with adaptive scaling and improved local search precision for better convergence.", "configspace": "", "generation": 7, "fitness": 0.860566093396088, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.861 with standard deviation 0.018. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8858884904073446, 0.8461957297951265], "final_y": [0.11874804534293504, 0.12198100740057771, 0.1187392685060592]}, "mutation_prompt": null}
{"id": "70d3bbd8-dec8-4489-b3cc-bf338b8dd3a7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristicV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in) + np.random.normal(0, 0.01)  # Adding noise tolerance\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 3, self.dim)  # Faster layer growth\n\n    def _select_best(self, pop, func):\n        best_index = np.argmin([func(ind) for ind in pop])\n        return pop[best_index]\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristicV2", "description": "HybridMetaheuristicV2 integrates adaptive layer growth with noise-tolerant evaluation to enhance solution robustness and convergence.", "configspace": "", "generation": 7, "fitness": 0.6876478821418153, "feedback": "The algorithm HybridMetaheuristicV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.688 with standard deviation 0.027. And the mean value of best solutions found was 0.192 (0. is the best) with standard deviation 0.019.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.6490725243287543, 0.7084287159384777, 0.7054424061582137], "final_y": [0.2156209653416159, 0.1702433386818767, 0.19103396660959382]}, "mutation_prompt": null}
{"id": "71c1e0aa-d9c8-4c43-9543-b5bf9d2aa010", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * np.exp(-len(self.history) / (self.budget * 0.5))  # Improved adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in) + np.random.normal(0, 0.01)  # Added noise handling\n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 1, self.dim)  # Slower layer growth\n\n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Improved adaptive scaling and layer growth strategy with noise-handling for enhanced convergence in high-dimensional, noisy optimization problems.", "configspace": "", "generation": 7, "fitness": 0.7989358239952397, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.799 with standard deviation 0.096. And the mean value of best solutions found was 0.148 (0. is the best) with standard deviation 0.037.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.6652752466506491, 0.8858884904073446, 0.845643734927725], "final_y": [0.2014367685750209, 0.12198100740057771, 0.12198436351802955]}, "mutation_prompt": null}
{"id": "f1dda743-f892-4f81-bf3d-28a313c229c7", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        adapt_cr = self.cr * (1 - (len(self.history) / self.budget))  # Adaptive crossover\n        cross_points = np.random.rand(self.dim) < adapt_cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Introduced adaptive crossover probability to enhance exploration and convergence further.", "configspace": "", "generation": 7, "fitness": 0.8295427125043847, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.830 with standard deviation 0.058. And the mean value of best solutions found was 0.120 (0. is the best) with standard deviation 0.002.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8877516019619975, 0.7512624755653635], "final_y": [0.11874804534293504, 0.11873934456403512, 0.12312761998472632]}, "mutation_prompt": null}
{"id": "cff72750-1cd8-43f1-b654-be58dd98888c", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.f = 0.8  # DE scale factor\n        self.cr = 0.9  # DE crossover probability\n        self.history = []\n\n    def _de_mutation(self, pop):\n        idxs = np.random.choice(range(self.population_size), 3, replace=False)\n        a, b, c = pop[idxs]\n        adapt_f = self.f * (1 - (len(self.history) / self.budget))  # Adaptive scaling\n        return np.clip(a + adapt_f * (b - c), 0, 1)\n\n    def _de_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.cr\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _local_search(self, x, bounds, func):\n        def wrapped_func(x_in):\n            self.history.append(x_in)\n            return func(x_in)\n        \n        result = minimize(wrapped_func, x, bounds=bounds, method='L-BFGS-B')\n        return result.x\n\n    def _adaptive_layer_growth(self, base_dim, current_dim):\n        return min(current_dim + 2, self.dim)\n    \n    def __call__(self, func):\n        bounds = np.array([func.bounds.lb, func.bounds.ub]).T\n        best_solution = None\n        best_value = float('inf')\n        current_dim = 10  # Start with 10 layers\n\n        pop = np.random.rand(self.population_size, current_dim)\n        pop = bounds[:, 0] + pop * (bounds[:, 1] - bounds[:, 0])\n\n        evaluations = 0\n        while evaluations < self.budget:\n            new_pop = np.zeros_like(pop)\n\n            for i in range(self.population_size):\n                target = pop[i]\n                mutant = self._de_mutation(pop)\n                trial = self._de_crossover(target, mutant)\n                trial = self._local_search(trial, bounds, func)\n\n                f_trial = func(trial)\n                f_target = func(target)\n\n                if f_trial < f_target:\n                    new_pop[i] = trial\n                else:\n                    new_pop[i] = target\n\n                evaluations += 1\n                if evaluations >= self.budget:\n                    break\n\n            self.population_size = max(10, int(self.population_size * 0.99))  # Dynamically adjust population size\n\n            pop = new_pop\n\n            for individual in pop:\n                value = func(individual)\n                if value < best_value:\n                    best_value = value\n                    best_solution = individual\n\n            current_dim = self._adaptive_layer_growth(current_dim, current_dim)\n            pop = np.hstack((pop, np.random.rand(self.population_size, current_dim - pop.shape[1])))\n\n        return best_solution", "name": "HybridMetaheuristic", "description": "Enhanced DE mutation strategy with adaptive scaling and dynamic population size for improved exploration and convergence.", "configspace": "", "generation": 7, "fitness": 0.863169027065345, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.863 with standard deviation 0.017. And the mean value of best solutions found was 0.119 (0. is the best) with standard deviation 0.000.", "error": "", "parent_id": "98ae4dc9-3991-4c38-a76e-440389173a1b", "metadata": {"aucs": [0.849614059985793, 0.8870954590442979, 0.8527975621659444], "final_y": [0.11874804534293504, 0.11874001514710464, 0.1187525200831584]}, "mutation_prompt": null}
